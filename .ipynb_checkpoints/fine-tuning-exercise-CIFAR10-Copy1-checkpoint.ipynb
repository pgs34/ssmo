{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e895f5c-2910-44d0-aac2-d9afb0f33b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47ffec2-8590-4af0-a35e-d3b98f8049e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def subsample_dataset(dataset, num_samples, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    indices = torch.randperm(len(dataset))[:num_samples]\n",
    "    return Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc58c71-5adc-4a94-9cda-9b44dd8a048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.4914, 0.4822, 0.4465),\n",
    "        std=(0.2023, 0.1994, 0.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.4914, 0.4822, 0.4465),\n",
    "        std=(0.2023, 0.1994, 0.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "full_train_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "# 5,000개만 사용\n",
    "train_dataset_small = subsample_dataset(\n",
    "    full_train_dataset,\n",
    "    num_samples=5000,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset_small,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4c2bf5-6903-4a64-b205-bfc3c1737ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666d733b-cffe-40be-8b16-962a2d056246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_CIFAR(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 24, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(24, 48, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(48 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "class MLP_CIFAR(nn.Module):\n",
    "    def __init__(self, patch=4, hidden=512, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.patch = patch\n",
    "        dim = 3 * patch * patch\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.cls = nn.Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        p = self.patch\n",
    "\n",
    "        x = x.unfold(2, p, p).unfold(3, p, p)\n",
    "        x = x.contiguous().view(B, -1, C*p*p)\n",
    "\n",
    "        h = self.net(x).mean(dim=1)\n",
    "        return self.cls(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14dc636e-bc79-4e50-93aa-c4938ee6c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def fine_tune(model, optimizer, criterion, train_loader, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        copy.deepcopy(model.state_dict()),\n",
    "        train_loss / len(train_loader)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44452b90-ee92-4cb1-85fc-e0460958cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6681f868-1f3f-4a68-91e5-e81eb59b7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kd_loss(student_logits, teacher_logits, T=2.0):\n",
    "    return kl_loss(\n",
    "        F.log_softmax(student_logits / T, dim=1),\n",
    "        F.softmax(teacher_logits / T, dim=1)\n",
    "    ) * (T * T)\n",
    "\n",
    "def studygroup(\n",
    "    model1,\n",
    "    model2,\n",
    "    optimizer1,\n",
    "    optimizer2,\n",
    "    train_loader,\n",
    "    device,\n",
    "    T=2.0\n",
    "):\n",
    "    model1.train()\n",
    "    model2.train()\n",
    "\n",
    "    train_loss1 = 0.0\n",
    "    train_loss2 = 0.0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        logits1 = model1(x)\n",
    "        logits2 = model2(x)\n",
    "\n",
    "        pred1 = logits1.argmax(dim=1)\n",
    "        pred2 = logits2.argmax(dim=1)\n",
    "\n",
    "        correct1 = pred1 == y\n",
    "        correct2 = pred2 == y\n",
    "\n",
    "        # index 정의\n",
    "        index1 = correct1 & ~correct2   # model1 \n",
    "        index2 = ~correct1 & correct2   # model2 \n",
    "        index3 = ~(index1 | index2)    \n",
    "\n",
    "        # ----------------------\n",
    "        # model1 update\n",
    "        # ----------------------\n",
    "        loss1 = 0.0\n",
    "        if index2.any():\n",
    "            loss1 += kd_loss(\n",
    "                logits1[index2],\n",
    "                logits2[index2].detach(),\n",
    "                T=T\n",
    "            )\n",
    "        if index3.any():\n",
    "            loss1 += ce_loss(\n",
    "                logits1[index3],\n",
    "                y[index3]\n",
    "            )\n",
    "\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "        # ----------------------\n",
    "        # model2 update\n",
    "        # ----------------------\n",
    "        loss2 = 0.0\n",
    "        if index1.any():\n",
    "            loss2 += kd_loss(\n",
    "                logits2[index1],\n",
    "                logits1[index1].detach(),\n",
    "                T=T\n",
    "            )\n",
    "        if index3.any():\n",
    "            loss2 += ce_loss(\n",
    "                logits2[index3],\n",
    "                y[index3]\n",
    "            )\n",
    "\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        train_loss1 += loss1.item()\n",
    "        train_loss2 += loss2.item()\n",
    "\n",
    "    return (\n",
    "        model1,\n",
    "        model2,\n",
    "        copy.deepcopy(model1.state_dict()),\n",
    "        copy.deepcopy(model2.state_dict()),\n",
    "        train_loss1 / len(train_loader),\n",
    "        train_loss2 / len(train_loader)\n",
    "    )\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f72ebd37-eeff-4cde-988e-931026a2e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_baseline(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    epochs,\n",
    "    log_dict\n",
    "):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model, _, train_loss = fine_tune(\n",
    "            model,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            train_loader,\n",
    "            device\n",
    "        )\n",
    "\n",
    "        test_acc = evaluate(model, test_loader, device)\n",
    "\n",
    "        log_dict[\"train_loss\"].append(train_loss)\n",
    "        log_dict[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        print(\n",
    "            f\"[Baseline][{epoch:02d}] \"\n",
    "            f\"Loss={train_loss:.4f}, Acc={test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "def train_studygroup(\n",
    "    model1,\n",
    "    model2,\n",
    "    optimizer1,\n",
    "    optimizer2,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    epochs,\n",
    "    log1,\n",
    "    log2,\n",
    "    T=2.0\n",
    "):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model1, model2, _, _, loss1, loss2 = studygroup(\n",
    "            model1,\n",
    "            model2,\n",
    "            optimizer1,\n",
    "            optimizer2,\n",
    "            train_loader,\n",
    "            device,\n",
    "            T=T\n",
    "        )\n",
    "\n",
    "        acc1 = evaluate(model1, test_loader, device)\n",
    "        acc2 = evaluate(model2, test_loader, device)\n",
    "\n",
    "        log1[\"train_loss\"].append(loss1)\n",
    "        log1[\"test_acc\"].append(acc1)\n",
    "\n",
    "        log2[\"train_loss\"].append(loss2)\n",
    "        log2[\"test_acc\"].append(acc2)\n",
    "\n",
    "        print(\n",
    "            f\"[Studygroup][{epoch:02d}] \"\n",
    "            f\"CNN Loss={loss1:.4f}, Acc={acc1:.4f} | \"\n",
    "            f\"MLP Loss={loss2:.4f}, Acc={acc2:.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee30a1b-c96a-471e-8651-25f4bc55dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 2000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn_master = CNN_CIFAR().to(device)\n",
    "mlp_master = MLP_CIFAR().to(device)\n",
    "\n",
    "cnn_init_state = copy.deepcopy(cnn_master.state_dict())\n",
    "mlp_init_state = copy.deepcopy(mlp_master.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e26ea7e1-84d6-4415-a59f-10f0d0d6e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_log():\n",
    "    return {\n",
    "        \"train_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "logs = {\n",
    "    \"baseline_cnn\": init_log(),\n",
    "    \"baseline_mlp\": init_log(),\n",
    "    \"studygroup_cnn\": init_log(),\n",
    "    \"studygroup_mlp\": init_log(),\n",
    "    \"individual_cnn1\": init_log(),\n",
    "    \"individual_cnn2\": init_log(),\n",
    "    \"individual_mlp1\": init_log(),\n",
    "    \"individual_mlp2\": init_log()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4613882-db40-40d5-b710-fd9e1858322f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13620ecb63ef41569fc3922a5c7110ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline][00] Loss=2.0509, Acc=0.3364\n",
      "[Baseline][01] Loss=1.7858, Acc=0.4069\n",
      "[Baseline][02] Loss=1.6972, Acc=0.4233\n",
      "[Baseline][03] Loss=1.6094, Acc=0.4482\n",
      "[Baseline][04] Loss=1.5124, Acc=0.4610\n",
      "[Baseline][05] Loss=1.4824, Acc=0.4926\n",
      "[Baseline][06] Loss=1.4504, Acc=0.5021\n",
      "[Baseline][07] Loss=1.4097, Acc=0.4955\n",
      "[Baseline][08] Loss=1.3811, Acc=0.5152\n",
      "[Baseline][09] Loss=1.3818, Acc=0.5359\n",
      "[Baseline][10] Loss=1.3316, Acc=0.5382\n",
      "[Baseline][11] Loss=1.3239, Acc=0.5224\n",
      "[Baseline][12] Loss=1.3078, Acc=0.5410\n",
      "[Baseline][13] Loss=1.2553, Acc=0.5208\n",
      "[Baseline][14] Loss=1.2656, Acc=0.5514\n",
      "[Baseline][15] Loss=1.2262, Acc=0.5649\n",
      "[Baseline][16] Loss=1.1955, Acc=0.5638\n",
      "[Baseline][17] Loss=1.1923, Acc=0.5824\n",
      "[Baseline][18] Loss=1.1441, Acc=0.5713\n",
      "[Baseline][19] Loss=1.1734, Acc=0.5894\n",
      "[Baseline][20] Loss=1.1283, Acc=0.5847\n",
      "[Baseline][21] Loss=1.1190, Acc=0.5748\n",
      "[Baseline][22] Loss=1.1214, Acc=0.5936\n",
      "[Baseline][23] Loss=1.0808, Acc=0.6014\n",
      "[Baseline][24] Loss=1.0562, Acc=0.5858\n",
      "[Baseline][25] Loss=1.0546, Acc=0.5894\n",
      "[Baseline][26] Loss=1.0663, Acc=0.6015\n",
      "[Baseline][27] Loss=1.0590, Acc=0.6120\n",
      "[Baseline][28] Loss=1.0168, Acc=0.6094\n",
      "[Baseline][29] Loss=1.0144, Acc=0.6194\n",
      "[Baseline][30] Loss=0.9596, Acc=0.6137\n",
      "[Baseline][31] Loss=0.9876, Acc=0.6143\n",
      "[Baseline][32] Loss=0.9811, Acc=0.6194\n",
      "[Baseline][33] Loss=0.9582, Acc=0.6221\n",
      "[Baseline][34] Loss=0.9537, Acc=0.6123\n",
      "[Baseline][35] Loss=0.9455, Acc=0.6171\n",
      "[Baseline][36] Loss=0.9462, Acc=0.6229\n",
      "[Baseline][37] Loss=0.9081, Acc=0.6217\n",
      "[Baseline][38] Loss=0.8966, Acc=0.6310\n",
      "[Baseline][39] Loss=0.8983, Acc=0.6276\n",
      "[Baseline][40] Loss=0.9155, Acc=0.6120\n",
      "[Baseline][41] Loss=0.9140, Acc=0.6283\n",
      "[Baseline][42] Loss=0.8732, Acc=0.6190\n",
      "[Baseline][43] Loss=0.9023, Acc=0.6167\n",
      "[Baseline][44] Loss=0.8725, Acc=0.6307\n",
      "[Baseline][45] Loss=0.8458, Acc=0.6378\n",
      "[Baseline][46] Loss=0.8628, Acc=0.6419\n",
      "[Baseline][47] Loss=0.8211, Acc=0.6244\n",
      "[Baseline][48] Loss=0.8129, Acc=0.6366\n",
      "[Baseline][49] Loss=0.8211, Acc=0.6390\n",
      "[Baseline][50] Loss=0.8243, Acc=0.6432\n",
      "[Baseline][51] Loss=0.8233, Acc=0.6367\n",
      "[Baseline][52] Loss=0.8044, Acc=0.6340\n",
      "[Baseline][53] Loss=0.7946, Acc=0.6452\n",
      "[Baseline][54] Loss=0.7892, Acc=0.6451\n",
      "[Baseline][55] Loss=0.7744, Acc=0.6421\n",
      "[Baseline][56] Loss=0.7711, Acc=0.6390\n",
      "[Baseline][57] Loss=0.7972, Acc=0.6188\n",
      "[Baseline][58] Loss=0.7912, Acc=0.6377\n",
      "[Baseline][59] Loss=0.7641, Acc=0.6367\n",
      "[Baseline][60] Loss=0.7654, Acc=0.6517\n",
      "[Baseline][61] Loss=0.7718, Acc=0.6452\n",
      "[Baseline][62] Loss=0.7451, Acc=0.6524\n",
      "[Baseline][63] Loss=0.7176, Acc=0.6485\n",
      "[Baseline][64] Loss=0.7246, Acc=0.6437\n",
      "[Baseline][65] Loss=0.7104, Acc=0.6456\n",
      "[Baseline][66] Loss=0.7199, Acc=0.6483\n",
      "[Baseline][67] Loss=0.7063, Acc=0.6450\n",
      "[Baseline][68] Loss=0.7707, Acc=0.6465\n",
      "[Baseline][69] Loss=0.7006, Acc=0.6470\n",
      "[Baseline][70] Loss=0.7184, Acc=0.6497\n",
      "[Baseline][71] Loss=0.7124, Acc=0.6448\n",
      "[Baseline][72] Loss=0.6839, Acc=0.6500\n",
      "[Baseline][73] Loss=0.6642, Acc=0.6465\n",
      "[Baseline][74] Loss=0.6579, Acc=0.6442\n",
      "[Baseline][75] Loss=0.6968, Acc=0.6550\n",
      "[Baseline][76] Loss=0.6464, Acc=0.6505\n",
      "[Baseline][77] Loss=0.6467, Acc=0.6492\n",
      "[Baseline][78] Loss=0.6553, Acc=0.6383\n",
      "[Baseline][79] Loss=0.6708, Acc=0.6525\n",
      "[Baseline][80] Loss=0.6470, Acc=0.6540\n",
      "[Baseline][81] Loss=0.6707, Acc=0.6470\n",
      "[Baseline][82] Loss=0.6656, Acc=0.6450\n",
      "[Baseline][83] Loss=0.6410, Acc=0.6527\n",
      "[Baseline][84] Loss=0.6415, Acc=0.6391\n",
      "[Baseline][85] Loss=0.6794, Acc=0.6397\n",
      "[Baseline][86] Loss=0.5968, Acc=0.6554\n",
      "[Baseline][87] Loss=0.6210, Acc=0.6446\n",
      "[Baseline][88] Loss=0.5908, Acc=0.6524\n",
      "[Baseline][89] Loss=0.6415, Acc=0.6561\n",
      "[Baseline][90] Loss=0.6405, Acc=0.6424\n",
      "[Baseline][91] Loss=0.5868, Acc=0.6489\n",
      "[Baseline][92] Loss=0.5752, Acc=0.6579\n",
      "[Baseline][93] Loss=0.5817, Acc=0.6380\n",
      "[Baseline][94] Loss=0.6277, Acc=0.6542\n",
      "[Baseline][95] Loss=0.5630, Acc=0.6519\n",
      "[Baseline][96] Loss=0.5571, Acc=0.6499\n",
      "[Baseline][97] Loss=0.5774, Acc=0.6547\n",
      "[Baseline][98] Loss=0.5375, Acc=0.6506\n",
      "[Baseline][99] Loss=0.5399, Acc=0.6461\n",
      "[Baseline][100] Loss=0.6282, Acc=0.6455\n",
      "[Baseline][101] Loss=0.5720, Acc=0.6532\n",
      "[Baseline][102] Loss=0.5488, Acc=0.6523\n",
      "[Baseline][103] Loss=0.5249, Acc=0.6549\n",
      "[Baseline][104] Loss=0.5375, Acc=0.6526\n",
      "[Baseline][105] Loss=0.5568, Acc=0.6490\n",
      "[Baseline][106] Loss=0.5465, Acc=0.6457\n",
      "[Baseline][107] Loss=0.5581, Acc=0.6489\n",
      "[Baseline][108] Loss=0.5298, Acc=0.6537\n",
      "[Baseline][109] Loss=0.5585, Acc=0.6548\n",
      "[Baseline][110] Loss=0.5226, Acc=0.6538\n",
      "[Baseline][111] Loss=0.5154, Acc=0.6456\n",
      "[Baseline][112] Loss=0.5499, Acc=0.6541\n",
      "[Baseline][113] Loss=0.5195, Acc=0.6514\n",
      "[Baseline][114] Loss=0.5209, Acc=0.6513\n",
      "[Baseline][115] Loss=0.5499, Acc=0.6489\n",
      "[Baseline][116] Loss=0.5333, Acc=0.6527\n",
      "[Baseline][117] Loss=0.4901, Acc=0.6502\n",
      "[Baseline][118] Loss=0.5176, Acc=0.6457\n",
      "[Baseline][119] Loss=0.4924, Acc=0.6484\n",
      "[Baseline][120] Loss=0.4888, Acc=0.6530\n",
      "[Baseline][121] Loss=0.4867, Acc=0.6507\n",
      "[Baseline][122] Loss=0.4771, Acc=0.6533\n",
      "[Baseline][123] Loss=0.4510, Acc=0.6509\n",
      "[Baseline][124] Loss=0.4953, Acc=0.6431\n",
      "[Baseline][125] Loss=0.4533, Acc=0.6493\n",
      "[Baseline][126] Loss=0.4934, Acc=0.6554\n",
      "[Baseline][127] Loss=0.4631, Acc=0.6515\n",
      "[Baseline][128] Loss=0.5199, Acc=0.6542\n",
      "[Baseline][129] Loss=0.4821, Acc=0.6436\n",
      "[Baseline][130] Loss=0.4461, Acc=0.6591\n",
      "[Baseline][131] Loss=0.4423, Acc=0.6581\n",
      "[Baseline][132] Loss=0.4533, Acc=0.6574\n",
      "[Baseline][133] Loss=0.4628, Acc=0.6532\n",
      "[Baseline][134] Loss=0.4506, Acc=0.6510\n",
      "[Baseline][135] Loss=0.4956, Acc=0.6462\n",
      "[Baseline][136] Loss=0.4523, Acc=0.6466\n",
      "[Baseline][137] Loss=0.4808, Acc=0.6406\n",
      "[Baseline][138] Loss=0.4711, Acc=0.6523\n",
      "[Baseline][139] Loss=0.4574, Acc=0.6536\n",
      "[Baseline][140] Loss=0.4335, Acc=0.6559\n",
      "[Baseline][141] Loss=0.4190, Acc=0.6526\n",
      "[Baseline][142] Loss=0.4060, Acc=0.6557\n",
      "[Baseline][143] Loss=0.4364, Acc=0.6515\n",
      "[Baseline][144] Loss=0.4284, Acc=0.6541\n",
      "[Baseline][145] Loss=0.4200, Acc=0.6531\n",
      "[Baseline][146] Loss=0.4185, Acc=0.6590\n",
      "[Baseline][147] Loss=0.4512, Acc=0.6543\n",
      "[Baseline][148] Loss=0.4231, Acc=0.6405\n",
      "[Baseline][149] Loss=0.4178, Acc=0.6535\n",
      "[Baseline][150] Loss=0.4130, Acc=0.6496\n",
      "[Baseline][151] Loss=0.4031, Acc=0.6523\n",
      "[Baseline][152] Loss=0.3890, Acc=0.6555\n",
      "[Baseline][153] Loss=0.3841, Acc=0.6550\n",
      "[Baseline][154] Loss=0.3950, Acc=0.6540\n",
      "[Baseline][155] Loss=0.3945, Acc=0.6603\n",
      "[Baseline][156] Loss=0.4109, Acc=0.6580\n",
      "[Baseline][157] Loss=0.3979, Acc=0.6557\n",
      "[Baseline][158] Loss=0.3945, Acc=0.6346\n",
      "[Baseline][159] Loss=0.4417, Acc=0.6561\n",
      "[Baseline][160] Loss=0.4194, Acc=0.6539\n",
      "[Baseline][161] Loss=0.4137, Acc=0.6533\n",
      "[Baseline][162] Loss=0.3827, Acc=0.6483\n",
      "[Baseline][163] Loss=0.4569, Acc=0.6419\n",
      "[Baseline][164] Loss=0.3677, Acc=0.6542\n",
      "[Baseline][165] Loss=0.3782, Acc=0.6515\n",
      "[Baseline][166] Loss=0.3790, Acc=0.6546\n",
      "[Baseline][167] Loss=0.3514, Acc=0.6612\n",
      "[Baseline][168] Loss=0.3495, Acc=0.6488\n",
      "[Baseline][169] Loss=0.3440, Acc=0.6592\n",
      "[Baseline][170] Loss=0.3544, Acc=0.6409\n",
      "[Baseline][171] Loss=0.3577, Acc=0.6469\n",
      "[Baseline][172] Loss=0.3607, Acc=0.6563\n",
      "[Baseline][173] Loss=0.3613, Acc=0.6513\n",
      "[Baseline][174] Loss=0.3836, Acc=0.6503\n",
      "[Baseline][175] Loss=0.3555, Acc=0.6545\n",
      "[Baseline][176] Loss=0.3699, Acc=0.6498\n",
      "[Baseline][177] Loss=0.3951, Acc=0.6350\n",
      "[Baseline][178] Loss=0.3979, Acc=0.6495\n",
      "[Baseline][179] Loss=0.3833, Acc=0.6524\n",
      "[Baseline][180] Loss=0.3350, Acc=0.6573\n",
      "[Baseline][181] Loss=0.3131, Acc=0.6509\n",
      "[Baseline][182] Loss=0.3262, Acc=0.6533\n",
      "[Baseline][183] Loss=0.3351, Acc=0.6521\n",
      "[Baseline][184] Loss=0.3651, Acc=0.6483\n",
      "[Baseline][185] Loss=0.3790, Acc=0.6412\n",
      "[Baseline][186] Loss=0.3694, Acc=0.6487\n",
      "[Baseline][187] Loss=0.3457, Acc=0.6507\n",
      "[Baseline][188] Loss=0.3446, Acc=0.6508\n",
      "[Baseline][189] Loss=0.3255, Acc=0.6541\n",
      "[Baseline][190] Loss=0.3003, Acc=0.6548\n",
      "[Baseline][191] Loss=0.3115, Acc=0.6539\n",
      "[Baseline][192] Loss=0.3191, Acc=0.6550\n",
      "[Baseline][193] Loss=0.3041, Acc=0.6554\n",
      "[Baseline][194] Loss=0.3425, Acc=0.6514\n",
      "[Baseline][195] Loss=0.3367, Acc=0.6510\n",
      "[Baseline][196] Loss=0.3319, Acc=0.6494\n",
      "[Baseline][197] Loss=0.3294, Acc=0.6511\n",
      "[Baseline][198] Loss=0.3092, Acc=0.6470\n",
      "[Baseline][199] Loss=0.3372, Acc=0.6472\n",
      "[Baseline][200] Loss=0.3280, Acc=0.6557\n",
      "[Baseline][201] Loss=0.3398, Acc=0.6532\n",
      "[Baseline][202] Loss=0.3153, Acc=0.6527\n",
      "[Baseline][203] Loss=0.3065, Acc=0.6500\n",
      "[Baseline][204] Loss=0.3103, Acc=0.6570\n",
      "[Baseline][205] Loss=0.3090, Acc=0.6561\n",
      "[Baseline][206] Loss=0.2986, Acc=0.6480\n",
      "[Baseline][207] Loss=0.3234, Acc=0.6474\n",
      "[Baseline][208] Loss=0.3183, Acc=0.6439\n",
      "[Baseline][209] Loss=0.3018, Acc=0.6525\n",
      "[Baseline][210] Loss=0.3068, Acc=0.6557\n",
      "[Baseline][211] Loss=0.3272, Acc=0.6506\n",
      "[Baseline][212] Loss=0.3527, Acc=0.6480\n",
      "[Baseline][213] Loss=0.3249, Acc=0.6490\n",
      "[Baseline][214] Loss=0.2889, Acc=0.6515\n",
      "[Baseline][215] Loss=0.2827, Acc=0.6472\n",
      "[Baseline][216] Loss=0.2986, Acc=0.6427\n",
      "[Baseline][217] Loss=0.3267, Acc=0.6585\n",
      "[Baseline][218] Loss=0.3341, Acc=0.6371\n",
      "[Baseline][219] Loss=0.3228, Acc=0.6525\n",
      "[Baseline][220] Loss=0.2976, Acc=0.6468\n",
      "[Baseline][221] Loss=0.2738, Acc=0.6521\n",
      "[Baseline][222] Loss=0.2831, Acc=0.6450\n",
      "[Baseline][223] Loss=0.3137, Acc=0.6544\n",
      "[Baseline][224] Loss=0.2809, Acc=0.6422\n",
      "[Baseline][225] Loss=0.2669, Acc=0.6500\n",
      "[Baseline][226] Loss=0.2869, Acc=0.6512\n",
      "[Baseline][227] Loss=0.2719, Acc=0.6513\n",
      "[Baseline][228] Loss=0.2844, Acc=0.6472\n",
      "[Baseline][229] Loss=0.2677, Acc=0.6530\n",
      "[Baseline][230] Loss=0.3236, Acc=0.6537\n",
      "[Baseline][231] Loss=0.3201, Acc=0.6472\n",
      "[Baseline][232] Loss=0.3232, Acc=0.6514\n",
      "[Baseline][233] Loss=0.2666, Acc=0.6478\n",
      "[Baseline][234] Loss=0.3128, Acc=0.6498\n",
      "[Baseline][235] Loss=0.3019, Acc=0.6469\n",
      "[Baseline][236] Loss=0.2775, Acc=0.6417\n",
      "[Baseline][237] Loss=0.2673, Acc=0.6541\n",
      "[Baseline][238] Loss=0.2861, Acc=0.6431\n",
      "[Baseline][239] Loss=0.2834, Acc=0.6522\n",
      "[Baseline][240] Loss=0.2690, Acc=0.6455\n",
      "[Baseline][241] Loss=0.2588, Acc=0.6530\n",
      "[Baseline][242] Loss=0.2797, Acc=0.6504\n",
      "[Baseline][243] Loss=0.2765, Acc=0.6509\n",
      "[Baseline][244] Loss=0.3289, Acc=0.6501\n",
      "[Baseline][245] Loss=0.2638, Acc=0.6513\n",
      "[Baseline][246] Loss=0.2883, Acc=0.6397\n",
      "[Baseline][247] Loss=0.2682, Acc=0.6480\n",
      "[Baseline][248] Loss=0.3867, Acc=0.6458\n",
      "[Baseline][249] Loss=0.2696, Acc=0.6525\n",
      "[Baseline][250] Loss=0.2524, Acc=0.6459\n",
      "[Baseline][251] Loss=0.2481, Acc=0.6473\n",
      "[Baseline][252] Loss=0.2600, Acc=0.6530\n",
      "[Baseline][253] Loss=0.2560, Acc=0.6563\n",
      "[Baseline][254] Loss=0.2793, Acc=0.6497\n",
      "[Baseline][255] Loss=0.2536, Acc=0.6482\n",
      "[Baseline][256] Loss=0.2430, Acc=0.6524\n",
      "[Baseline][257] Loss=0.2470, Acc=0.6531\n",
      "[Baseline][258] Loss=0.2760, Acc=0.6495\n",
      "[Baseline][259] Loss=0.2391, Acc=0.6490\n",
      "[Baseline][260] Loss=0.2472, Acc=0.6532\n",
      "[Baseline][261] Loss=0.2309, Acc=0.6437\n",
      "[Baseline][262] Loss=0.2681, Acc=0.6451\n",
      "[Baseline][263] Loss=0.2407, Acc=0.6460\n",
      "[Baseline][264] Loss=0.2372, Acc=0.6487\n",
      "[Baseline][265] Loss=0.2389, Acc=0.6491\n",
      "[Baseline][266] Loss=0.2223, Acc=0.6549\n",
      "[Baseline][267] Loss=0.2486, Acc=0.6492\n",
      "[Baseline][268] Loss=0.3414, Acc=0.6415\n",
      "[Baseline][269] Loss=0.2813, Acc=0.6498\n",
      "[Baseline][270] Loss=0.2381, Acc=0.6517\n",
      "[Baseline][271] Loss=0.2391, Acc=0.6431\n",
      "[Baseline][272] Loss=0.2306, Acc=0.6541\n",
      "[Baseline][273] Loss=0.2614, Acc=0.6534\n",
      "[Baseline][274] Loss=0.2796, Acc=0.6507\n",
      "[Baseline][275] Loss=0.2727, Acc=0.6362\n",
      "[Baseline][276] Loss=0.2538, Acc=0.6476\n",
      "[Baseline][277] Loss=0.3134, Acc=0.6465\n",
      "[Baseline][278] Loss=0.2541, Acc=0.6470\n",
      "[Baseline][279] Loss=0.2611, Acc=0.6470\n",
      "[Baseline][280] Loss=0.2387, Acc=0.6418\n",
      "[Baseline][281] Loss=0.2684, Acc=0.6463\n",
      "[Baseline][282] Loss=0.3331, Acc=0.6406\n",
      "[Baseline][283] Loss=0.2668, Acc=0.6530\n",
      "[Baseline][284] Loss=0.2948, Acc=0.6511\n",
      "[Baseline][285] Loss=0.2376, Acc=0.6488\n",
      "[Baseline][286] Loss=0.2648, Acc=0.6521\n",
      "[Baseline][287] Loss=0.2617, Acc=0.6480\n",
      "[Baseline][288] Loss=0.2550, Acc=0.6501\n",
      "[Baseline][289] Loss=0.2365, Acc=0.6493\n",
      "[Baseline][290] Loss=0.2124, Acc=0.6490\n",
      "[Baseline][291] Loss=0.2207, Acc=0.6443\n",
      "[Baseline][292] Loss=0.2100, Acc=0.6517\n",
      "[Baseline][293] Loss=0.2176, Acc=0.6544\n",
      "[Baseline][294] Loss=0.2183, Acc=0.6552\n",
      "[Baseline][295] Loss=0.2154, Acc=0.6517\n",
      "[Baseline][296] Loss=0.2157, Acc=0.6493\n",
      "[Baseline][297] Loss=0.2360, Acc=0.6452\n",
      "[Baseline][298] Loss=0.2731, Acc=0.6501\n",
      "[Baseline][299] Loss=0.2230, Acc=0.6504\n",
      "[Baseline][300] Loss=0.2593, Acc=0.6451\n",
      "[Baseline][301] Loss=0.2751, Acc=0.6441\n",
      "[Baseline][302] Loss=0.1964, Acc=0.6436\n",
      "[Baseline][303] Loss=0.2234, Acc=0.6483\n",
      "[Baseline][304] Loss=0.2040, Acc=0.6458\n",
      "[Baseline][305] Loss=0.2301, Acc=0.6496\n",
      "[Baseline][306] Loss=0.2231, Acc=0.6445\n",
      "[Baseline][307] Loss=0.2245, Acc=0.6461\n",
      "[Baseline][308] Loss=0.2198, Acc=0.6429\n",
      "[Baseline][309] Loss=0.2409, Acc=0.6478\n",
      "[Baseline][310] Loss=0.2326, Acc=0.6428\n",
      "[Baseline][311] Loss=0.2312, Acc=0.6468\n",
      "[Baseline][312] Loss=0.1893, Acc=0.6479\n",
      "[Baseline][313] Loss=0.1910, Acc=0.6467\n",
      "[Baseline][314] Loss=0.1987, Acc=0.6489\n",
      "[Baseline][315] Loss=0.2141, Acc=0.6514\n",
      "[Baseline][316] Loss=0.2299, Acc=0.6454\n",
      "[Baseline][317] Loss=0.1924, Acc=0.6483\n",
      "[Baseline][318] Loss=0.2111, Acc=0.6519\n",
      "[Baseline][319] Loss=0.1843, Acc=0.6494\n",
      "[Baseline][320] Loss=0.2102, Acc=0.6444\n",
      "[Baseline][321] Loss=0.2062, Acc=0.6486\n",
      "[Baseline][322] Loss=0.2262, Acc=0.6489\n",
      "[Baseline][323] Loss=0.2199, Acc=0.6435\n",
      "[Baseline][324] Loss=0.1948, Acc=0.6538\n",
      "[Baseline][325] Loss=0.2209, Acc=0.6515\n",
      "[Baseline][326] Loss=0.1794, Acc=0.6420\n",
      "[Baseline][327] Loss=0.2079, Acc=0.6431\n",
      "[Baseline][328] Loss=0.2415, Acc=0.6449\n",
      "[Baseline][329] Loss=0.2128, Acc=0.6517\n",
      "[Baseline][330] Loss=0.2230, Acc=0.6510\n",
      "[Baseline][331] Loss=0.1871, Acc=0.6450\n",
      "[Baseline][332] Loss=0.1985, Acc=0.6491\n",
      "[Baseline][333] Loss=0.2472, Acc=0.6502\n",
      "[Baseline][334] Loss=0.1922, Acc=0.6505\n",
      "[Baseline][335] Loss=0.1754, Acc=0.6524\n",
      "[Baseline][336] Loss=0.1735, Acc=0.6485\n",
      "[Baseline][337] Loss=0.2294, Acc=0.6507\n",
      "[Baseline][338] Loss=0.1874, Acc=0.6415\n",
      "[Baseline][339] Loss=0.1842, Acc=0.6466\n",
      "[Baseline][340] Loss=0.1743, Acc=0.6517\n",
      "[Baseline][341] Loss=0.1904, Acc=0.6387\n",
      "[Baseline][342] Loss=0.1992, Acc=0.6465\n",
      "[Baseline][343] Loss=0.1867, Acc=0.6366\n",
      "[Baseline][344] Loss=0.2572, Acc=0.6437\n",
      "[Baseline][345] Loss=0.1860, Acc=0.6472\n",
      "[Baseline][346] Loss=0.1968, Acc=0.6431\n",
      "[Baseline][347] Loss=0.2112, Acc=0.6492\n",
      "[Baseline][348] Loss=0.1546, Acc=0.6444\n",
      "[Baseline][349] Loss=0.1890, Acc=0.6446\n",
      "[Baseline][350] Loss=0.1891, Acc=0.6486\n",
      "[Baseline][351] Loss=0.2285, Acc=0.6482\n",
      "[Baseline][352] Loss=0.2264, Acc=0.6465\n",
      "[Baseline][353] Loss=0.2024, Acc=0.6465\n",
      "[Baseline][354] Loss=0.1865, Acc=0.6497\n",
      "[Baseline][355] Loss=0.1675, Acc=0.6524\n",
      "[Baseline][356] Loss=0.1777, Acc=0.6465\n",
      "[Baseline][357] Loss=0.1964, Acc=0.6456\n",
      "[Baseline][358] Loss=0.2806, Acc=0.6434\n",
      "[Baseline][359] Loss=0.2445, Acc=0.6426\n",
      "[Baseline][360] Loss=0.2280, Acc=0.6447\n",
      "[Baseline][361] Loss=0.2052, Acc=0.6451\n",
      "[Baseline][362] Loss=0.1963, Acc=0.6511\n",
      "[Baseline][363] Loss=0.1894, Acc=0.6489\n",
      "[Baseline][364] Loss=0.2146, Acc=0.6428\n",
      "[Baseline][365] Loss=0.1954, Acc=0.6460\n",
      "[Baseline][366] Loss=0.1881, Acc=0.6525\n",
      "[Baseline][367] Loss=0.2117, Acc=0.6438\n",
      "[Baseline][368] Loss=0.1921, Acc=0.6466\n",
      "[Baseline][369] Loss=0.2236, Acc=0.6496\n",
      "[Baseline][370] Loss=0.1874, Acc=0.6455\n",
      "[Baseline][371] Loss=0.2003, Acc=0.6482\n",
      "[Baseline][372] Loss=0.2310, Acc=0.6409\n",
      "[Baseline][373] Loss=0.1742, Acc=0.6448\n",
      "[Baseline][374] Loss=0.1750, Acc=0.6446\n",
      "[Baseline][375] Loss=0.1788, Acc=0.6530\n",
      "[Baseline][376] Loss=0.1650, Acc=0.6532\n",
      "[Baseline][377] Loss=0.1437, Acc=0.6458\n",
      "[Baseline][378] Loss=0.2271, Acc=0.6451\n",
      "[Baseline][379] Loss=0.1794, Acc=0.6468\n",
      "[Baseline][380] Loss=0.1579, Acc=0.6423\n",
      "[Baseline][381] Loss=0.2008, Acc=0.6527\n",
      "[Baseline][382] Loss=0.1649, Acc=0.6411\n",
      "[Baseline][383] Loss=0.1712, Acc=0.6484\n",
      "[Baseline][384] Loss=0.2157, Acc=0.6417\n",
      "[Baseline][385] Loss=0.1690, Acc=0.6501\n",
      "[Baseline][386] Loss=0.1467, Acc=0.6515\n",
      "[Baseline][387] Loss=0.1718, Acc=0.6409\n",
      "[Baseline][388] Loss=0.2182, Acc=0.6393\n",
      "[Baseline][389] Loss=0.1883, Acc=0.6466\n",
      "[Baseline][390] Loss=0.1681, Acc=0.6393\n",
      "[Baseline][391] Loss=0.1867, Acc=0.6421\n",
      "[Baseline][392] Loss=0.1894, Acc=0.6360\n",
      "[Baseline][393] Loss=0.2245, Acc=0.6391\n",
      "[Baseline][394] Loss=0.1700, Acc=0.6447\n",
      "[Baseline][395] Loss=0.1569, Acc=0.6466\n",
      "[Baseline][396] Loss=0.1750, Acc=0.6410\n",
      "[Baseline][397] Loss=0.1627, Acc=0.6501\n",
      "[Baseline][398] Loss=0.1513, Acc=0.6514\n",
      "[Baseline][399] Loss=0.1645, Acc=0.6459\n",
      "[Baseline][400] Loss=0.1463, Acc=0.6516\n",
      "[Baseline][401] Loss=0.1810, Acc=0.6444\n",
      "[Baseline][402] Loss=0.2627, Acc=0.6441\n",
      "[Baseline][403] Loss=0.1936, Acc=0.6482\n",
      "[Baseline][404] Loss=0.1566, Acc=0.6514\n",
      "[Baseline][405] Loss=0.1635, Acc=0.6447\n",
      "[Baseline][406] Loss=0.2001, Acc=0.6458\n",
      "[Baseline][407] Loss=0.2153, Acc=0.6472\n",
      "[Baseline][408] Loss=0.1761, Acc=0.6533\n",
      "[Baseline][409] Loss=0.2031, Acc=0.6421\n",
      "[Baseline][410] Loss=0.1857, Acc=0.6515\n",
      "[Baseline][411] Loss=0.1534, Acc=0.6498\n",
      "[Baseline][412] Loss=0.1718, Acc=0.6502\n",
      "[Baseline][413] Loss=0.1629, Acc=0.6491\n",
      "[Baseline][414] Loss=0.1631, Acc=0.6438\n",
      "[Baseline][415] Loss=0.1474, Acc=0.6461\n",
      "[Baseline][416] Loss=0.1461, Acc=0.6497\n",
      "[Baseline][417] Loss=0.1621, Acc=0.6487\n",
      "[Baseline][418] Loss=0.1477, Acc=0.6470\n",
      "[Baseline][419] Loss=0.1451, Acc=0.6495\n",
      "[Baseline][420] Loss=0.1883, Acc=0.6463\n",
      "[Baseline][421] Loss=0.1939, Acc=0.6486\n",
      "[Baseline][422] Loss=0.1523, Acc=0.6417\n",
      "[Baseline][423] Loss=0.1474, Acc=0.6494\n",
      "[Baseline][424] Loss=0.1412, Acc=0.6488\n",
      "[Baseline][425] Loss=0.1951, Acc=0.6467\n",
      "[Baseline][426] Loss=0.1791, Acc=0.6445\n",
      "[Baseline][427] Loss=0.1647, Acc=0.6509\n",
      "[Baseline][428] Loss=0.1535, Acc=0.6481\n",
      "[Baseline][429] Loss=0.1543, Acc=0.6371\n",
      "[Baseline][430] Loss=0.1629, Acc=0.6423\n",
      "[Baseline][431] Loss=0.1641, Acc=0.6460\n",
      "[Baseline][432] Loss=0.1732, Acc=0.6490\n",
      "[Baseline][433] Loss=0.1542, Acc=0.6479\n",
      "[Baseline][434] Loss=0.2269, Acc=0.6464\n",
      "[Baseline][435] Loss=0.1922, Acc=0.6414\n",
      "[Baseline][436] Loss=0.1763, Acc=0.6476\n",
      "[Baseline][437] Loss=0.2028, Acc=0.6434\n",
      "[Baseline][438] Loss=0.1941, Acc=0.6414\n",
      "[Baseline][439] Loss=0.1698, Acc=0.6465\n",
      "[Baseline][440] Loss=0.1657, Acc=0.6434\n",
      "[Baseline][441] Loss=0.1782, Acc=0.6451\n",
      "[Baseline][442] Loss=0.1737, Acc=0.6452\n",
      "[Baseline][443] Loss=0.1448, Acc=0.6506\n",
      "[Baseline][444] Loss=0.1402, Acc=0.6480\n",
      "[Baseline][445] Loss=0.1582, Acc=0.6423\n",
      "[Baseline][446] Loss=0.1664, Acc=0.6434\n",
      "[Baseline][447] Loss=0.1592, Acc=0.6463\n",
      "[Baseline][448] Loss=0.1512, Acc=0.6417\n",
      "[Baseline][449] Loss=0.1383, Acc=0.6433\n",
      "[Baseline][450] Loss=0.1460, Acc=0.6415\n",
      "[Baseline][451] Loss=0.1934, Acc=0.6398\n",
      "[Baseline][452] Loss=0.1516, Acc=0.6462\n",
      "[Baseline][453] Loss=0.1475, Acc=0.6502\n",
      "[Baseline][454] Loss=0.1425, Acc=0.6462\n",
      "[Baseline][455] Loss=0.1932, Acc=0.6407\n",
      "[Baseline][456] Loss=0.1547, Acc=0.6394\n",
      "[Baseline][457] Loss=0.1653, Acc=0.6442\n",
      "[Baseline][458] Loss=0.1658, Acc=0.6355\n",
      "[Baseline][459] Loss=0.1425, Acc=0.6511\n",
      "[Baseline][460] Loss=0.1483, Acc=0.6472\n",
      "[Baseline][461] Loss=0.1350, Acc=0.6352\n",
      "[Baseline][462] Loss=0.1392, Acc=0.6397\n",
      "[Baseline][463] Loss=0.1369, Acc=0.6478\n",
      "[Baseline][464] Loss=0.1233, Acc=0.6487\n",
      "[Baseline][465] Loss=0.1365, Acc=0.6467\n",
      "[Baseline][466] Loss=0.1352, Acc=0.6454\n",
      "[Baseline][467] Loss=0.1682, Acc=0.6507\n",
      "[Baseline][468] Loss=0.1623, Acc=0.6499\n",
      "[Baseline][469] Loss=0.1320, Acc=0.6525\n",
      "[Baseline][470] Loss=0.1615, Acc=0.6448\n",
      "[Baseline][471] Loss=0.2082, Acc=0.6401\n",
      "[Baseline][472] Loss=0.1758, Acc=0.6416\n",
      "[Baseline][473] Loss=0.1335, Acc=0.6502\n",
      "[Baseline][474] Loss=0.1284, Acc=0.6478\n",
      "[Baseline][475] Loss=0.1334, Acc=0.6457\n",
      "[Baseline][476] Loss=0.1381, Acc=0.6431\n",
      "[Baseline][477] Loss=0.1285, Acc=0.6539\n",
      "[Baseline][478] Loss=0.1545, Acc=0.6376\n",
      "[Baseline][479] Loss=0.2139, Acc=0.6414\n",
      "[Baseline][480] Loss=0.1487, Acc=0.6482\n",
      "[Baseline][481] Loss=0.1516, Acc=0.6415\n",
      "[Baseline][482] Loss=0.1261, Acc=0.6523\n",
      "[Baseline][483] Loss=0.1451, Acc=0.6512\n",
      "[Baseline][484] Loss=0.1538, Acc=0.6476\n",
      "[Baseline][485] Loss=0.1368, Acc=0.6480\n",
      "[Baseline][486] Loss=0.1424, Acc=0.6412\n",
      "[Baseline][487] Loss=0.2141, Acc=0.6455\n",
      "[Baseline][488] Loss=0.3010, Acc=0.6448\n",
      "[Baseline][489] Loss=0.1847, Acc=0.6491\n",
      "[Baseline][490] Loss=0.1792, Acc=0.6449\n",
      "[Baseline][491] Loss=0.1381, Acc=0.6494\n",
      "[Baseline][492] Loss=0.1412, Acc=0.6513\n",
      "[Baseline][493] Loss=0.1503, Acc=0.6502\n",
      "[Baseline][494] Loss=0.1434, Acc=0.6546\n",
      "[Baseline][495] Loss=0.1232, Acc=0.6489\n",
      "[Baseline][496] Loss=0.1296, Acc=0.6496\n",
      "[Baseline][497] Loss=0.1134, Acc=0.6500\n",
      "[Baseline][498] Loss=0.1070, Acc=0.6495\n",
      "[Baseline][499] Loss=0.1159, Acc=0.6524\n",
      "[Baseline][500] Loss=0.1624, Acc=0.6391\n",
      "[Baseline][501] Loss=0.1548, Acc=0.6491\n",
      "[Baseline][502] Loss=0.1330, Acc=0.6442\n",
      "[Baseline][503] Loss=0.1475, Acc=0.6454\n",
      "[Baseline][504] Loss=0.1206, Acc=0.6475\n",
      "[Baseline][505] Loss=0.2077, Acc=0.6454\n",
      "[Baseline][506] Loss=0.1482, Acc=0.6432\n",
      "[Baseline][507] Loss=0.1312, Acc=0.6428\n",
      "[Baseline][508] Loss=0.1330, Acc=0.6440\n",
      "[Baseline][509] Loss=0.1532, Acc=0.6444\n",
      "[Baseline][510] Loss=0.1336, Acc=0.6409\n",
      "[Baseline][511] Loss=0.1253, Acc=0.6458\n",
      "[Baseline][512] Loss=0.1365, Acc=0.6448\n",
      "[Baseline][513] Loss=0.1097, Acc=0.6446\n",
      "[Baseline][514] Loss=0.1084, Acc=0.6466\n",
      "[Baseline][515] Loss=0.1328, Acc=0.6386\n",
      "[Baseline][516] Loss=0.1201, Acc=0.6421\n",
      "[Baseline][517] Loss=0.1193, Acc=0.6468\n",
      "[Baseline][518] Loss=0.1194, Acc=0.6468\n",
      "[Baseline][519] Loss=0.1714, Acc=0.6396\n",
      "[Baseline][520] Loss=0.1955, Acc=0.6381\n",
      "[Baseline][521] Loss=0.1606, Acc=0.6461\n",
      "[Baseline][522] Loss=0.1298, Acc=0.6455\n",
      "[Baseline][523] Loss=0.1378, Acc=0.6461\n",
      "[Baseline][524] Loss=0.1740, Acc=0.6446\n",
      "[Baseline][525] Loss=0.2003, Acc=0.6430\n",
      "[Baseline][526] Loss=0.1644, Acc=0.6417\n",
      "[Baseline][527] Loss=0.2116, Acc=0.6401\n",
      "[Baseline][528] Loss=0.1338, Acc=0.6411\n",
      "[Baseline][529] Loss=0.1332, Acc=0.6450\n",
      "[Baseline][530] Loss=0.1279, Acc=0.6404\n",
      "[Baseline][531] Loss=0.1230, Acc=0.6429\n",
      "[Baseline][532] Loss=0.1166, Acc=0.6467\n",
      "[Baseline][533] Loss=0.1156, Acc=0.6457\n",
      "[Baseline][534] Loss=0.1397, Acc=0.6422\n",
      "[Baseline][535] Loss=0.1232, Acc=0.6494\n",
      "[Baseline][536] Loss=0.2325, Acc=0.6416\n",
      "[Baseline][537] Loss=0.1305, Acc=0.6475\n",
      "[Baseline][538] Loss=0.1202, Acc=0.6410\n",
      "[Baseline][539] Loss=0.1365, Acc=0.6411\n",
      "[Baseline][540] Loss=0.1590, Acc=0.6434\n",
      "[Baseline][541] Loss=0.1427, Acc=0.6443\n",
      "[Baseline][542] Loss=0.1426, Acc=0.6420\n",
      "[Baseline][543] Loss=0.1724, Acc=0.6417\n",
      "[Baseline][544] Loss=0.1784, Acc=0.6444\n",
      "[Baseline][545] Loss=0.1892, Acc=0.6390\n",
      "[Baseline][546] Loss=0.2109, Acc=0.6463\n",
      "[Baseline][547] Loss=0.1690, Acc=0.6454\n",
      "[Baseline][548] Loss=0.1387, Acc=0.6421\n",
      "[Baseline][549] Loss=0.1094, Acc=0.6475\n",
      "[Baseline][550] Loss=0.1087, Acc=0.6439\n",
      "[Baseline][551] Loss=0.1018, Acc=0.6416\n",
      "[Baseline][552] Loss=0.1284, Acc=0.6438\n",
      "[Baseline][553] Loss=0.1337, Acc=0.6410\n",
      "[Baseline][554] Loss=0.1256, Acc=0.6471\n",
      "[Baseline][555] Loss=0.0914, Acc=0.6490\n",
      "[Baseline][556] Loss=0.1092, Acc=0.6497\n",
      "[Baseline][557] Loss=0.1470, Acc=0.6424\n",
      "[Baseline][558] Loss=0.1152, Acc=0.6473\n",
      "[Baseline][559] Loss=0.1326, Acc=0.6468\n",
      "[Baseline][560] Loss=0.1785, Acc=0.6448\n",
      "[Baseline][561] Loss=0.1420, Acc=0.6378\n",
      "[Baseline][562] Loss=0.1160, Acc=0.6478\n",
      "[Baseline][563] Loss=0.1207, Acc=0.6468\n",
      "[Baseline][564] Loss=0.1180, Acc=0.6438\n",
      "[Baseline][565] Loss=0.1097, Acc=0.6496\n",
      "[Baseline][566] Loss=0.1072, Acc=0.6441\n",
      "[Baseline][567] Loss=0.1202, Acc=0.6381\n",
      "[Baseline][568] Loss=0.1109, Acc=0.6494\n",
      "[Baseline][569] Loss=0.1151, Acc=0.6484\n",
      "[Baseline][570] Loss=0.1273, Acc=0.6370\n",
      "[Baseline][571] Loss=0.1262, Acc=0.6450\n",
      "[Baseline][572] Loss=0.1225, Acc=0.6430\n",
      "[Baseline][573] Loss=0.1419, Acc=0.6440\n",
      "[Baseline][574] Loss=0.1120, Acc=0.6490\n",
      "[Baseline][575] Loss=0.1199, Acc=0.6485\n",
      "[Baseline][576] Loss=0.0946, Acc=0.6435\n",
      "[Baseline][577] Loss=0.1155, Acc=0.6459\n",
      "[Baseline][578] Loss=0.1025, Acc=0.6459\n",
      "[Baseline][579] Loss=0.1030, Acc=0.6402\n",
      "[Baseline][580] Loss=0.1068, Acc=0.6445\n",
      "[Baseline][581] Loss=0.1325, Acc=0.6446\n",
      "[Baseline][582] Loss=0.1538, Acc=0.6426\n",
      "[Baseline][583] Loss=0.1030, Acc=0.6463\n",
      "[Baseline][584] Loss=0.1090, Acc=0.6459\n",
      "[Baseline][585] Loss=0.1141, Acc=0.6413\n",
      "[Baseline][586] Loss=0.1353, Acc=0.6441\n",
      "[Baseline][587] Loss=0.1613, Acc=0.6466\n",
      "[Baseline][588] Loss=0.1642, Acc=0.6394\n",
      "[Baseline][589] Loss=0.1235, Acc=0.6423\n",
      "[Baseline][590] Loss=0.1135, Acc=0.6398\n",
      "[Baseline][591] Loss=0.1421, Acc=0.6419\n",
      "[Baseline][592] Loss=0.1177, Acc=0.6476\n",
      "[Baseline][593] Loss=0.1294, Acc=0.6449\n",
      "[Baseline][594] Loss=0.1235, Acc=0.6419\n",
      "[Baseline][595] Loss=0.1271, Acc=0.6436\n",
      "[Baseline][596] Loss=0.1359, Acc=0.6442\n",
      "[Baseline][597] Loss=0.1206, Acc=0.6469\n",
      "[Baseline][598] Loss=0.1259, Acc=0.6400\n",
      "[Baseline][599] Loss=0.1131, Acc=0.6392\n",
      "[Baseline][600] Loss=0.1094, Acc=0.6400\n",
      "[Baseline][601] Loss=0.1095, Acc=0.6465\n",
      "[Baseline][602] Loss=0.1258, Acc=0.6352\n",
      "[Baseline][603] Loss=0.1017, Acc=0.6440\n",
      "[Baseline][604] Loss=0.1050, Acc=0.6406\n",
      "[Baseline][605] Loss=0.1154, Acc=0.6432\n",
      "[Baseline][606] Loss=0.1349, Acc=0.6398\n",
      "[Baseline][607] Loss=0.1567, Acc=0.6367\n",
      "[Baseline][608] Loss=0.1232, Acc=0.6434\n",
      "[Baseline][609] Loss=0.1102, Acc=0.6436\n",
      "[Baseline][610] Loss=0.1107, Acc=0.6443\n",
      "[Baseline][611] Loss=0.1645, Acc=0.6394\n",
      "[Baseline][612] Loss=0.1467, Acc=0.6479\n",
      "[Baseline][613] Loss=0.2260, Acc=0.6335\n",
      "[Baseline][614] Loss=0.1504, Acc=0.6441\n",
      "[Baseline][615] Loss=0.1106, Acc=0.6458\n",
      "[Baseline][616] Loss=0.1569, Acc=0.6323\n",
      "[Baseline][617] Loss=0.1161, Acc=0.6375\n",
      "[Baseline][618] Loss=0.1082, Acc=0.6447\n",
      "[Baseline][619] Loss=0.1025, Acc=0.6464\n",
      "[Baseline][620] Loss=0.1026, Acc=0.6476\n",
      "[Baseline][621] Loss=0.1051, Acc=0.6498\n",
      "[Baseline][622] Loss=0.1013, Acc=0.6430\n",
      "[Baseline][623] Loss=0.1068, Acc=0.6469\n",
      "[Baseline][624] Loss=0.1138, Acc=0.6487\n",
      "[Baseline][625] Loss=0.1569, Acc=0.6394\n",
      "[Baseline][626] Loss=0.1073, Acc=0.6451\n",
      "[Baseline][627] Loss=0.0994, Acc=0.6453\n",
      "[Baseline][628] Loss=0.1018, Acc=0.6457\n",
      "[Baseline][629] Loss=0.1003, Acc=0.6482\n",
      "[Baseline][630] Loss=0.1082, Acc=0.6449\n",
      "[Baseline][631] Loss=0.1076, Acc=0.6463\n",
      "[Baseline][632] Loss=0.1192, Acc=0.6494\n",
      "[Baseline][633] Loss=0.0967, Acc=0.6536\n",
      "[Baseline][634] Loss=0.0919, Acc=0.6477\n",
      "[Baseline][635] Loss=0.0907, Acc=0.6537\n",
      "[Baseline][636] Loss=0.0950, Acc=0.6491\n",
      "[Baseline][637] Loss=0.1314, Acc=0.6501\n",
      "[Baseline][638] Loss=0.1158, Acc=0.6460\n",
      "[Baseline][639] Loss=0.1112, Acc=0.6468\n",
      "[Baseline][640] Loss=0.1086, Acc=0.6429\n",
      "[Baseline][641] Loss=0.1016, Acc=0.6490\n",
      "[Baseline][642] Loss=0.1028, Acc=0.6446\n",
      "[Baseline][643] Loss=0.1054, Acc=0.6437\n",
      "[Baseline][644] Loss=0.1026, Acc=0.6460\n",
      "[Baseline][645] Loss=0.1111, Acc=0.6427\n",
      "[Baseline][646] Loss=0.1445, Acc=0.6396\n",
      "[Baseline][647] Loss=0.1826, Acc=0.6418\n",
      "[Baseline][648] Loss=0.1285, Acc=0.6386\n",
      "[Baseline][649] Loss=0.1153, Acc=0.6432\n",
      "[Baseline][650] Loss=0.0985, Acc=0.6406\n",
      "[Baseline][651] Loss=0.1250, Acc=0.6456\n",
      "[Baseline][652] Loss=0.1177, Acc=0.6526\n",
      "[Baseline][653] Loss=0.1727, Acc=0.6407\n",
      "[Baseline][654] Loss=0.1497, Acc=0.6462\n",
      "[Baseline][655] Loss=0.1282, Acc=0.6405\n",
      "[Baseline][656] Loss=0.1151, Acc=0.6414\n",
      "[Baseline][657] Loss=0.1113, Acc=0.6442\n",
      "[Baseline][658] Loss=0.1082, Acc=0.6473\n",
      "[Baseline][659] Loss=0.1135, Acc=0.6440\n",
      "[Baseline][660] Loss=0.1104, Acc=0.6376\n",
      "[Baseline][661] Loss=0.0904, Acc=0.6501\n",
      "[Baseline][662] Loss=0.0965, Acc=0.6481\n",
      "[Baseline][663] Loss=0.1366, Acc=0.6438\n",
      "[Baseline][664] Loss=0.1613, Acc=0.6433\n",
      "[Baseline][665] Loss=0.1145, Acc=0.6449\n",
      "[Baseline][666] Loss=0.0874, Acc=0.6513\n",
      "[Baseline][667] Loss=0.0985, Acc=0.6476\n",
      "[Baseline][668] Loss=0.1018, Acc=0.6495\n",
      "[Baseline][669] Loss=0.1353, Acc=0.6384\n",
      "[Baseline][670] Loss=0.1024, Acc=0.6512\n",
      "[Baseline][671] Loss=0.0911, Acc=0.6416\n",
      "[Baseline][672] Loss=0.0977, Acc=0.6484\n",
      "[Baseline][673] Loss=0.1187, Acc=0.6443\n",
      "[Baseline][674] Loss=0.0937, Acc=0.6457\n",
      "[Baseline][675] Loss=0.1013, Acc=0.6409\n",
      "[Baseline][676] Loss=0.0830, Acc=0.6464\n",
      "[Baseline][677] Loss=0.0938, Acc=0.6448\n",
      "[Baseline][678] Loss=0.0971, Acc=0.6453\n",
      "[Baseline][679] Loss=0.0946, Acc=0.6448\n",
      "[Baseline][680] Loss=0.0976, Acc=0.6407\n",
      "[Baseline][681] Loss=0.1075, Acc=0.6497\n",
      "[Baseline][682] Loss=0.1398, Acc=0.6450\n",
      "[Baseline][683] Loss=0.1161, Acc=0.6529\n",
      "[Baseline][684] Loss=0.1025, Acc=0.6406\n",
      "[Baseline][685] Loss=0.1038, Acc=0.6437\n",
      "[Baseline][686] Loss=0.0876, Acc=0.6482\n",
      "[Baseline][687] Loss=0.1040, Acc=0.6450\n",
      "[Baseline][688] Loss=0.1452, Acc=0.6384\n",
      "[Baseline][689] Loss=0.1121, Acc=0.6394\n",
      "[Baseline][690] Loss=0.1071, Acc=0.6386\n",
      "[Baseline][691] Loss=0.0910, Acc=0.6415\n",
      "[Baseline][692] Loss=0.0897, Acc=0.6452\n",
      "[Baseline][693] Loss=0.1325, Acc=0.6432\n",
      "[Baseline][694] Loss=0.1106, Acc=0.6373\n",
      "[Baseline][695] Loss=0.1077, Acc=0.6477\n",
      "[Baseline][696] Loss=0.1039, Acc=0.6474\n",
      "[Baseline][697] Loss=0.0909, Acc=0.6489\n",
      "[Baseline][698] Loss=0.1478, Acc=0.6513\n",
      "[Baseline][699] Loss=0.1093, Acc=0.6414\n",
      "[Baseline][700] Loss=0.1025, Acc=0.6511\n",
      "[Baseline][701] Loss=0.0936, Acc=0.6476\n",
      "[Baseline][702] Loss=0.0979, Acc=0.6457\n",
      "[Baseline][703] Loss=0.0865, Acc=0.6460\n",
      "[Baseline][704] Loss=0.0909, Acc=0.6435\n",
      "[Baseline][705] Loss=0.0954, Acc=0.6489\n",
      "[Baseline][706] Loss=0.0774, Acc=0.6492\n",
      "[Baseline][707] Loss=0.0878, Acc=0.6460\n",
      "[Baseline][708] Loss=0.0948, Acc=0.6444\n",
      "[Baseline][709] Loss=0.0893, Acc=0.6476\n",
      "[Baseline][710] Loss=0.0972, Acc=0.6438\n",
      "[Baseline][711] Loss=0.1524, Acc=0.6354\n",
      "[Baseline][712] Loss=0.1131, Acc=0.6488\n",
      "[Baseline][713] Loss=0.1173, Acc=0.6402\n",
      "[Baseline][714] Loss=0.1097, Acc=0.6379\n",
      "[Baseline][715] Loss=0.0957, Acc=0.6396\n",
      "[Baseline][716] Loss=0.0949, Acc=0.6442\n",
      "[Baseline][717] Loss=0.1460, Acc=0.6409\n",
      "[Baseline][718] Loss=0.1054, Acc=0.6426\n",
      "[Baseline][719] Loss=0.1162, Acc=0.6404\n",
      "[Baseline][720] Loss=0.2075, Acc=0.6445\n",
      "[Baseline][721] Loss=0.1030, Acc=0.6411\n",
      "[Baseline][722] Loss=0.1104, Acc=0.6405\n",
      "[Baseline][723] Loss=0.0898, Acc=0.6424\n",
      "[Baseline][724] Loss=0.0879, Acc=0.6461\n",
      "[Baseline][725] Loss=0.0807, Acc=0.6455\n",
      "[Baseline][726] Loss=0.1002, Acc=0.6385\n",
      "[Baseline][727] Loss=0.0859, Acc=0.6411\n",
      "[Baseline][728] Loss=0.0785, Acc=0.6514\n",
      "[Baseline][729] Loss=0.0947, Acc=0.6436\n",
      "[Baseline][730] Loss=0.1034, Acc=0.6321\n",
      "[Baseline][731] Loss=0.0907, Acc=0.6349\n",
      "[Baseline][732] Loss=0.0812, Acc=0.6455\n",
      "[Baseline][733] Loss=0.1282, Acc=0.6297\n",
      "[Baseline][734] Loss=0.1465, Acc=0.6381\n",
      "[Baseline][735] Loss=0.1048, Acc=0.6445\n",
      "[Baseline][736] Loss=0.0958, Acc=0.6420\n",
      "[Baseline][737] Loss=0.0938, Acc=0.6354\n",
      "[Baseline][738] Loss=0.0925, Acc=0.6387\n",
      "[Baseline][739] Loss=0.0850, Acc=0.6453\n",
      "[Baseline][740] Loss=0.0792, Acc=0.6440\n",
      "[Baseline][741] Loss=0.0982, Acc=0.6455\n",
      "[Baseline][742] Loss=0.0802, Acc=0.6481\n",
      "[Baseline][743] Loss=0.0767, Acc=0.6480\n",
      "[Baseline][744] Loss=0.0829, Acc=0.6452\n",
      "[Baseline][745] Loss=0.1225, Acc=0.6395\n",
      "[Baseline][746] Loss=0.1234, Acc=0.6433\n",
      "[Baseline][747] Loss=0.1055, Acc=0.6343\n",
      "[Baseline][748] Loss=0.0774, Acc=0.6459\n",
      "[Baseline][749] Loss=0.0931, Acc=0.6479\n",
      "[Baseline][750] Loss=0.0980, Acc=0.6426\n",
      "[Baseline][751] Loss=0.0860, Acc=0.6487\n",
      "[Baseline][752] Loss=0.1106, Acc=0.6452\n",
      "[Baseline][753] Loss=0.1000, Acc=0.6436\n",
      "[Baseline][754] Loss=0.1139, Acc=0.6448\n",
      "[Baseline][755] Loss=0.1011, Acc=0.6421\n",
      "[Baseline][756] Loss=0.0871, Acc=0.6477\n",
      "[Baseline][757] Loss=0.0845, Acc=0.6466\n",
      "[Baseline][758] Loss=0.1045, Acc=0.6410\n",
      "[Baseline][759] Loss=0.1448, Acc=0.6384\n",
      "[Baseline][760] Loss=0.1099, Acc=0.6424\n",
      "[Baseline][761] Loss=0.1155, Acc=0.6434\n",
      "[Baseline][762] Loss=0.0744, Acc=0.6393\n",
      "[Baseline][763] Loss=0.1039, Acc=0.6471\n",
      "[Baseline][764] Loss=0.1519, Acc=0.6471\n",
      "[Baseline][765] Loss=0.0981, Acc=0.6381\n",
      "[Baseline][766] Loss=0.0983, Acc=0.6372\n",
      "[Baseline][767] Loss=0.1230, Acc=0.6436\n",
      "[Baseline][768] Loss=0.1444, Acc=0.6391\n",
      "[Baseline][769] Loss=0.1085, Acc=0.6445\n",
      "[Baseline][770] Loss=0.1134, Acc=0.6432\n",
      "[Baseline][771] Loss=0.0869, Acc=0.6447\n",
      "[Baseline][772] Loss=0.0928, Acc=0.6403\n",
      "[Baseline][773] Loss=0.1467, Acc=0.6406\n",
      "[Baseline][774] Loss=0.1020, Acc=0.6423\n",
      "[Baseline][775] Loss=0.1048, Acc=0.6471\n",
      "[Baseline][776] Loss=0.0872, Acc=0.6420\n",
      "[Baseline][777] Loss=0.0988, Acc=0.6421\n",
      "[Baseline][778] Loss=0.1063, Acc=0.6428\n",
      "[Baseline][779] Loss=0.1615, Acc=0.6326\n",
      "[Baseline][780] Loss=0.1018, Acc=0.6470\n",
      "[Baseline][781] Loss=0.0807, Acc=0.6445\n",
      "[Baseline][782] Loss=0.0798, Acc=0.6488\n",
      "[Baseline][783] Loss=0.0901, Acc=0.6464\n",
      "[Baseline][784] Loss=0.1273, Acc=0.6431\n",
      "[Baseline][785] Loss=0.0912, Acc=0.6469\n",
      "[Baseline][786] Loss=0.1009, Acc=0.6421\n",
      "[Baseline][787] Loss=0.0877, Acc=0.6460\n",
      "[Baseline][788] Loss=0.0852, Acc=0.6443\n",
      "[Baseline][789] Loss=0.0873, Acc=0.6414\n",
      "[Baseline][790] Loss=0.0889, Acc=0.6401\n",
      "[Baseline][791] Loss=0.0860, Acc=0.6390\n",
      "[Baseline][792] Loss=0.0833, Acc=0.6435\n",
      "[Baseline][793] Loss=0.1256, Acc=0.6339\n",
      "[Baseline][794] Loss=0.1071, Acc=0.6354\n",
      "[Baseline][795] Loss=0.1105, Acc=0.6367\n",
      "[Baseline][796] Loss=0.1615, Acc=0.6325\n",
      "[Baseline][797] Loss=0.1353, Acc=0.6331\n",
      "[Baseline][798] Loss=0.0987, Acc=0.6381\n",
      "[Baseline][799] Loss=0.0900, Acc=0.6405\n",
      "[Baseline][800] Loss=0.1194, Acc=0.6409\n",
      "[Baseline][801] Loss=0.0957, Acc=0.6371\n",
      "[Baseline][802] Loss=0.0785, Acc=0.6409\n",
      "[Baseline][803] Loss=0.1116, Acc=0.6399\n",
      "[Baseline][804] Loss=0.1006, Acc=0.6370\n",
      "[Baseline][805] Loss=0.1188, Acc=0.6382\n",
      "[Baseline][806] Loss=0.1179, Acc=0.6370\n",
      "[Baseline][807] Loss=0.1531, Acc=0.6341\n",
      "[Baseline][808] Loss=0.0889, Acc=0.6401\n",
      "[Baseline][809] Loss=0.0742, Acc=0.6371\n",
      "[Baseline][810] Loss=0.0759, Acc=0.6413\n",
      "[Baseline][811] Loss=0.0861, Acc=0.6397\n",
      "[Baseline][812] Loss=0.1133, Acc=0.6390\n",
      "[Baseline][813] Loss=0.0954, Acc=0.6339\n",
      "[Baseline][814] Loss=0.0838, Acc=0.6432\n",
      "[Baseline][815] Loss=0.0836, Acc=0.6425\n",
      "[Baseline][816] Loss=0.0999, Acc=0.6415\n",
      "[Baseline][817] Loss=0.1814, Acc=0.6384\n",
      "[Baseline][818] Loss=0.0867, Acc=0.6409\n",
      "[Baseline][819] Loss=0.0859, Acc=0.6354\n",
      "[Baseline][820] Loss=0.0879, Acc=0.6368\n",
      "[Baseline][821] Loss=0.0932, Acc=0.6380\n",
      "[Baseline][822] Loss=0.0751, Acc=0.6375\n",
      "[Baseline][823] Loss=0.0733, Acc=0.6381\n",
      "[Baseline][824] Loss=0.0874, Acc=0.6398\n",
      "[Baseline][825] Loss=0.1298, Acc=0.6373\n",
      "[Baseline][826] Loss=0.0873, Acc=0.6448\n",
      "[Baseline][827] Loss=0.0717, Acc=0.6414\n",
      "[Baseline][828] Loss=0.0835, Acc=0.6406\n",
      "[Baseline][829] Loss=0.0897, Acc=0.6397\n",
      "[Baseline][830] Loss=0.1126, Acc=0.6404\n",
      "[Baseline][831] Loss=0.1256, Acc=0.6403\n",
      "[Baseline][832] Loss=0.0882, Acc=0.6348\n",
      "[Baseline][833] Loss=0.0872, Acc=0.6406\n",
      "[Baseline][834] Loss=0.1569, Acc=0.6401\n",
      "[Baseline][835] Loss=0.0987, Acc=0.6442\n",
      "[Baseline][836] Loss=0.0792, Acc=0.6372\n",
      "[Baseline][837] Loss=0.0723, Acc=0.6395\n",
      "[Baseline][838] Loss=0.0795, Acc=0.6401\n",
      "[Baseline][839] Loss=0.0755, Acc=0.6407\n",
      "[Baseline][840] Loss=0.0741, Acc=0.6413\n",
      "[Baseline][841] Loss=0.0797, Acc=0.6434\n",
      "[Baseline][842] Loss=0.1262, Acc=0.6382\n",
      "[Baseline][843] Loss=0.0881, Acc=0.6427\n",
      "[Baseline][844] Loss=0.0897, Acc=0.6372\n",
      "[Baseline][845] Loss=0.0990, Acc=0.6401\n",
      "[Baseline][846] Loss=0.0967, Acc=0.6425\n",
      "[Baseline][847] Loss=0.0858, Acc=0.6325\n",
      "[Baseline][848] Loss=0.0846, Acc=0.6421\n",
      "[Baseline][849] Loss=0.1048, Acc=0.6427\n",
      "[Baseline][850] Loss=0.1179, Acc=0.6367\n",
      "[Baseline][851] Loss=0.1768, Acc=0.6383\n",
      "[Baseline][852] Loss=0.1101, Acc=0.6400\n",
      "[Baseline][853] Loss=0.0896, Acc=0.6428\n",
      "[Baseline][854] Loss=0.1025, Acc=0.6313\n",
      "[Baseline][855] Loss=0.0818, Acc=0.6412\n",
      "[Baseline][856] Loss=0.0880, Acc=0.6431\n",
      "[Baseline][857] Loss=0.0775, Acc=0.6426\n",
      "[Baseline][858] Loss=0.0773, Acc=0.6421\n",
      "[Baseline][859] Loss=0.0849, Acc=0.6420\n",
      "[Baseline][860] Loss=0.0840, Acc=0.6491\n",
      "[Baseline][861] Loss=0.1006, Acc=0.6404\n",
      "[Baseline][862] Loss=0.1571, Acc=0.6377\n",
      "[Baseline][863] Loss=0.1051, Acc=0.6326\n",
      "[Baseline][864] Loss=0.0925, Acc=0.6441\n",
      "[Baseline][865] Loss=0.1223, Acc=0.6380\n",
      "[Baseline][866] Loss=0.1184, Acc=0.6368\n",
      "[Baseline][867] Loss=0.0959, Acc=0.6423\n",
      "[Baseline][868] Loss=0.0968, Acc=0.6377\n",
      "[Baseline][869] Loss=0.0757, Acc=0.6374\n",
      "[Baseline][870] Loss=0.0764, Acc=0.6433\n",
      "[Baseline][871] Loss=0.0750, Acc=0.6476\n",
      "[Baseline][872] Loss=0.1170, Acc=0.6404\n",
      "[Baseline][873] Loss=0.0863, Acc=0.6393\n",
      "[Baseline][874] Loss=0.0829, Acc=0.6399\n",
      "[Baseline][875] Loss=0.0910, Acc=0.6429\n",
      "[Baseline][876] Loss=0.1853, Acc=0.6327\n",
      "[Baseline][877] Loss=0.0954, Acc=0.6412\n",
      "[Baseline][878] Loss=0.1165, Acc=0.6390\n",
      "[Baseline][879] Loss=0.0885, Acc=0.6409\n",
      "[Baseline][880] Loss=0.0696, Acc=0.6359\n",
      "[Baseline][881] Loss=0.0802, Acc=0.6434\n",
      "[Baseline][882] Loss=0.1094, Acc=0.6369\n",
      "[Baseline][883] Loss=0.1033, Acc=0.6404\n",
      "[Baseline][884] Loss=0.0881, Acc=0.6418\n",
      "[Baseline][885] Loss=0.0850, Acc=0.6416\n",
      "[Baseline][886] Loss=0.0849, Acc=0.6350\n",
      "[Baseline][887] Loss=0.1112, Acc=0.6314\n",
      "[Baseline][888] Loss=0.0749, Acc=0.6350\n",
      "[Baseline][889] Loss=0.0839, Acc=0.6353\n",
      "[Baseline][890] Loss=0.0761, Acc=0.6401\n",
      "[Baseline][891] Loss=0.0922, Acc=0.6449\n",
      "[Baseline][892] Loss=0.1126, Acc=0.6394\n",
      "[Baseline][893] Loss=0.1312, Acc=0.6417\n",
      "[Baseline][894] Loss=0.1012, Acc=0.6423\n",
      "[Baseline][895] Loss=0.0781, Acc=0.6446\n",
      "[Baseline][896] Loss=0.0716, Acc=0.6455\n",
      "[Baseline][897] Loss=0.0904, Acc=0.6446\n",
      "[Baseline][898] Loss=0.1544, Acc=0.6407\n",
      "[Baseline][899] Loss=0.0811, Acc=0.6443\n",
      "[Baseline][900] Loss=0.1404, Acc=0.6419\n",
      "[Baseline][901] Loss=0.0885, Acc=0.6436\n",
      "[Baseline][902] Loss=0.0795, Acc=0.6470\n",
      "[Baseline][903] Loss=0.0670, Acc=0.6485\n",
      "[Baseline][904] Loss=0.0683, Acc=0.6458\n",
      "[Baseline][905] Loss=0.0703, Acc=0.6477\n",
      "[Baseline][906] Loss=0.0997, Acc=0.6418\n",
      "[Baseline][907] Loss=0.1202, Acc=0.6422\n",
      "[Baseline][908] Loss=0.1001, Acc=0.6422\n",
      "[Baseline][909] Loss=0.0814, Acc=0.6461\n",
      "[Baseline][910] Loss=0.0797, Acc=0.6396\n",
      "[Baseline][911] Loss=0.0924, Acc=0.6379\n",
      "[Baseline][912] Loss=0.1101, Acc=0.6421\n",
      "[Baseline][913] Loss=0.0822, Acc=0.6428\n",
      "[Baseline][914] Loss=0.0787, Acc=0.6422\n",
      "[Baseline][915] Loss=0.1005, Acc=0.6385\n",
      "[Baseline][916] Loss=0.0766, Acc=0.6478\n",
      "[Baseline][917] Loss=0.0709, Acc=0.6379\n",
      "[Baseline][918] Loss=0.0927, Acc=0.6467\n",
      "[Baseline][919] Loss=0.0745, Acc=0.6481\n",
      "[Baseline][920] Loss=0.0681, Acc=0.6430\n",
      "[Baseline][921] Loss=0.0674, Acc=0.6460\n",
      "[Baseline][922] Loss=0.0753, Acc=0.6494\n",
      "[Baseline][923] Loss=0.0618, Acc=0.6472\n",
      "[Baseline][924] Loss=0.0708, Acc=0.6444\n",
      "[Baseline][925] Loss=0.0752, Acc=0.6488\n",
      "[Baseline][926] Loss=0.0754, Acc=0.6480\n",
      "[Baseline][927] Loss=0.0781, Acc=0.6429\n",
      "[Baseline][928] Loss=0.0908, Acc=0.6473\n",
      "[Baseline][929] Loss=0.1858, Acc=0.6387\n",
      "[Baseline][930] Loss=0.0925, Acc=0.6462\n",
      "[Baseline][931] Loss=0.0831, Acc=0.6436\n",
      "[Baseline][932] Loss=0.0796, Acc=0.6411\n",
      "[Baseline][933] Loss=0.0689, Acc=0.6488\n",
      "[Baseline][934] Loss=0.0628, Acc=0.6475\n",
      "[Baseline][935] Loss=0.0729, Acc=0.6480\n",
      "[Baseline][936] Loss=0.0858, Acc=0.6415\n",
      "[Baseline][937] Loss=0.0680, Acc=0.6390\n",
      "[Baseline][938] Loss=0.0713, Acc=0.6465\n",
      "[Baseline][939] Loss=0.0723, Acc=0.6492\n",
      "[Baseline][940] Loss=0.0725, Acc=0.6403\n",
      "[Baseline][941] Loss=0.0844, Acc=0.6467\n",
      "[Baseline][942] Loss=0.0787, Acc=0.6398\n",
      "[Baseline][943] Loss=0.1308, Acc=0.6386\n",
      "[Baseline][944] Loss=0.0953, Acc=0.6455\n",
      "[Baseline][945] Loss=0.0846, Acc=0.6405\n",
      "[Baseline][946] Loss=0.0831, Acc=0.6405\n",
      "[Baseline][947] Loss=0.0917, Acc=0.6428\n",
      "[Baseline][948] Loss=0.0841, Acc=0.6435\n",
      "[Baseline][949] Loss=0.0743, Acc=0.6378\n",
      "[Baseline][950] Loss=0.0790, Acc=0.6464\n",
      "[Baseline][951] Loss=0.0634, Acc=0.6432\n",
      "[Baseline][952] Loss=0.0655, Acc=0.6442\n",
      "[Baseline][953] Loss=0.0646, Acc=0.6459\n",
      "[Baseline][954] Loss=0.0763, Acc=0.6457\n",
      "[Baseline][955] Loss=0.0777, Acc=0.6401\n",
      "[Baseline][956] Loss=0.0807, Acc=0.6335\n",
      "[Baseline][957] Loss=0.1354, Acc=0.6362\n",
      "[Baseline][958] Loss=0.1746, Acc=0.6329\n",
      "[Baseline][959] Loss=0.1381, Acc=0.6381\n",
      "[Baseline][960] Loss=0.0962, Acc=0.6400\n",
      "[Baseline][961] Loss=0.0846, Acc=0.6441\n",
      "[Baseline][962] Loss=0.1055, Acc=0.6355\n",
      "[Baseline][963] Loss=0.1433, Acc=0.6442\n",
      "[Baseline][964] Loss=0.1031, Acc=0.6464\n",
      "[Baseline][965] Loss=0.0824, Acc=0.6467\n",
      "[Baseline][966] Loss=0.0796, Acc=0.6446\n",
      "[Baseline][967] Loss=0.0696, Acc=0.6440\n",
      "[Baseline][968] Loss=0.0821, Acc=0.6313\n",
      "[Baseline][969] Loss=0.0780, Acc=0.6425\n",
      "[Baseline][970] Loss=0.0601, Acc=0.6515\n",
      "[Baseline][971] Loss=0.0734, Acc=0.6416\n",
      "[Baseline][972] Loss=0.1659, Acc=0.6399\n",
      "[Baseline][973] Loss=0.0994, Acc=0.6472\n",
      "[Baseline][974] Loss=0.1516, Acc=0.6451\n",
      "[Baseline][975] Loss=0.2061, Acc=0.6430\n",
      "[Baseline][976] Loss=0.1676, Acc=0.6433\n",
      "[Baseline][977] Loss=0.1005, Acc=0.6341\n",
      "[Baseline][978] Loss=0.0799, Acc=0.6438\n",
      "[Baseline][979] Loss=0.0731, Acc=0.6444\n",
      "[Baseline][980] Loss=0.0718, Acc=0.6439\n",
      "[Baseline][981] Loss=0.1094, Acc=0.6404\n",
      "[Baseline][982] Loss=0.0908, Acc=0.6447\n",
      "[Baseline][983] Loss=0.0933, Acc=0.6461\n",
      "[Baseline][984] Loss=0.0722, Acc=0.6464\n",
      "[Baseline][985] Loss=0.0887, Acc=0.6395\n",
      "[Baseline][986] Loss=0.1041, Acc=0.6395\n",
      "[Baseline][987] Loss=0.0753, Acc=0.6421\n",
      "[Baseline][988] Loss=0.0650, Acc=0.6414\n",
      "[Baseline][989] Loss=0.0589, Acc=0.6436\n",
      "[Baseline][990] Loss=0.0724, Acc=0.6446\n",
      "[Baseline][991] Loss=0.0643, Acc=0.6469\n",
      "[Baseline][992] Loss=0.0715, Acc=0.6449\n",
      "[Baseline][993] Loss=0.0588, Acc=0.6458\n",
      "[Baseline][994] Loss=0.0543, Acc=0.6488\n",
      "[Baseline][995] Loss=0.0717, Acc=0.6448\n",
      "[Baseline][996] Loss=0.0659, Acc=0.6429\n",
      "[Baseline][997] Loss=0.0571, Acc=0.6422\n",
      "[Baseline][998] Loss=0.0667, Acc=0.6427\n",
      "[Baseline][999] Loss=0.0653, Acc=0.6438\n",
      "[Baseline][1000] Loss=0.0590, Acc=0.6483\n",
      "[Baseline][1001] Loss=0.0800, Acc=0.6438\n",
      "[Baseline][1002] Loss=0.0655, Acc=0.6430\n",
      "[Baseline][1003] Loss=0.0696, Acc=0.6493\n",
      "[Baseline][1004] Loss=0.1703, Acc=0.6388\n",
      "[Baseline][1005] Loss=0.1008, Acc=0.6466\n",
      "[Baseline][1006] Loss=0.1873, Acc=0.6344\n",
      "[Baseline][1007] Loss=0.1020, Acc=0.6442\n",
      "[Baseline][1008] Loss=0.1276, Acc=0.6395\n",
      "[Baseline][1009] Loss=0.0840, Acc=0.6429\n",
      "[Baseline][1010] Loss=0.1068, Acc=0.6472\n",
      "[Baseline][1011] Loss=0.0848, Acc=0.6390\n",
      "[Baseline][1012] Loss=0.0549, Acc=0.6417\n",
      "[Baseline][1013] Loss=0.0844, Acc=0.6408\n",
      "[Baseline][1014] Loss=0.0701, Acc=0.6399\n",
      "[Baseline][1015] Loss=0.0960, Acc=0.6421\n",
      "[Baseline][1016] Loss=0.1131, Acc=0.6417\n",
      "[Baseline][1017] Loss=0.0970, Acc=0.6393\n",
      "[Baseline][1018] Loss=0.0912, Acc=0.6417\n",
      "[Baseline][1019] Loss=0.1917, Acc=0.6353\n",
      "[Baseline][1020] Loss=0.0787, Acc=0.6455\n",
      "[Baseline][1021] Loss=0.0703, Acc=0.6407\n",
      "[Baseline][1022] Loss=0.0688, Acc=0.6445\n",
      "[Baseline][1023] Loss=0.0669, Acc=0.6446\n",
      "[Baseline][1024] Loss=0.0702, Acc=0.6460\n",
      "[Baseline][1025] Loss=0.0788, Acc=0.6457\n",
      "[Baseline][1026] Loss=0.0578, Acc=0.6448\n",
      "[Baseline][1027] Loss=0.0856, Acc=0.6432\n",
      "[Baseline][1028] Loss=0.1059, Acc=0.6453\n",
      "[Baseline][1029] Loss=0.0741, Acc=0.6472\n",
      "[Baseline][1030] Loss=0.0671, Acc=0.6457\n",
      "[Baseline][1031] Loss=0.0639, Acc=0.6492\n",
      "[Baseline][1032] Loss=0.0683, Acc=0.6418\n",
      "[Baseline][1033] Loss=0.0645, Acc=0.6459\n",
      "[Baseline][1034] Loss=0.0606, Acc=0.6414\n",
      "[Baseline][1035] Loss=0.0797, Acc=0.6425\n",
      "[Baseline][1036] Loss=0.0674, Acc=0.6459\n",
      "[Baseline][1037] Loss=0.0670, Acc=0.6424\n",
      "[Baseline][1038] Loss=0.0544, Acc=0.6471\n",
      "[Baseline][1039] Loss=0.0549, Acc=0.6457\n",
      "[Baseline][1040] Loss=0.0667, Acc=0.6427\n",
      "[Baseline][1041] Loss=0.1137, Acc=0.6385\n",
      "[Baseline][1042] Loss=0.0758, Acc=0.6451\n",
      "[Baseline][1043] Loss=0.0749, Acc=0.6433\n",
      "[Baseline][1044] Loss=0.0707, Acc=0.6503\n",
      "[Baseline][1045] Loss=0.0542, Acc=0.6472\n",
      "[Baseline][1046] Loss=0.0747, Acc=0.6463\n",
      "[Baseline][1047] Loss=0.0948, Acc=0.6478\n",
      "[Baseline][1048] Loss=0.0819, Acc=0.6482\n",
      "[Baseline][1049] Loss=0.0632, Acc=0.6449\n",
      "[Baseline][1050] Loss=0.0542, Acc=0.6478\n",
      "[Baseline][1051] Loss=0.0613, Acc=0.6454\n",
      "[Baseline][1052] Loss=0.0680, Acc=0.6430\n",
      "[Baseline][1053] Loss=0.0719, Acc=0.6448\n",
      "[Baseline][1054] Loss=0.0683, Acc=0.6425\n",
      "[Baseline][1055] Loss=0.0819, Acc=0.6416\n",
      "[Baseline][1056] Loss=0.0820, Acc=0.6435\n",
      "[Baseline][1057] Loss=0.0650, Acc=0.6409\n",
      "[Baseline][1058] Loss=0.0677, Acc=0.6387\n",
      "[Baseline][1059] Loss=0.0600, Acc=0.6446\n",
      "[Baseline][1060] Loss=0.0824, Acc=0.6439\n",
      "[Baseline][1061] Loss=0.0733, Acc=0.6475\n",
      "[Baseline][1062] Loss=0.0810, Acc=0.6449\n",
      "[Baseline][1063] Loss=0.0612, Acc=0.6452\n",
      "[Baseline][1064] Loss=0.0818, Acc=0.6405\n",
      "[Baseline][1065] Loss=0.0604, Acc=0.6375\n",
      "[Baseline][1066] Loss=0.1110, Acc=0.6447\n",
      "[Baseline][1067] Loss=0.0910, Acc=0.6415\n",
      "[Baseline][1068] Loss=0.0800, Acc=0.6453\n",
      "[Baseline][1069] Loss=0.1077, Acc=0.6325\n",
      "[Baseline][1070] Loss=0.0947, Acc=0.6415\n",
      "[Baseline][1071] Loss=0.0623, Acc=0.6438\n",
      "[Baseline][1072] Loss=0.0808, Acc=0.6392\n",
      "[Baseline][1073] Loss=0.1406, Acc=0.6446\n",
      "[Baseline][1074] Loss=0.1006, Acc=0.6405\n",
      "[Baseline][1075] Loss=0.1462, Acc=0.6479\n",
      "[Baseline][1076] Loss=0.0847, Acc=0.6456\n",
      "[Baseline][1077] Loss=0.0836, Acc=0.6486\n",
      "[Baseline][1078] Loss=0.0987, Acc=0.6444\n",
      "[Baseline][1079] Loss=0.0916, Acc=0.6520\n",
      "[Baseline][1080] Loss=0.1251, Acc=0.6476\n",
      "[Baseline][1081] Loss=0.0886, Acc=0.6443\n",
      "[Baseline][1082] Loss=0.0742, Acc=0.6399\n",
      "[Baseline][1083] Loss=0.0831, Acc=0.6436\n",
      "[Baseline][1084] Loss=0.1035, Acc=0.6493\n",
      "[Baseline][1085] Loss=0.0745, Acc=0.6422\n",
      "[Baseline][1086] Loss=0.0817, Acc=0.6475\n",
      "[Baseline][1087] Loss=0.0644, Acc=0.6499\n",
      "[Baseline][1088] Loss=0.0621, Acc=0.6426\n",
      "[Baseline][1089] Loss=0.0693, Acc=0.6472\n",
      "[Baseline][1090] Loss=0.0645, Acc=0.6460\n",
      "[Baseline][1091] Loss=0.0687, Acc=0.6447\n",
      "[Baseline][1092] Loss=0.0574, Acc=0.6476\n",
      "[Baseline][1093] Loss=0.0579, Acc=0.6477\n",
      "[Baseline][1094] Loss=0.0574, Acc=0.6489\n",
      "[Baseline][1095] Loss=0.0701, Acc=0.6479\n",
      "[Baseline][1096] Loss=0.0867, Acc=0.6517\n",
      "[Baseline][1097] Loss=0.1648, Acc=0.6416\n",
      "[Baseline][1098] Loss=0.1560, Acc=0.6446\n",
      "[Baseline][1099] Loss=0.0836, Acc=0.6436\n",
      "[Baseline][1100] Loss=0.0804, Acc=0.6461\n",
      "[Baseline][1101] Loss=0.0752, Acc=0.6483\n",
      "[Baseline][1102] Loss=0.0721, Acc=0.6462\n",
      "[Baseline][1103] Loss=0.0970, Acc=0.6494\n",
      "[Baseline][1104] Loss=0.0605, Acc=0.6529\n",
      "[Baseline][1105] Loss=0.0677, Acc=0.6496\n",
      "[Baseline][1106] Loss=0.1152, Acc=0.6439\n",
      "[Baseline][1107] Loss=0.1006, Acc=0.6488\n",
      "[Baseline][1108] Loss=0.1140, Acc=0.6452\n",
      "[Baseline][1109] Loss=0.0759, Acc=0.6498\n",
      "[Baseline][1110] Loss=0.0746, Acc=0.6456\n",
      "[Baseline][1111] Loss=0.0686, Acc=0.6470\n",
      "[Baseline][1112] Loss=0.0874, Acc=0.6433\n",
      "[Baseline][1113] Loss=0.0839, Acc=0.6474\n",
      "[Baseline][1114] Loss=0.0754, Acc=0.6476\n",
      "[Baseline][1115] Loss=0.0890, Acc=0.6445\n",
      "[Baseline][1116] Loss=0.0730, Acc=0.6428\n",
      "[Baseline][1117] Loss=0.0573, Acc=0.6510\n",
      "[Baseline][1118] Loss=0.0608, Acc=0.6498\n",
      "[Baseline][1119] Loss=0.0562, Acc=0.6481\n",
      "[Baseline][1120] Loss=0.0720, Acc=0.6458\n",
      "[Baseline][1121] Loss=0.0515, Acc=0.6452\n",
      "[Baseline][1122] Loss=0.0564, Acc=0.6508\n",
      "[Baseline][1123] Loss=0.0634, Acc=0.6422\n",
      "[Baseline][1124] Loss=0.1289, Acc=0.6485\n",
      "[Baseline][1125] Loss=0.0955, Acc=0.6458\n",
      "[Baseline][1126] Loss=0.0843, Acc=0.6497\n",
      "[Baseline][1127] Loss=0.0633, Acc=0.6457\n",
      "[Baseline][1128] Loss=0.0538, Acc=0.6492\n",
      "[Baseline][1129] Loss=0.0569, Acc=0.6496\n",
      "[Baseline][1130] Loss=0.0656, Acc=0.6464\n",
      "[Baseline][1131] Loss=0.0600, Acc=0.6502\n",
      "[Baseline][1132] Loss=0.0534, Acc=0.6412\n",
      "[Baseline][1133] Loss=0.0631, Acc=0.6470\n",
      "[Baseline][1134] Loss=0.0672, Acc=0.6439\n",
      "[Baseline][1135] Loss=0.1164, Acc=0.6469\n",
      "[Baseline][1136] Loss=0.0736, Acc=0.6421\n",
      "[Baseline][1137] Loss=0.0631, Acc=0.6505\n",
      "[Baseline][1138] Loss=0.0664, Acc=0.6473\n",
      "[Baseline][1139] Loss=0.0730, Acc=0.6488\n",
      "[Baseline][1140] Loss=0.1574, Acc=0.6387\n",
      "[Baseline][1141] Loss=0.0746, Acc=0.6412\n",
      "[Baseline][1142] Loss=0.0703, Acc=0.6432\n",
      "[Baseline][1143] Loss=0.0542, Acc=0.6427\n",
      "[Baseline][1144] Loss=0.0551, Acc=0.6488\n",
      "[Baseline][1145] Loss=0.0730, Acc=0.6449\n",
      "[Baseline][1146] Loss=0.1007, Acc=0.6422\n",
      "[Baseline][1147] Loss=0.0864, Acc=0.6407\n",
      "[Baseline][1148] Loss=0.0730, Acc=0.6387\n",
      "[Baseline][1149] Loss=0.1099, Acc=0.6430\n",
      "[Baseline][1150] Loss=0.0792, Acc=0.6466\n",
      "[Baseline][1151] Loss=0.0810, Acc=0.6388\n",
      "[Baseline][1152] Loss=0.0748, Acc=0.6483\n",
      "[Baseline][1153] Loss=0.0575, Acc=0.6439\n",
      "[Baseline][1154] Loss=0.0730, Acc=0.6493\n",
      "[Baseline][1155] Loss=0.0741, Acc=0.6467\n",
      "[Baseline][1156] Loss=0.0861, Acc=0.6407\n",
      "[Baseline][1157] Loss=0.0737, Acc=0.6395\n",
      "[Baseline][1158] Loss=0.0694, Acc=0.6474\n",
      "[Baseline][1159] Loss=0.0604, Acc=0.6438\n",
      "[Baseline][1160] Loss=0.0652, Acc=0.6419\n",
      "[Baseline][1161] Loss=0.0738, Acc=0.6448\n",
      "[Baseline][1162] Loss=0.0647, Acc=0.6401\n",
      "[Baseline][1163] Loss=0.0714, Acc=0.6404\n",
      "[Baseline][1164] Loss=0.0643, Acc=0.6445\n",
      "[Baseline][1165] Loss=0.0719, Acc=0.6432\n",
      "[Baseline][1166] Loss=0.0495, Acc=0.6409\n",
      "[Baseline][1167] Loss=0.0691, Acc=0.6420\n",
      "[Baseline][1168] Loss=0.0514, Acc=0.6420\n",
      "[Baseline][1169] Loss=0.0626, Acc=0.6432\n",
      "[Baseline][1170] Loss=0.0630, Acc=0.6450\n",
      "[Baseline][1171] Loss=0.0552, Acc=0.6462\n",
      "[Baseline][1172] Loss=0.0587, Acc=0.6492\n",
      "[Baseline][1173] Loss=0.0567, Acc=0.6499\n",
      "[Baseline][1174] Loss=0.0640, Acc=0.6454\n",
      "[Baseline][1175] Loss=0.0756, Acc=0.6392\n",
      "[Baseline][1176] Loss=0.1320, Acc=0.6354\n",
      "[Baseline][1177] Loss=0.1173, Acc=0.6401\n",
      "[Baseline][1178] Loss=0.1595, Acc=0.6390\n",
      "[Baseline][1179] Loss=0.0910, Acc=0.6319\n",
      "[Baseline][1180] Loss=0.0782, Acc=0.6423\n",
      "[Baseline][1181] Loss=0.1178, Acc=0.6416\n",
      "[Baseline][1182] Loss=0.1622, Acc=0.6345\n",
      "[Baseline][1183] Loss=0.0971, Acc=0.6336\n",
      "[Baseline][1184] Loss=0.0789, Acc=0.6414\n",
      "[Baseline][1185] Loss=0.0894, Acc=0.6458\n",
      "[Baseline][1186] Loss=0.1022, Acc=0.6375\n",
      "[Baseline][1187] Loss=0.1889, Acc=0.6395\n",
      "[Baseline][1188] Loss=0.0781, Acc=0.6440\n",
      "[Baseline][1189] Loss=0.1186, Acc=0.6403\n",
      "[Baseline][1190] Loss=0.1168, Acc=0.6417\n",
      "[Baseline][1191] Loss=0.1296, Acc=0.6397\n",
      "[Baseline][1192] Loss=0.0787, Acc=0.6427\n",
      "[Baseline][1193] Loss=0.0791, Acc=0.6466\n",
      "[Baseline][1194] Loss=0.0680, Acc=0.6434\n",
      "[Baseline][1195] Loss=0.0611, Acc=0.6417\n",
      "[Baseline][1196] Loss=0.0656, Acc=0.6477\n",
      "[Baseline][1197] Loss=0.0569, Acc=0.6488\n",
      "[Baseline][1198] Loss=0.0641, Acc=0.6416\n",
      "[Baseline][1199] Loss=0.0496, Acc=0.6503\n",
      "[Baseline][1200] Loss=0.0508, Acc=0.6496\n",
      "[Baseline][1201] Loss=0.0513, Acc=0.6432\n",
      "[Baseline][1202] Loss=0.0554, Acc=0.6469\n",
      "[Baseline][1203] Loss=0.0526, Acc=0.6454\n",
      "[Baseline][1204] Loss=0.0595, Acc=0.6482\n",
      "[Baseline][1205] Loss=0.0690, Acc=0.6487\n",
      "[Baseline][1206] Loss=0.0989, Acc=0.6461\n",
      "[Baseline][1207] Loss=0.0813, Acc=0.6419\n",
      "[Baseline][1208] Loss=0.0565, Acc=0.6477\n",
      "[Baseline][1209] Loss=0.0572, Acc=0.6465\n",
      "[Baseline][1210] Loss=0.0527, Acc=0.6453\n",
      "[Baseline][1211] Loss=0.0584, Acc=0.6462\n",
      "[Baseline][1212] Loss=0.0775, Acc=0.6470\n",
      "[Baseline][1213] Loss=0.0622, Acc=0.6443\n",
      "[Baseline][1214] Loss=0.0728, Acc=0.6422\n",
      "[Baseline][1215] Loss=0.0704, Acc=0.6428\n",
      "[Baseline][1216] Loss=0.1278, Acc=0.6409\n",
      "[Baseline][1217] Loss=0.0994, Acc=0.6391\n",
      "[Baseline][1218] Loss=0.0651, Acc=0.6386\n",
      "[Baseline][1219] Loss=0.0617, Acc=0.6445\n",
      "[Baseline][1220] Loss=0.0576, Acc=0.6459\n",
      "[Baseline][1221] Loss=0.0592, Acc=0.6447\n",
      "[Baseline][1222] Loss=0.0645, Acc=0.6499\n",
      "[Baseline][1223] Loss=0.0928, Acc=0.6379\n",
      "[Baseline][1224] Loss=0.0658, Acc=0.6392\n",
      "[Baseline][1225] Loss=0.0986, Acc=0.6365\n",
      "[Baseline][1226] Loss=0.1547, Acc=0.6367\n",
      "[Baseline][1227] Loss=0.0745, Acc=0.6412\n",
      "[Baseline][1228] Loss=0.0670, Acc=0.6414\n",
      "[Baseline][1229] Loss=0.0548, Acc=0.6493\n",
      "[Baseline][1230] Loss=0.0586, Acc=0.6408\n",
      "[Baseline][1231] Loss=0.0528, Acc=0.6514\n",
      "[Baseline][1232] Loss=0.0700, Acc=0.6498\n",
      "[Baseline][1233] Loss=0.0604, Acc=0.6460\n",
      "[Baseline][1234] Loss=0.1285, Acc=0.6361\n",
      "[Baseline][1235] Loss=0.1648, Acc=0.6430\n",
      "[Baseline][1236] Loss=0.0920, Acc=0.6440\n",
      "[Baseline][1237] Loss=0.0672, Acc=0.6400\n",
      "[Baseline][1238] Loss=0.0839, Acc=0.6446\n",
      "[Baseline][1239] Loss=0.0652, Acc=0.6415\n",
      "[Baseline][1240] Loss=0.0607, Acc=0.6413\n",
      "[Baseline][1241] Loss=0.0598, Acc=0.6461\n",
      "[Baseline][1242] Loss=0.0786, Acc=0.6521\n",
      "[Baseline][1243] Loss=0.1825, Acc=0.6373\n",
      "[Baseline][1244] Loss=0.0792, Acc=0.6442\n",
      "[Baseline][1245] Loss=0.0587, Acc=0.6438\n",
      "[Baseline][1246] Loss=0.0599, Acc=0.6421\n",
      "[Baseline][1247] Loss=0.0538, Acc=0.6403\n",
      "[Baseline][1248] Loss=0.0800, Acc=0.6386\n",
      "[Baseline][1249] Loss=0.1025, Acc=0.6368\n",
      "[Baseline][1250] Loss=0.1682, Acc=0.6387\n",
      "[Baseline][1251] Loss=0.1044, Acc=0.6436\n",
      "[Baseline][1252] Loss=0.0806, Acc=0.6432\n",
      "[Baseline][1253] Loss=0.1023, Acc=0.6439\n",
      "[Baseline][1254] Loss=0.0841, Acc=0.6420\n",
      "[Baseline][1255] Loss=0.0734, Acc=0.6456\n",
      "[Baseline][1256] Loss=0.0686, Acc=0.6435\n",
      "[Baseline][1257] Loss=0.0600, Acc=0.6439\n",
      "[Baseline][1258] Loss=0.0547, Acc=0.6478\n",
      "[Baseline][1259] Loss=0.0518, Acc=0.6428\n",
      "[Baseline][1260] Loss=0.0466, Acc=0.6391\n",
      "[Baseline][1261] Loss=0.0593, Acc=0.6480\n",
      "[Baseline][1262] Loss=0.0620, Acc=0.6500\n",
      "[Baseline][1263] Loss=0.0849, Acc=0.6427\n",
      "[Baseline][1264] Loss=0.0516, Acc=0.6472\n",
      "[Baseline][1265] Loss=0.0526, Acc=0.6455\n",
      "[Baseline][1266] Loss=0.0551, Acc=0.6492\n",
      "[Baseline][1267] Loss=0.0660, Acc=0.6403\n",
      "[Baseline][1268] Loss=0.0521, Acc=0.6420\n",
      "[Baseline][1269] Loss=0.0477, Acc=0.6425\n",
      "[Baseline][1270] Loss=0.0500, Acc=0.6458\n",
      "[Baseline][1271] Loss=0.0520, Acc=0.6472\n",
      "[Baseline][1272] Loss=0.0696, Acc=0.6450\n",
      "[Baseline][1273] Loss=0.0531, Acc=0.6432\n",
      "[Baseline][1274] Loss=0.0555, Acc=0.6380\n",
      "[Baseline][1275] Loss=0.0521, Acc=0.6515\n",
      "[Baseline][1276] Loss=0.0506, Acc=0.6451\n",
      "[Baseline][1277] Loss=0.0584, Acc=0.6496\n",
      "[Baseline][1278] Loss=0.1144, Acc=0.6436\n",
      "[Baseline][1279] Loss=0.1134, Acc=0.6349\n",
      "[Baseline][1280] Loss=0.0816, Acc=0.6467\n",
      "[Baseline][1281] Loss=0.0569, Acc=0.6495\n",
      "[Baseline][1282] Loss=0.0548, Acc=0.6496\n",
      "[Baseline][1283] Loss=0.0526, Acc=0.6498\n",
      "[Baseline][1284] Loss=0.0465, Acc=0.6436\n",
      "[Baseline][1285] Loss=0.0519, Acc=0.6504\n",
      "[Baseline][1286] Loss=0.0530, Acc=0.6434\n",
      "[Baseline][1287] Loss=0.0610, Acc=0.6429\n",
      "[Baseline][1288] Loss=0.0646, Acc=0.6402\n",
      "[Baseline][1289] Loss=0.0558, Acc=0.6392\n",
      "[Baseline][1290] Loss=0.0688, Acc=0.6410\n",
      "[Baseline][1291] Loss=0.0848, Acc=0.6406\n",
      "[Baseline][1292] Loss=0.0588, Acc=0.6420\n",
      "[Baseline][1293] Loss=0.0592, Acc=0.6421\n",
      "[Baseline][1294] Loss=0.0540, Acc=0.6446\n",
      "[Baseline][1295] Loss=0.0485, Acc=0.6360\n",
      "[Baseline][1296] Loss=0.0515, Acc=0.6412\n",
      "[Baseline][1297] Loss=0.0472, Acc=0.6414\n",
      "[Baseline][1298] Loss=0.0557, Acc=0.6459\n",
      "[Baseline][1299] Loss=0.0591, Acc=0.6454\n",
      "[Baseline][1300] Loss=0.0974, Acc=0.6412\n",
      "[Baseline][1301] Loss=0.1062, Acc=0.6393\n",
      "[Baseline][1302] Loss=0.0765, Acc=0.6396\n",
      "[Baseline][1303] Loss=0.0592, Acc=0.6372\n",
      "[Baseline][1304] Loss=0.0693, Acc=0.6431\n",
      "[Baseline][1305] Loss=0.0668, Acc=0.6438\n",
      "[Baseline][1306] Loss=0.0765, Acc=0.6430\n",
      "[Baseline][1307] Loss=0.0904, Acc=0.6389\n",
      "[Baseline][1308] Loss=0.0759, Acc=0.6436\n",
      "[Baseline][1309] Loss=0.0771, Acc=0.6482\n",
      "[Baseline][1310] Loss=0.1401, Acc=0.6420\n",
      "[Baseline][1311] Loss=0.0955, Acc=0.6412\n",
      "[Baseline][1312] Loss=0.0637, Acc=0.6401\n",
      "[Baseline][1313] Loss=0.0646, Acc=0.6455\n",
      "[Baseline][1314] Loss=0.0552, Acc=0.6446\n",
      "[Baseline][1315] Loss=0.0564, Acc=0.6424\n",
      "[Baseline][1316] Loss=0.0654, Acc=0.6454\n",
      "[Baseline][1317] Loss=0.0575, Acc=0.6364\n",
      "[Baseline][1318] Loss=0.0603, Acc=0.6475\n",
      "[Baseline][1319] Loss=0.0545, Acc=0.6459\n",
      "[Baseline][1320] Loss=0.0544, Acc=0.6433\n",
      "[Baseline][1321] Loss=0.0550, Acc=0.6477\n",
      "[Baseline][1322] Loss=0.0835, Acc=0.6413\n",
      "[Baseline][1323] Loss=0.0758, Acc=0.6489\n",
      "[Baseline][1324] Loss=0.0640, Acc=0.6407\n",
      "[Baseline][1325] Loss=0.0547, Acc=0.6453\n",
      "[Baseline][1326] Loss=0.0737, Acc=0.6422\n",
      "[Baseline][1327] Loss=0.1078, Acc=0.6335\n",
      "[Baseline][1328] Loss=0.1669, Acc=0.6336\n",
      "[Baseline][1329] Loss=0.1239, Acc=0.6372\n",
      "[Baseline][1330] Loss=0.0881, Acc=0.6395\n",
      "[Baseline][1331] Loss=0.0866, Acc=0.6430\n",
      "[Baseline][1332] Loss=0.0622, Acc=0.6436\n",
      "[Baseline][1333] Loss=0.0886, Acc=0.6405\n",
      "[Baseline][1334] Loss=0.0617, Acc=0.6451\n",
      "[Baseline][1335] Loss=0.0657, Acc=0.6460\n",
      "[Baseline][1336] Loss=0.0536, Acc=0.6459\n",
      "[Baseline][1337] Loss=0.0495, Acc=0.6473\n",
      "[Baseline][1338] Loss=0.0593, Acc=0.6451\n",
      "[Baseline][1339] Loss=0.1725, Acc=0.6409\n",
      "[Baseline][1340] Loss=0.0997, Acc=0.6370\n",
      "[Baseline][1341] Loss=0.0647, Acc=0.6479\n",
      "[Baseline][1342] Loss=0.0597, Acc=0.6461\n",
      "[Baseline][1343] Loss=0.0489, Acc=0.6404\n",
      "[Baseline][1344] Loss=0.1011, Acc=0.6431\n",
      "[Baseline][1345] Loss=0.0619, Acc=0.6385\n",
      "[Baseline][1346] Loss=0.0509, Acc=0.6405\n",
      "[Baseline][1347] Loss=0.0549, Acc=0.6446\n",
      "[Baseline][1348] Loss=0.0570, Acc=0.6365\n",
      "[Baseline][1349] Loss=0.0555, Acc=0.6413\n",
      "[Baseline][1350] Loss=0.0517, Acc=0.6408\n",
      "[Baseline][1351] Loss=0.0594, Acc=0.6437\n",
      "[Baseline][1352] Loss=0.0490, Acc=0.6385\n",
      "[Baseline][1353] Loss=0.0714, Acc=0.6412\n",
      "[Baseline][1354] Loss=0.1596, Acc=0.6347\n",
      "[Baseline][1355] Loss=0.0863, Acc=0.6361\n",
      "[Baseline][1356] Loss=0.0914, Acc=0.6382\n",
      "[Baseline][1357] Loss=0.0544, Acc=0.6399\n",
      "[Baseline][1358] Loss=0.0545, Acc=0.6447\n",
      "[Baseline][1359] Loss=0.0554, Acc=0.6393\n",
      "[Baseline][1360] Loss=0.0660, Acc=0.6376\n",
      "[Baseline][1361] Loss=0.0526, Acc=0.6415\n",
      "[Baseline][1362] Loss=0.0471, Acc=0.6464\n",
      "[Baseline][1363] Loss=0.0570, Acc=0.6408\n",
      "[Baseline][1364] Loss=0.0831, Acc=0.6471\n",
      "[Baseline][1365] Loss=0.0666, Acc=0.6470\n",
      "[Baseline][1366] Loss=0.0665, Acc=0.6378\n",
      "[Baseline][1367] Loss=0.0641, Acc=0.6471\n",
      "[Baseline][1368] Loss=0.0488, Acc=0.6466\n",
      "[Baseline][1369] Loss=0.0444, Acc=0.6466\n",
      "[Baseline][1370] Loss=0.0429, Acc=0.6419\n",
      "[Baseline][1371] Loss=0.0486, Acc=0.6359\n",
      "[Baseline][1372] Loss=0.0574, Acc=0.6401\n",
      "[Baseline][1373] Loss=0.0544, Acc=0.6409\n",
      "[Baseline][1374] Loss=0.0609, Acc=0.6428\n",
      "[Baseline][1375] Loss=0.0798, Acc=0.6367\n",
      "[Baseline][1376] Loss=0.0462, Acc=0.6384\n",
      "[Baseline][1377] Loss=0.0619, Acc=0.6407\n",
      "[Baseline][1378] Loss=0.0555, Acc=0.6355\n",
      "[Baseline][1379] Loss=0.0512, Acc=0.6392\n",
      "[Baseline][1380] Loss=0.0638, Acc=0.6396\n",
      "[Baseline][1381] Loss=0.0736, Acc=0.6421\n",
      "[Baseline][1382] Loss=0.0735, Acc=0.6392\n",
      "[Baseline][1383] Loss=0.0654, Acc=0.6430\n",
      "[Baseline][1384] Loss=0.0576, Acc=0.6427\n",
      "[Baseline][1385] Loss=0.0609, Acc=0.6442\n",
      "[Baseline][1386] Loss=0.0647, Acc=0.6391\n",
      "[Baseline][1387] Loss=0.0522, Acc=0.6431\n",
      "[Baseline][1388] Loss=0.0621, Acc=0.6449\n",
      "[Baseline][1389] Loss=0.0657, Acc=0.6383\n",
      "[Baseline][1390] Loss=0.0550, Acc=0.6402\n",
      "[Baseline][1391] Loss=0.0698, Acc=0.6468\n",
      "[Baseline][1392] Loss=0.0595, Acc=0.6377\n",
      "[Baseline][1393] Loss=0.0534, Acc=0.6420\n",
      "[Baseline][1394] Loss=0.0641, Acc=0.6375\n",
      "[Baseline][1395] Loss=0.0580, Acc=0.6381\n",
      "[Baseline][1396] Loss=0.0551, Acc=0.6399\n",
      "[Baseline][1397] Loss=0.0553, Acc=0.6428\n",
      "[Baseline][1398] Loss=0.0533, Acc=0.6349\n",
      "[Baseline][1399] Loss=0.0643, Acc=0.6404\n",
      "[Baseline][1400] Loss=0.0533, Acc=0.6440\n",
      "[Baseline][1401] Loss=0.0626, Acc=0.6401\n",
      "[Baseline][1402] Loss=0.1332, Acc=0.6385\n",
      "[Baseline][1403] Loss=0.1133, Acc=0.6426\n",
      "[Baseline][1404] Loss=0.0738, Acc=0.6460\n",
      "[Baseline][1405] Loss=0.0684, Acc=0.6434\n",
      "[Baseline][1406] Loss=0.0552, Acc=0.6424\n",
      "[Baseline][1407] Loss=0.0575, Acc=0.6466\n",
      "[Baseline][1408] Loss=0.0715, Acc=0.6363\n",
      "[Baseline][1409] Loss=0.0613, Acc=0.6445\n",
      "[Baseline][1410] Loss=0.0479, Acc=0.6498\n",
      "[Baseline][1411] Loss=0.0553, Acc=0.6478\n",
      "[Baseline][1412] Loss=0.0496, Acc=0.6478\n",
      "[Baseline][1413] Loss=0.0659, Acc=0.6391\n",
      "[Baseline][1414] Loss=0.1323, Acc=0.6389\n",
      "[Baseline][1415] Loss=0.0900, Acc=0.6435\n",
      "[Baseline][1416] Loss=0.0657, Acc=0.6438\n",
      "[Baseline][1417] Loss=0.0638, Acc=0.6445\n",
      "[Baseline][1418] Loss=0.0540, Acc=0.6422\n",
      "[Baseline][1419] Loss=0.1032, Acc=0.6375\n",
      "[Baseline][1420] Loss=0.0745, Acc=0.6445\n",
      "[Baseline][1421] Loss=0.0579, Acc=0.6421\n",
      "[Baseline][1422] Loss=0.0693, Acc=0.6374\n",
      "[Baseline][1423] Loss=0.0624, Acc=0.6440\n",
      "[Baseline][1424] Loss=0.0547, Acc=0.6453\n",
      "[Baseline][1425] Loss=0.0549, Acc=0.6487\n",
      "[Baseline][1426] Loss=0.1681, Acc=0.6410\n",
      "[Baseline][1427] Loss=0.0725, Acc=0.6416\n",
      "[Baseline][1428] Loss=0.0715, Acc=0.6465\n",
      "[Baseline][1429] Loss=0.0553, Acc=0.6447\n",
      "[Baseline][1430] Loss=0.0471, Acc=0.6440\n",
      "[Baseline][1431] Loss=0.0568, Acc=0.6479\n",
      "[Baseline][1432] Loss=0.0515, Acc=0.6507\n",
      "[Baseline][1433] Loss=0.0518, Acc=0.6430\n",
      "[Baseline][1434] Loss=0.0518, Acc=0.6450\n",
      "[Baseline][1435] Loss=0.0703, Acc=0.6434\n",
      "[Baseline][1436] Loss=0.0578, Acc=0.6439\n",
      "[Baseline][1437] Loss=0.0576, Acc=0.6441\n",
      "[Baseline][1438] Loss=0.0672, Acc=0.6471\n",
      "[Baseline][1439] Loss=0.1309, Acc=0.6347\n",
      "[Baseline][1440] Loss=0.0759, Acc=0.6377\n",
      "[Baseline][1441] Loss=0.0539, Acc=0.6401\n",
      "[Baseline][1442] Loss=0.0526, Acc=0.6407\n",
      "[Baseline][1443] Loss=0.0535, Acc=0.6386\n",
      "[Baseline][1444] Loss=0.0468, Acc=0.6470\n",
      "[Baseline][1445] Loss=0.0551, Acc=0.6432\n",
      "[Baseline][1446] Loss=0.0520, Acc=0.6408\n",
      "[Baseline][1447] Loss=0.0521, Acc=0.6397\n",
      "[Baseline][1448] Loss=0.0491, Acc=0.6445\n",
      "[Baseline][1449] Loss=0.0528, Acc=0.6407\n",
      "[Baseline][1450] Loss=0.0638, Acc=0.6417\n",
      "[Baseline][1451] Loss=0.0542, Acc=0.6409\n",
      "[Baseline][1452] Loss=0.0527, Acc=0.6478\n",
      "[Baseline][1453] Loss=0.0483, Acc=0.6422\n",
      "[Baseline][1454] Loss=0.0441, Acc=0.6386\n",
      "[Baseline][1455] Loss=0.0576, Acc=0.6485\n",
      "[Baseline][1456] Loss=0.0516, Acc=0.6463\n",
      "[Baseline][1457] Loss=0.0468, Acc=0.6441\n",
      "[Baseline][1458] Loss=0.0586, Acc=0.6443\n",
      "[Baseline][1459] Loss=0.0581, Acc=0.6464\n",
      "[Baseline][1460] Loss=0.0488, Acc=0.6443\n",
      "[Baseline][1461] Loss=0.0537, Acc=0.6414\n",
      "[Baseline][1462] Loss=0.0784, Acc=0.6435\n",
      "[Baseline][1463] Loss=0.0599, Acc=0.6428\n",
      "[Baseline][1464] Loss=0.0565, Acc=0.6413\n",
      "[Baseline][1465] Loss=0.0580, Acc=0.6396\n",
      "[Baseline][1466] Loss=0.0630, Acc=0.6427\n",
      "[Baseline][1467] Loss=0.0750, Acc=0.6406\n",
      "[Baseline][1468] Loss=0.0831, Acc=0.6410\n",
      "[Baseline][1469] Loss=0.0701, Acc=0.6430\n",
      "[Baseline][1470] Loss=0.1002, Acc=0.6425\n",
      "[Baseline][1471] Loss=0.0831, Acc=0.6396\n",
      "[Baseline][1472] Loss=0.1569, Acc=0.6397\n",
      "[Baseline][1473] Loss=0.0968, Acc=0.6380\n",
      "[Baseline][1474] Loss=0.1268, Acc=0.6349\n",
      "[Baseline][1475] Loss=0.1925, Acc=0.6322\n",
      "[Baseline][1476] Loss=0.0986, Acc=0.6410\n",
      "[Baseline][1477] Loss=0.0665, Acc=0.6424\n",
      "[Baseline][1478] Loss=0.0652, Acc=0.6415\n",
      "[Baseline][1479] Loss=0.0544, Acc=0.6436\n",
      "[Baseline][1480] Loss=0.0651, Acc=0.6446\n",
      "[Baseline][1481] Loss=0.1226, Acc=0.6379\n",
      "[Baseline][1482] Loss=0.0684, Acc=0.6417\n",
      "[Baseline][1483] Loss=0.0536, Acc=0.6374\n",
      "[Baseline][1484] Loss=0.0516, Acc=0.6444\n",
      "[Baseline][1485] Loss=0.0531, Acc=0.6472\n",
      "[Baseline][1486] Loss=0.0566, Acc=0.6420\n",
      "[Baseline][1487] Loss=0.0654, Acc=0.6388\n",
      "[Baseline][1488] Loss=0.0528, Acc=0.6402\n",
      "[Baseline][1489] Loss=0.0562, Acc=0.6361\n",
      "[Baseline][1490] Loss=0.1087, Acc=0.6348\n",
      "[Baseline][1491] Loss=0.0533, Acc=0.6382\n",
      "[Baseline][1492] Loss=0.0605, Acc=0.6397\n",
      "[Baseline][1493] Loss=0.0463, Acc=0.6395\n",
      "[Baseline][1494] Loss=0.0435, Acc=0.6405\n",
      "[Baseline][1495] Loss=0.0493, Acc=0.6427\n",
      "[Baseline][1496] Loss=0.0399, Acc=0.6428\n",
      "[Baseline][1497] Loss=0.0480, Acc=0.6382\n",
      "[Baseline][1498] Loss=0.0594, Acc=0.6386\n",
      "[Baseline][1499] Loss=0.0619, Acc=0.6398\n",
      "[Baseline][1500] Loss=0.0548, Acc=0.6436\n",
      "[Baseline][1501] Loss=0.0478, Acc=0.6384\n",
      "[Baseline][1502] Loss=0.0500, Acc=0.6441\n",
      "[Baseline][1503] Loss=0.0506, Acc=0.6422\n",
      "[Baseline][1504] Loss=0.0500, Acc=0.6407\n",
      "[Baseline][1505] Loss=0.0640, Acc=0.6390\n",
      "[Baseline][1506] Loss=0.1225, Acc=0.6311\n",
      "[Baseline][1507] Loss=0.1029, Acc=0.6377\n",
      "[Baseline][1508] Loss=0.0761, Acc=0.6403\n",
      "[Baseline][1509] Loss=0.0673, Acc=0.6435\n",
      "[Baseline][1510] Loss=0.0476, Acc=0.6454\n",
      "[Baseline][1511] Loss=0.0589, Acc=0.6457\n",
      "[Baseline][1512] Loss=0.0540, Acc=0.6403\n",
      "[Baseline][1513] Loss=0.0530, Acc=0.6404\n",
      "[Baseline][1514] Loss=0.0557, Acc=0.6397\n",
      "[Baseline][1515] Loss=0.0448, Acc=0.6382\n",
      "[Baseline][1516] Loss=0.0485, Acc=0.6390\n",
      "[Baseline][1517] Loss=0.0491, Acc=0.6422\n",
      "[Baseline][1518] Loss=0.0443, Acc=0.6426\n",
      "[Baseline][1519] Loss=0.0433, Acc=0.6358\n",
      "[Baseline][1520] Loss=0.0552, Acc=0.6446\n",
      "[Baseline][1521] Loss=0.0510, Acc=0.6418\n",
      "[Baseline][1522] Loss=0.0759, Acc=0.6374\n",
      "[Baseline][1523] Loss=0.0522, Acc=0.6393\n",
      "[Baseline][1524] Loss=0.0645, Acc=0.6444\n",
      "[Baseline][1525] Loss=0.0688, Acc=0.6405\n",
      "[Baseline][1526] Loss=0.2055, Acc=0.6355\n",
      "[Baseline][1527] Loss=0.0899, Acc=0.6380\n",
      "[Baseline][1528] Loss=0.0993, Acc=0.6432\n",
      "[Baseline][1529] Loss=0.0627, Acc=0.6471\n",
      "[Baseline][1530] Loss=0.0532, Acc=0.6464\n",
      "[Baseline][1531] Loss=0.0674, Acc=0.6426\n",
      "[Baseline][1532] Loss=0.1079, Acc=0.6390\n",
      "[Baseline][1533] Loss=0.0866, Acc=0.6435\n",
      "[Baseline][1534] Loss=0.1460, Acc=0.6379\n",
      "[Baseline][1535] Loss=0.0814, Acc=0.6439\n",
      "[Baseline][1536] Loss=0.0910, Acc=0.6435\n",
      "[Baseline][1537] Loss=0.0696, Acc=0.6377\n",
      "[Baseline][1538] Loss=0.0424, Acc=0.6453\n",
      "[Baseline][1539] Loss=0.0503, Acc=0.6472\n",
      "[Baseline][1540] Loss=0.0443, Acc=0.6448\n",
      "[Baseline][1541] Loss=0.0536, Acc=0.6422\n",
      "[Baseline][1542] Loss=0.0575, Acc=0.6422\n",
      "[Baseline][1543] Loss=0.1365, Acc=0.6362\n",
      "[Baseline][1544] Loss=0.0752, Acc=0.6417\n",
      "[Baseline][1545] Loss=0.0474, Acc=0.6395\n",
      "[Baseline][1546] Loss=0.0508, Acc=0.6379\n",
      "[Baseline][1547] Loss=0.0495, Acc=0.6433\n",
      "[Baseline][1548] Loss=0.0390, Acc=0.6407\n",
      "[Baseline][1549] Loss=0.0377, Acc=0.6448\n",
      "[Baseline][1550] Loss=0.0478, Acc=0.6413\n",
      "[Baseline][1551] Loss=0.0637, Acc=0.6441\n",
      "[Baseline][1552] Loss=0.0436, Acc=0.6421\n",
      "[Baseline][1553] Loss=0.0403, Acc=0.6424\n",
      "[Baseline][1554] Loss=0.0479, Acc=0.6458\n",
      "[Baseline][1555] Loss=0.0453, Acc=0.6395\n",
      "[Baseline][1556] Loss=0.0520, Acc=0.6434\n",
      "[Baseline][1557] Loss=0.1055, Acc=0.6380\n",
      "[Baseline][1558] Loss=0.0633, Acc=0.6409\n",
      "[Baseline][1559] Loss=0.0860, Acc=0.6403\n",
      "[Baseline][1560] Loss=0.1164, Acc=0.6397\n",
      "[Baseline][1561] Loss=0.0540, Acc=0.6378\n",
      "[Baseline][1562] Loss=0.0574, Acc=0.6410\n",
      "[Baseline][1563] Loss=0.0452, Acc=0.6439\n",
      "[Baseline][1564] Loss=0.0829, Acc=0.6404\n",
      "[Baseline][1565] Loss=0.1387, Acc=0.6371\n",
      "[Baseline][1566] Loss=0.0638, Acc=0.6392\n",
      "[Baseline][1567] Loss=0.0529, Acc=0.6417\n",
      "[Baseline][1568] Loss=0.0524, Acc=0.6416\n",
      "[Baseline][1569] Loss=0.0403, Acc=0.6442\n",
      "[Baseline][1570] Loss=0.0439, Acc=0.6410\n",
      "[Baseline][1571] Loss=0.0498, Acc=0.6442\n",
      "[Baseline][1572] Loss=0.0433, Acc=0.6430\n",
      "[Baseline][1573] Loss=0.0489, Acc=0.6423\n",
      "[Baseline][1574] Loss=0.0785, Acc=0.6391\n",
      "[Baseline][1575] Loss=0.0587, Acc=0.6390\n",
      "[Baseline][1576] Loss=0.0562, Acc=0.6400\n",
      "[Baseline][1577] Loss=0.0899, Acc=0.6430\n",
      "[Baseline][1578] Loss=0.1566, Acc=0.6316\n",
      "[Baseline][1579] Loss=0.0681, Acc=0.6418\n",
      "[Baseline][1580] Loss=0.0735, Acc=0.6436\n",
      "[Baseline][1581] Loss=0.0652, Acc=0.6447\n",
      "[Baseline][1582] Loss=0.0495, Acc=0.6484\n",
      "[Baseline][1583] Loss=0.0418, Acc=0.6498\n",
      "[Baseline][1584] Loss=0.0683, Acc=0.6495\n",
      "[Baseline][1585] Loss=0.1800, Acc=0.6380\n",
      "[Baseline][1586] Loss=0.0843, Acc=0.6411\n",
      "[Baseline][1587] Loss=0.0694, Acc=0.6441\n",
      "[Baseline][1588] Loss=0.1204, Acc=0.6414\n",
      "[Baseline][1589] Loss=0.0705, Acc=0.6459\n",
      "[Baseline][1590] Loss=0.0644, Acc=0.6436\n",
      "[Baseline][1591] Loss=0.0507, Acc=0.6451\n",
      "[Baseline][1592] Loss=0.0444, Acc=0.6481\n",
      "[Baseline][1593] Loss=0.0403, Acc=0.6447\n",
      "[Baseline][1594] Loss=0.0557, Acc=0.6494\n",
      "[Baseline][1595] Loss=0.0505, Acc=0.6482\n",
      "[Baseline][1596] Loss=0.0489, Acc=0.6481\n",
      "[Baseline][1597] Loss=0.0452, Acc=0.6397\n",
      "[Baseline][1598] Loss=0.0414, Acc=0.6420\n",
      "[Baseline][1599] Loss=0.0549, Acc=0.6459\n",
      "[Baseline][1600] Loss=0.0436, Acc=0.6458\n",
      "[Baseline][1601] Loss=0.0430, Acc=0.6434\n",
      "[Baseline][1602] Loss=0.0544, Acc=0.6460\n",
      "[Baseline][1603] Loss=0.0476, Acc=0.6430\n",
      "[Baseline][1604] Loss=0.0441, Acc=0.6404\n",
      "[Baseline][1605] Loss=0.0726, Acc=0.6400\n",
      "[Baseline][1606] Loss=0.0442, Acc=0.6453\n",
      "[Baseline][1607] Loss=0.0405, Acc=0.6521\n",
      "[Baseline][1608] Loss=0.0585, Acc=0.6442\n",
      "[Baseline][1609] Loss=0.1360, Acc=0.6372\n",
      "[Baseline][1610] Loss=0.0808, Acc=0.6476\n",
      "[Baseline][1611] Loss=0.0688, Acc=0.6384\n",
      "[Baseline][1612] Loss=0.0544, Acc=0.6386\n",
      "[Baseline][1613] Loss=0.0508, Acc=0.6405\n",
      "[Baseline][1614] Loss=0.0488, Acc=0.6424\n",
      "[Baseline][1615] Loss=0.0489, Acc=0.6456\n",
      "[Baseline][1616] Loss=0.0407, Acc=0.6417\n",
      "[Baseline][1617] Loss=0.0445, Acc=0.6427\n",
      "[Baseline][1618] Loss=0.0434, Acc=0.6515\n",
      "[Baseline][1619] Loss=0.0507, Acc=0.6459\n",
      "[Baseline][1620] Loss=0.0396, Acc=0.6406\n",
      "[Baseline][1621] Loss=0.0743, Acc=0.6373\n",
      "[Baseline][1622] Loss=0.0913, Acc=0.6400\n",
      "[Baseline][1623] Loss=0.1972, Acc=0.6322\n",
      "[Baseline][1624] Loss=0.0894, Acc=0.6362\n",
      "[Baseline][1625] Loss=0.0605, Acc=0.6424\n",
      "[Baseline][1626] Loss=0.0512, Acc=0.6417\n",
      "[Baseline][1627] Loss=0.0381, Acc=0.6453\n",
      "[Baseline][1628] Loss=0.0564, Acc=0.6423\n",
      "[Baseline][1629] Loss=0.0518, Acc=0.6494\n",
      "[Baseline][1630] Loss=0.0530, Acc=0.6444\n",
      "[Baseline][1631] Loss=0.0430, Acc=0.6420\n",
      "[Baseline][1632] Loss=0.0419, Acc=0.6513\n",
      "[Baseline][1633] Loss=0.0393, Acc=0.6444\n",
      "[Baseline][1634] Loss=0.0597, Acc=0.6494\n",
      "[Baseline][1635] Loss=0.0815, Acc=0.6416\n",
      "[Baseline][1636] Loss=0.0486, Acc=0.6364\n",
      "[Baseline][1637] Loss=0.0650, Acc=0.6396\n",
      "[Baseline][1638] Loss=0.1663, Acc=0.6330\n",
      "[Baseline][1639] Loss=0.1008, Acc=0.6376\n",
      "[Baseline][1640] Loss=0.0526, Acc=0.6459\n",
      "[Baseline][1641] Loss=0.0613, Acc=0.6488\n",
      "[Baseline][1642] Loss=0.0578, Acc=0.6447\n",
      "[Baseline][1643] Loss=0.0487, Acc=0.6470\n",
      "[Baseline][1644] Loss=0.0539, Acc=0.6481\n",
      "[Baseline][1645] Loss=0.0476, Acc=0.6460\n",
      "[Baseline][1646] Loss=0.0519, Acc=0.6424\n",
      "[Baseline][1647] Loss=0.0612, Acc=0.6451\n",
      "[Baseline][1648] Loss=0.0686, Acc=0.6372\n",
      "[Baseline][1649] Loss=0.0791, Acc=0.6426\n",
      "[Baseline][1650] Loss=0.1578, Acc=0.6422\n",
      "[Baseline][1651] Loss=0.0774, Acc=0.6438\n",
      "[Baseline][1652] Loss=0.0609, Acc=0.6405\n",
      "[Baseline][1653] Loss=0.0465, Acc=0.6454\n",
      "[Baseline][1654] Loss=0.0584, Acc=0.6383\n",
      "[Baseline][1655] Loss=0.0544, Acc=0.6441\n",
      "[Baseline][1656] Loss=0.0585, Acc=0.6427\n",
      "[Baseline][1657] Loss=0.0594, Acc=0.6428\n",
      "[Baseline][1658] Loss=0.0634, Acc=0.6446\n",
      "[Baseline][1659] Loss=0.1108, Acc=0.6446\n",
      "[Baseline][1660] Loss=0.0556, Acc=0.6461\n",
      "[Baseline][1661] Loss=0.0448, Acc=0.6392\n",
      "[Baseline][1662] Loss=0.0607, Acc=0.6453\n",
      "[Baseline][1663] Loss=0.0818, Acc=0.6391\n",
      "[Baseline][1664] Loss=0.0602, Acc=0.6488\n",
      "[Baseline][1665] Loss=0.0537, Acc=0.6374\n",
      "[Baseline][1666] Loss=0.0439, Acc=0.6390\n",
      "[Baseline][1667] Loss=0.0450, Acc=0.6435\n",
      "[Baseline][1668] Loss=0.0477, Acc=0.6406\n",
      "[Baseline][1669] Loss=0.0414, Acc=0.6441\n",
      "[Baseline][1670] Loss=0.0361, Acc=0.6460\n",
      "[Baseline][1671] Loss=0.0475, Acc=0.6409\n",
      "[Baseline][1672] Loss=0.0563, Acc=0.6403\n",
      "[Baseline][1673] Loss=0.0526, Acc=0.6424\n",
      "[Baseline][1674] Loss=0.0438, Acc=0.6443\n",
      "[Baseline][1675] Loss=0.0416, Acc=0.6481\n",
      "[Baseline][1676] Loss=0.0542, Acc=0.6439\n",
      "[Baseline][1677] Loss=0.0428, Acc=0.6409\n",
      "[Baseline][1678] Loss=0.0527, Acc=0.6447\n",
      "[Baseline][1679] Loss=0.0392, Acc=0.6474\n",
      "[Baseline][1680] Loss=0.0402, Acc=0.6445\n",
      "[Baseline][1681] Loss=0.0375, Acc=0.6492\n",
      "[Baseline][1682] Loss=0.0494, Acc=0.6451\n",
      "[Baseline][1683] Loss=0.0414, Acc=0.6412\n",
      "[Baseline][1684] Loss=0.0429, Acc=0.6404\n",
      "[Baseline][1685] Loss=0.0436, Acc=0.6470\n",
      "[Baseline][1686] Loss=0.0494, Acc=0.6467\n",
      "[Baseline][1687] Loss=0.0444, Acc=0.6470\n",
      "[Baseline][1688] Loss=0.0626, Acc=0.6453\n",
      "[Baseline][1689] Loss=0.0635, Acc=0.6392\n",
      "[Baseline][1690] Loss=0.0856, Acc=0.6380\n",
      "[Baseline][1691] Loss=0.2117, Acc=0.6370\n",
      "[Baseline][1692] Loss=0.1991, Acc=0.6379\n",
      "[Baseline][1693] Loss=0.1389, Acc=0.6386\n",
      "[Baseline][1694] Loss=0.0758, Acc=0.6380\n",
      "[Baseline][1695] Loss=0.0560, Acc=0.6434\n",
      "[Baseline][1696] Loss=0.0587, Acc=0.6438\n",
      "[Baseline][1697] Loss=0.0468, Acc=0.6443\n",
      "[Baseline][1698] Loss=0.0473, Acc=0.6417\n",
      "[Baseline][1699] Loss=0.0378, Acc=0.6425\n",
      "[Baseline][1700] Loss=0.0563, Acc=0.6453\n",
      "[Baseline][1701] Loss=0.0543, Acc=0.6444\n",
      "[Baseline][1702] Loss=0.0408, Acc=0.6468\n",
      "[Baseline][1703] Loss=0.0417, Acc=0.6398\n",
      "[Baseline][1704] Loss=0.0398, Acc=0.6448\n",
      "[Baseline][1705] Loss=0.0580, Acc=0.6417\n",
      "[Baseline][1706] Loss=0.0523, Acc=0.6516\n",
      "[Baseline][1707] Loss=0.0811, Acc=0.6427\n",
      "[Baseline][1708] Loss=0.0590, Acc=0.6480\n",
      "[Baseline][1709] Loss=0.0565, Acc=0.6471\n",
      "[Baseline][1710] Loss=0.0459, Acc=0.6397\n",
      "[Baseline][1711] Loss=0.0533, Acc=0.6467\n",
      "[Baseline][1712] Loss=0.0500, Acc=0.6439\n",
      "[Baseline][1713] Loss=0.0438, Acc=0.6399\n",
      "[Baseline][1714] Loss=0.0465, Acc=0.6377\n",
      "[Baseline][1715] Loss=0.1122, Acc=0.6380\n",
      "[Baseline][1716] Loss=0.0610, Acc=0.6442\n",
      "[Baseline][1717] Loss=0.0542, Acc=0.6435\n",
      "[Baseline][1718] Loss=0.1014, Acc=0.6398\n",
      "[Baseline][1719] Loss=0.0854, Acc=0.6378\n",
      "[Baseline][1720] Loss=0.0603, Acc=0.6379\n",
      "[Baseline][1721] Loss=0.0500, Acc=0.6467\n",
      "[Baseline][1722] Loss=0.0493, Acc=0.6430\n",
      "[Baseline][1723] Loss=0.0509, Acc=0.6369\n",
      "[Baseline][1724] Loss=0.0457, Acc=0.6466\n",
      "[Baseline][1725] Loss=0.0554, Acc=0.6421\n",
      "[Baseline][1726] Loss=0.0747, Acc=0.6382\n",
      "[Baseline][1727] Loss=0.0692, Acc=0.6431\n",
      "[Baseline][1728] Loss=0.0472, Acc=0.6436\n",
      "[Baseline][1729] Loss=0.0373, Acc=0.6480\n",
      "[Baseline][1789] Loss=0.0416, Acc=0.6417\n",
      "[Baseline][1790] Loss=0.0371, Acc=0.6437\n",
      "[Baseline][1791] Loss=0.0384, Acc=0.6420\n",
      "[Baseline][1792] Loss=0.0470, Acc=0.6456\n",
      "[Baseline][1793] Loss=0.0542, Acc=0.6425\n",
      "[Baseline][1794] Loss=0.0424, Acc=0.6455\n",
      "[Baseline][1795] Loss=0.0364, Acc=0.6454\n",
      "[Baseline][1796] Loss=0.0459, Acc=0.6444\n",
      "[Baseline][1797] Loss=0.0510, Acc=0.6458\n",
      "[Baseline][1798] Loss=0.1143, Acc=0.6395\n",
      "[Baseline][1799] Loss=0.0722, Acc=0.6417\n",
      "[Baseline][1800] Loss=0.0429, Acc=0.6408\n",
      "[Baseline][1801] Loss=0.0388, Acc=0.6430\n",
      "[Baseline][1802] Loss=0.0395, Acc=0.6453\n",
      "[Baseline][1803] Loss=0.0473, Acc=0.6454\n",
      "[Baseline][1804] Loss=0.0546, Acc=0.6398\n",
      "[Baseline][1805] Loss=0.0465, Acc=0.6434\n",
      "[Baseline][1806] Loss=0.0323, Acc=0.6427\n",
      "[Baseline][1807] Loss=0.0433, Acc=0.6397\n",
      "[Baseline][1808] Loss=0.0872, Acc=0.6435\n",
      "[Baseline][1809] Loss=0.0575, Acc=0.6384\n",
      "[Baseline][1810] Loss=0.0480, Acc=0.6432\n",
      "[Baseline][1811] Loss=0.0406, Acc=0.6450\n",
      "[Baseline][1812] Loss=0.0460, Acc=0.6389\n",
      "[Baseline][1813] Loss=0.0388, Acc=0.6368\n",
      "[Baseline][1814] Loss=0.0362, Acc=0.6431\n",
      "[Baseline][1815] Loss=0.0343, Acc=0.6453\n",
      "[Baseline][1816] Loss=0.0453, Acc=0.6417\n",
      "[Baseline][1817] Loss=0.1037, Acc=0.6382\n",
      "[Baseline][1818] Loss=0.1610, Acc=0.6438\n",
      "[Baseline][1819] Loss=0.0661, Acc=0.6399\n",
      "[Baseline][1820] Loss=0.0538, Acc=0.6472\n",
      "[Baseline][1821] Loss=0.0919, Acc=0.6395\n",
      "[Baseline][1822] Loss=0.0670, Acc=0.6447\n",
      "[Baseline][1823] Loss=0.1102, Acc=0.6456\n",
      "[Baseline][1824] Loss=0.0638, Acc=0.6455\n",
      "[Baseline][1825] Loss=0.0693, Acc=0.6367\n",
      "[Baseline][1826] Loss=0.0455, Acc=0.6486\n",
      "[Baseline][1827] Loss=0.0508, Acc=0.6436\n",
      "[Baseline][1828] Loss=0.0512, Acc=0.6387\n",
      "[Baseline][1829] Loss=0.0502, Acc=0.6464\n",
      "[Baseline][1830] Loss=0.0491, Acc=0.6463\n",
      "[Baseline][1831] Loss=0.0908, Acc=0.6414\n",
      "[Baseline][1832] Loss=0.0648, Acc=0.6378\n",
      "[Baseline][1833] Loss=0.0518, Acc=0.6385\n",
      "[Baseline][1834] Loss=0.1596, Acc=0.6366\n",
      "[Baseline][1835] Loss=0.1437, Acc=0.6356\n",
      "[Baseline][1836] Loss=0.0626, Acc=0.6457\n",
      "[Baseline][1837] Loss=0.0450, Acc=0.6421\n",
      "[Baseline][1838] Loss=0.0693, Acc=0.6413\n",
      "[Baseline][1839] Loss=0.1344, Acc=0.6372\n",
      "[Baseline][1840] Loss=0.0688, Acc=0.6413\n",
      "[Baseline][1841] Loss=0.0557, Acc=0.6470\n",
      "[Baseline][1842] Loss=0.0410, Acc=0.6515\n",
      "[Baseline][1843] Loss=0.0522, Acc=0.6483\n",
      "[Baseline][1844] Loss=0.0366, Acc=0.6459\n",
      "[Baseline][1845] Loss=0.0426, Acc=0.6396\n",
      "[Baseline][1846] Loss=0.0551, Acc=0.6495\n",
      "[Baseline][1847] Loss=0.0441, Acc=0.6478\n",
      "[Baseline][1848] Loss=0.0363, Acc=0.6460\n",
      "[Baseline][1849] Loss=0.0572, Acc=0.6483\n",
      "[Baseline][1850] Loss=0.0470, Acc=0.6445\n",
      "[Baseline][1851] Loss=0.1127, Acc=0.6417\n",
      "[Baseline][1852] Loss=0.0612, Acc=0.6391\n",
      "[Baseline][1853] Loss=0.0421, Acc=0.6398\n",
      "[Baseline][1854] Loss=0.0401, Acc=0.6423\n",
      "[Baseline][1855] Loss=0.0408, Acc=0.6407\n",
      "[Baseline][1856] Loss=0.0352, Acc=0.6430\n",
      "[Baseline][1857] Loss=0.0410, Acc=0.6464\n",
      "[Baseline][1858] Loss=0.0354, Acc=0.6474\n",
      "[Baseline][1859] Loss=0.0332, Acc=0.6456\n",
      "[Baseline][1860] Loss=0.0426, Acc=0.6464\n",
      "[Baseline][1861] Loss=0.0364, Acc=0.6414\n",
      "[Baseline][1862] Loss=0.0449, Acc=0.6420\n",
      "[Baseline][1863] Loss=0.0437, Acc=0.6435\n",
      "[Baseline][1864] Loss=0.0368, Acc=0.6411\n",
      "[Baseline][1865] Loss=0.0488, Acc=0.6449\n",
      "[Baseline][1866] Loss=0.0397, Acc=0.6445\n",
      "[Baseline][1867] Loss=0.0429, Acc=0.6409\n",
      "[Baseline][1868] Loss=0.1237, Acc=0.6360\n",
      "[Baseline][1869] Loss=0.0810, Acc=0.6435\n",
      "[Baseline][1870] Loss=0.0412, Acc=0.6410\n",
      "[Baseline][1871] Loss=0.0428, Acc=0.6435\n",
      "[Baseline][1872] Loss=0.0804, Acc=0.6456\n",
      "[Baseline][1873] Loss=0.1148, Acc=0.6397\n",
      "[Baseline][1874] Loss=0.0642, Acc=0.6442\n",
      "[Baseline][1875] Loss=0.0630, Acc=0.6435\n",
      "[Baseline][1876] Loss=0.0475, Acc=0.6428\n",
      "[Baseline][1877] Loss=0.0407, Acc=0.6462\n",
      "[Baseline][1878] Loss=0.0452, Acc=0.6408\n",
      "[Baseline][1879] Loss=0.0613, Acc=0.6426\n",
      "[Baseline][1880] Loss=0.0561, Acc=0.6439\n",
      "[Baseline][1881] Loss=0.0501, Acc=0.6441\n",
      "[Baseline][1882] Loss=0.0473, Acc=0.6441\n",
      "[Baseline][1883] Loss=0.0348, Acc=0.6482\n",
      "[Baseline][1884] Loss=0.0872, Acc=0.6394\n",
      "[Baseline][1885] Loss=0.0686, Acc=0.6443\n",
      "[Baseline][1886] Loss=0.0526, Acc=0.6443\n",
      "[Baseline][1887] Loss=0.0480, Acc=0.6434\n",
      "[Baseline][1888] Loss=0.0613, Acc=0.6446\n",
      "[Baseline][1889] Loss=0.0459, Acc=0.6424\n",
      "[Baseline][1890] Loss=0.0633, Acc=0.6406\n",
      "[Baseline][1891] Loss=0.0455, Acc=0.6440\n",
      "[Baseline][1892] Loss=0.0493, Acc=0.6502\n",
      "[Baseline][1893] Loss=0.0359, Acc=0.6433\n",
      "[Baseline][1894] Loss=0.0369, Acc=0.6473\n",
      "[Baseline][1895] Loss=0.0298, Acc=0.6463\n",
      "[Baseline][1896] Loss=0.0385, Acc=0.6389\n",
      "[Baseline][1897] Loss=0.0336, Acc=0.6499\n",
      "[Baseline][1898] Loss=0.0301, Acc=0.6433\n",
      "[Baseline][1899] Loss=0.0410, Acc=0.6464\n",
      "[Baseline][1900] Loss=0.0479, Acc=0.6394\n",
      "[Baseline][1901] Loss=0.0506, Acc=0.6442\n",
      "[Baseline][1902] Loss=0.0439, Acc=0.6400\n",
      "[Baseline][1903] Loss=0.0503, Acc=0.6402\n",
      "[Baseline][1904] Loss=0.0469, Acc=0.6430\n",
      "[Baseline][1905] Loss=0.0465, Acc=0.6406\n",
      "[Baseline][1906] Loss=0.0394, Acc=0.6420\n",
      "[Baseline][1907] Loss=0.0445, Acc=0.6405\n",
      "[Baseline][1908] Loss=0.0513, Acc=0.6408\n",
      "[Baseline][1909] Loss=0.0497, Acc=0.6416\n",
      "[Baseline][1910] Loss=0.0998, Acc=0.6407\n",
      "[Baseline][1911] Loss=0.0614, Acc=0.6402\n",
      "[Baseline][1912] Loss=0.0648, Acc=0.6481\n",
      "[Baseline][1913] Loss=0.0443, Acc=0.6434\n",
      "[Baseline][1914] Loss=0.0577, Acc=0.6423\n",
      "[Baseline][1915] Loss=0.0778, Acc=0.6462\n",
      "[Baseline][1916] Loss=0.1712, Acc=0.6415\n",
      "[Baseline][1917] Loss=0.0790, Acc=0.6463\n",
      "[Baseline][1918] Loss=0.0746, Acc=0.6457\n",
      "[Baseline][1919] Loss=0.0605, Acc=0.6425\n",
      "[Baseline][1920] Loss=0.0589, Acc=0.6405\n",
      "[Baseline][1921] Loss=0.0619, Acc=0.6462\n",
      "[Baseline][1922] Loss=0.0430, Acc=0.6397\n",
      "[Baseline][1923] Loss=0.0440, Acc=0.6382\n",
      "[Baseline][1924] Loss=0.0485, Acc=0.6451\n",
      "[Baseline][1925] Loss=0.0434, Acc=0.6473\n",
      "[Baseline][1926] Loss=0.0443, Acc=0.6512\n",
      "[Baseline][1927] Loss=0.0391, Acc=0.6505\n",
      "[Baseline][1928] Loss=0.0585, Acc=0.6443\n",
      "[Baseline][1929] Loss=0.0505, Acc=0.6422\n",
      "[Baseline][1930] Loss=0.0469, Acc=0.6423\n",
      "[Baseline][1931] Loss=0.0397, Acc=0.6411\n",
      "[Baseline][1932] Loss=0.0437, Acc=0.6455\n",
      "[Baseline][1933] Loss=0.0418, Acc=0.6467\n",
      "[Baseline][1934] Loss=0.0422, Acc=0.6446\n",
      "[Baseline][1935] Loss=0.0464, Acc=0.6408\n",
      "[Baseline][1936] Loss=0.0599, Acc=0.6413\n",
      "[Baseline][1937] Loss=0.0476, Acc=0.6438\n",
      "[Baseline][1938] Loss=0.1124, Acc=0.6447\n",
      "[Baseline][1939] Loss=0.0651, Acc=0.6411\n",
      "[Baseline][1940] Loss=0.0780, Acc=0.6421\n",
      "[Baseline][1941] Loss=0.1332, Acc=0.6400\n",
      "[Baseline][1942] Loss=0.0799, Acc=0.6452\n",
      "[Baseline][1943] Loss=0.0906, Acc=0.6343\n",
      "[Baseline][1944] Loss=0.0862, Acc=0.6456\n",
      "[Baseline][1945] Loss=0.0678, Acc=0.6446\n",
      "[Baseline][1946] Loss=0.1148, Acc=0.6432\n",
      "[Baseline][1947] Loss=0.0528, Acc=0.6426\n",
      "[Baseline][1948] Loss=0.0592, Acc=0.6467\n",
      "[Baseline][1949] Loss=0.0387, Acc=0.6388\n",
      "[Baseline][1950] Loss=0.0429, Acc=0.6447\n",
      "[Baseline][1951] Loss=0.0500, Acc=0.6440\n",
      "[Baseline][1952] Loss=0.0422, Acc=0.6476\n",
      "[Baseline][1953] Loss=0.0319, Acc=0.6447\n",
      "[Baseline][1954] Loss=0.0345, Acc=0.6456\n",
      "[Baseline][1955] Loss=0.0416, Acc=0.6487\n",
      "[Baseline][1956] Loss=0.0372, Acc=0.6457\n",
      "[Baseline][1957] Loss=0.0388, Acc=0.6477\n",
      "[Baseline][1958] Loss=0.0502, Acc=0.6431\n",
      "[Baseline][1959] Loss=0.0464, Acc=0.6422\n",
      "[Baseline][1960] Loss=0.0357, Acc=0.6493\n",
      "[Baseline][1961] Loss=0.0800, Acc=0.6368\n",
      "[Baseline][1962] Loss=0.0664, Acc=0.6433\n",
      "[Baseline][1963] Loss=0.0546, Acc=0.6432\n",
      "[Baseline][1964] Loss=0.0500, Acc=0.6431\n",
      "[Baseline][1965] Loss=0.0365, Acc=0.6427\n",
      "[Baseline][1966] Loss=0.0484, Acc=0.6498\n",
      "[Baseline][1967] Loss=0.0479, Acc=0.6431\n",
      "[Baseline][1968] Loss=0.0712, Acc=0.6369\n",
      "[Baseline][1969] Loss=0.0519, Acc=0.6470\n",
      "[Baseline][1970] Loss=0.0435, Acc=0.6425\n",
      "[Baseline][1971] Loss=0.0479, Acc=0.6438\n",
      "[Baseline][1972] Loss=0.0535, Acc=0.6457\n",
      "[Baseline][1973] Loss=0.0601, Acc=0.6437\n",
      "[Baseline][1974] Loss=0.0468, Acc=0.6457\n",
      "[Baseline][1975] Loss=0.0531, Acc=0.6432\n",
      "[Baseline][1976] Loss=0.0477, Acc=0.6478\n",
      "[Baseline][1977] Loss=0.0362, Acc=0.6388\n",
      "[Baseline][1978] Loss=0.0448, Acc=0.6428\n",
      "[Baseline][1979] Loss=0.0562, Acc=0.6429\n",
      "[Baseline][1980] Loss=0.0627, Acc=0.6427\n",
      "[Baseline][1981] Loss=0.1121, Acc=0.6341\n",
      "[Baseline][1982] Loss=0.0671, Acc=0.6386\n",
      "[Baseline][1983] Loss=0.0547, Acc=0.6467\n",
      "[Baseline][1984] Loss=0.0481, Acc=0.6453\n",
      "[Baseline][1985] Loss=0.0529, Acc=0.6424\n",
      "[Baseline][1986] Loss=0.1140, Acc=0.6371\n",
      "[Baseline][1987] Loss=0.0577, Acc=0.6443\n",
      "[Baseline][1988] Loss=0.0420, Acc=0.6489\n",
      "[Baseline][1989] Loss=0.0451, Acc=0.6437\n",
      "[Baseline][1990] Loss=0.0516, Acc=0.6447\n",
      "[Baseline][1991] Loss=0.0555, Acc=0.6406\n",
      "[Baseline][1992] Loss=0.0530, Acc=0.6424\n",
      "[Baseline][1993] Loss=0.0468, Acc=0.6431\n",
      "[Baseline][1994] Loss=0.0458, Acc=0.6437\n",
      "[Baseline][1995] Loss=0.0411, Acc=0.6473\n",
      "[Baseline][1996] Loss=0.0361, Acc=0.6495\n",
      "[Baseline][1997] Loss=0.0487, Acc=0.6426\n",
      "[Baseline][1998] Loss=0.0435, Acc=0.6437\n",
      "[Baseline][1999] Loss=0.0465, Acc=0.6484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cd344ccef24416b3134705c2007de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline][00] Loss=2.2588, Acc=0.1682\n",
      "[Baseline][01] Loss=2.2149, Acc=0.2105\n",
      "[Baseline][02] Loss=2.1506, Acc=0.2089\n",
      "[Baseline][03] Loss=2.1285, Acc=0.2466\n",
      "[Baseline][04] Loss=2.1164, Acc=0.2264\n",
      "[Baseline][05] Loss=2.0609, Acc=0.2567\n",
      "[Baseline][06] Loss=2.0415, Acc=0.2227\n",
      "[Baseline][07] Loss=2.0343, Acc=0.2470\n",
      "[Baseline][08] Loss=2.0025, Acc=0.2830\n",
      "[Baseline][09] Loss=1.9923, Acc=0.2677\n",
      "[Baseline][10] Loss=1.9741, Acc=0.2850\n",
      "[Baseline][11] Loss=1.9620, Acc=0.2861\n",
      "[Baseline][12] Loss=1.9388, Acc=0.2698\n",
      "[Baseline][13] Loss=1.9364, Acc=0.2820\n",
      "[Baseline][14] Loss=1.9197, Acc=0.2699\n",
      "[Baseline][15] Loss=1.8998, Acc=0.3137\n",
      "[Baseline][16] Loss=1.8821, Acc=0.2890\n",
      "[Baseline][17] Loss=1.8724, Acc=0.2872\n",
      "[Baseline][18] Loss=1.8710, Acc=0.3165\n",
      "[Baseline][19] Loss=1.8389, Acc=0.3007\n",
      "[Baseline][20] Loss=1.8832, Acc=0.3254\n",
      "[Baseline][21] Loss=1.8637, Acc=0.3059\n",
      "[Baseline][22] Loss=1.8509, Acc=0.3075\n",
      "[Baseline][23] Loss=1.8382, Acc=0.2927\n",
      "[Baseline][24] Loss=1.8201, Acc=0.3299\n",
      "[Baseline][25] Loss=1.8031, Acc=0.3191\n",
      "[Baseline][26] Loss=1.7877, Acc=0.3221\n",
      "[Baseline][27] Loss=1.7692, Acc=0.3145\n",
      "[Baseline][28] Loss=1.8003, Acc=0.3047\n",
      "[Baseline][29] Loss=1.7835, Acc=0.3521\n",
      "[Baseline][30] Loss=1.7782, Acc=0.3089\n",
      "[Baseline][31] Loss=1.7604, Acc=0.3492\n",
      "[Baseline][32] Loss=1.7700, Acc=0.3436\n",
      "[Baseline][33] Loss=1.7423, Acc=0.3308\n",
      "[Baseline][34] Loss=1.7491, Acc=0.3358\n",
      "[Baseline][35] Loss=1.7332, Acc=0.3540\n",
      "[Baseline][36] Loss=1.7074, Acc=0.3537\n",
      "[Baseline][37] Loss=1.7393, Acc=0.3455\n",
      "[Baseline][38] Loss=1.7251, Acc=0.3396\n",
      "[Baseline][39] Loss=1.6819, Acc=0.3627\n",
      "[Baseline][40] Loss=1.7271, Acc=0.3349\n",
      "[Baseline][41] Loss=1.6842, Acc=0.3741\n",
      "[Baseline][42] Loss=1.6821, Acc=0.3544\n",
      "[Baseline][43] Loss=1.7108, Acc=0.3796\n",
      "[Baseline][44] Loss=1.6520, Acc=0.3556\n",
      "[Baseline][45] Loss=1.6632, Acc=0.3668\n",
      "[Baseline][46] Loss=1.6526, Acc=0.3646\n",
      "[Baseline][47] Loss=1.6694, Acc=0.3820\n",
      "[Baseline][48] Loss=1.6479, Acc=0.3755\n",
      "[Baseline][49] Loss=1.6243, Acc=0.3649\n",
      "[Baseline][50] Loss=1.6469, Acc=0.3762\n",
      "[Baseline][51] Loss=1.6577, Acc=0.3787\n",
      "[Baseline][52] Loss=1.6484, Acc=0.3744\n",
      "[Baseline][53] Loss=1.6236, Acc=0.3786\n",
      "[Baseline][54] Loss=1.6174, Acc=0.3689\n",
      "[Baseline][55] Loss=1.6149, Acc=0.3709\n",
      "[Baseline][56] Loss=1.6120, Acc=0.3745\n",
      "[Baseline][57] Loss=1.6050, Acc=0.4003\n",
      "[Baseline][58] Loss=1.6185, Acc=0.3726\n",
      "[Baseline][59] Loss=1.6072, Acc=0.3857\n",
      "[Baseline][60] Loss=1.6006, Acc=0.4092\n",
      "[Baseline][61] Loss=1.5913, Acc=0.3994\n",
      "[Baseline][62] Loss=1.5882, Acc=0.3993\n",
      "[Baseline][63] Loss=1.5930, Acc=0.4103\n",
      "[Baseline][64] Loss=1.5807, Acc=0.3786\n",
      "[Baseline][65] Loss=1.6021, Acc=0.4117\n",
      "[Baseline][66] Loss=1.5755, Acc=0.3834\n",
      "[Baseline][67] Loss=1.5559, Acc=0.4108\n",
      "[Baseline][68] Loss=1.5496, Acc=0.4253\n",
      "[Baseline][69] Loss=1.5296, Acc=0.4238\n",
      "[Baseline][70] Loss=1.5589, Acc=0.4128\n",
      "[Baseline][71] Loss=1.5846, Acc=0.3819\n",
      "[Baseline][72] Loss=1.5440, Acc=0.4181\n",
      "[Baseline][73] Loss=1.5286, Acc=0.3947\n",
      "[Baseline][74] Loss=1.5674, Acc=0.4022\n",
      "[Baseline][75] Loss=1.5687, Acc=0.3975\n",
      "[Baseline][76] Loss=1.5309, Acc=0.4236\n",
      "[Baseline][77] Loss=1.5203, Acc=0.4190\n",
      "[Baseline][78] Loss=1.5434, Acc=0.4099\n",
      "[Baseline][79] Loss=1.5348, Acc=0.3775\n",
      "[Baseline][80] Loss=1.5547, Acc=0.4100\n",
      "[Baseline][81] Loss=1.5380, Acc=0.4281\n",
      "[Baseline][82] Loss=1.5410, Acc=0.4142\n",
      "[Baseline][83] Loss=1.5154, Acc=0.3928\n",
      "[Baseline][84] Loss=1.5284, Acc=0.4154\n",
      "[Baseline][85] Loss=1.5297, Acc=0.4332\n",
      "[Baseline][86] Loss=1.5107, Acc=0.4022\n",
      "[Baseline][87] Loss=1.5175, Acc=0.4130\n",
      "[Baseline][88] Loss=1.5102, Acc=0.4131\n",
      "[Baseline][89] Loss=1.5158, Acc=0.3971\n",
      "[Baseline][90] Loss=1.5018, Acc=0.4312\n",
      "[Baseline][91] Loss=1.4967, Acc=0.4316\n",
      "[Baseline][92] Loss=1.5026, Acc=0.4181\n",
      "[Baseline][93] Loss=1.5208, Acc=0.4317\n",
      "[Baseline][94] Loss=1.4906, Acc=0.4237\n",
      "[Baseline][95] Loss=1.4876, Acc=0.4096\n",
      "[Baseline][96] Loss=1.5074, Acc=0.4312\n",
      "[Baseline][97] Loss=1.4809, Acc=0.4356\n",
      "[Baseline][98] Loss=1.4776, Acc=0.4344\n",
      "[Baseline][99] Loss=1.4802, Acc=0.4446\n",
      "[Baseline][100] Loss=1.4514, Acc=0.4394\n",
      "[Baseline][101] Loss=1.4657, Acc=0.4349\n",
      "[Baseline][102] Loss=1.5040, Acc=0.4465\n",
      "[Baseline][103] Loss=1.4642, Acc=0.4458\n",
      "[Baseline][104] Loss=1.4594, Acc=0.4302\n",
      "[Baseline][105] Loss=1.4839, Acc=0.4266\n",
      "[Baseline][106] Loss=1.4575, Acc=0.4445\n",
      "[Baseline][107] Loss=1.4442, Acc=0.4555\n",
      "[Baseline][108] Loss=1.4478, Acc=0.4479\n",
      "[Baseline][109] Loss=1.4702, Acc=0.4408\n",
      "[Baseline][110] Loss=1.4553, Acc=0.4365\n",
      "[Baseline][111] Loss=1.4473, Acc=0.4271\n",
      "[Baseline][112] Loss=1.4312, Acc=0.4434\n",
      "[Baseline][113] Loss=1.4369, Acc=0.4387\n",
      "[Baseline][114] Loss=1.4526, Acc=0.4560\n",
      "[Baseline][115] Loss=1.4235, Acc=0.4200\n",
      "[Baseline][116] Loss=1.4349, Acc=0.4558\n",
      "[Baseline][117] Loss=1.4444, Acc=0.4455\n",
      "[Baseline][118] Loss=1.4234, Acc=0.4448\n",
      "[Baseline][119] Loss=1.4204, Acc=0.4509\n",
      "[Baseline][120] Loss=1.4463, Acc=0.4211\n",
      "[Baseline][121] Loss=1.4356, Acc=0.4413\n",
      "[Baseline][122] Loss=1.4495, Acc=0.4460\n",
      "[Baseline][123] Loss=1.4202, Acc=0.4216\n",
      "[Baseline][124] Loss=1.4391, Acc=0.4411\n",
      "[Baseline][125] Loss=1.4378, Acc=0.4486\n",
      "[Baseline][126] Loss=1.4070, Acc=0.4370\n",
      "[Baseline][127] Loss=1.4319, Acc=0.4164\n",
      "[Baseline][128] Loss=1.4322, Acc=0.4387\n",
      "[Baseline][129] Loss=1.4358, Acc=0.4392\n",
      "[Baseline][130] Loss=1.4395, Acc=0.4314\n",
      "[Baseline][131] Loss=1.4365, Acc=0.4434\n",
      "[Baseline][132] Loss=1.3999, Acc=0.4644\n",
      "[Baseline][133] Loss=1.4124, Acc=0.4354\n",
      "[Baseline][134] Loss=1.4074, Acc=0.4130\n",
      "[Baseline][135] Loss=1.4388, Acc=0.4613\n",
      "[Baseline][136] Loss=1.3884, Acc=0.4555\n",
      "[Baseline][137] Loss=1.4235, Acc=0.4445\n",
      "[Baseline][138] Loss=1.4269, Acc=0.4662\n",
      "[Baseline][139] Loss=1.4060, Acc=0.4414\n",
      "[Baseline][140] Loss=1.4108, Acc=0.4441\n",
      "[Baseline][141] Loss=1.4006, Acc=0.4573\n",
      "[Baseline][142] Loss=1.4229, Acc=0.4738\n",
      "[Baseline][143] Loss=1.4015, Acc=0.4445\n",
      "[Baseline][144] Loss=1.4058, Acc=0.4333\n",
      "[Baseline][145] Loss=1.4232, Acc=0.4507\n",
      "[Baseline][146] Loss=1.3896, Acc=0.4652\n",
      "[Baseline][147] Loss=1.3848, Acc=0.4578\n",
      "[Baseline][148] Loss=1.3894, Acc=0.4564\n",
      "[Baseline][149] Loss=1.3620, Acc=0.4655\n",
      "[Baseline][150] Loss=1.3902, Acc=0.4648\n",
      "[Baseline][151] Loss=1.3880, Acc=0.4625\n",
      "[Baseline][152] Loss=1.3688, Acc=0.4629\n",
      "[Baseline][153] Loss=1.3749, Acc=0.4434\n",
      "[Baseline][154] Loss=1.3813, Acc=0.4630\n",
      "[Baseline][155] Loss=1.3935, Acc=0.4715\n",
      "[Baseline][156] Loss=1.3810, Acc=0.4521\n",
      "[Baseline][157] Loss=1.3761, Acc=0.4469\n",
      "[Baseline][158] Loss=1.3858, Acc=0.4629\n",
      "[Baseline][159] Loss=1.3733, Acc=0.4506\n",
      "[Baseline][160] Loss=1.3716, Acc=0.4722\n",
      "[Baseline][161] Loss=1.3529, Acc=0.4503\n",
      "[Baseline][162] Loss=1.3791, Acc=0.4542\n",
      "[Baseline][163] Loss=1.3906, Acc=0.4431\n",
      "[Baseline][164] Loss=1.3703, Acc=0.4527\n",
      "[Baseline][165] Loss=1.3714, Acc=0.4629\n",
      "[Baseline][166] Loss=1.3585, Acc=0.4667\n",
      "[Baseline][167] Loss=1.3633, Acc=0.4587\n",
      "[Baseline][168] Loss=1.3710, Acc=0.4632\n",
      "[Baseline][169] Loss=1.3672, Acc=0.4674\n",
      "[Baseline][170] Loss=1.3565, Acc=0.4681\n",
      "[Baseline][171] Loss=1.3494, Acc=0.4811\n",
      "[Baseline][172] Loss=1.3597, Acc=0.4703\n",
      "[Baseline][173] Loss=1.3493, Acc=0.4628\n",
      "[Baseline][174] Loss=1.4033, Acc=0.4661\n",
      "[Baseline][175] Loss=1.3560, Acc=0.4680\n",
      "[Baseline][176] Loss=1.3550, Acc=0.4661\n",
      "[Baseline][177] Loss=1.3555, Acc=0.4543\n",
      "[Baseline][178] Loss=1.3889, Acc=0.4768\n",
      "[Baseline][179] Loss=1.3406, Acc=0.4643\n",
      "[Baseline][180] Loss=1.3530, Acc=0.4719\n",
      "[Baseline][181] Loss=1.3536, Acc=0.4730\n",
      "[Baseline][182] Loss=1.3587, Acc=0.4567\n",
      "[Baseline][183] Loss=1.3331, Acc=0.4694\n",
      "[Baseline][184] Loss=1.3457, Acc=0.4633\n",
      "[Baseline][185] Loss=1.3426, Acc=0.4888\n",
      "[Baseline][186] Loss=1.3392, Acc=0.4812\n",
      "[Baseline][187] Loss=1.3578, Acc=0.4593\n",
      "[Baseline][188] Loss=1.3343, Acc=0.4480\n",
      "[Baseline][189] Loss=1.3412, Acc=0.4687\n",
      "[Baseline][190] Loss=1.3449, Acc=0.4663\n",
      "[Baseline][191] Loss=1.3408, Acc=0.4569\n",
      "[Baseline][192] Loss=1.3071, Acc=0.4531\n",
      "[Baseline][193] Loss=1.3130, Acc=0.4625\n",
      "[Baseline][194] Loss=1.3155, Acc=0.4786\n",
      "[Baseline][195] Loss=1.3322, Acc=0.4806\n",
      "[Baseline][196] Loss=1.3119, Acc=0.4753\n",
      "[Baseline][197] Loss=1.3010, Acc=0.4814\n",
      "[Baseline][198] Loss=1.3310, Acc=0.4725\n",
      "[Baseline][199] Loss=1.3272, Acc=0.4253\n",
      "[Baseline][200] Loss=1.3505, Acc=0.4779\n",
      "[Baseline][201] Loss=1.3087, Acc=0.4812\n",
      "[Baseline][202] Loss=1.3012, Acc=0.4792\n",
      "[Baseline][203] Loss=1.3215, Acc=0.4512\n",
      "[Baseline][204] Loss=1.3320, Acc=0.4835\n",
      "[Baseline][205] Loss=1.3473, Acc=0.4664\n",
      "[Baseline][206] Loss=1.3131, Acc=0.4736\n",
      "[Baseline][207] Loss=1.3337, Acc=0.4773\n",
      "[Baseline][208] Loss=1.3214, Acc=0.4757\n",
      "[Baseline][209] Loss=1.3512, Acc=0.4730\n",
      "[Baseline][210] Loss=1.3271, Acc=0.4721\n",
      "[Baseline][211] Loss=1.3083, Acc=0.4842\n",
      "[Baseline][212] Loss=1.2874, Acc=0.4771\n",
      "[Baseline][213] Loss=1.2968, Acc=0.4912\n",
      "[Baseline][214] Loss=1.3169, Acc=0.4804\n",
      "[Baseline][215] Loss=1.3134, Acc=0.4938\n",
      "[Baseline][216] Loss=1.2890, Acc=0.4765\n",
      "[Baseline][217] Loss=1.2734, Acc=0.4845\n",
      "[Baseline][218] Loss=1.2871, Acc=0.4732\n",
      "[Baseline][219] Loss=1.3076, Acc=0.4786\n",
      "[Baseline][220] Loss=1.3168, Acc=0.4685\n",
      "[Baseline][221] Loss=1.3140, Acc=0.4782\n",
      "[Baseline][222] Loss=1.2700, Acc=0.4954\n",
      "[Baseline][223] Loss=1.2915, Acc=0.4781\n",
      "[Baseline][224] Loss=1.3060, Acc=0.4723\n",
      "[Baseline][225] Loss=1.3098, Acc=0.4814\n",
      "[Baseline][226] Loss=1.3004, Acc=0.4888\n",
      "[Baseline][227] Loss=1.2864, Acc=0.5017\n",
      "[Baseline][228] Loss=1.2720, Acc=0.4745\n",
      "[Baseline][229] Loss=1.3009, Acc=0.4878\n",
      "[Baseline][230] Loss=1.2844, Acc=0.4806\n",
      "[Baseline][231] Loss=1.2925, Acc=0.4858\n",
      "[Baseline][232] Loss=1.3061, Acc=0.4967\n",
      "[Baseline][233] Loss=1.2833, Acc=0.4975\n",
      "[Baseline][234] Loss=1.2728, Acc=0.4806\n",
      "[Baseline][235] Loss=1.2930, Acc=0.4960\n",
      "[Baseline][236] Loss=1.2696, Acc=0.4920\n",
      "[Baseline][237] Loss=1.2908, Acc=0.4739\n",
      "[Baseline][238] Loss=1.2842, Acc=0.4730\n",
      "[Baseline][239] Loss=1.2857, Acc=0.4961\n",
      "[Baseline][240] Loss=1.2720, Acc=0.4857\n",
      "[Baseline][241] Loss=1.2677, Acc=0.4996\n",
      "[Baseline][242] Loss=1.2746, Acc=0.4989\n",
      "[Baseline][243] Loss=1.2652, Acc=0.4875\n",
      "[Baseline][244] Loss=1.2605, Acc=0.4992\n",
      "[Baseline][245] Loss=1.2758, Acc=0.4857\n",
      "[Baseline][246] Loss=1.2538, Acc=0.4889\n",
      "[Baseline][247] Loss=1.2918, Acc=0.4969\n",
      "[Baseline][248] Loss=1.2745, Acc=0.4999\n",
      "[Baseline][249] Loss=1.2419, Acc=0.4909\n",
      "[Baseline][250] Loss=1.2655, Acc=0.4832\n",
      "[Baseline][251] Loss=1.2664, Acc=0.4697\n",
      "[Baseline][252] Loss=1.2808, Acc=0.4780\n",
      "[Baseline][253] Loss=1.2577, Acc=0.4922\n",
      "[Baseline][254] Loss=1.2670, Acc=0.4912\n",
      "[Baseline][255] Loss=1.2490, Acc=0.4984\n",
      "[Baseline][256] Loss=1.2527, Acc=0.4636\n",
      "[Baseline][257] Loss=1.2472, Acc=0.5014\n",
      "[Baseline][258] Loss=1.2436, Acc=0.4719\n",
      "[Baseline][259] Loss=1.2972, Acc=0.4748\n",
      "[Baseline][260] Loss=1.3052, Acc=0.4902\n",
      "[Baseline][261] Loss=1.2439, Acc=0.4913\n",
      "[Baseline][262] Loss=1.2671, Acc=0.4861\n",
      "[Baseline][263] Loss=1.2754, Acc=0.4690\n",
      "[Baseline][264] Loss=1.2902, Acc=0.4996\n",
      "[Baseline][265] Loss=1.2696, Acc=0.5003\n",
      "[Baseline][266] Loss=1.2549, Acc=0.4902\n",
      "[Baseline][267] Loss=1.2601, Acc=0.5042\n",
      "[Baseline][268] Loss=1.2490, Acc=0.4979\n",
      "[Baseline][269] Loss=1.2487, Acc=0.4967\n",
      "[Baseline][270] Loss=1.2385, Acc=0.4976\n",
      "[Baseline][271] Loss=1.2231, Acc=0.5009\n",
      "[Baseline][272] Loss=1.2507, Acc=0.5016\n",
      "[Baseline][273] Loss=1.2246, Acc=0.4981\n",
      "[Baseline][274] Loss=1.2333, Acc=0.4705\n",
      "[Baseline][275] Loss=1.2472, Acc=0.4798\n",
      "[Baseline][276] Loss=1.2678, Acc=0.5002\n",
      "[Baseline][277] Loss=1.2724, Acc=0.5045\n",
      "[Baseline][278] Loss=1.2565, Acc=0.4922\n",
      "[Baseline][279] Loss=1.2365, Acc=0.5083\n",
      "[Baseline][280] Loss=1.2356, Acc=0.5057\n",
      "[Baseline][281] Loss=1.2470, Acc=0.5126\n",
      "[Baseline][282] Loss=1.2522, Acc=0.4756\n",
      "[Baseline][283] Loss=1.2577, Acc=0.4979\n",
      "[Baseline][284] Loss=1.2344, Acc=0.5044\n",
      "[Baseline][285] Loss=1.2126, Acc=0.4823\n",
      "[Baseline][286] Loss=1.2128, Acc=0.4957\n",
      "[Baseline][287] Loss=1.2321, Acc=0.5096\n",
      "[Baseline][288] Loss=1.2448, Acc=0.5100\n",
      "[Baseline][289] Loss=1.2322, Acc=0.5019\n",
      "[Baseline][290] Loss=1.2410, Acc=0.5031\n",
      "[Baseline][291] Loss=1.2308, Acc=0.5106\n",
      "[Baseline][292] Loss=1.2058, Acc=0.4971\n",
      "[Baseline][293] Loss=1.2196, Acc=0.4966\n",
      "[Baseline][294] Loss=1.2082, Acc=0.4890\n",
      "[Baseline][295] Loss=1.2559, Acc=0.4946\n",
      "[Baseline][296] Loss=1.2063, Acc=0.5021\n",
      "[Baseline][297] Loss=1.2123, Acc=0.5048\n",
      "[Baseline][298] Loss=1.2027, Acc=0.5065\n",
      "[Baseline][299] Loss=1.2114, Acc=0.4994\n",
      "[Baseline][300] Loss=1.2332, Acc=0.5108\n",
      "[Baseline][301] Loss=1.2306, Acc=0.4885\n",
      "[Baseline][302] Loss=1.2310, Acc=0.5135\n",
      "[Baseline][303] Loss=1.2438, Acc=0.5070\n",
      "[Baseline][304] Loss=1.2099, Acc=0.5036\n",
      "[Baseline][305] Loss=1.2185, Acc=0.5091\n",
      "[Baseline][306] Loss=1.1987, Acc=0.5000\n",
      "[Baseline][307] Loss=1.1973, Acc=0.5142\n",
      "[Baseline][308] Loss=1.2167, Acc=0.5071\n",
      "[Baseline][309] Loss=1.2237, Acc=0.5034\n",
      "[Baseline][310] Loss=1.2144, Acc=0.4937\n",
      "[Baseline][311] Loss=1.2050, Acc=0.5113\n",
      "[Baseline][312] Loss=1.2001, Acc=0.5047\n",
      "[Baseline][313] Loss=1.2349, Acc=0.4980\n",
      "[Baseline][314] Loss=1.2228, Acc=0.4910\n",
      "[Baseline][315] Loss=1.2035, Acc=0.5170\n",
      "[Baseline][316] Loss=1.2084, Acc=0.5009\n",
      "[Baseline][317] Loss=1.1877, Acc=0.5082\n",
      "[Baseline][318] Loss=1.2078, Acc=0.5197\n",
      "[Baseline][319] Loss=1.2017, Acc=0.5084\n",
      "[Baseline][320] Loss=1.2025, Acc=0.5117\n",
      "[Baseline][321] Loss=1.1860, Acc=0.5040\n",
      "[Baseline][322] Loss=1.1997, Acc=0.5112\n",
      "[Baseline][323] Loss=1.1927, Acc=0.5071\n",
      "[Baseline][324] Loss=1.1744, Acc=0.5160\n",
      "[Baseline][325] Loss=1.2177, Acc=0.5157\n",
      "[Baseline][326] Loss=1.1893, Acc=0.5068\n",
      "[Baseline][327] Loss=1.1769, Acc=0.4961\n",
      "[Baseline][328] Loss=1.1831, Acc=0.5130\n",
      "[Baseline][329] Loss=1.1931, Acc=0.5107\n",
      "[Baseline][330] Loss=1.1718, Acc=0.5143\n",
      "[Baseline][331] Loss=1.1876, Acc=0.5020\n",
      "[Baseline][332] Loss=1.2215, Acc=0.5079\n",
      "[Baseline][333] Loss=1.1693, Acc=0.5112\n",
      "[Baseline][334] Loss=1.1613, Acc=0.5092\n",
      "[Baseline][335] Loss=1.1893, Acc=0.4890\n",
      "[Baseline][336] Loss=1.1842, Acc=0.5099\n",
      "[Baseline][337] Loss=1.1985, Acc=0.5149\n",
      "[Baseline][338] Loss=1.1974, Acc=0.4912\n",
      "[Baseline][339] Loss=1.1793, Acc=0.5178\n",
      "[Baseline][340] Loss=1.1852, Acc=0.4980\n",
      "[Baseline][341] Loss=1.2076, Acc=0.4985\n",
      "[Baseline][342] Loss=1.1736, Acc=0.5063\n",
      "[Baseline][343] Loss=1.1661, Acc=0.5084\n",
      "[Baseline][344] Loss=1.1964, Acc=0.4945\n",
      "[Baseline][345] Loss=1.1535, Acc=0.5105\n",
      "[Baseline][346] Loss=1.1629, Acc=0.5121\n",
      "[Baseline][347] Loss=1.1796, Acc=0.5020\n",
      "[Baseline][348] Loss=1.1883, Acc=0.5053\n",
      "[Baseline][349] Loss=1.1743, Acc=0.5135\n",
      "[Baseline][350] Loss=1.1722, Acc=0.4926\n",
      "[Baseline][351] Loss=1.1810, Acc=0.5148\n",
      "[Baseline][352] Loss=1.1652, Acc=0.5180\n",
      "[Baseline][353] Loss=1.1561, Acc=0.5219\n",
      "[Baseline][354] Loss=1.1396, Acc=0.5167\n",
      "[Baseline][355] Loss=1.1554, Acc=0.5086\n",
      "[Baseline][356] Loss=1.1649, Acc=0.5189\n",
      "[Baseline][357] Loss=1.1364, Acc=0.5121\n",
      "[Baseline][358] Loss=1.1583, Acc=0.5235\n",
      "[Baseline][359] Loss=1.1559, Acc=0.5134\n",
      "[Baseline][360] Loss=1.1731, Acc=0.4989\n",
      "[Baseline][361] Loss=1.1992, Acc=0.5132\n",
      "[Baseline][362] Loss=1.1533, Acc=0.5171\n",
      "[Baseline][363] Loss=1.1413, Acc=0.5189\n",
      "[Baseline][364] Loss=1.1689, Acc=0.5141\n",
      "[Baseline][365] Loss=1.1795, Acc=0.5019\n",
      "[Baseline][366] Loss=1.1749, Acc=0.5175\n",
      "[Baseline][367] Loss=1.1534, Acc=0.5217\n",
      "[Baseline][368] Loss=1.1546, Acc=0.5126\n",
      "[Baseline][369] Loss=1.1679, Acc=0.5091\n",
      "[Baseline][370] Loss=1.1507, Acc=0.5139\n",
      "[Baseline][371] Loss=1.1373, Acc=0.5097\n",
      "[Baseline][372] Loss=1.1550, Acc=0.5063\n",
      "[Baseline][373] Loss=1.1686, Acc=0.5276\n",
      "[Baseline][374] Loss=1.1904, Acc=0.5048\n",
      "[Baseline][375] Loss=1.1597, Acc=0.5163\n",
      "[Baseline][376] Loss=1.1591, Acc=0.5141\n",
      "[Baseline][377] Loss=1.1581, Acc=0.5172\n",
      "[Baseline][378] Loss=1.1673, Acc=0.5153\n",
      "[Baseline][379] Loss=1.1301, Acc=0.5142\n",
      "[Baseline][380] Loss=1.1364, Acc=0.5216\n",
      "[Baseline][381] Loss=1.1387, Acc=0.5113\n",
      "[Baseline][382] Loss=1.1470, Acc=0.4988\n",
      "[Baseline][383] Loss=1.1293, Acc=0.5138\n",
      "[Baseline][384] Loss=1.1540, Acc=0.5172\n",
      "[Baseline][385] Loss=1.1256, Acc=0.5126\n",
      "[Baseline][386] Loss=1.1436, Acc=0.4992\n",
      "[Baseline][387] Loss=1.1544, Acc=0.5194\n",
      "[Baseline][388] Loss=1.1434, Acc=0.5081\n",
      "[Baseline][389] Loss=1.1616, Acc=0.5262\n",
      "[Baseline][390] Loss=1.1571, Acc=0.5206\n",
      "[Baseline][391] Loss=1.1482, Acc=0.5206\n",
      "[Baseline][392] Loss=1.1455, Acc=0.5196\n",
      "[Baseline][393] Loss=1.1365, Acc=0.5218\n",
      "[Baseline][394] Loss=1.1232, Acc=0.5235\n",
      "[Baseline][395] Loss=1.1377, Acc=0.5110\n",
      "[Baseline][396] Loss=1.1387, Acc=0.5154\n",
      "[Baseline][397] Loss=1.1149, Acc=0.5103\n",
      "[Baseline][398] Loss=1.1207, Acc=0.5181\n",
      "[Baseline][399] Loss=1.1328, Acc=0.5224\n",
      "[Baseline][400] Loss=1.0950, Acc=0.5228\n",
      "[Baseline][401] Loss=1.1231, Acc=0.5202\n",
      "[Baseline][402] Loss=1.1101, Acc=0.5124\n",
      "[Baseline][403] Loss=1.1356, Acc=0.5229\n",
      "[Baseline][404] Loss=1.1262, Acc=0.5166\n",
      "[Baseline][405] Loss=1.1286, Acc=0.5263\n",
      "[Baseline][406] Loss=1.1249, Acc=0.4970\n",
      "[Baseline][407] Loss=1.1210, Acc=0.5230\n",
      "[Baseline][408] Loss=1.1118, Acc=0.5138\n",
      "[Baseline][409] Loss=1.1406, Acc=0.5226\n",
      "[Baseline][410] Loss=1.1365, Acc=0.5250\n",
      "[Baseline][411] Loss=1.1328, Acc=0.5327\n",
      "[Baseline][412] Loss=1.1290, Acc=0.5181\n",
      "[Baseline][413] Loss=1.1324, Acc=0.5307\n",
      "[Baseline][414] Loss=1.0934, Acc=0.5217\n",
      "[Baseline][415] Loss=1.1267, Acc=0.5183\n",
      "[Baseline][416] Loss=1.1112, Acc=0.5316\n",
      "[Baseline][417] Loss=1.1018, Acc=0.5232\n",
      "[Baseline][418] Loss=1.1424, Acc=0.5129\n",
      "[Baseline][419] Loss=1.1402, Acc=0.5322\n",
      "[Baseline][420] Loss=1.1099, Acc=0.5173\n",
      "[Baseline][421] Loss=1.0997, Acc=0.5228\n",
      "[Baseline][422] Loss=1.1203, Acc=0.5151\n",
      "[Baseline][423] Loss=1.1171, Acc=0.5233\n",
      "[Baseline][424] Loss=1.1145, Acc=0.5330\n",
      "[Baseline][425] Loss=1.1294, Acc=0.5161\n",
      "[Baseline][426] Loss=1.1307, Acc=0.5066\n",
      "[Baseline][427] Loss=1.1199, Acc=0.5230\n",
      "[Baseline][428] Loss=1.1187, Acc=0.5241\n",
      "[Baseline][429] Loss=1.0948, Acc=0.5279\n",
      "[Baseline][430] Loss=1.0860, Acc=0.5027\n",
      "[Baseline][431] Loss=1.1109, Acc=0.5287\n",
      "[Baseline][432] Loss=1.1035, Acc=0.5158\n",
      "[Baseline][433] Loss=1.1027, Acc=0.5212\n",
      "[Baseline][434] Loss=1.0877, Acc=0.5204\n",
      "[Baseline][435] Loss=1.1226, Acc=0.5303\n",
      "[Baseline][436] Loss=1.1390, Acc=0.5169\n",
      "[Baseline][437] Loss=1.1277, Acc=0.5074\n",
      "[Baseline][438] Loss=1.0995, Acc=0.4997\n",
      "[Baseline][439] Loss=1.1022, Acc=0.5147\n",
      "[Baseline][440] Loss=1.1328, Acc=0.5242\n",
      "[Baseline][441] Loss=1.1190, Acc=0.5225\n",
      "[Baseline][442] Loss=1.1209, Acc=0.5184\n",
      "[Baseline][443] Loss=1.1086, Acc=0.5018\n",
      "[Baseline][444] Loss=1.1153, Acc=0.5048\n",
      "[Baseline][445] Loss=1.0991, Acc=0.5333\n",
      "[Baseline][446] Loss=1.0717, Acc=0.5177\n",
      "[Baseline][447] Loss=1.1249, Acc=0.5232\n",
      "[Baseline][448] Loss=1.1146, Acc=0.5324\n",
      "[Baseline][449] Loss=1.0858, Acc=0.5295\n",
      "[Baseline][450] Loss=1.0927, Acc=0.5166\n",
      "[Baseline][451] Loss=1.0868, Acc=0.5273\n",
      "[Baseline][452] Loss=1.0939, Acc=0.5209\n",
      "[Baseline][453] Loss=1.1205, Acc=0.5277\n",
      "[Baseline][454] Loss=1.1036, Acc=0.5247\n",
      "[Baseline][455] Loss=1.0792, Acc=0.5081\n",
      "[Baseline][456] Loss=1.0770, Acc=0.5146\n",
      "[Baseline][457] Loss=1.0887, Acc=0.5200\n",
      "[Baseline][458] Loss=1.0947, Acc=0.5340\n",
      "[Baseline][459] Loss=1.0827, Acc=0.5221\n",
      "[Baseline][460] Loss=1.1198, Acc=0.5282\n",
      "[Baseline][461] Loss=1.0899, Acc=0.5108\n",
      "[Baseline][462] Loss=1.0932, Acc=0.5240\n",
      "[Baseline][463] Loss=1.0670, Acc=0.5289\n",
      "[Baseline][464] Loss=1.1027, Acc=0.5324\n",
      "[Baseline][465] Loss=1.0975, Acc=0.5236\n",
      "[Baseline][466] Loss=1.0798, Acc=0.5272\n",
      "[Baseline][467] Loss=1.0965, Acc=0.5253\n",
      "[Baseline][468] Loss=1.1143, Acc=0.5268\n",
      "[Baseline][469] Loss=1.1059, Acc=0.5276\n",
      "[Baseline][470] Loss=1.0833, Acc=0.5110\n",
      "[Baseline][471] Loss=1.0786, Acc=0.5179\n",
      "[Baseline][472] Loss=1.0669, Acc=0.5095\n",
      "[Baseline][473] Loss=1.0692, Acc=0.5256\n",
      "[Baseline][474] Loss=1.0593, Acc=0.5267\n",
      "[Baseline][475] Loss=1.0721, Acc=0.5189\n",
      "[Baseline][476] Loss=1.1041, Acc=0.5178\n",
      "[Baseline][477] Loss=1.0776, Acc=0.5307\n",
      "[Baseline][478] Loss=1.0819, Acc=0.5217\n",
      "[Baseline][479] Loss=1.0580, Acc=0.5253\n",
      "[Baseline][480] Loss=1.0620, Acc=0.5253\n",
      "[Baseline][481] Loss=1.0613, Acc=0.5251\n",
      "[Baseline][482] Loss=1.0610, Acc=0.5306\n",
      "[Baseline][483] Loss=1.0543, Acc=0.5319\n",
      "[Baseline][484] Loss=1.1036, Acc=0.5234\n",
      "[Baseline][485] Loss=1.1183, Acc=0.5272\n",
      "[Baseline][486] Loss=1.0612, Acc=0.5273\n",
      "[Baseline][487] Loss=1.0859, Acc=0.5351\n",
      "[Baseline][488] Loss=1.0672, Acc=0.5316\n",
      "[Baseline][489] Loss=1.0694, Acc=0.5323\n",
      "[Baseline][490] Loss=1.0589, Acc=0.5380\n",
      "[Baseline][491] Loss=1.0951, Acc=0.5266\n",
      "[Baseline][492] Loss=1.1071, Acc=0.5123\n",
      "[Baseline][493] Loss=1.0966, Acc=0.5310\n",
      "[Baseline][494] Loss=1.0605, Acc=0.5206\n",
      "[Baseline][495] Loss=1.0626, Acc=0.4956\n",
      "[Baseline][496] Loss=1.0775, Acc=0.5195\n",
      "[Baseline][497] Loss=1.0479, Acc=0.5312\n",
      "[Baseline][498] Loss=1.0732, Acc=0.5220\n",
      "[Baseline][499] Loss=1.0872, Acc=0.5327\n",
      "[Baseline][500] Loss=1.0752, Acc=0.5261\n",
      "[Baseline][501] Loss=1.0549, Acc=0.5148\n",
      "[Baseline][502] Loss=1.0556, Acc=0.5305\n",
      "[Baseline][503] Loss=1.0303, Acc=0.5320\n",
      "[Baseline][504] Loss=1.0483, Acc=0.5303\n",
      "[Baseline][505] Loss=1.0648, Acc=0.5351\n",
      "[Baseline][506] Loss=1.0750, Acc=0.5287\n",
      "[Baseline][507] Loss=1.0643, Acc=0.5261\n",
      "[Baseline][508] Loss=1.0409, Acc=0.5295\n",
      "[Baseline][509] Loss=1.0559, Acc=0.5278\n",
      "[Baseline][510] Loss=1.0833, Acc=0.5171\n",
      "[Baseline][511] Loss=1.0608, Acc=0.5413\n",
      "[Baseline][512] Loss=1.0599, Acc=0.5338\n",
      "[Baseline][513] Loss=1.0398, Acc=0.5386\n",
      "[Baseline][514] Loss=1.0421, Acc=0.5321\n",
      "[Baseline][515] Loss=1.0426, Acc=0.5386\n",
      "[Baseline][516] Loss=1.0518, Acc=0.5222\n",
      "[Baseline][517] Loss=1.0650, Acc=0.5214\n",
      "[Baseline][518] Loss=1.0676, Acc=0.5303\n",
      "[Baseline][519] Loss=1.0591, Acc=0.5311\n",
      "[Baseline][520] Loss=1.0408, Acc=0.5332\n",
      "[Baseline][521] Loss=1.0556, Acc=0.5410\n",
      "[Baseline][522] Loss=1.0419, Acc=0.5416\n",
      "[Baseline][523] Loss=1.0314, Acc=0.5313\n",
      "[Baseline][524] Loss=1.0442, Acc=0.5383\n",
      "[Baseline][525] Loss=1.0331, Acc=0.5451\n",
      "[Baseline][526] Loss=1.0446, Acc=0.5240\n",
      "[Baseline][527] Loss=1.0438, Acc=0.5363\n",
      "[Baseline][528] Loss=1.0333, Acc=0.5299\n",
      "[Baseline][529] Loss=1.0603, Acc=0.5380\n",
      "[Baseline][530] Loss=1.0588, Acc=0.5310\n",
      "[Baseline][531] Loss=1.0606, Acc=0.5355\n",
      "[Baseline][532] Loss=1.0383, Acc=0.5112\n",
      "[Baseline][533] Loss=1.0777, Acc=0.5265\n",
      "[Baseline][534] Loss=1.0301, Acc=0.5327\n",
      "[Baseline][535] Loss=1.0345, Acc=0.5407\n",
      "[Baseline][536] Loss=1.0137, Acc=0.5338\n",
      "[Baseline][537] Loss=1.0226, Acc=0.5297\n",
      "[Baseline][538] Loss=1.0686, Acc=0.5298\n",
      "[Baseline][539] Loss=1.0706, Acc=0.5312\n",
      "[Baseline][540] Loss=1.0357, Acc=0.5275\n",
      "[Baseline][541] Loss=1.0388, Acc=0.5284\n",
      "[Baseline][542] Loss=1.0191, Acc=0.5288\n",
      "[Baseline][543] Loss=1.0374, Acc=0.5455\n",
      "[Baseline][544] Loss=1.0252, Acc=0.5268\n",
      "[Baseline][545] Loss=1.0329, Acc=0.5406\n",
      "[Baseline][546] Loss=1.0287, Acc=0.5433\n",
      "[Baseline][547] Loss=1.0351, Acc=0.5295\n",
      "[Baseline][548] Loss=1.0395, Acc=0.5289\n",
      "[Baseline][549] Loss=1.0351, Acc=0.5399\n",
      "[Baseline][550] Loss=1.0154, Acc=0.5376\n",
      "[Baseline][551] Loss=1.0100, Acc=0.5388\n",
      "[Baseline][552] Loss=1.0241, Acc=0.5354\n",
      "[Baseline][553] Loss=1.0424, Acc=0.5469\n",
      "[Baseline][554] Loss=1.0498, Acc=0.5220\n",
      "[Baseline][555] Loss=1.0316, Acc=0.5306\n",
      "[Baseline][556] Loss=1.0383, Acc=0.5415\n",
      "[Baseline][557] Loss=1.0112, Acc=0.5386\n",
      "[Baseline][558] Loss=0.9911, Acc=0.5316\n",
      "[Baseline][559] Loss=1.0369, Acc=0.5280\n",
      "[Baseline][560] Loss=1.0436, Acc=0.5465\n",
      "[Baseline][561] Loss=1.0203, Acc=0.5317\n",
      "[Baseline][562] Loss=1.0328, Acc=0.5322\n",
      "[Baseline][563] Loss=1.0457, Acc=0.5343\n",
      "[Baseline][564] Loss=1.0225, Acc=0.5391\n",
      "[Baseline][565] Loss=1.0114, Acc=0.5409\n",
      "[Baseline][566] Loss=0.9942, Acc=0.5414\n",
      "[Baseline][567] Loss=1.0022, Acc=0.5377\n",
      "[Baseline][568] Loss=1.0278, Acc=0.5354\n",
      "[Baseline][569] Loss=0.9923, Acc=0.5310\n",
      "[Baseline][570] Loss=1.0368, Acc=0.5325\n",
      "[Baseline][571] Loss=1.0264, Acc=0.5439\n",
      "[Baseline][572] Loss=1.0162, Acc=0.5380\n",
      "[Baseline][573] Loss=1.0407, Acc=0.5425\n",
      "[Baseline][574] Loss=1.0279, Acc=0.5407\n",
      "[Baseline][575] Loss=1.0140, Acc=0.5388\n",
      "[Baseline][576] Loss=1.0265, Acc=0.5510\n",
      "[Baseline][577] Loss=1.0290, Acc=0.5366\n",
      "[Baseline][578] Loss=1.0105, Acc=0.5458\n",
      "[Baseline][579] Loss=1.0036, Acc=0.5428\n",
      "[Baseline][580] Loss=0.9934, Acc=0.5491\n",
      "[Baseline][581] Loss=1.0118, Acc=0.5357\n",
      "[Baseline][582] Loss=1.0323, Acc=0.5406\n",
      "[Baseline][583] Loss=1.0378, Acc=0.5258\n",
      "[Baseline][584] Loss=1.0331, Acc=0.5285\n",
      "[Baseline][585] Loss=1.0134, Acc=0.5526\n",
      "[Baseline][586] Loss=0.9977, Acc=0.5392\n",
      "[Baseline][587] Loss=0.9932, Acc=0.5417\n",
      "[Baseline][588] Loss=1.0013, Acc=0.5423\n",
      "[Baseline][589] Loss=1.0194, Acc=0.5360\n",
      "[Baseline][590] Loss=1.0017, Acc=0.5306\n",
      "[Baseline][591] Loss=1.0078, Acc=0.5399\n",
      "[Baseline][592] Loss=1.0124, Acc=0.5324\n",
      "[Baseline][593] Loss=0.9893, Acc=0.5514\n",
      "[Baseline][594] Loss=0.9983, Acc=0.5440\n",
      "[Baseline][595] Loss=1.0219, Acc=0.5415\n",
      "[Baseline][596] Loss=1.0295, Acc=0.5468\n",
      "[Baseline][597] Loss=1.0039, Acc=0.5362\n",
      "[Baseline][598] Loss=1.0337, Acc=0.5312\n",
      "[Baseline][599] Loss=1.0115, Acc=0.5377\n",
      "[Baseline][600] Loss=1.0023, Acc=0.5429\n",
      "[Baseline][601] Loss=0.9863, Acc=0.5211\n",
      "[Baseline][602] Loss=1.0347, Acc=0.5420\n",
      "[Baseline][603] Loss=0.9910, Acc=0.5447\n",
      "[Baseline][604] Loss=0.9943, Acc=0.5384\n",
      "[Baseline][605] Loss=1.0047, Acc=0.5472\n",
      "[Baseline][606] Loss=0.9984, Acc=0.5451\n",
      "[Baseline][607] Loss=1.0378, Acc=0.5396\n",
      "[Baseline][608] Loss=1.0121, Acc=0.5406\n",
      "[Baseline][609] Loss=1.0125, Acc=0.5455\n",
      "[Baseline][610] Loss=1.0065, Acc=0.5357\n",
      "[Baseline][611] Loss=1.0308, Acc=0.5461\n",
      "[Baseline][612] Loss=0.9953, Acc=0.5497\n",
      "[Baseline][613] Loss=0.9680, Acc=0.5328\n",
      "[Baseline][614] Loss=0.9810, Acc=0.5408\n",
      "[Baseline][615] Loss=0.9968, Acc=0.5468\n",
      "[Baseline][616] Loss=1.0001, Acc=0.5405\n",
      "[Baseline][617] Loss=0.9749, Acc=0.5394\n",
      "[Baseline][618] Loss=0.9844, Acc=0.5446\n",
      "[Baseline][619] Loss=0.9813, Acc=0.5413\n",
      "[Baseline][620] Loss=0.9737, Acc=0.5530\n",
      "[Baseline][621] Loss=1.0134, Acc=0.5353\n",
      "[Baseline][622] Loss=0.9928, Acc=0.5377\n",
      "[Baseline][623] Loss=0.9889, Acc=0.5310\n",
      "[Baseline][624] Loss=0.9862, Acc=0.5412\n",
      "[Baseline][625] Loss=1.0071, Acc=0.5456\n",
      "[Baseline][626] Loss=0.9685, Acc=0.5412\n",
      "[Baseline][627] Loss=0.9832, Acc=0.5457\n",
      "[Baseline][628] Loss=0.9861, Acc=0.5384\n",
      "[Baseline][629] Loss=0.9916, Acc=0.5457\n",
      "[Baseline][630] Loss=0.9877, Acc=0.5339\n",
      "[Baseline][631] Loss=0.9758, Acc=0.5469\n",
      "[Baseline][632] Loss=0.9607, Acc=0.5464\n",
      "[Baseline][633] Loss=0.9667, Acc=0.5234\n",
      "[Baseline][634] Loss=1.0041, Acc=0.5262\n",
      "[Baseline][635] Loss=0.9933, Acc=0.5358\n",
      "[Baseline][636] Loss=1.0053, Acc=0.5403\n",
      "[Baseline][637] Loss=0.9877, Acc=0.5319\n",
      "[Baseline][638] Loss=1.0102, Acc=0.5324\n",
      "[Baseline][639] Loss=0.9596, Acc=0.5491\n",
      "[Baseline][640] Loss=0.9723, Acc=0.5372\n",
      "[Baseline][641] Loss=0.9854, Acc=0.5462\n",
      "[Baseline][642] Loss=0.9652, Acc=0.5284\n",
      "[Baseline][643] Loss=0.9790, Acc=0.5374\n",
      "[Baseline][644] Loss=0.9856, Acc=0.5461\n",
      "[Baseline][645] Loss=0.9886, Acc=0.5498\n",
      "[Baseline][646] Loss=0.9908, Acc=0.5519\n",
      "[Baseline][647] Loss=0.9749, Acc=0.5341\n",
      "[Baseline][648] Loss=0.9595, Acc=0.5372\n",
      "[Baseline][649] Loss=0.9917, Acc=0.5386\n",
      "[Baseline][650] Loss=0.9617, Acc=0.5527\n",
      "[Baseline][651] Loss=0.9947, Acc=0.5334\n",
      "[Baseline][652] Loss=0.9945, Acc=0.5336\n",
      "[Baseline][653] Loss=0.9729, Acc=0.5358\n",
      "[Baseline][654] Loss=1.0155, Acc=0.5397\n",
      "[Baseline][655] Loss=0.9858, Acc=0.5414\n",
      "[Baseline][656] Loss=0.9651, Acc=0.5377\n",
      "[Baseline][657] Loss=0.9785, Acc=0.5498\n",
      "[Baseline][658] Loss=0.9687, Acc=0.5506\n",
      "[Baseline][659] Loss=0.9641, Acc=0.5498\n",
      "[Baseline][660] Loss=0.9677, Acc=0.5325\n",
      "[Baseline][661] Loss=0.9736, Acc=0.5399\n",
      "[Baseline][662] Loss=0.9759, Acc=0.5418\n",
      "[Baseline][663] Loss=0.9758, Acc=0.5370\n",
      "[Baseline][664] Loss=0.9793, Acc=0.5557\n",
      "[Baseline][665] Loss=0.9533, Acc=0.5473\n",
      "[Baseline][666] Loss=0.9706, Acc=0.5517\n",
      "[Baseline][667] Loss=0.9520, Acc=0.5395\n",
      "[Baseline][668] Loss=0.9868, Acc=0.5343\n",
      "[Baseline][669] Loss=0.9631, Acc=0.5325\n",
      "[Baseline][670] Loss=0.9737, Acc=0.5428\n",
      "[Baseline][671] Loss=0.9396, Acc=0.5454\n",
      "[Baseline][672] Loss=0.9479, Acc=0.5490\n",
      "[Baseline][673] Loss=0.9740, Acc=0.5480\n",
      "[Baseline][674] Loss=0.9629, Acc=0.5490\n",
      "[Baseline][675] Loss=0.9579, Acc=0.5484\n",
      "[Baseline][676] Loss=0.9569, Acc=0.5364\n",
      "[Baseline][677] Loss=0.9774, Acc=0.4946\n",
      "[Baseline][678] Loss=1.0080, Acc=0.5364\n",
      "[Baseline][679] Loss=0.9462, Acc=0.5331\n",
      "[Baseline][680] Loss=0.9590, Acc=0.5404\n",
      "[Baseline][681] Loss=0.9415, Acc=0.5459\n",
      "[Baseline][682] Loss=0.9528, Acc=0.5504\n",
      "[Baseline][683] Loss=0.9401, Acc=0.5414\n",
      "[Baseline][684] Loss=0.9978, Acc=0.5372\n",
      "[Baseline][685] Loss=0.9737, Acc=0.5475\n",
      "[Baseline][686] Loss=0.9715, Acc=0.5457\n",
      "[Baseline][687] Loss=0.9659, Acc=0.5390\n",
      "[Baseline][688] Loss=0.9704, Acc=0.5536\n",
      "[Baseline][689] Loss=0.9377, Acc=0.5396\n",
      "[Baseline][690] Loss=0.9597, Acc=0.5497\n",
      "[Baseline][691] Loss=0.9844, Acc=0.5357\n",
      "[Baseline][692] Loss=0.9384, Acc=0.5572\n",
      "[Baseline][693] Loss=0.9386, Acc=0.5528\n",
      "[Baseline][694] Loss=0.9298, Acc=0.5424\n",
      "[Baseline][695] Loss=0.9530, Acc=0.5490\n",
      "[Baseline][696] Loss=0.9913, Acc=0.5285\n",
      "[Baseline][697] Loss=0.9727, Acc=0.5393\n",
      "[Baseline][698] Loss=0.9631, Acc=0.5476\n",
      "[Baseline][699] Loss=0.9481, Acc=0.5510\n",
      "[Baseline][700] Loss=0.9484, Acc=0.5528\n",
      "[Baseline][701] Loss=0.9606, Acc=0.5522\n",
      "[Baseline][702] Loss=0.9639, Acc=0.5486\n",
      "[Baseline][703] Loss=0.9492, Acc=0.5531\n",
      "[Baseline][704] Loss=0.9525, Acc=0.5402\n",
      "[Baseline][705] Loss=0.9521, Acc=0.5213\n",
      "[Baseline][706] Loss=0.9631, Acc=0.5520\n",
      "[Baseline][707] Loss=0.9602, Acc=0.5483\n",
      "[Baseline][708] Loss=0.9528, Acc=0.5521\n",
      "[Baseline][709] Loss=0.9499, Acc=0.5544\n",
      "[Baseline][710] Loss=0.9548, Acc=0.5528\n",
      "[Baseline][711] Loss=0.9847, Acc=0.5416\n",
      "[Baseline][712] Loss=0.9423, Acc=0.5497\n",
      "[Baseline][713] Loss=0.9338, Acc=0.5478\n",
      "[Baseline][714] Loss=0.9634, Acc=0.5306\n",
      "[Baseline][715] Loss=0.9433, Acc=0.5464\n",
      "[Baseline][716] Loss=0.9374, Acc=0.5325\n",
      "[Baseline][717] Loss=0.9508, Acc=0.5509\n",
      "[Baseline][718] Loss=0.9675, Acc=0.5443\n",
      "[Baseline][719] Loss=0.9775, Acc=0.5478\n",
      "[Baseline][720] Loss=0.9520, Acc=0.5435\n",
      "[Baseline][721] Loss=0.9377, Acc=0.5299\n",
      "[Baseline][722] Loss=0.9514, Acc=0.5466\n",
      "[Baseline][723] Loss=0.9423, Acc=0.5596\n",
      "[Baseline][724] Loss=0.9124, Acc=0.5394\n",
      "[Baseline][725] Loss=0.9418, Acc=0.5430\n",
      "[Baseline][726] Loss=0.9490, Acc=0.5526\n",
      "[Baseline][727] Loss=0.9277, Acc=0.5479\n",
      "[Baseline][728] Loss=0.9290, Acc=0.5389\n",
      "[Baseline][729] Loss=0.9436, Acc=0.5459\n",
      "[Baseline][730] Loss=0.9394, Acc=0.5431\n",
      "[Baseline][731] Loss=0.9535, Acc=0.5396\n",
      "[Baseline][732] Loss=0.9473, Acc=0.5485\n",
      "[Baseline][733] Loss=0.9417, Acc=0.5424\n",
      "[Baseline][734] Loss=0.9580, Acc=0.5545\n",
      "[Baseline][735] Loss=0.9426, Acc=0.5385\n",
      "[Baseline][736] Loss=0.9386, Acc=0.5466\n",
      "[Baseline][737] Loss=0.9322, Acc=0.5531\n",
      "[Baseline][738] Loss=0.9428, Acc=0.5475\n",
      "[Baseline][739] Loss=0.9395, Acc=0.5480\n",
      "[Baseline][740] Loss=0.9123, Acc=0.5450\n",
      "[Baseline][741] Loss=0.9207, Acc=0.5535\n",
      "[Baseline][742] Loss=0.9449, Acc=0.5450\n",
      "[Baseline][743] Loss=0.9292, Acc=0.5397\n",
      "[Baseline][744] Loss=0.9104, Acc=0.5408\n",
      "[Baseline][745] Loss=0.9361, Acc=0.5463\n",
      "[Baseline][746] Loss=0.9412, Acc=0.5491\n",
      "[Baseline][747] Loss=0.9201, Acc=0.5500\n",
      "[Baseline][748] Loss=0.9183, Acc=0.5544\n",
      "[Baseline][749] Loss=0.9351, Acc=0.5286\n",
      "[Baseline][750] Loss=0.9316, Acc=0.5500\n",
      "[Baseline][751] Loss=0.9304, Acc=0.5417\n",
      "[Baseline][752] Loss=0.9469, Acc=0.5423\n",
      "[Baseline][753] Loss=0.9285, Acc=0.5316\n",
      "[Baseline][754] Loss=0.9448, Acc=0.5461\n",
      "[Baseline][755] Loss=0.9245, Acc=0.5473\n",
      "[Baseline][756] Loss=0.9099, Acc=0.5374\n",
      "[Baseline][757] Loss=0.9138, Acc=0.5428\n",
      "[Baseline][758] Loss=0.9429, Acc=0.5309\n",
      "[Baseline][759] Loss=0.9372, Acc=0.5388\n",
      "[Baseline][760] Loss=0.9410, Acc=0.5617\n",
      "[Baseline][761] Loss=0.9186, Acc=0.5465\n",
      "[Baseline][762] Loss=0.9327, Acc=0.5471\n",
      "[Baseline][763] Loss=0.9405, Acc=0.5473\n",
      "[Baseline][764] Loss=0.9292, Acc=0.5451\n",
      "[Baseline][765] Loss=0.9171, Acc=0.5362\n",
      "[Baseline][766] Loss=0.9287, Acc=0.5575\n",
      "[Baseline][767] Loss=0.9071, Acc=0.5409\n",
      "[Baseline][768] Loss=0.8797, Acc=0.5329\n",
      "[Baseline][769] Loss=0.9177, Acc=0.5520\n",
      "[Baseline][770] Loss=0.9046, Acc=0.5517\n",
      "[Baseline][771] Loss=0.9024, Acc=0.5334\n",
      "[Baseline][772] Loss=0.9075, Acc=0.5522\n",
      "[Baseline][773] Loss=0.8892, Acc=0.5601\n",
      "[Baseline][774] Loss=0.9105, Acc=0.5333\n",
      "[Baseline][775] Loss=0.9116, Acc=0.5570\n",
      "[Baseline][776] Loss=0.9040, Acc=0.5510\n",
      "[Baseline][777] Loss=0.9078, Acc=0.5521\n",
      "[Baseline][778] Loss=0.9304, Acc=0.5464\n",
      "[Baseline][779] Loss=0.9349, Acc=0.5348\n",
      "[Baseline][780] Loss=0.9479, Acc=0.5479\n",
      "[Baseline][781] Loss=0.9351, Acc=0.5584\n",
      "[Baseline][782] Loss=0.9355, Acc=0.5536\n",
      "[Baseline][783] Loss=0.9479, Acc=0.5473\n",
      "[Baseline][784] Loss=0.9101, Acc=0.5417\n",
      "[Baseline][785] Loss=0.9370, Acc=0.5499\n",
      "[Baseline][786] Loss=0.9398, Acc=0.5548\n",
      "[Baseline][787] Loss=0.9117, Acc=0.5529\n",
      "[Baseline][788] Loss=0.9234, Acc=0.5460\n",
      "[Baseline][789] Loss=0.8886, Acc=0.5511\n",
      "[Baseline][790] Loss=0.9375, Acc=0.5487\n",
      "[Baseline][791] Loss=0.9560, Acc=0.5498\n",
      "[Baseline][792] Loss=0.8981, Acc=0.5426\n",
      "[Baseline][793] Loss=0.9355, Acc=0.5491\n",
      "[Baseline][794] Loss=0.9370, Acc=0.5592\n",
      "[Baseline][795] Loss=0.9112, Acc=0.5532\n",
      "[Baseline][796] Loss=0.8962, Acc=0.5547\n",
      "[Baseline][797] Loss=0.9018, Acc=0.5378\n",
      "[Baseline][798] Loss=0.9011, Acc=0.5469\n",
      "[Baseline][799] Loss=0.8976, Acc=0.5449\n",
      "[Baseline][800] Loss=0.9171, Acc=0.5606\n",
      "[Baseline][801] Loss=0.9259, Acc=0.5491\n",
      "[Baseline][802] Loss=0.8887, Acc=0.5541\n",
      "[Baseline][803] Loss=0.9053, Acc=0.5531\n",
      "[Baseline][804] Loss=0.9073, Acc=0.5405\n",
      "[Baseline][805] Loss=0.8982, Acc=0.5646\n",
      "[Baseline][806] Loss=0.8990, Acc=0.5553\n",
      "[Baseline][807] Loss=0.8806, Acc=0.5496\n",
      "[Baseline][808] Loss=0.8981, Acc=0.5422\n",
      "[Baseline][809] Loss=0.9248, Acc=0.5470\n",
      "[Baseline][810] Loss=0.8909, Acc=0.5519\n",
      "[Baseline][811] Loss=0.9032, Acc=0.5549\n",
      "[Baseline][812] Loss=0.8889, Acc=0.5585\n",
      "[Baseline][813] Loss=0.8867, Acc=0.5554\n",
      "[Baseline][814] Loss=0.8674, Acc=0.5460\n",
      "[Baseline][815] Loss=0.8938, Acc=0.5493\n",
      "[Baseline][816] Loss=0.8980, Acc=0.5423\n",
      "[Baseline][817] Loss=0.9205, Acc=0.5537\n",
      "[Baseline][818] Loss=0.9384, Acc=0.5438\n",
      "[Baseline][819] Loss=0.9452, Acc=0.5394\n",
      "[Baseline][820] Loss=0.9132, Acc=0.5388\n",
      "[Baseline][821] Loss=0.9036, Acc=0.5362\n",
      "[Baseline][822] Loss=0.9164, Acc=0.5528\n",
      "[Baseline][823] Loss=0.9208, Acc=0.5535\n",
      "[Baseline][824] Loss=0.9004, Acc=0.5522\n",
      "[Baseline][825] Loss=0.8754, Acc=0.5598\n",
      "[Baseline][826] Loss=0.8708, Acc=0.5582\n",
      "[Baseline][827] Loss=0.8768, Acc=0.5637\n",
      "[Baseline][828] Loss=0.8769, Acc=0.5544\n",
      "[Baseline][829] Loss=0.8947, Acc=0.5495\n",
      "[Baseline][830] Loss=0.9210, Acc=0.5440\n",
      "[Baseline][831] Loss=0.9001, Acc=0.5529\n",
      "[Baseline][832] Loss=0.8740, Acc=0.5626\n",
      "[Baseline][833] Loss=0.8871, Acc=0.5584\n",
      "[Baseline][834] Loss=0.8944, Acc=0.5551\n",
      "[Baseline][835] Loss=0.8964, Acc=0.5569\n",
      "[Baseline][836] Loss=0.8871, Acc=0.5602\n",
      "[Baseline][837] Loss=0.8792, Acc=0.5559\n",
      "[Baseline][838] Loss=0.8926, Acc=0.5592\n",
      "[Baseline][839] Loss=0.8799, Acc=0.5547\n",
      "[Baseline][840] Loss=0.8988, Acc=0.5435\n",
      "[Baseline][841] Loss=0.9126, Acc=0.5479\n",
      "[Baseline][842] Loss=0.9046, Acc=0.5433\n",
      "[Baseline][843] Loss=0.8967, Acc=0.5568\n",
      "[Baseline][844] Loss=0.8764, Acc=0.5504\n",
      "[Baseline][845] Loss=0.8931, Acc=0.5515\n",
      "[Baseline][846] Loss=0.8927, Acc=0.5579\n",
      "[Baseline][847] Loss=0.8580, Acc=0.5402\n",
      "[Baseline][848] Loss=0.8861, Acc=0.5424\n",
      "[Baseline][849] Loss=0.8868, Acc=0.5567\n",
      "[Baseline][850] Loss=0.8876, Acc=0.5512\n",
      "[Baseline][851] Loss=0.8662, Acc=0.5448\n",
      "[Baseline][852] Loss=0.8828, Acc=0.5651\n",
      "[Baseline][853] Loss=0.8920, Acc=0.5550\n",
      "[Baseline][854] Loss=0.8795, Acc=0.5548\n",
      "[Baseline][855] Loss=0.8596, Acc=0.5568\n",
      "[Baseline][856] Loss=0.8790, Acc=0.5128\n",
      "[Baseline][857] Loss=0.9017, Acc=0.5568\n",
      "[Baseline][858] Loss=0.8881, Acc=0.5464\n",
      "[Baseline][859] Loss=0.8941, Acc=0.5480\n",
      "[Baseline][860] Loss=0.8751, Acc=0.5637\n",
      "[Baseline][861] Loss=0.8947, Acc=0.5535\n",
      "[Baseline][862] Loss=0.8831, Acc=0.5513\n",
      "[Baseline][863] Loss=0.8680, Acc=0.5474\n",
      "[Baseline][864] Loss=0.8870, Acc=0.5340\n",
      "[Baseline][865] Loss=0.8970, Acc=0.5527\n",
      "[Baseline][866] Loss=0.8683, Acc=0.5582\n",
      "[Baseline][867] Loss=0.8553, Acc=0.5596\n",
      "[Baseline][868] Loss=0.8706, Acc=0.5546\n",
      "[Baseline][869] Loss=0.8747, Acc=0.5622\n",
      "[Baseline][870] Loss=0.8763, Acc=0.5550\n",
      "[Baseline][871] Loss=0.9465, Acc=0.5649\n",
      "[Baseline][872] Loss=0.8913, Acc=0.5508\n",
      "[Baseline][873] Loss=0.8735, Acc=0.5613\n",
      "[Baseline][874] Loss=0.8506, Acc=0.5579\n",
      "[Baseline][875] Loss=0.8816, Acc=0.5521\n",
      "[Baseline][876] Loss=0.9113, Acc=0.5457\n",
      "[Baseline][877] Loss=0.8664, Acc=0.5586\n",
      "[Baseline][878] Loss=0.8604, Acc=0.5598\n",
      "[Baseline][879] Loss=0.8626, Acc=0.5503\n",
      "[Baseline][880] Loss=0.8705, Acc=0.5577\n",
      "[Baseline][881] Loss=0.8571, Acc=0.5633\n",
      "[Baseline][882] Loss=0.8713, Acc=0.5535\n",
      "[Baseline][883] Loss=0.8746, Acc=0.5512\n",
      "[Baseline][884] Loss=0.8704, Acc=0.5628\n",
      "[Baseline][885] Loss=0.8533, Acc=0.5588\n",
      "[Baseline][886] Loss=0.8551, Acc=0.5648\n",
      "[Baseline][887] Loss=0.8702, Acc=0.5583\n",
      "[Baseline][888] Loss=0.8741, Acc=0.5440\n",
      "[Baseline][889] Loss=0.8705, Acc=0.5590\n",
      "[Baseline][890] Loss=0.8740, Acc=0.5589\n",
      "[Baseline][891] Loss=0.8504, Acc=0.5597\n",
      "[Baseline][892] Loss=0.8383, Acc=0.5385\n",
      "[Baseline][893] Loss=0.8834, Acc=0.5654\n",
      "[Baseline][894] Loss=0.8521, Acc=0.5570\n",
      "[Baseline][895] Loss=0.8569, Acc=0.5590\n",
      "[Baseline][896] Loss=0.8629, Acc=0.5606\n",
      "[Baseline][897] Loss=0.8482, Acc=0.5571\n",
      "[Baseline][898] Loss=0.8431, Acc=0.5544\n",
      "[Baseline][899] Loss=0.8579, Acc=0.5601\n",
      "[Baseline][900] Loss=0.8268, Acc=0.5529\n",
      "[Baseline][901] Loss=0.8384, Acc=0.5476\n",
      "[Baseline][902] Loss=0.8624, Acc=0.5598\n",
      "[Baseline][903] Loss=0.8645, Acc=0.5551\n",
      "[Baseline][904] Loss=0.8399, Acc=0.5587\n",
      "[Baseline][905] Loss=0.8342, Acc=0.5486\n",
      "[Baseline][906] Loss=0.8718, Acc=0.5645\n",
      "[Baseline][907] Loss=0.8813, Acc=0.5663\n",
      "[Baseline][908] Loss=0.8645, Acc=0.5478\n",
      "[Baseline][909] Loss=0.8646, Acc=0.5560\n",
      "[Baseline][910] Loss=0.8560, Acc=0.5524\n",
      "[Baseline][911] Loss=0.8455, Acc=0.5501\n",
      "[Baseline][912] Loss=0.8594, Acc=0.5618\n",
      "[Baseline][913] Loss=0.8478, Acc=0.5559\n",
      "[Baseline][914] Loss=0.8196, Acc=0.5610\n",
      "[Baseline][915] Loss=0.8322, Acc=0.5613\n",
      "[Baseline][916] Loss=0.8375, Acc=0.5636\n",
      "[Baseline][917] Loss=0.8531, Acc=0.5328\n",
      "[Baseline][918] Loss=0.8607, Acc=0.5577\n",
      "[Baseline][919] Loss=0.8604, Acc=0.5612\n",
      "[Baseline][920] Loss=0.8917, Acc=0.5583\n",
      "[Baseline][921] Loss=0.8493, Acc=0.5508\n",
      "[Baseline][922] Loss=0.8560, Acc=0.5495\n",
      "[Baseline][923] Loss=0.8631, Acc=0.5542\n",
      "[Baseline][924] Loss=0.8736, Acc=0.5573\n",
      "[Baseline][925] Loss=0.8468, Acc=0.5373\n",
      "[Baseline][926] Loss=0.8801, Acc=0.5710\n",
      "[Baseline][927] Loss=0.8289, Acc=0.5585\n",
      "[Baseline][928] Loss=0.8630, Acc=0.5645\n",
      "[Baseline][929] Loss=0.8762, Acc=0.5591\n",
      "[Baseline][930] Loss=0.8235, Acc=0.5425\n",
      "[Baseline][931] Loss=0.8519, Acc=0.5631\n",
      "[Baseline][932] Loss=0.8734, Acc=0.5554\n",
      "[Baseline][933] Loss=0.8595, Acc=0.5525\n",
      "[Baseline][934] Loss=0.8763, Acc=0.5625\n",
      "[Baseline][935] Loss=0.8493, Acc=0.5633\n",
      "[Baseline][936] Loss=0.8518, Acc=0.5543\n",
      "[Baseline][937] Loss=0.8533, Acc=0.5604\n",
      "[Baseline][938] Loss=0.8139, Acc=0.5618\n",
      "[Baseline][939] Loss=0.8159, Acc=0.5573\n",
      "[Baseline][940] Loss=0.8415, Acc=0.5563\n",
      "[Baseline][941] Loss=0.8485, Acc=0.5594\n",
      "[Baseline][942] Loss=0.8427, Acc=0.5567\n",
      "[Baseline][943] Loss=0.8636, Acc=0.5623\n",
      "[Baseline][944] Loss=0.8329, Acc=0.5520\n",
      "[Baseline][945] Loss=0.8515, Acc=0.5577\n",
      "[Baseline][946] Loss=0.8343, Acc=0.5444\n",
      "[Baseline][947] Loss=0.8588, Acc=0.5604\n",
      "[Baseline][948] Loss=0.8354, Acc=0.5554\n",
      "[Baseline][949] Loss=0.8684, Acc=0.5560\n",
      "[Baseline][950] Loss=0.8504, Acc=0.5571\n",
      "[Baseline][951] Loss=0.8460, Acc=0.5642\n",
      "[Baseline][952] Loss=0.8173, Acc=0.5484\n",
      "[Baseline][953] Loss=0.8356, Acc=0.5603\n",
      "[Baseline][954] Loss=0.8546, Acc=0.5449\n",
      "[Baseline][955] Loss=0.8477, Acc=0.5696\n",
      "[Baseline][956] Loss=0.8206, Acc=0.5489\n",
      "[Baseline][957] Loss=0.8478, Acc=0.5592\n",
      "[Baseline][958] Loss=0.8721, Acc=0.5609\n",
      "[Baseline][959] Loss=0.8317, Acc=0.5566\n",
      "[Baseline][960] Loss=0.8410, Acc=0.5506\n",
      "[Baseline][961] Loss=0.8388, Acc=0.5610\n",
      "[Baseline][962] Loss=0.8370, Acc=0.5678\n",
      "[Baseline][963] Loss=0.8368, Acc=0.5510\n",
      "[Baseline][964] Loss=0.8567, Acc=0.5511\n",
      "[Baseline][965] Loss=0.8334, Acc=0.5556\n",
      "[Baseline][966] Loss=0.8484, Acc=0.5515\n",
      "[Baseline][967] Loss=0.8451, Acc=0.5532\n",
      "[Baseline][968] Loss=0.8330, Acc=0.5615\n",
      "[Baseline][969] Loss=0.8421, Acc=0.5582\n",
      "[Baseline][970] Loss=0.8755, Acc=0.5341\n",
      "[Baseline][971] Loss=0.8446, Acc=0.5626\n",
      "[Baseline][972] Loss=0.8202, Acc=0.5242\n",
      "[Baseline][973] Loss=0.8043, Acc=0.5656\n",
      "[Baseline][974] Loss=0.8155, Acc=0.5525\n",
      "[Baseline][975] Loss=0.8183, Acc=0.5615\n",
      "[Baseline][976] Loss=0.8209, Acc=0.5600\n",
      "[Baseline][977] Loss=0.8422, Acc=0.5595\n",
      "[Baseline][978] Loss=0.8291, Acc=0.5624\n",
      "[Baseline][979] Loss=0.8474, Acc=0.5525\n",
      "[Baseline][980] Loss=0.8364, Acc=0.5552\n",
      "[Baseline][981] Loss=0.8745, Acc=0.5521\n",
      "[Baseline][982] Loss=0.8285, Acc=0.5518\n",
      "[Baseline][983] Loss=0.8260, Acc=0.5612\n",
      "[Baseline][984] Loss=0.8229, Acc=0.5501\n",
      "[Baseline][985] Loss=0.8202, Acc=0.5442\n",
      "[Baseline][986] Loss=0.8290, Acc=0.5546\n",
      "[Baseline][987] Loss=0.8281, Acc=0.5560\n",
      "[Baseline][988] Loss=0.8123, Acc=0.5403\n",
      "[Baseline][989] Loss=0.8170, Acc=0.5625\n",
      "[Baseline][990] Loss=0.8251, Acc=0.5552\n",
      "[Baseline][991] Loss=0.8467, Acc=0.5550\n",
      "[Baseline][992] Loss=0.8068, Acc=0.5671\n",
      "[Baseline][993] Loss=0.8225, Acc=0.5667\n",
      "[Baseline][994] Loss=0.8466, Acc=0.5525\n",
      "[Baseline][995] Loss=0.7975, Acc=0.5566\n",
      "[Baseline][996] Loss=0.7996, Acc=0.5542\n",
      "[Baseline][997] Loss=0.8223, Acc=0.5539\n",
      "[Baseline][998] Loss=0.8383, Acc=0.5697\n",
      "[Baseline][999] Loss=0.8054, Acc=0.5668\n",
      "[Baseline][1000] Loss=0.8279, Acc=0.5712\n",
      "[Baseline][1001] Loss=0.8177, Acc=0.5680\n",
      "[Baseline][1002] Loss=0.8118, Acc=0.5624\n",
      "[Baseline][1003] Loss=0.7969, Acc=0.5503\n",
      "[Baseline][1004] Loss=0.8165, Acc=0.5621\n",
      "[Baseline][1005] Loss=0.7924, Acc=0.5629\n",
      "[Baseline][1006] Loss=0.7928, Acc=0.5501\n",
      "[Baseline][1007] Loss=0.8145, Acc=0.5667\n",
      "[Baseline][1008] Loss=0.8117, Acc=0.5604\n",
      "[Baseline][1009] Loss=0.8199, Acc=0.5527\n",
      "[Baseline][1010] Loss=0.8185, Acc=0.5677\n",
      "[Baseline][1011] Loss=0.7964, Acc=0.5657\n",
      "[Baseline][1012] Loss=0.7971, Acc=0.5648\n",
      "[Baseline][1013] Loss=0.8331, Acc=0.5602\n",
      "[Baseline][1014] Loss=0.8103, Acc=0.5622\n",
      "[Baseline][1015] Loss=0.8025, Acc=0.5710\n",
      "[Baseline][1016] Loss=0.8030, Acc=0.5624\n",
      "[Baseline][1017] Loss=0.8364, Acc=0.5617\n",
      "[Baseline][1018] Loss=0.8116, Acc=0.5480\n",
      "[Baseline][1019] Loss=0.8029, Acc=0.5535\n",
      "[Baseline][1020] Loss=0.8338, Acc=0.5580\n",
      "[Baseline][1021] Loss=0.8173, Acc=0.5557\n",
      "[Baseline][1022] Loss=0.8116, Acc=0.5603\n",
      "[Baseline][1023] Loss=0.8192, Acc=0.5625\n",
      "[Baseline][1024] Loss=0.8230, Acc=0.5597\n",
      "[Baseline][1025] Loss=0.8177, Acc=0.5633\n",
      "[Baseline][1026] Loss=0.8135, Acc=0.5647\n",
      "[Baseline][1027] Loss=0.8135, Acc=0.5496\n",
      "[Baseline][1028] Loss=0.8247, Acc=0.5601\n",
      "[Baseline][1029] Loss=0.8243, Acc=0.5590\n",
      "[Baseline][1030] Loss=0.8300, Acc=0.5560\n",
      "[Baseline][1031] Loss=0.7958, Acc=0.5671\n",
      "[Baseline][1032] Loss=0.8178, Acc=0.5645\n",
      "[Baseline][1033] Loss=0.8421, Acc=0.5543\n",
      "[Baseline][1034] Loss=0.8508, Acc=0.5586\n",
      "[Baseline][1035] Loss=0.8114, Acc=0.5657\n",
      "[Baseline][1036] Loss=0.8089, Acc=0.5645\n",
      "[Baseline][1037] Loss=0.8019, Acc=0.5560\n",
      "[Baseline][1038] Loss=0.8007, Acc=0.5504\n",
      "[Baseline][1039] Loss=0.8292, Acc=0.5645\n",
      "[Baseline][1040] Loss=0.8278, Acc=0.5587\n",
      "[Baseline][1041] Loss=0.8004, Acc=0.5569\n",
      "[Baseline][1042] Loss=0.7918, Acc=0.5648\n",
      "[Baseline][1043] Loss=0.8112, Acc=0.5691\n",
      "[Baseline][1044] Loss=0.8421, Acc=0.5491\n",
      "[Baseline][1045] Loss=0.8139, Acc=0.5488\n",
      "[Baseline][1046] Loss=0.8016, Acc=0.5577\n",
      "[Baseline][1047] Loss=0.7947, Acc=0.5580\n",
      "[Baseline][1048] Loss=0.8161, Acc=0.5663\n",
      "[Baseline][1049] Loss=0.8248, Acc=0.5674\n",
      "[Baseline][1050] Loss=0.8091, Acc=0.5668\n",
      "[Baseline][1051] Loss=0.7739, Acc=0.5642\n",
      "[Baseline][1052] Loss=0.8147, Acc=0.5643\n",
      "[Baseline][1053] Loss=0.8151, Acc=0.5469\n",
      "[Baseline][1054] Loss=0.8257, Acc=0.5432\n",
      "[Baseline][1055] Loss=0.8228, Acc=0.5682\n",
      "[Baseline][1056] Loss=0.7933, Acc=0.5541\n",
      "[Baseline][1057] Loss=0.7934, Acc=0.5679\n",
      "[Baseline][1058] Loss=0.8105, Acc=0.5526\n",
      "[Baseline][1059] Loss=0.8179, Acc=0.5709\n",
      "[Baseline][1060] Loss=0.7853, Acc=0.5740\n",
      "[Baseline][1061] Loss=0.7809, Acc=0.5662\n",
      "[Baseline][1062] Loss=0.7740, Acc=0.5631\n",
      "[Baseline][1063] Loss=0.8173, Acc=0.5661\n",
      "[Baseline][1064] Loss=0.8128, Acc=0.5738\n",
      "[Baseline][1065] Loss=0.8205, Acc=0.5525\n",
      "[Baseline][1066] Loss=0.8115, Acc=0.5744\n",
      "[Baseline][1067] Loss=0.8076, Acc=0.5712\n",
      "[Baseline][1068] Loss=0.7997, Acc=0.5642\n",
      "[Baseline][1069] Loss=0.7719, Acc=0.5658\n",
      "[Baseline][1070] Loss=0.7738, Acc=0.5606\n",
      "[Baseline][1071] Loss=0.7860, Acc=0.5648\n",
      "[Baseline][1072] Loss=0.7953, Acc=0.5656\n",
      "[Baseline][1073] Loss=0.7904, Acc=0.5570\n",
      "[Baseline][1074] Loss=0.7731, Acc=0.5636\n",
      "[Baseline][1075] Loss=0.7805, Acc=0.5659\n",
      "[Baseline][1076] Loss=0.7736, Acc=0.5752\n",
      "[Baseline][1077] Loss=0.7775, Acc=0.5514\n",
      "[Baseline][1078] Loss=0.8390, Acc=0.5644\n",
      "[Baseline][1079] Loss=0.7938, Acc=0.5604\n",
      "[Baseline][1080] Loss=0.8097, Acc=0.5551\n",
      "[Baseline][1081] Loss=0.7841, Acc=0.5627\n",
      "[Baseline][1082] Loss=0.7966, Acc=0.5624\n",
      "[Baseline][1083] Loss=0.8182, Acc=0.5491\n",
      "[Baseline][1084] Loss=0.8364, Acc=0.5644\n",
      "[Baseline][1085] Loss=0.7932, Acc=0.5582\n",
      "[Baseline][1086] Loss=0.8185, Acc=0.5611\n",
      "[Baseline][1087] Loss=0.8031, Acc=0.5671\n",
      "[Baseline][1088] Loss=0.7826, Acc=0.5687\n",
      "[Baseline][1089] Loss=0.7550, Acc=0.5631\n",
      "[Baseline][1090] Loss=0.7852, Acc=0.5546\n",
      "[Baseline][1091] Loss=0.8067, Acc=0.5708\n",
      "[Baseline][1092] Loss=0.8017, Acc=0.5552\n",
      "[Baseline][1093] Loss=0.8102, Acc=0.5612\n",
      "[Baseline][1094] Loss=0.7762, Acc=0.5635\n",
      "[Baseline][1095] Loss=0.7928, Acc=0.5676\n",
      "[Baseline][1096] Loss=0.7987, Acc=0.5630\n",
      "[Baseline][1097] Loss=0.8186, Acc=0.5754\n",
      "[Baseline][1098] Loss=0.7756, Acc=0.5684\n",
      "[Baseline][1099] Loss=0.7585, Acc=0.5619\n",
      "[Baseline][1100] Loss=0.7617, Acc=0.5574\n",
      "[Baseline][1101] Loss=0.7991, Acc=0.5638\n",
      "[Baseline][1102] Loss=0.7945, Acc=0.5523\n",
      "[Baseline][1103] Loss=0.8048, Acc=0.5590\n",
      "[Baseline][1104] Loss=0.7955, Acc=0.5495\n",
      "[Baseline][1105] Loss=0.8182, Acc=0.5641\n",
      "[Baseline][1106] Loss=0.7908, Acc=0.5693\n",
      "[Baseline][1107] Loss=0.7781, Acc=0.5580\n",
      "[Baseline][1108] Loss=0.7917, Acc=0.5692\n",
      "[Baseline][1109] Loss=0.7653, Acc=0.5591\n",
      "[Baseline][1110] Loss=0.7866, Acc=0.5695\n",
      "[Baseline][1111] Loss=0.7898, Acc=0.5648\n",
      "[Baseline][1112] Loss=0.7990, Acc=0.5572\n",
      "[Baseline][1113] Loss=0.7738, Acc=0.5600\n",
      "[Baseline][1114] Loss=0.7740, Acc=0.5513\n",
      "[Baseline][1115] Loss=0.7854, Acc=0.5664\n",
      "[Baseline][1116] Loss=0.7752, Acc=0.5521\n",
      "[Baseline][1117] Loss=0.7942, Acc=0.5742\n",
      "[Baseline][1118] Loss=0.7626, Acc=0.5694\n",
      "[Baseline][1119] Loss=0.7806, Acc=0.5591\n",
      "[Baseline][1120] Loss=0.7924, Acc=0.5632\n",
      "[Baseline][1121] Loss=0.7691, Acc=0.5670\n",
      "[Baseline][1122] Loss=0.7657, Acc=0.5554\n",
      "[Baseline][1123] Loss=0.7793, Acc=0.5655\n",
      "[Baseline][1124] Loss=0.7693, Acc=0.5576\n",
      "[Baseline][1125] Loss=0.7727, Acc=0.5483\n",
      "[Baseline][1126] Loss=0.7881, Acc=0.5590\n",
      "[Baseline][1127] Loss=0.7825, Acc=0.5542\n",
      "[Baseline][1128] Loss=0.7815, Acc=0.5709\n",
      "[Baseline][1129] Loss=0.7856, Acc=0.5582\n",
      "[Baseline][1130] Loss=0.7660, Acc=0.5653\n",
      "[Baseline][1131] Loss=0.7555, Acc=0.5594\n",
      "[Baseline][1132] Loss=0.7955, Acc=0.5586\n",
      "[Baseline][1133] Loss=0.7922, Acc=0.5581\n",
      "[Baseline][1134] Loss=0.8053, Acc=0.5659\n",
      "[Baseline][1135] Loss=0.7770, Acc=0.5681\n",
      "[Baseline][1136] Loss=0.7502, Acc=0.5654\n",
      "[Baseline][1137] Loss=0.7571, Acc=0.5657\n",
      "[Baseline][1138] Loss=0.7618, Acc=0.5554\n",
      "[Baseline][1139] Loss=0.7653, Acc=0.5519\n",
      "[Baseline][1140] Loss=0.8056, Acc=0.5691\n",
      "[Baseline][1141] Loss=0.7389, Acc=0.5626\n",
      "[Baseline][1142] Loss=0.7606, Acc=0.5568\n",
      "[Baseline][1143] Loss=0.7556, Acc=0.5708\n",
      "[Baseline][1144] Loss=0.8116, Acc=0.5607\n",
      "[Baseline][1145] Loss=0.7414, Acc=0.5686\n",
      "[Baseline][1146] Loss=0.7742, Acc=0.5587\n",
      "[Baseline][1147] Loss=0.7669, Acc=0.5567\n",
      "[Baseline][1148] Loss=0.7627, Acc=0.5638\n",
      "[Baseline][1149] Loss=0.7381, Acc=0.5672\n",
      "[Baseline][1150] Loss=0.7462, Acc=0.5603\n",
      "[Baseline][1151] Loss=0.7539, Acc=0.5629\n",
      "[Baseline][1152] Loss=0.7717, Acc=0.5583\n",
      "[Baseline][1153] Loss=0.7578, Acc=0.5663\n",
      "[Baseline][1154] Loss=0.7633, Acc=0.5665\n",
      "[Baseline][1155] Loss=0.7685, Acc=0.5576\n",
      "[Baseline][1156] Loss=0.7546, Acc=0.5667\n",
      "[Baseline][1157] Loss=0.7580, Acc=0.5676\n",
      "[Baseline][1158] Loss=0.7716, Acc=0.5658\n",
      "[Baseline][1159] Loss=0.7961, Acc=0.5592\n",
      "[Baseline][1160] Loss=0.7460, Acc=0.5615\n",
      "[Baseline][1161] Loss=0.7616, Acc=0.5583\n",
      "[Baseline][1162] Loss=0.8057, Acc=0.5672\n",
      "[Baseline][1163] Loss=0.8076, Acc=0.5750\n",
      "[Baseline][1164] Loss=0.7777, Acc=0.5565\n",
      "[Baseline][1165] Loss=0.7682, Acc=0.5549\n",
      "[Baseline][1166] Loss=0.7762, Acc=0.5569\n",
      "[Baseline][1167] Loss=0.7726, Acc=0.5660\n",
      "[Baseline][1168] Loss=0.7589, Acc=0.5704\n",
      "[Baseline][1169] Loss=0.7289, Acc=0.5647\n",
      "[Baseline][1170] Loss=0.7430, Acc=0.5680\n",
      "[Baseline][1171] Loss=0.7312, Acc=0.5692\n",
      "[Baseline][1172] Loss=0.7475, Acc=0.5728\n",
      "[Baseline][1173] Loss=0.7769, Acc=0.5515\n",
      "[Baseline][1174] Loss=0.7610, Acc=0.5572\n",
      "[Baseline][1175] Loss=0.7650, Acc=0.5568\n",
      "[Baseline][1176] Loss=0.7535, Acc=0.5604\n",
      "[Baseline][1177] Loss=0.7781, Acc=0.5674\n",
      "[Baseline][1178] Loss=0.7667, Acc=0.5535\n",
      "[Baseline][1179] Loss=0.7830, Acc=0.5637\n",
      "[Baseline][1180] Loss=0.7361, Acc=0.5660\n",
      "[Baseline][1181] Loss=0.7573, Acc=0.5571\n",
      "[Baseline][1182] Loss=0.7530, Acc=0.5504\n",
      "[Baseline][1183] Loss=0.7902, Acc=0.5724\n",
      "[Baseline][1184] Loss=0.7721, Acc=0.5568\n",
      "[Baseline][1185] Loss=0.7567, Acc=0.5728\n",
      "[Baseline][1186] Loss=0.7438, Acc=0.5611\n",
      "[Baseline][1187] Loss=0.7397, Acc=0.5662\n",
      "[Baseline][1188] Loss=0.7244, Acc=0.5581\n",
      "[Baseline][1189] Loss=0.7531, Acc=0.5645\n",
      "[Baseline][1190] Loss=0.7543, Acc=0.5663\n",
      "[Baseline][1191] Loss=0.7351, Acc=0.5634\n",
      "[Baseline][1192] Loss=0.7510, Acc=0.5612\n",
      "[Baseline][1193] Loss=0.7776, Acc=0.5676\n",
      "[Baseline][1194] Loss=0.7541, Acc=0.5765\n",
      "[Baseline][1195] Loss=0.7457, Acc=0.5571\n",
      "[Baseline][1196] Loss=0.7659, Acc=0.5669\n",
      "[Baseline][1197] Loss=0.7586, Acc=0.5653\n",
      "[Baseline][1198] Loss=0.7531, Acc=0.5592\n",
      "[Baseline][1199] Loss=0.7625, Acc=0.5654\n",
      "[Baseline][1200] Loss=0.7394, Acc=0.5733\n",
      "[Baseline][1201] Loss=0.7436, Acc=0.5651\n",
      "[Baseline][1202] Loss=0.7897, Acc=0.5645\n",
      "[Baseline][1203] Loss=0.7457, Acc=0.5617\n",
      "[Baseline][1204] Loss=0.7620, Acc=0.5579\n",
      "[Baseline][1205] Loss=0.7433, Acc=0.5643\n",
      "[Baseline][1206] Loss=0.7241, Acc=0.5647\n",
      "[Baseline][1207] Loss=0.7329, Acc=0.5660\n",
      "[Baseline][1208] Loss=0.7158, Acc=0.5639\n",
      "[Baseline][1209] Loss=0.7551, Acc=0.5591\n",
      "[Baseline][1210] Loss=0.7568, Acc=0.5642\n",
      "[Baseline][1211] Loss=0.8092, Acc=0.5597\n",
      "[Baseline][1212] Loss=0.7402, Acc=0.5660\n",
      "[Baseline][1213] Loss=0.7436, Acc=0.5561\n",
      "[Baseline][1214] Loss=0.7462, Acc=0.5592\n",
      "[Baseline][1215] Loss=0.7367, Acc=0.5630\n",
      "[Baseline][1216] Loss=0.7552, Acc=0.5499\n",
      "[Baseline][1217] Loss=0.7989, Acc=0.5619\n",
      "[Baseline][1218] Loss=0.7867, Acc=0.5624\n",
      "[Baseline][1219] Loss=0.7503, Acc=0.5698\n",
      "[Baseline][1220] Loss=0.7448, Acc=0.5535\n",
      "[Baseline][1221] Loss=0.7853, Acc=0.5705\n",
      "[Baseline][1222] Loss=0.7503, Acc=0.5534\n",
      "[Baseline][1223] Loss=0.7570, Acc=0.5647\n",
      "[Baseline][1224] Loss=0.7706, Acc=0.5623\n",
      "[Baseline][1225] Loss=0.7435, Acc=0.5578\n",
      "[Baseline][1226] Loss=0.7550, Acc=0.5567\n",
      "[Baseline][1227] Loss=0.7159, Acc=0.5588\n",
      "[Baseline][1228] Loss=0.7179, Acc=0.5653\n",
      "[Baseline][1229] Loss=0.7060, Acc=0.5718\n",
      "[Baseline][1230] Loss=0.7521, Acc=0.5631\n",
      "[Baseline][1231] Loss=0.7675, Acc=0.5697\n",
      "[Baseline][1232] Loss=0.7877, Acc=0.5662\n",
      "[Baseline][1233] Loss=0.7590, Acc=0.5660\n",
      "[Baseline][1234] Loss=0.7632, Acc=0.5712\n",
      "[Baseline][1235] Loss=0.7469, Acc=0.5548\n",
      "[Baseline][1236] Loss=0.7379, Acc=0.5641\n",
      "[Baseline][1237] Loss=0.7328, Acc=0.5644\n",
      "[Baseline][1238] Loss=0.7502, Acc=0.5507\n",
      "[Baseline][1239] Loss=0.7551, Acc=0.5609\n",
      "[Baseline][1240] Loss=0.7277, Acc=0.5740\n",
      "[Baseline][1241] Loss=0.7687, Acc=0.5680\n",
      "[Baseline][1242] Loss=0.7230, Acc=0.5673\n",
      "[Baseline][1243] Loss=0.7169, Acc=0.5657\n",
      "[Baseline][1244] Loss=0.7480, Acc=0.5625\n",
      "[Baseline][1245] Loss=0.7765, Acc=0.5700\n",
      "[Baseline][1246] Loss=0.7285, Acc=0.5644\n",
      "[Baseline][1247] Loss=0.7074, Acc=0.5631\n",
      "[Baseline][1248] Loss=0.7183, Acc=0.5703\n",
      "[Baseline][1249] Loss=0.7078, Acc=0.5494\n",
      "[Baseline][1250] Loss=0.7102, Acc=0.5674\n",
      "[Baseline][1251] Loss=0.7237, Acc=0.5579\n",
      "[Baseline][1252] Loss=0.7798, Acc=0.5538\n",
      "[Baseline][1253] Loss=0.7480, Acc=0.5571\n",
      "[Baseline][1254] Loss=0.7599, Acc=0.5686\n",
      "[Baseline][1255] Loss=0.7225, Acc=0.5680\n",
      "[Baseline][1256] Loss=0.7379, Acc=0.5606\n",
      "[Baseline][1257] Loss=0.7553, Acc=0.5687\n",
      "[Baseline][1258] Loss=0.7372, Acc=0.5631\n",
      "[Baseline][1259] Loss=0.7358, Acc=0.5731\n",
      "[Baseline][1260] Loss=0.7436, Acc=0.5671\n",
      "[Baseline][1261] Loss=0.7608, Acc=0.5711\n",
      "[Baseline][1262] Loss=0.7740, Acc=0.5475\n",
      "[Baseline][1263] Loss=0.7579, Acc=0.5672\n",
      "[Baseline][1264] Loss=0.7269, Acc=0.5703\n",
      "[Baseline][1265] Loss=0.7322, Acc=0.5616\n",
      "[Baseline][1266] Loss=0.7399, Acc=0.5660\n",
      "[Baseline][1267] Loss=0.7452, Acc=0.5636\n",
      "[Baseline][1268] Loss=0.7829, Acc=0.5651\n",
      "[Baseline][1269] Loss=0.7472, Acc=0.5621\n",
      "[Baseline][1270] Loss=0.7431, Acc=0.5685\n",
      "[Baseline][1271] Loss=0.7131, Acc=0.5566\n",
      "[Baseline][1272] Loss=0.7798, Acc=0.5491\n",
      "[Baseline][1273] Loss=0.7552, Acc=0.5724\n",
      "[Baseline][1274] Loss=0.7063, Acc=0.5737\n",
      "[Baseline][1275] Loss=0.7147, Acc=0.5597\n",
      "[Baseline][1276] Loss=0.7280, Acc=0.5596\n",
      "[Baseline][1277] Loss=0.7472, Acc=0.5620\n",
      "[Baseline][1278] Loss=0.7134, Acc=0.5526\n",
      "[Baseline][1279] Loss=0.7298, Acc=0.5536\n",
      "[Baseline][1280] Loss=0.7638, Acc=0.5580\n",
      "[Baseline][1281] Loss=0.7369, Acc=0.5727\n",
      "[Baseline][1282] Loss=0.7221, Acc=0.5748\n",
      "[Baseline][1283] Loss=0.7252, Acc=0.5740\n",
      "[Baseline][1284] Loss=0.7134, Acc=0.5608\n",
      "[Baseline][1285] Loss=0.7356, Acc=0.5687\n",
      "[Baseline][1286] Loss=0.7491, Acc=0.5642\n",
      "[Baseline][1287] Loss=0.7225, Acc=0.5656\n",
      "[Baseline][1288] Loss=0.7609, Acc=0.5726\n",
      "[Baseline][1289] Loss=0.7267, Acc=0.5739\n",
      "[Baseline][1290] Loss=0.7240, Acc=0.5540\n",
      "[Baseline][1291] Loss=0.7411, Acc=0.5689\n",
      "[Baseline][1292] Loss=0.7136, Acc=0.5690\n",
      "[Baseline][1293] Loss=0.7088, Acc=0.5679\n",
      "[Baseline][1294] Loss=0.7318, Acc=0.5599\n",
      "[Baseline][1295] Loss=0.7189, Acc=0.5678\n",
      "[Baseline][1296] Loss=0.7123, Acc=0.5585\n",
      "[Baseline][1297] Loss=0.7417, Acc=0.5708\n",
      "[Baseline][1298] Loss=0.6966, Acc=0.5754\n",
      "[Baseline][1299] Loss=0.7216, Acc=0.5656\n",
      "[Baseline][1300] Loss=0.7631, Acc=0.5516\n",
      "[Baseline][1301] Loss=0.7520, Acc=0.5542\n",
      "[Baseline][1302] Loss=0.7335, Acc=0.5579\n",
      "[Baseline][1303] Loss=0.7253, Acc=0.5657\n",
      "[Baseline][1304] Loss=0.6980, Acc=0.5709\n",
      "[Baseline][1305] Loss=0.7152, Acc=0.5659\n",
      "[Baseline][1306] Loss=0.7231, Acc=0.5627\n",
      "[Baseline][1307] Loss=0.7161, Acc=0.5721\n",
      "[Baseline][1308] Loss=0.7202, Acc=0.5607\n",
      "[Baseline][1309] Loss=0.7119, Acc=0.5523\n",
      "[Baseline][1310] Loss=0.7460, Acc=0.5606\n",
      "[Baseline][1311] Loss=0.7371, Acc=0.5717\n",
      "[Baseline][1312] Loss=0.6898, Acc=0.5743\n",
      "[Baseline][1313] Loss=0.7045, Acc=0.5751\n",
      "[Baseline][1314] Loss=0.6936, Acc=0.5588\n",
      "[Baseline][1315] Loss=0.7005, Acc=0.5679\n",
      "[Baseline][1316] Loss=0.7422, Acc=0.5668\n",
      "[Baseline][1317] Loss=0.7393, Acc=0.5675\n",
      "[Baseline][1318] Loss=0.7066, Acc=0.5609\n",
      "[Baseline][1319] Loss=0.7243, Acc=0.5655\n",
      "[Baseline][1320] Loss=0.7015, Acc=0.5660\n",
      "[Baseline][1321] Loss=0.7300, Acc=0.5710\n",
      "[Baseline][1322] Loss=0.7164, Acc=0.5602\n",
      "[Baseline][1323] Loss=0.7320, Acc=0.5583\n",
      "[Baseline][1324] Loss=0.7497, Acc=0.5671\n",
      "[Baseline][1325] Loss=0.7100, Acc=0.5761\n",
      "[Baseline][1326] Loss=0.7008, Acc=0.5715\n",
      "[Baseline][1327] Loss=0.7420, Acc=0.5681\n",
      "[Baseline][1328] Loss=0.7308, Acc=0.5691\n",
      "[Baseline][1329] Loss=0.7204, Acc=0.5674\n",
      "[Baseline][1330] Loss=0.7120, Acc=0.5697\n",
      "[Baseline][1331] Loss=0.7183, Acc=0.5654\n",
      "[Baseline][1332] Loss=0.7223, Acc=0.5644\n",
      "[Baseline][1333] Loss=0.6997, Acc=0.5733\n",
      "[Baseline][1334] Loss=0.6952, Acc=0.5661\n",
      "[Baseline][1335] Loss=0.7007, Acc=0.5714\n",
      "[Baseline][1336] Loss=0.7261, Acc=0.5619\n",
      "[Baseline][1337] Loss=0.7014, Acc=0.5629\n",
      "[Baseline][1338] Loss=0.7007, Acc=0.5659\n",
      "[Baseline][1339] Loss=0.6913, Acc=0.5678\n",
      "[Baseline][1340] Loss=0.6964, Acc=0.5775\n",
      "[Baseline][1341] Loss=0.6898, Acc=0.5670\n",
      "[Baseline][1342] Loss=0.7225, Acc=0.5678\n",
      "[Baseline][1343] Loss=0.7385, Acc=0.5798\n",
      "[Baseline][1344] Loss=0.7099, Acc=0.5772\n",
      "[Baseline][1345] Loss=0.7212, Acc=0.5725\n",
      "[Baseline][1346] Loss=0.7282, Acc=0.5709\n",
      "[Baseline][1347] Loss=0.7193, Acc=0.5688\n",
      "[Baseline][1348] Loss=0.7229, Acc=0.5664\n",
      "[Baseline][1349] Loss=0.7595, Acc=0.5727\n",
      "[Baseline][1350] Loss=0.7142, Acc=0.5609\n",
      "[Baseline][1351] Loss=0.7299, Acc=0.5549\n",
      "[Baseline][1352] Loss=0.7198, Acc=0.5660\n",
      "[Baseline][1353] Loss=0.6812, Acc=0.5725\n",
      "[Baseline][1354] Loss=0.6918, Acc=0.5703\n",
      "[Baseline][1355] Loss=0.7278, Acc=0.5666\n",
      "[Baseline][1356] Loss=0.7259, Acc=0.5688\n",
      "[Baseline][1357] Loss=0.7190, Acc=0.5688\n",
      "[Baseline][1358] Loss=0.7237, Acc=0.5595\n",
      "[Baseline][1359] Loss=0.7399, Acc=0.5682\n",
      "[Baseline][1360] Loss=0.6973, Acc=0.5626\n",
      "[Baseline][1361] Loss=0.7040, Acc=0.5697\n",
      "[Baseline][1362] Loss=0.6942, Acc=0.5694\n",
      "[Baseline][1363] Loss=0.6981, Acc=0.5710\n",
      "[Baseline][1364] Loss=0.7000, Acc=0.5622\n",
      "[Baseline][1365] Loss=0.6787, Acc=0.5654\n",
      "[Baseline][1366] Loss=0.6791, Acc=0.5715\n",
      "[Baseline][1367] Loss=0.7155, Acc=0.5598\n",
      "[Baseline][1368] Loss=0.6970, Acc=0.5633\n",
      "[Baseline][1369] Loss=0.7164, Acc=0.5691\n",
      "[Baseline][1370] Loss=0.7179, Acc=0.5715\n",
      "[Baseline][1371] Loss=0.7303, Acc=0.5738\n",
      "[Baseline][1372] Loss=0.7172, Acc=0.5566\n",
      "[Baseline][1373] Loss=0.7192, Acc=0.5648\n",
      "[Baseline][1374] Loss=0.7228, Acc=0.5592\n",
      "[Baseline][1375] Loss=0.7315, Acc=0.5770\n",
      "[Baseline][1376] Loss=0.7075, Acc=0.5695\n",
      "[Baseline][1377] Loss=0.6894, Acc=0.5639\n",
      "[Baseline][1378] Loss=0.7071, Acc=0.5532\n",
      "[Baseline][1379] Loss=0.7226, Acc=0.5687\n",
      "[Baseline][1380] Loss=0.7006, Acc=0.5698\n",
      "[Baseline][1381] Loss=0.7116, Acc=0.5568\n",
      "[Baseline][1382] Loss=0.7023, Acc=0.5671\n",
      "[Baseline][1383] Loss=0.6895, Acc=0.5698\n",
      "[Baseline][1384] Loss=0.6782, Acc=0.5689\n",
      "[Baseline][1385] Loss=0.6837, Acc=0.5769\n",
      "[Baseline][1386] Loss=0.7052, Acc=0.5726\n",
      "[Baseline][1387] Loss=0.6753, Acc=0.5573\n",
      "[Baseline][1388] Loss=0.6976, Acc=0.5617\n",
      "[Baseline][1389] Loss=0.7071, Acc=0.5558\n",
      "[Baseline][1390] Loss=0.6985, Acc=0.5615\n",
      "[Baseline][1391] Loss=0.6810, Acc=0.5594\n",
      "[Baseline][1392] Loss=0.6923, Acc=0.5602\n",
      "[Baseline][1393] Loss=0.7090, Acc=0.5650\n",
      "[Baseline][1394] Loss=0.6877, Acc=0.5759\n",
      "[Baseline][1395] Loss=0.7064, Acc=0.5634\n",
      "[Baseline][1396] Loss=0.6844, Acc=0.5682\n",
      "[Baseline][1397] Loss=0.6870, Acc=0.5563\n",
      "[Baseline][1398] Loss=0.7548, Acc=0.5715\n",
      "[Baseline][1399] Loss=0.6897, Acc=0.5524\n",
      "[Baseline][1400] Loss=0.7100, Acc=0.5648\n",
      "[Baseline][1401] Loss=0.6824, Acc=0.5736\n",
      "[Baseline][1402] Loss=0.6816, Acc=0.5732\n",
      "[Baseline][1403] Loss=0.7418, Acc=0.5603\n",
      "[Baseline][1404] Loss=0.7406, Acc=0.5649\n",
      "[Baseline][1405] Loss=0.6910, Acc=0.5723\n",
      "[Baseline][1406] Loss=0.6719, Acc=0.5631\n",
      "[Baseline][1407] Loss=0.6995, Acc=0.5645\n",
      "[Baseline][1408] Loss=0.6885, Acc=0.5770\n",
      "[Baseline][1409] Loss=0.6826, Acc=0.5656\n",
      "[Baseline][1410] Loss=0.7086, Acc=0.5704\n",
      "[Baseline][1411] Loss=0.6870, Acc=0.5674\n",
      "[Baseline][1412] Loss=0.6803, Acc=0.5604\n",
      "[Baseline][1413] Loss=0.6783, Acc=0.5750\n",
      "[Baseline][1414] Loss=0.6657, Acc=0.5578\n",
      "[Baseline][1415] Loss=0.7114, Acc=0.5642\n",
      "[Baseline][1416] Loss=0.7284, Acc=0.5547\n",
      "[Baseline][1417] Loss=0.7051, Acc=0.5715\n",
      "[Baseline][1418] Loss=0.7021, Acc=0.5735\n",
      "[Baseline][1419] Loss=0.7005, Acc=0.5703\n",
      "[Baseline][1420] Loss=0.6868, Acc=0.5589\n",
      "[Baseline][1421] Loss=0.6941, Acc=0.5714\n",
      "[Baseline][1422] Loss=0.6821, Acc=0.5736\n",
      "[Baseline][1423] Loss=0.7112, Acc=0.5616\n",
      "[Baseline][1424] Loss=0.6777, Acc=0.5681\n",
      "[Baseline][1425] Loss=0.7208, Acc=0.5658\n",
      "[Baseline][1426] Loss=0.7062, Acc=0.5784\n",
      "[Baseline][1427] Loss=0.6729, Acc=0.5711\n",
      "[Baseline][1428] Loss=0.6945, Acc=0.5642\n",
      "[Baseline][1429] Loss=0.6753, Acc=0.5598\n",
      "[Baseline][1430] Loss=0.6936, Acc=0.5690\n",
      "[Baseline][1431] Loss=0.7020, Acc=0.5629\n",
      "[Baseline][1432] Loss=0.6634, Acc=0.5692\n",
      "[Baseline][1433] Loss=0.6692, Acc=0.5729\n",
      "[Baseline][1434] Loss=0.7203, Acc=0.5589\n",
      "[Baseline][1435] Loss=0.6767, Acc=0.5740\n",
      "[Baseline][1436] Loss=0.6745, Acc=0.5758\n",
      "[Baseline][1437] Loss=0.7182, Acc=0.5728\n",
      "[Baseline][1438] Loss=0.6922, Acc=0.5476\n",
      "[Baseline][1439] Loss=0.7183, Acc=0.5681\n",
      "[Baseline][1440] Loss=0.7318, Acc=0.5545\n",
      "[Baseline][1441] Loss=0.7440, Acc=0.5571\n",
      "[Baseline][1442] Loss=0.6999, Acc=0.5725\n",
      "[Baseline][1443] Loss=0.6815, Acc=0.5590\n",
      "[Baseline][1444] Loss=0.7171, Acc=0.5627\n",
      "[Baseline][1445] Loss=0.6738, Acc=0.5704\n",
      "[Baseline][1446] Loss=0.6848, Acc=0.5641\n",
      "[Baseline][1447] Loss=0.6677, Acc=0.5750\n",
      "[Baseline][1448] Loss=0.6855, Acc=0.5658\n",
      "[Baseline][1449] Loss=0.6910, Acc=0.5660\n",
      "[Baseline][1450] Loss=0.6786, Acc=0.5707\n",
      "[Baseline][1451] Loss=0.6394, Acc=0.5704\n",
      "[Baseline][1452] Loss=0.6682, Acc=0.5646\n",
      "[Baseline][1453] Loss=0.6635, Acc=0.5471\n",
      "[Baseline][1454] Loss=0.6700, Acc=0.5701\n",
      "[Baseline][1455] Loss=0.6681, Acc=0.5707\n",
      "[Baseline][1456] Loss=0.6748, Acc=0.5737\n",
      "[Baseline][1457] Loss=0.6523, Acc=0.5689\n",
      "[Baseline][1458] Loss=0.6710, Acc=0.5562\n",
      "[Baseline][1459] Loss=0.6854, Acc=0.5531\n",
      "[Baseline][1460] Loss=0.6746, Acc=0.5631\n",
      "[Baseline][1461] Loss=0.7095, Acc=0.5723\n",
      "[Baseline][1462] Loss=0.6922, Acc=0.5675\n",
      "[Baseline][1463] Loss=0.7323, Acc=0.5724\n",
      "[Baseline][1464] Loss=0.6722, Acc=0.5563\n",
      "[Baseline][1465] Loss=0.6674, Acc=0.5683\n",
      "[Baseline][1466] Loss=0.6920, Acc=0.5696\n",
      "[Baseline][1467] Loss=0.6649, Acc=0.5569\n",
      "[Baseline][1468] Loss=0.6706, Acc=0.5776\n",
      "[Baseline][1469] Loss=0.6871, Acc=0.5644\n",
      "[Baseline][1470] Loss=0.6720, Acc=0.5664\n",
      "[Baseline][1471] Loss=0.6635, Acc=0.5757\n",
      "[Baseline][1472] Loss=0.6769, Acc=0.5784\n",
      "[Baseline][1473] Loss=0.6571, Acc=0.5593\n",
      "[Baseline][1474] Loss=0.6725, Acc=0.5674\n",
      "[Baseline][1475] Loss=0.6866, Acc=0.5722\n",
      "[Baseline][1476] Loss=0.6850, Acc=0.5660\n",
      "[Baseline][1477] Loss=0.6981, Acc=0.5681\n",
      "[Baseline][1478] Loss=0.6685, Acc=0.5683\n",
      "[Baseline][1479] Loss=0.6640, Acc=0.5698\n",
      "[Baseline][1480] Loss=0.6758, Acc=0.5706\n",
      "[Baseline][1481] Loss=0.6890, Acc=0.5523\n",
      "[Baseline][1482] Loss=0.7179, Acc=0.5619\n",
      "[Baseline][1483] Loss=0.6724, Acc=0.5572\n",
      "[Baseline][1484] Loss=0.6763, Acc=0.5683\n",
      "[Baseline][1485] Loss=0.6538, Acc=0.5655\n",
      "[Baseline][1486] Loss=0.7023, Acc=0.5378\n",
      "[Baseline][1487] Loss=0.7560, Acc=0.5659\n",
      "[Baseline][1488] Loss=0.7015, Acc=0.5655\n",
      "[Baseline][1489] Loss=0.6554, Acc=0.5545\n",
      "[Baseline][1490] Loss=0.6812, Acc=0.5725\n",
      "[Baseline][1491] Loss=0.6606, Acc=0.5742\n",
      "[Baseline][1492] Loss=0.6487, Acc=0.5733\n",
      "[Baseline][1493] Loss=0.6293, Acc=0.5699\n",
      "[Baseline][1494] Loss=0.6684, Acc=0.5527\n",
      "[Baseline][1495] Loss=0.7217, Acc=0.5616\n",
      "[Baseline][1496] Loss=0.6678, Acc=0.5707\n",
      "[Baseline][1497] Loss=0.6636, Acc=0.5644\n",
      "[Baseline][1498] Loss=0.6562, Acc=0.5704\n",
      "[Baseline][1499] Loss=0.6593, Acc=0.5738\n",
      "[Baseline][1500] Loss=0.6636, Acc=0.5615\n",
      "[Baseline][1501] Loss=0.6783, Acc=0.5778\n",
      "[Baseline][1502] Loss=0.6810, Acc=0.5660\n",
      "[Baseline][1503] Loss=0.6624, Acc=0.5748\n",
      "[Baseline][1504] Loss=0.6882, Acc=0.5686\n",
      "[Baseline][1505] Loss=0.6533, Acc=0.5702\n",
      "[Baseline][1506] Loss=0.6815, Acc=0.5812\n",
      "[Baseline][1507] Loss=0.6414, Acc=0.5738\n",
      "[Baseline][1508] Loss=0.7107, Acc=0.5616\n",
      "[Baseline][1509] Loss=0.6751, Acc=0.5800\n",
      "[Baseline][1510] Loss=0.6905, Acc=0.5651\n",
      "[Baseline][1511] Loss=0.6755, Acc=0.5742\n",
      "[Baseline][1512] Loss=0.6517, Acc=0.5676\n",
      "[Baseline][1513] Loss=0.6702, Acc=0.5737\n",
      "[Baseline][1514] Loss=0.6974, Acc=0.5662\n",
      "[Baseline][1515] Loss=0.6852, Acc=0.5722\n",
      "[Baseline][1516] Loss=0.6576, Acc=0.5736\n",
      "[Baseline][1517] Loss=0.6654, Acc=0.5720\n",
      "[Baseline][1518] Loss=0.6675, Acc=0.5777\n",
      "[Baseline][1519] Loss=0.6871, Acc=0.5669\n",
      "[Baseline][1520] Loss=0.6846, Acc=0.5600\n",
      "[Baseline][1521] Loss=0.6527, Acc=0.5692\n",
      "[Baseline][1522] Loss=0.6440, Acc=0.5726\n",
      "[Baseline][1523] Loss=0.6551, Acc=0.5743\n",
      "[Baseline][1524] Loss=0.6473, Acc=0.5722\n",
      "[Baseline][1525] Loss=0.6579, Acc=0.5716\n",
      "[Baseline][1526] Loss=0.6642, Acc=0.5536\n",
      "[Baseline][1527] Loss=0.6509, Acc=0.5715\n",
      "[Baseline][1528] Loss=0.6553, Acc=0.5698\n",
      "[Baseline][1529] Loss=0.6425, Acc=0.5684\n",
      "[Baseline][1530] Loss=0.6263, Acc=0.5696\n",
      "[Baseline][1531] Loss=0.6451, Acc=0.5695\n",
      "[Baseline][1532] Loss=0.6672, Acc=0.5616\n",
      "[Baseline][1533] Loss=0.6690, Acc=0.5684\n",
      "[Baseline][1534] Loss=0.6538, Acc=0.5705\n",
      "[Baseline][1535] Loss=0.6391, Acc=0.5710\n",
      "[Baseline][1536] Loss=0.6628, Acc=0.5728\n",
      "[Baseline][1537] Loss=0.6569, Acc=0.5698\n",
      "[Baseline][1538] Loss=0.6470, Acc=0.5552\n",
      "[Baseline][1539] Loss=0.6661, Acc=0.5734\n",
      "[Baseline][1540] Loss=0.6419, Acc=0.5660\n",
      "[Baseline][1541] Loss=0.6583, Acc=0.5673\n",
      "[Baseline][1542] Loss=0.6853, Acc=0.5591\n",
      "[Baseline][1543] Loss=0.6500, Acc=0.5689\n",
      "[Baseline][1544] Loss=0.6606, Acc=0.5651\n",
      "[Baseline][1545] Loss=0.6641, Acc=0.5775\n",
      "[Baseline][1546] Loss=0.6328, Acc=0.5659\n",
      "[Baseline][1547] Loss=0.6530, Acc=0.5532\n",
      "[Baseline][1548] Loss=0.6648, Acc=0.5712\n",
      "[Baseline][1549] Loss=0.6505, Acc=0.5626\n",
      "[Baseline][1550] Loss=0.6548, Acc=0.5663\n",
      "[Baseline][1551] Loss=0.6757, Acc=0.5685\n",
      "[Baseline][1552] Loss=0.6644, Acc=0.5683\n",
      "[Baseline][1553] Loss=0.6701, Acc=0.5672\n",
      "[Baseline][1554] Loss=0.6624, Acc=0.5727\n",
      "[Baseline][1555] Loss=0.6558, Acc=0.5696\n",
      "[Baseline][1556] Loss=0.6594, Acc=0.5691\n",
      "[Baseline][1557] Loss=0.6467, Acc=0.5628\n",
      "[Baseline][1558] Loss=0.6658, Acc=0.5713\n",
      "[Baseline][1559] Loss=0.6332, Acc=0.5632\n",
      "[Baseline][1560] Loss=0.6621, Acc=0.5743\n",
      "[Baseline][1561] Loss=0.6614, Acc=0.5719\n",
      "[Baseline][1562] Loss=0.6852, Acc=0.5529\n",
      "[Baseline][1563] Loss=0.7095, Acc=0.5691\n",
      "[Baseline][1564] Loss=0.7198, Acc=0.5656\n",
      "[Baseline][1565] Loss=0.6691, Acc=0.5760\n",
      "[Baseline][1566] Loss=0.6419, Acc=0.5720\n",
      "[Baseline][1567] Loss=0.6332, Acc=0.5744\n",
      "[Baseline][1568] Loss=0.6309, Acc=0.5640\n",
      "[Baseline][1569] Loss=0.6505, Acc=0.5776\n",
      "[Baseline][1570] Loss=0.6442, Acc=0.5630\n",
      "[Baseline][1571] Loss=0.6436, Acc=0.5649\n",
      "[Baseline][1572] Loss=0.6600, Acc=0.5755\n",
      "[Baseline][1573] Loss=0.6430, Acc=0.5622\n",
      "[Baseline][1574] Loss=0.6267, Acc=0.5687\n",
      "[Baseline][1575] Loss=0.6296, Acc=0.5774\n",
      "[Baseline][1576] Loss=0.6228, Acc=0.5736\n",
      "[Baseline][1577] Loss=0.6726, Acc=0.5616\n",
      "[Baseline][1578] Loss=0.7032, Acc=0.5617\n",
      "[Baseline][1579] Loss=0.6988, Acc=0.5630\n",
      "[Baseline][1580] Loss=0.6304, Acc=0.5665\n",
      "[Baseline][1581] Loss=0.6514, Acc=0.5636\n",
      "[Baseline][1582] Loss=0.6528, Acc=0.5692\n",
      "[Baseline][1583] Loss=0.6618, Acc=0.5658\n",
      "[Baseline][1584] Loss=0.6615, Acc=0.5653\n",
      "[Baseline][1585] Loss=0.6488, Acc=0.5741\n",
      "[Baseline][1586] Loss=0.6358, Acc=0.5721\n",
      "[Baseline][1587] Loss=0.6418, Acc=0.5708\n",
      "[Baseline][1588] Loss=0.6431, Acc=0.5710\n",
      "[Baseline][1589] Loss=0.6252, Acc=0.5706\n",
      "[Baseline][1590] Loss=0.6309, Acc=0.5666\n",
      "[Baseline][1591] Loss=0.6238, Acc=0.5723\n",
      "[Baseline][1592] Loss=0.6287, Acc=0.5746\n",
      "[Baseline][1593] Loss=0.6420, Acc=0.5625\n",
      "[Baseline][1594] Loss=0.6729, Acc=0.5671\n",
      "[Baseline][1595] Loss=0.6701, Acc=0.5797\n",
      "[Baseline][1596] Loss=0.6648, Acc=0.5622\n",
      "[Baseline][1597] Loss=0.6599, Acc=0.5519\n",
      "[Baseline][1598] Loss=0.6753, Acc=0.5665\n",
      "[Baseline][1599] Loss=0.6378, Acc=0.5696\n",
      "[Baseline][1600] Loss=0.6326, Acc=0.5759\n",
      "[Baseline][1601] Loss=0.6439, Acc=0.5762\n",
      "[Baseline][1602] Loss=0.6287, Acc=0.5678\n",
      "[Baseline][1603] Loss=0.6303, Acc=0.5684\n",
      "[Baseline][1604] Loss=0.6224, Acc=0.5757\n",
      "[Baseline][1605] Loss=0.6375, Acc=0.5598\n",
      "[Baseline][1606] Loss=0.6770, Acc=0.5715\n",
      "[Baseline][1607] Loss=0.6233, Acc=0.5676\n",
      "[Baseline][1608] Loss=0.6360, Acc=0.5691\n",
      "[Baseline][1609] Loss=0.6382, Acc=0.5639\n",
      "[Baseline][1610] Loss=0.6321, Acc=0.5744\n",
      "[Baseline][1611] Loss=0.6123, Acc=0.5683\n",
      "[Baseline][1612] Loss=0.6556, Acc=0.5755\n",
      "[Baseline][1613] Loss=0.6218, Acc=0.5703\n",
      "[Baseline][1614] Loss=0.6564, Acc=0.5589\n",
      "[Baseline][1615] Loss=0.6983, Acc=0.5703\n",
      "[Baseline][1616] Loss=0.6478, Acc=0.5827\n",
      "[Baseline][1617] Loss=0.6537, Acc=0.5516\n",
      "[Baseline][1618] Loss=0.6774, Acc=0.5650\n",
      "[Baseline][1619] Loss=0.6694, Acc=0.5696\n",
      "[Baseline][1620] Loss=0.6484, Acc=0.5657\n",
      "[Baseline][1621] Loss=0.6346, Acc=0.5590\n",
      "[Baseline][1622] Loss=0.6506, Acc=0.5681\n",
      "[Baseline][1623] Loss=0.6383, Acc=0.5659\n",
      "[Baseline][1624] Loss=0.6990, Acc=0.5665\n",
      "[Baseline][1625] Loss=0.6528, Acc=0.5707\n",
      "[Baseline][1626] Loss=0.6369, Acc=0.5698\n",
      "[Baseline][1627] Loss=0.6393, Acc=0.5714\n",
      "[Baseline][1628] Loss=0.6270, Acc=0.5627\n",
      "[Baseline][1629] Loss=0.6356, Acc=0.5640\n",
      "[Baseline][1630] Loss=0.6928, Acc=0.5492\n",
      "[Baseline][1631] Loss=0.6573, Acc=0.5733\n",
      "[Baseline][1632] Loss=0.6348, Acc=0.5695\n",
      "[Baseline][1633] Loss=0.6391, Acc=0.5738\n",
      "[Baseline][1634] Loss=0.6323, Acc=0.5635\n",
      "[Baseline][1635] Loss=0.6671, Acc=0.5749\n",
      "[Baseline][1636] Loss=0.6183, Acc=0.5755\n",
      "[Baseline][1637] Loss=0.6159, Acc=0.5635\n",
      "[Baseline][1638] Loss=0.6488, Acc=0.5698\n",
      "[Baseline][1639] Loss=0.6475, Acc=0.5639\n",
      "[Baseline][1640] Loss=0.6341, Acc=0.5648\n",
      "[Baseline][1641] Loss=0.7103, Acc=0.5466\n",
      "[Baseline][1642] Loss=0.6284, Acc=0.5717\n",
      "[Baseline][1643] Loss=0.6147, Acc=0.5552\n",
      "[Baseline][1644] Loss=0.6452, Acc=0.5592\n",
      "[Baseline][1645] Loss=0.6395, Acc=0.5744\n",
      "[Baseline][1646] Loss=0.6197, Acc=0.5658\n",
      "[Baseline][1647] Loss=0.6429, Acc=0.5634\n",
      "[Baseline][1648] Loss=0.6334, Acc=0.5736\n",
      "[Baseline][1649] Loss=0.6194, Acc=0.5703\n",
      "[Baseline][1650] Loss=0.6187, Acc=0.5708\n",
      "[Baseline][1651] Loss=0.6115, Acc=0.5698\n",
      "[Baseline][1652] Loss=0.6340, Acc=0.5714\n",
      "[Baseline][1653] Loss=0.6182, Acc=0.5714\n",
      "[Baseline][1654] Loss=0.6137, Acc=0.5684\n",
      "[Baseline][1655] Loss=0.6028, Acc=0.5700\n",
      "[Baseline][1656] Loss=0.6120, Acc=0.5593\n",
      "[Baseline][1657] Loss=0.6194, Acc=0.5704\n",
      "[Baseline][1658] Loss=0.6325, Acc=0.5757\n",
      "[Baseline][1659] Loss=0.6418, Acc=0.5665\n",
      "[Baseline][1660] Loss=0.6064, Acc=0.5734\n",
      "[Baseline][1661] Loss=0.6272, Acc=0.5747\n",
      "[Baseline][1662] Loss=0.6452, Acc=0.5601\n",
      "[Baseline][1663] Loss=0.6410, Acc=0.5668\n",
      "[Baseline][1664] Loss=0.6262, Acc=0.5747\n",
      "[Baseline][1665] Loss=0.6401, Acc=0.5672\n",
      "[Baseline][1666] Loss=0.6387, Acc=0.5690\n",
      "[Baseline][1667] Loss=0.6044, Acc=0.5629\n",
      "[Baseline][1668] Loss=0.6244, Acc=0.5370\n",
      "[Baseline][1669] Loss=0.7094, Acc=0.5647\n",
      "[Baseline][1670] Loss=0.6057, Acc=0.5743\n",
      "[Baseline][1671] Loss=0.6178, Acc=0.5697\n",
      "[Baseline][1672] Loss=0.6179, Acc=0.5629\n",
      "[Baseline][1673] Loss=0.6434, Acc=0.5583\n",
      "[Baseline][1674] Loss=0.6275, Acc=0.5734\n",
      "[Baseline][1675] Loss=0.6276, Acc=0.5749\n",
      "[Baseline][1676] Loss=0.6071, Acc=0.5662\n",
      "[Baseline][1677] Loss=0.6014, Acc=0.5766\n",
      "[Baseline][1678] Loss=0.6179, Acc=0.5725\n",
      "[Baseline][1679] Loss=0.6023, Acc=0.5667\n",
      "[Baseline][1680] Loss=0.6218, Acc=0.5670\n",
      "[Baseline][1681] Loss=0.6228, Acc=0.5786\n",
      "[Baseline][1682] Loss=0.6277, Acc=0.5700\n",
      "[Baseline][1683] Loss=0.6286, Acc=0.5749\n",
      "[Baseline][1684] Loss=0.6239, Acc=0.5695\n",
      "[Baseline][1685] Loss=0.6245, Acc=0.5535\n",
      "[Baseline][1686] Loss=0.6947, Acc=0.5683\n",
      "[Baseline][1687] Loss=0.6289, Acc=0.5605\n",
      "[Baseline][1688] Loss=0.6395, Acc=0.5676\n",
      "[Baseline][1689] Loss=0.6285, Acc=0.5596\n",
      "[Baseline][1690] Loss=0.5964, Acc=0.5648\n",
      "[Baseline][1691] Loss=0.6127, Acc=0.5736\n",
      "[Baseline][1692] Loss=0.6587, Acc=0.5650\n",
      "[Baseline][1693] Loss=0.6250, Acc=0.5567\n",
      "[Baseline][1694] Loss=0.6221, Acc=0.5703\n",
      "[Baseline][1695] Loss=0.6123, Acc=0.5737\n",
      "[Baseline][1696] Loss=0.6113, Acc=0.5525\n",
      "[Baseline][1697] Loss=0.5902, Acc=0.5555\n",
      "[Baseline][1698] Loss=0.6361, Acc=0.5643\n",
      "[Baseline][1699] Loss=0.6240, Acc=0.5730\n",
      "[Baseline][1700] Loss=0.6009, Acc=0.5714\n",
      "[Baseline][1701] Loss=0.6439, Acc=0.5742\n",
      "[Baseline][1702] Loss=0.6049, Acc=0.5670\n",
      "[Baseline][1703] Loss=0.6014, Acc=0.5735\n",
      "[Baseline][1704] Loss=0.6620, Acc=0.5646\n",
      "[Baseline][1705] Loss=0.6023, Acc=0.5759\n",
      "[Baseline][1706] Loss=0.6166, Acc=0.5594\n",
      "[Baseline][1707] Loss=0.6261, Acc=0.5680\n",
      "[Baseline][1708] Loss=0.6069, Acc=0.5690\n",
      "[Baseline][1709] Loss=0.6201, Acc=0.5710\n",
      "[Baseline][1710] Loss=0.6213, Acc=0.5634\n",
      "[Baseline][1711] Loss=0.6235, Acc=0.5569\n",
      "[Baseline][1712] Loss=0.6120, Acc=0.5743\n",
      "[Baseline][1713] Loss=0.6067, Acc=0.5665\n",
      "[Baseline][1714] Loss=0.6244, Acc=0.5744\n",
      "[Baseline][1715] Loss=0.6194, Acc=0.5686\n",
      "[Baseline][1716] Loss=0.6012, Acc=0.5658\n",
      "[Baseline][1717] Loss=0.6097, Acc=0.5674\n",
      "[Baseline][1718] Loss=0.6582, Acc=0.5588\n",
      "[Baseline][1719] Loss=0.6527, Acc=0.5721\n",
      "[Baseline][1720] Loss=0.6140, Acc=0.5749\n",
      "[Baseline][1721] Loss=0.6267, Acc=0.5738\n",
      "[Baseline][1722] Loss=0.6214, Acc=0.5727\n",
      "[Baseline][1723] Loss=0.6077, Acc=0.5744\n",
      "[Baseline][1724] Loss=0.6170, Acc=0.5696\n",
      "[Baseline][1725] Loss=0.6177, Acc=0.5674\n",
      "[Baseline][1726] Loss=0.5915, Acc=0.5785\n",
      "[Baseline][1727] Loss=0.5987, Acc=0.5665\n",
      "[Baseline][1728] Loss=0.6061, Acc=0.5621\n",
      "[Baseline][1729] Loss=0.6161, Acc=0.5635\n",
      "[Baseline][1730] Loss=0.6374, Acc=0.5700\n",
      "[Baseline][1731] Loss=0.6315, Acc=0.5649\n",
      "[Baseline][1732] Loss=0.6000, Acc=0.5678\n",
      "[Baseline][1733] Loss=0.6230, Acc=0.5665\n",
      "[Baseline][1734] Loss=0.6418, Acc=0.5620\n",
      "[Baseline][1735] Loss=0.5953, Acc=0.5668\n",
      "[Baseline][1736] Loss=0.6062, Acc=0.5690\n",
      "[Baseline][1737] Loss=0.6124, Acc=0.5625\n",
      "[Baseline][1738] Loss=0.6268, Acc=0.5645\n",
      "[Baseline][1739] Loss=0.6108, Acc=0.5699\n",
      "[Baseline][1740] Loss=0.6045, Acc=0.5754\n",
      "[Baseline][1741] Loss=0.6010, Acc=0.5687\n",
      "[Baseline][1742] Loss=0.6158, Acc=0.5688\n",
      "[Baseline][1743] Loss=0.6001, Acc=0.5649\n",
      "[Baseline][1744] Loss=0.5847, Acc=0.5743\n",
      "[Baseline][1745] Loss=0.6120, Acc=0.5673\n",
      "[Baseline][1746] Loss=0.6100, Acc=0.5561\n",
      "[Baseline][1747] Loss=0.6026, Acc=0.5641\n",
      "[Baseline][1748] Loss=0.6100, Acc=0.5769\n",
      "[Baseline][1749] Loss=0.6138, Acc=0.5707\n",
      "[Baseline][1750] Loss=0.5723, Acc=0.5620\n",
      "[Baseline][1751] Loss=0.5858, Acc=0.5720\n",
      "[Baseline][1752] Loss=0.6342, Acc=0.5579\n",
      "[Baseline][1753] Loss=0.6505, Acc=0.5772\n",
      "[Baseline][1754] Loss=0.6295, Acc=0.5752\n",
      "[Baseline][1755] Loss=0.6336, Acc=0.5669\n",
      "[Baseline][1756] Loss=0.5887, Acc=0.5615\n",
      "[Baseline][1757] Loss=0.6003, Acc=0.5687\n",
      "[Baseline][1758] Loss=0.6073, Acc=0.5753\n",
      "[Baseline][1759] Loss=0.6136, Acc=0.5659\n",
      "[Baseline][1760] Loss=0.6501, Acc=0.5653\n",
      "[Baseline][1761] Loss=0.6029, Acc=0.5637\n",
      "[Baseline][1762] Loss=0.6569, Acc=0.5704\n",
      "[Baseline][1763] Loss=0.6090, Acc=0.5658\n",
      "[Baseline][1764] Loss=0.6205, Acc=0.5619\n",
      "[Baseline][1765] Loss=0.6085, Acc=0.5685\n",
      "[Baseline][1766] Loss=0.6045, Acc=0.5643\n",
      "[Baseline][1767] Loss=0.6170, Acc=0.5676\n",
      "[Baseline][1768] Loss=0.6273, Acc=0.5688\n",
      "[Baseline][1769] Loss=0.6077, Acc=0.5660\n",
      "[Baseline][1770] Loss=0.6191, Acc=0.5682\n",
      "[Baseline][1771] Loss=0.6736, Acc=0.5672\n",
      "[Baseline][1772] Loss=0.6222, Acc=0.5725\n",
      "[Baseline][1773] Loss=0.6007, Acc=0.5635\n",
      "[Baseline][1774] Loss=0.5880, Acc=0.5581\n",
      "[Baseline][1775] Loss=0.5960, Acc=0.5665\n",
      "[Baseline][1776] Loss=0.5951, Acc=0.5722\n",
      "[Baseline][1777] Loss=0.5992, Acc=0.5732\n",
      "[Baseline][1778] Loss=0.6138, Acc=0.5665\n",
      "[Baseline][1779] Loss=0.6212, Acc=0.5649\n",
      "[Baseline][1780] Loss=0.5895, Acc=0.5672\n",
      "[Baseline][1781] Loss=0.5780, Acc=0.5770\n",
      "[Baseline][1782] Loss=0.6044, Acc=0.5673\n",
      "[Baseline][1783] Loss=0.5775, Acc=0.5622\n",
      "[Baseline][1784] Loss=0.6027, Acc=0.5813\n",
      "[Baseline][1785] Loss=0.6107, Acc=0.5590\n",
      "[Baseline][1786] Loss=0.5915, Acc=0.5755\n",
      "[Baseline][1787] Loss=0.5813, Acc=0.5717\n",
      "[Baseline][1788] Loss=0.5858, Acc=0.5704\n",
      "[Baseline][1789] Loss=0.6471, Acc=0.5635\n",
      "[Baseline][1790] Loss=0.6355, Acc=0.5736\n",
      "[Baseline][1791] Loss=0.6049, Acc=0.5663\n",
      "[Baseline][1792] Loss=0.6149, Acc=0.5691\n",
      "[Baseline][1793] Loss=0.5804, Acc=0.5616\n",
      "[Baseline][1794] Loss=0.6099, Acc=0.5627\n",
      "[Baseline][1795] Loss=0.6282, Acc=0.5735\n",
      "[Baseline][1796] Loss=0.6031, Acc=0.5672\n",
      "[Baseline][1797] Loss=0.6239, Acc=0.5705\n",
      "[Baseline][1798] Loss=0.6178, Acc=0.5720\n",
      "[Baseline][1799] Loss=0.6099, Acc=0.5641\n",
      "[Baseline][1800] Loss=0.6112, Acc=0.5750\n",
      "[Baseline][1801] Loss=0.5895, Acc=0.5678\n",
      "[Baseline][1802] Loss=0.6205, Acc=0.5682\n",
      "[Baseline][1803] Loss=0.6054, Acc=0.5649\n",
      "[Baseline][1804] Loss=0.5835, Acc=0.5667\n",
      "[Baseline][1805] Loss=0.5876, Acc=0.5666\n",
      "[Baseline][1806] Loss=0.6258, Acc=0.5668\n",
      "[Baseline][1807] Loss=0.5944, Acc=0.5791\n",
      "[Baseline][1808] Loss=0.5896, Acc=0.5724\n",
      "[Baseline][1809] Loss=0.5933, Acc=0.5644\n",
      "[Baseline][1810] Loss=0.6094, Acc=0.5686\n",
      "[Baseline][1811] Loss=0.6158, Acc=0.5603\n",
      "[Baseline][1812] Loss=0.5997, Acc=0.5678\n",
      "[Baseline][1813] Loss=0.5968, Acc=0.5540\n",
      "[Baseline][1814] Loss=0.6335, Acc=0.5656\n",
      "[Baseline][1815] Loss=0.5804, Acc=0.5639\n",
      "[Baseline][1816] Loss=0.5923, Acc=0.5667\n",
      "[Baseline][1817] Loss=0.5815, Acc=0.5702\n",
      "[Baseline][1818] Loss=0.5916, Acc=0.5704\n",
      "[Baseline][1819] Loss=0.5985, Acc=0.5754\n",
      "[Baseline][1820] Loss=0.5758, Acc=0.5605\n",
      "[Baseline][1821] Loss=0.6059, Acc=0.5740\n",
      "[Baseline][1822] Loss=0.5742, Acc=0.5712\n",
      "[Baseline][1823] Loss=0.5779, Acc=0.5766\n",
      "[Baseline][1824] Loss=0.6130, Acc=0.5718\n",
      "[Baseline][1825] Loss=0.5814, Acc=0.5615\n",
      "[Baseline][1826] Loss=0.5956, Acc=0.5629\n",
      "[Baseline][1827] Loss=0.5989, Acc=0.5636\n",
      "[Baseline][1828] Loss=0.5754, Acc=0.5692\n",
      "[Baseline][1829] Loss=0.6074, Acc=0.5660\n",
      "[Baseline][1830] Loss=0.6050, Acc=0.5754\n",
      "[Baseline][1831] Loss=0.6109, Acc=0.5683\n",
      "[Baseline][1832] Loss=0.6339, Acc=0.5727\n",
      "[Baseline][1833] Loss=0.6099, Acc=0.5672\n",
      "[Baseline][1834] Loss=0.5940, Acc=0.5555\n",
      "[Baseline][1835] Loss=0.6122, Acc=0.5779\n",
      "[Baseline][1836] Loss=0.5781, Acc=0.5776\n",
      "[Baseline][1837] Loss=0.5639, Acc=0.5710\n",
      "[Baseline][1838] Loss=0.5819, Acc=0.5544\n",
      "[Baseline][1839] Loss=0.5935, Acc=0.5740\n",
      "[Baseline][1840] Loss=0.5678, Acc=0.5595\n",
      "[Baseline][1841] Loss=0.6222, Acc=0.5713\n",
      "[Baseline][1842] Loss=0.6145, Acc=0.5584\n",
      "[Baseline][1843] Loss=0.6097, Acc=0.5703\n",
      "[Baseline][1844] Loss=0.5692, Acc=0.5753\n",
      "[Baseline][1845] Loss=0.5832, Acc=0.5603\n",
      "[Baseline][1846] Loss=0.5819, Acc=0.5708\n",
      "[Baseline][1847] Loss=0.6121, Acc=0.5666\n",
      "[Baseline][1848] Loss=0.5768, Acc=0.5731\n",
      "[Baseline][1849] Loss=0.5659, Acc=0.5695\n",
      "[Baseline][1850] Loss=0.5763, Acc=0.5623\n",
      "[Baseline][1851] Loss=0.5878, Acc=0.5751\n",
      "[Baseline][1852] Loss=0.5971, Acc=0.5682\n",
      "[Baseline][1853] Loss=0.6388, Acc=0.5568\n",
      "[Baseline][1854] Loss=0.6237, Acc=0.5548\n",
      "[Baseline][1855] Loss=0.5999, Acc=0.5632\n",
      "[Baseline][1856] Loss=0.5805, Acc=0.5770\n",
      "[Baseline][1857] Loss=0.5738, Acc=0.5757\n",
      "[Baseline][1858] Loss=0.5806, Acc=0.5682\n",
      "[Baseline][1859] Loss=0.5777, Acc=0.5724\n",
      "[Baseline][1860] Loss=0.5975, Acc=0.5724\n",
      "[Baseline][1861] Loss=0.6128, Acc=0.5662\n",
      "[Baseline][1862] Loss=0.5921, Acc=0.5652\n",
      "[Baseline][1863] Loss=0.6159, Acc=0.5712\n",
      "[Baseline][1864] Loss=0.6052, Acc=0.5582\n",
      "[Baseline][1865] Loss=0.6284, Acc=0.5724\n",
      "[Baseline][1866] Loss=0.5998, Acc=0.5692\n",
      "[Baseline][1867] Loss=0.6062, Acc=0.5604\n",
      "[Baseline][1868] Loss=0.5690, Acc=0.5707\n",
      "[Baseline][1869] Loss=0.5573, Acc=0.5466\n",
      "[Baseline][1870] Loss=0.5978, Acc=0.5703\n",
      "[Baseline][1871] Loss=0.5721, Acc=0.5571\n",
      "[Baseline][1872] Loss=0.6221, Acc=0.5556\n",
      "[Baseline][1873] Loss=0.6173, Acc=0.5683\n",
      "[Baseline][1874] Loss=0.5835, Acc=0.5593\n",
      "[Baseline][1875] Loss=0.5993, Acc=0.5692\n",
      "[Baseline][1876] Loss=0.6162, Acc=0.5635\n",
      "[Baseline][1877] Loss=0.5574, Acc=0.5725\n",
      "[Baseline][1878] Loss=0.5641, Acc=0.5535\n",
      "[Baseline][1879] Loss=0.5805, Acc=0.5706\n",
      "[Baseline][1880] Loss=0.5854, Acc=0.5758\n",
      "[Baseline][1881] Loss=0.5909, Acc=0.5657\n",
      "[Baseline][1882] Loss=0.5858, Acc=0.5703\n",
      "[Baseline][1883] Loss=0.5900, Acc=0.5673\n",
      "[Baseline][1884] Loss=0.5745, Acc=0.5723\n",
      "[Baseline][1885] Loss=0.5919, Acc=0.5827\n",
      "[Baseline][1886] Loss=0.5879, Acc=0.5693\n",
      "[Baseline][1887] Loss=0.5680, Acc=0.5767\n",
      "[Baseline][1888] Loss=0.5534, Acc=0.5745\n",
      "[Baseline][1889] Loss=0.5539, Acc=0.5697\n",
      "[Baseline][1890] Loss=0.5792, Acc=0.5649\n",
      "[Baseline][1891] Loss=0.5864, Acc=0.5735\n",
      "[Baseline][1892] Loss=0.6122, Acc=0.5718\n",
      "[Baseline][1893] Loss=0.5857, Acc=0.5697\n",
      "[Baseline][1894] Loss=0.6008, Acc=0.5630\n",
      "[Baseline][1895] Loss=0.5679, Acc=0.5624\n",
      "[Baseline][1896] Loss=0.5769, Acc=0.5579\n",
      "[Baseline][1897] Loss=0.6163, Acc=0.5552\n",
      "[Baseline][1898] Loss=0.5829, Acc=0.5787\n",
      "[Baseline][1899] Loss=0.5812, Acc=0.5697\n",
      "[Baseline][1900] Loss=0.5783, Acc=0.5719\n",
      "[Baseline][1901] Loss=0.5785, Acc=0.5725\n",
      "[Baseline][1902] Loss=0.5876, Acc=0.5635\n",
      "[Baseline][1903] Loss=0.5926, Acc=0.5735\n",
      "[Baseline][1904] Loss=0.5617, Acc=0.5619\n",
      "[Baseline][1905] Loss=0.5518, Acc=0.5657\n",
      "[Baseline][1906] Loss=0.6307, Acc=0.5693\n",
      "[Baseline][1907] Loss=0.5642, Acc=0.5498\n",
      "[Baseline][1908] Loss=0.5720, Acc=0.5639\n",
      "[Baseline][1909] Loss=0.5512, Acc=0.5774\n",
      "[Baseline][1910] Loss=0.5833, Acc=0.5780\n",
      "[Baseline][1911] Loss=0.5934, Acc=0.5702\n",
      "[Baseline][1912] Loss=0.5818, Acc=0.5691\n",
      "[Baseline][1913] Loss=0.5745, Acc=0.5640\n",
      "[Baseline][1914] Loss=0.5840, Acc=0.5775\n",
      "[Baseline][1915] Loss=0.5667, Acc=0.5696\n",
      "[Baseline][1916] Loss=0.5654, Acc=0.5717\n",
      "[Baseline][1917] Loss=0.5786, Acc=0.5652\n",
      "[Baseline][1918] Loss=0.5688, Acc=0.5618\n",
      "[Baseline][1919] Loss=0.5957, Acc=0.5729\n",
      "[Baseline][1920] Loss=0.5642, Acc=0.5597\n",
      "[Baseline][1921] Loss=0.5623, Acc=0.5660\n",
      "[Baseline][1922] Loss=0.5774, Acc=0.5728\n",
      "[Baseline][1923] Loss=0.5414, Acc=0.5681\n",
      "[Baseline][1924] Loss=0.5562, Acc=0.5596\n",
      "[Baseline][1925] Loss=0.6054, Acc=0.5784\n",
      "[Baseline][1926] Loss=0.5782, Acc=0.5624\n",
      "[Baseline][1927] Loss=0.5545, Acc=0.5741\n",
      "[Baseline][1928] Loss=0.5498, Acc=0.5617\n",
      "[Baseline][1929] Loss=0.5970, Acc=0.5693\n",
      "[Baseline][1930] Loss=0.5660, Acc=0.5578\n",
      "[Baseline][1931] Loss=0.5635, Acc=0.5636\n",
      "[Baseline][1932] Loss=0.6098, Acc=0.5734\n",
      "[Baseline][1933] Loss=0.5753, Acc=0.5774\n",
      "[Baseline][1934] Loss=0.5725, Acc=0.5634\n",
      "[Baseline][1935] Loss=0.5843, Acc=0.5748\n",
      "[Baseline][1936] Loss=0.5568, Acc=0.5690\n",
      "[Baseline][1937] Loss=0.5673, Acc=0.5693\n",
      "[Baseline][1938] Loss=0.5593, Acc=0.5628\n",
      "[Baseline][1939] Loss=0.5838, Acc=0.5662\n",
      "[Baseline][1940] Loss=0.5755, Acc=0.5677\n",
      "[Baseline][1941] Loss=0.5637, Acc=0.5671\n",
      "[Baseline][1942] Loss=0.5502, Acc=0.5650\n",
      "[Baseline][1943] Loss=0.5669, Acc=0.5681\n",
      "[Baseline][1944] Loss=0.5705, Acc=0.5614\n",
      "[Baseline][1945] Loss=0.5747, Acc=0.5553\n",
      "[Baseline][1946] Loss=0.5786, Acc=0.5750\n",
      "[Baseline][1947] Loss=0.5747, Acc=0.5691\n",
      "[Baseline][1948] Loss=0.5821, Acc=0.5675\n",
      "[Baseline][1949] Loss=0.5571, Acc=0.5724\n",
      "[Baseline][1950] Loss=0.6033, Acc=0.5684\n",
      "[Baseline][1951] Loss=0.6221, Acc=0.5676\n",
      "[Baseline][1952] Loss=0.5876, Acc=0.5559\n",
      "[Baseline][1953] Loss=0.5966, Acc=0.5659\n",
      "[Baseline][1954] Loss=0.5858, Acc=0.5626\n",
      "[Baseline][1955] Loss=0.5700, Acc=0.5651\n",
      "[Baseline][1956] Loss=0.6107, Acc=0.5701\n",
      "[Baseline][1957] Loss=0.5548, Acc=0.5817\n",
      "[Baseline][1958] Loss=0.5286, Acc=0.5735\n",
      "[Baseline][1959] Loss=0.5646, Acc=0.5682\n",
      "[Baseline][1960] Loss=0.5455, Acc=0.5720\n",
      "[Baseline][1961] Loss=0.5537, Acc=0.5759\n",
      "[Baseline][1962] Loss=0.5533, Acc=0.5663\n",
      "[Baseline][1963] Loss=0.5643, Acc=0.5688\n",
      "[Baseline][1964] Loss=0.5718, Acc=0.5782\n",
      "[Baseline][1965] Loss=0.5640, Acc=0.5644\n",
      "[Baseline][1966] Loss=0.5760, Acc=0.5589\n",
      "[Baseline][1967] Loss=0.5841, Acc=0.5757\n",
      "[Baseline][1968] Loss=0.5950, Acc=0.5707\n",
      "[Baseline][1969] Loss=0.5858, Acc=0.5753\n",
      "[Baseline][1970] Loss=0.5663, Acc=0.5780\n",
      "[Baseline][1971] Loss=0.5216, Acc=0.5738\n",
      "[Baseline][1972] Loss=0.5427, Acc=0.5666\n",
      "[Baseline][1973] Loss=0.5492, Acc=0.5715\n",
      "[Baseline][1974] Loss=0.5536, Acc=0.5731\n",
      "[Baseline][1975] Loss=0.5723, Acc=0.5721\n",
      "[Baseline][1976] Loss=0.6015, Acc=0.5818\n",
      "[Baseline][1977] Loss=0.5503, Acc=0.5673\n",
      "[Baseline][1978] Loss=0.5754, Acc=0.5677\n",
      "[Baseline][1979] Loss=0.5774, Acc=0.5646\n",
      "[Baseline][1980] Loss=0.5677, Acc=0.5719\n",
      "[Baseline][1981] Loss=0.5675, Acc=0.5511\n",
      "[Baseline][1982] Loss=0.6248, Acc=0.5717\n",
      "[Baseline][1983] Loss=0.5811, Acc=0.5687\n",
      "[Baseline][1984] Loss=0.5564, Acc=0.5763\n",
      "[Baseline][1985] Loss=0.5532, Acc=0.5767\n",
      "[Baseline][1986] Loss=0.5527, Acc=0.5615\n",
      "[Baseline][1987] Loss=0.5550, Acc=0.5742\n",
      "[Baseline][1988] Loss=0.5459, Acc=0.5615\n",
      "[Baseline][1989] Loss=0.5779, Acc=0.5773\n",
      "[Baseline][1990] Loss=0.5370, Acc=0.5700\n",
      "[Baseline][1991] Loss=0.5498, Acc=0.5747\n",
      "[Baseline][1992] Loss=0.5355, Acc=0.5694\n",
      "[Baseline][1993] Loss=0.5642, Acc=0.5650\n",
      "[Baseline][1994] Loss=0.5515, Acc=0.5704\n",
      "[Baseline][1995] Loss=0.5538, Acc=0.5697\n",
      "[Baseline][1996] Loss=0.5689, Acc=0.5656\n",
      "[Baseline][1997] Loss=0.5671, Acc=0.5638\n",
      "[Baseline][1998] Loss=0.5593, Acc=0.5727\n",
      "[Baseline][1999] Loss=0.5565, Acc=0.5697\n"
     ]
    }
   ],
   "source": [
    "cnn_base = CNN_CIFAR().to(device)\n",
    "cnn_base.load_state_dict(cnn_init_state)\n",
    "opt_cnn_base = torch.optim.Adam(cnn_base.parameters(), lr=1e-3)\n",
    "\n",
    "train_baseline(\n",
    "    cnn_base,\n",
    "    opt_cnn_base,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    epochs,\n",
    "    logs[\"baseline_cnn\"]\n",
    ")\n",
    "\n",
    "mlp_base = MLP_CIFAR().to(device)\n",
    "mlp_base.load_state_dict(mlp_init_state)\n",
    "opt_mlp_base = torch.optim.Adam(mlp_base.parameters(), lr=1e-3)\n",
    "\n",
    "train_baseline(\n",
    "    mlp_base,\n",
    "    opt_mlp_base,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    epochs,\n",
    "    logs[\"baseline_mlp\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccaff151-3ef7-4d9e-9ee4-64eea7e6f8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa7e7029dcf41f89dfc5b08e7ff3d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Studygroup][00] CNN Loss=2.2355, Acc=0.3047 | MLP Loss=2.3225, Acc=0.1517\n",
      "[Studygroup][01] CNN Loss=2.1588, Acc=0.3265 | MLP Loss=2.3237, Acc=0.1737\n",
      "[Studygroup][02] CNN Loss=2.0872, Acc=0.3771 | MLP Loss=2.3209, Acc=0.1813\n",
      "[Studygroup][03] CNN Loss=2.0331, Acc=0.4177 | MLP Loss=2.2904, Acc=0.2197\n",
      "[Studygroup][04] CNN Loss=2.0037, Acc=0.4272 | MLP Loss=2.2989, Acc=0.2402\n",
      "[Studygroup][05] CNN Loss=1.9726, Acc=0.4460 | MLP Loss=2.2842, Acc=0.2358\n",
      "[Studygroup][06] CNN Loss=1.9538, Acc=0.4307 | MLP Loss=2.2853, Acc=0.2357\n",
      "[Studygroup][07] CNN Loss=1.9539, Acc=0.4573 | MLP Loss=2.2411, Acc=0.2738\n",
      "[Studygroup][08] CNN Loss=1.8953, Acc=0.4784 | MLP Loss=2.2271, Acc=0.2687\n",
      "[Studygroup][09] CNN Loss=1.9072, Acc=0.4771 | MLP Loss=2.2585, Acc=0.2656\n",
      "[Studygroup][10] CNN Loss=1.8909, Acc=0.4932 | MLP Loss=2.2296, Acc=0.2464\n",
      "[Studygroup][11] CNN Loss=1.8503, Acc=0.4679 | MLP Loss=2.1946, Acc=0.2421\n",
      "[Studygroup][12] CNN Loss=1.8781, Acc=0.4757 | MLP Loss=2.2229, Acc=0.2639\n",
      "[Studygroup][13] CNN Loss=1.8610, Acc=0.5217 | MLP Loss=2.2012, Acc=0.2545\n",
      "[Studygroup][14] CNN Loss=1.8455, Acc=0.4940 | MLP Loss=2.1551, Acc=0.2464\n",
      "[Studygroup][15] CNN Loss=1.7701, Acc=0.5241 | MLP Loss=2.1710, Acc=0.3004\n",
      "[Studygroup][16] CNN Loss=1.7985, Acc=0.4974 | MLP Loss=2.1611, Acc=0.2957\n",
      "[Studygroup][17] CNN Loss=1.7703, Acc=0.5289 | MLP Loss=2.1684, Acc=0.2916\n",
      "[Studygroup][18] CNN Loss=1.7370, Acc=0.5342 | MLP Loss=2.1847, Acc=0.3042\n",
      "[Studygroup][19] CNN Loss=1.7731, Acc=0.5446 | MLP Loss=2.1628, Acc=0.2993\n",
      "[Studygroup][20] CNN Loss=1.7365, Acc=0.5544 | MLP Loss=2.1304, Acc=0.3129\n",
      "[Studygroup][21] CNN Loss=1.7467, Acc=0.5307 | MLP Loss=2.1614, Acc=0.3035\n",
      "[Studygroup][22] CNN Loss=1.7338, Acc=0.5517 | MLP Loss=2.1476, Acc=0.3224\n",
      "[Studygroup][23] CNN Loss=1.6996, Acc=0.5456 | MLP Loss=2.1730, Acc=0.3058\n",
      "[Studygroup][24] CNN Loss=1.7224, Acc=0.5310 | MLP Loss=2.1883, Acc=0.2893\n",
      "[Studygroup][25] CNN Loss=1.7046, Acc=0.5373 | MLP Loss=2.1591, Acc=0.3187\n",
      "[Studygroup][26] CNN Loss=1.6783, Acc=0.5653 | MLP Loss=2.1219, Acc=0.3221\n",
      "[Studygroup][27] CNN Loss=1.6800, Acc=0.5349 | MLP Loss=2.0958, Acc=0.3193\n",
      "[Studygroup][28] CNN Loss=1.6369, Acc=0.5684 | MLP Loss=2.0890, Acc=0.3320\n",
      "[Studygroup][29] CNN Loss=1.6096, Acc=0.5518 | MLP Loss=2.0934, Acc=0.3144\n",
      "[Studygroup][30] CNN Loss=1.5677, Acc=0.5518 | MLP Loss=2.0871, Acc=0.3065\n",
      "[Studygroup][31] CNN Loss=1.6129, Acc=0.5759 | MLP Loss=2.1145, Acc=0.3252\n",
      "[Studygroup][32] CNN Loss=1.5855, Acc=0.5815 | MLP Loss=2.1041, Acc=0.3349\n",
      "[Studygroup][33] CNN Loss=1.5573, Acc=0.5541 | MLP Loss=2.0966, Acc=0.3293\n",
      "[Studygroup][34] CNN Loss=1.5650, Acc=0.5702 | MLP Loss=2.0645, Acc=0.3244\n",
      "[Studygroup][35] CNN Loss=1.5654, Acc=0.5868 | MLP Loss=2.0777, Acc=0.3117\n",
      "[Studygroup][36] CNN Loss=1.5373, Acc=0.5502 | MLP Loss=2.0637, Acc=0.3154\n",
      "[Studygroup][37] CNN Loss=1.6108, Acc=0.5878 | MLP Loss=2.1598, Acc=0.3570\n",
      "[Studygroup][38] CNN Loss=1.5318, Acc=0.5605 | MLP Loss=2.0491, Acc=0.3337\n",
      "[Studygroup][39] CNN Loss=1.5375, Acc=0.5667 | MLP Loss=2.0913, Acc=0.3481\n",
      "[Studygroup][40] CNN Loss=1.5249, Acc=0.5697 | MLP Loss=2.0755, Acc=0.3507\n",
      "[Studygroup][41] CNN Loss=1.4904, Acc=0.5910 | MLP Loss=2.0666, Acc=0.3454\n",
      "[Studygroup][42] CNN Loss=1.5093, Acc=0.5856 | MLP Loss=2.0668, Acc=0.3256\n",
      "[Studygroup][43] CNN Loss=1.5128, Acc=0.5858 | MLP Loss=2.0743, Acc=0.3352\n",
      "[Studygroup][44] CNN Loss=1.5019, Acc=0.5892 | MLP Loss=2.0869, Acc=0.3340\n",
      "[Studygroup][45] CNN Loss=1.5414, Acc=0.5912 | MLP Loss=2.0993, Acc=0.3415\n",
      "[Studygroup][46] CNN Loss=1.4392, Acc=0.5974 | MLP Loss=2.0346, Acc=0.3516\n",
      "[Studygroup][47] CNN Loss=1.5095, Acc=0.5873 | MLP Loss=2.0754, Acc=0.3508\n",
      "[Studygroup][48] CNN Loss=1.4889, Acc=0.5966 | MLP Loss=2.0323, Acc=0.3777\n",
      "[Studygroup][49] CNN Loss=1.4581, Acc=0.5706 | MLP Loss=2.0320, Acc=0.3565\n",
      "[Studygroup][50] CNN Loss=1.4846, Acc=0.5886 | MLP Loss=2.0485, Acc=0.3248\n",
      "[Studygroup][51] CNN Loss=1.4606, Acc=0.6039 | MLP Loss=2.0530, Acc=0.3561\n",
      "[Studygroup][52] CNN Loss=1.4407, Acc=0.5986 | MLP Loss=2.0493, Acc=0.3373\n",
      "[Studygroup][53] CNN Loss=1.4418, Acc=0.6116 | MLP Loss=2.0329, Acc=0.3713\n",
      "[Studygroup][54] CNN Loss=1.4021, Acc=0.6106 | MLP Loss=2.0113, Acc=0.3613\n",
      "[Studygroup][55] CNN Loss=1.4410, Acc=0.6173 | MLP Loss=2.0549, Acc=0.3571\n",
      "[Studygroup][56] CNN Loss=1.4331, Acc=0.5964 | MLP Loss=2.0362, Acc=0.3797\n",
      "[Studygroup][57] CNN Loss=1.4384, Acc=0.6132 | MLP Loss=1.9963, Acc=0.3697\n",
      "[Studygroup][58] CNN Loss=1.4181, Acc=0.6073 | MLP Loss=2.0278, Acc=0.3479\n",
      "[Studygroup][59] CNN Loss=1.4135, Acc=0.6138 | MLP Loss=2.0415, Acc=0.3969\n",
      "[Studygroup][60] CNN Loss=1.4164, Acc=0.6126 | MLP Loss=2.0447, Acc=0.3880\n",
      "[Studygroup][61] CNN Loss=1.3986, Acc=0.6111 | MLP Loss=2.0412, Acc=0.3784\n",
      "[Studygroup][62] CNN Loss=1.3884, Acc=0.6112 | MLP Loss=2.0040, Acc=0.4121\n",
      "[Studygroup][63] CNN Loss=1.3926, Acc=0.6187 | MLP Loss=1.9756, Acc=0.3985\n",
      "[Studygroup][64] CNN Loss=1.3960, Acc=0.6080 | MLP Loss=1.9982, Acc=0.3585\n",
      "[Studygroup][65] CNN Loss=1.4072, Acc=0.6155 | MLP Loss=2.0194, Acc=0.3656\n",
      "[Studygroup][66] CNN Loss=1.4092, Acc=0.6143 | MLP Loss=2.0521, Acc=0.3811\n",
      "[Studygroup][67] CNN Loss=1.3938, Acc=0.6102 | MLP Loss=2.0068, Acc=0.4051\n",
      "[Studygroup][68] CNN Loss=1.3644, Acc=0.6188 | MLP Loss=1.9636, Acc=0.4131\n",
      "[Studygroup][69] CNN Loss=1.3226, Acc=0.6074 | MLP Loss=2.0095, Acc=0.3978\n",
      "[Studygroup][70] CNN Loss=1.3613, Acc=0.6061 | MLP Loss=1.9991, Acc=0.4074\n",
      "[Studygroup][71] CNN Loss=1.3889, Acc=0.5977 | MLP Loss=2.0063, Acc=0.4089\n",
      "[Studygroup][72] CNN Loss=1.3944, Acc=0.6170 | MLP Loss=2.0111, Acc=0.4069\n",
      "[Studygroup][73] CNN Loss=1.3730, Acc=0.6241 | MLP Loss=2.0140, Acc=0.3965\n",
      "[Studygroup][74] CNN Loss=1.3953, Acc=0.6160 | MLP Loss=1.9924, Acc=0.4014\n",
      "[Studygroup][75] CNN Loss=1.3887, Acc=0.6020 | MLP Loss=1.9713, Acc=0.3791\n",
      "[Studygroup][76] CNN Loss=1.3614, Acc=0.6202 | MLP Loss=2.0219, Acc=0.3940\n",
      "[Studygroup][77] CNN Loss=1.3528, Acc=0.6250 | MLP Loss=2.0324, Acc=0.4035\n",
      "[Studygroup][78] CNN Loss=1.3956, Acc=0.6129 | MLP Loss=1.9925, Acc=0.3980\n",
      "[Studygroup][79] CNN Loss=1.3240, Acc=0.6297 | MLP Loss=1.9665, Acc=0.4066\n",
      "[Studygroup][80] CNN Loss=1.3317, Acc=0.6138 | MLP Loss=1.9301, Acc=0.4232\n",
      "[Studygroup][81] CNN Loss=1.3350, Acc=0.6250 | MLP Loss=1.9490, Acc=0.4219\n",
      "[Studygroup][82] CNN Loss=1.3335, Acc=0.6044 | MLP Loss=1.9621, Acc=0.4075\n",
      "[Studygroup][83] CNN Loss=1.2946, Acc=0.6049 | MLP Loss=1.9782, Acc=0.4053\n",
      "[Studygroup][84] CNN Loss=1.3393, Acc=0.6295 | MLP Loss=1.9962, Acc=0.4138\n",
      "[Studygroup][85] CNN Loss=1.3314, Acc=0.6127 | MLP Loss=2.0121, Acc=0.4018\n",
      "[Studygroup][86] CNN Loss=1.3444, Acc=0.6228 | MLP Loss=1.9398, Acc=0.4280\n",
      "[Studygroup][87] CNN Loss=1.3013, Acc=0.6299 | MLP Loss=1.9829, Acc=0.4164\n",
      "[Studygroup][88] CNN Loss=1.2979, Acc=0.6331 | MLP Loss=1.9706, Acc=0.4253\n",
      "[Studygroup][89] CNN Loss=1.3198, Acc=0.6206 | MLP Loss=1.9517, Acc=0.4123\n",
      "[Studygroup][90] CNN Loss=1.3424, Acc=0.6294 | MLP Loss=1.9371, Acc=0.4176\n",
      "[Studygroup][91] CNN Loss=1.2840, Acc=0.6270 | MLP Loss=1.9535, Acc=0.4127\n",
      "[Studygroup][92] CNN Loss=1.3075, Acc=0.6164 | MLP Loss=1.9345, Acc=0.4311\n",
      "[Studygroup][93] CNN Loss=1.2667, Acc=0.6341 | MLP Loss=1.9774, Acc=0.4349\n",
      "[Studygroup][94] CNN Loss=1.2728, Acc=0.6229 | MLP Loss=1.9727, Acc=0.4268\n",
      "[Studygroup][95] CNN Loss=1.3062, Acc=0.6274 | MLP Loss=1.9829, Acc=0.4223\n",
      "[Studygroup][96] CNN Loss=1.3012, Acc=0.6152 | MLP Loss=1.9274, Acc=0.4199\n",
      "[Studygroup][97] CNN Loss=1.2690, Acc=0.6304 | MLP Loss=1.9556, Acc=0.3977\n",
      "[Studygroup][98] CNN Loss=1.2970, Acc=0.6273 | MLP Loss=1.9927, Acc=0.4079\n",
      "[Studygroup][99] CNN Loss=1.2615, Acc=0.6291 | MLP Loss=1.9703, Acc=0.4000\n",
      "[Studygroup][100] CNN Loss=1.3184, Acc=0.6295 | MLP Loss=1.9906, Acc=0.4139\n",
      "[Studygroup][101] CNN Loss=1.3074, Acc=0.6230 | MLP Loss=1.9884, Acc=0.4135\n",
      "[Studygroup][102] CNN Loss=1.2444, Acc=0.6199 | MLP Loss=1.9562, Acc=0.4241\n",
      "[Studygroup][103] CNN Loss=1.2688, Acc=0.6330 | MLP Loss=1.8931, Acc=0.4332\n",
      "[Studygroup][104] CNN Loss=1.2653, Acc=0.6317 | MLP Loss=1.9417, Acc=0.4335\n",
      "[Studygroup][105] CNN Loss=1.2966, Acc=0.6270 | MLP Loss=1.9134, Acc=0.4236\n",
      "[Studygroup][106] CNN Loss=1.2552, Acc=0.6150 | MLP Loss=1.9381, Acc=0.4316\n",
      "[Studygroup][107] CNN Loss=1.2543, Acc=0.6351 | MLP Loss=1.9820, Acc=0.4391\n",
      "[Studygroup][108] CNN Loss=1.2586, Acc=0.6316 | MLP Loss=1.9945, Acc=0.4263\n",
      "[Studygroup][109] CNN Loss=1.2539, Acc=0.6283 | MLP Loss=1.9374, Acc=0.4414\n",
      "[Studygroup][110] CNN Loss=1.2314, Acc=0.6393 | MLP Loss=1.9184, Acc=0.4351\n",
      "[Studygroup][111] CNN Loss=1.2400, Acc=0.6469 | MLP Loss=1.9585, Acc=0.4373\n",
      "[Studygroup][112] CNN Loss=1.2297, Acc=0.6246 | MLP Loss=1.9606, Acc=0.4529\n",
      "[Studygroup][113] CNN Loss=1.2293, Acc=0.6297 | MLP Loss=1.9459, Acc=0.4412\n",
      "[Studygroup][114] CNN Loss=1.2577, Acc=0.6214 | MLP Loss=1.9704, Acc=0.4464\n",
      "[Studygroup][115] CNN Loss=1.2214, Acc=0.6448 | MLP Loss=1.9215, Acc=0.4415\n",
      "[Studygroup][116] CNN Loss=1.2449, Acc=0.6338 | MLP Loss=1.9499, Acc=0.4490\n",
      "[Studygroup][117] CNN Loss=1.1943, Acc=0.6297 | MLP Loss=1.8791, Acc=0.4102\n",
      "[Studygroup][118] CNN Loss=1.1982, Acc=0.6330 | MLP Loss=1.9406, Acc=0.4191\n",
      "[Studygroup][119] CNN Loss=1.2625, Acc=0.6404 | MLP Loss=1.9669, Acc=0.4360\n",
      "[Studygroup][120] CNN Loss=1.2143, Acc=0.6288 | MLP Loss=1.9116, Acc=0.4268\n",
      "[Studygroup][121] CNN Loss=1.2014, Acc=0.6270 | MLP Loss=1.9514, Acc=0.4362\n",
      "[Studygroup][122] CNN Loss=1.2463, Acc=0.6335 | MLP Loss=2.0215, Acc=0.4330\n",
      "[Studygroup][123] CNN Loss=1.2604, Acc=0.6278 | MLP Loss=1.9311, Acc=0.4487\n",
      "[Studygroup][124] CNN Loss=1.2686, Acc=0.6391 | MLP Loss=1.9408, Acc=0.4424\n",
      "[Studygroup][125] CNN Loss=1.2455, Acc=0.6324 | MLP Loss=1.9481, Acc=0.4400\n",
      "[Studygroup][126] CNN Loss=1.1775, Acc=0.6434 | MLP Loss=1.9508, Acc=0.4518\n",
      "[Studygroup][127] CNN Loss=1.2569, Acc=0.6416 | MLP Loss=1.9290, Acc=0.4551\n",
      "[Studygroup][128] CNN Loss=1.1812, Acc=0.6368 | MLP Loss=1.9220, Acc=0.4554\n",
      "[Studygroup][129] CNN Loss=1.2564, Acc=0.6419 | MLP Loss=1.9857, Acc=0.4599\n",
      "[Studygroup][130] CNN Loss=1.1907, Acc=0.6472 | MLP Loss=1.9329, Acc=0.4411\n",
      "[Studygroup][131] CNN Loss=1.2053, Acc=0.6381 | MLP Loss=1.9324, Acc=0.4542\n",
      "[Studygroup][132] CNN Loss=1.2003, Acc=0.6186 | MLP Loss=1.9753, Acc=0.4250\n",
      "[Studygroup][133] CNN Loss=1.2130, Acc=0.6444 | MLP Loss=1.9181, Acc=0.4577\n",
      "[Studygroup][134] CNN Loss=1.2635, Acc=0.6493 | MLP Loss=1.9776, Acc=0.4481\n",
      "[Studygroup][135] CNN Loss=1.1820, Acc=0.6334 | MLP Loss=1.9139, Acc=0.4364\n",
      "[Studygroup][136] CNN Loss=1.2501, Acc=0.6451 | MLP Loss=1.9241, Acc=0.4473\n",
      "[Studygroup][137] CNN Loss=1.2174, Acc=0.6470 | MLP Loss=1.9281, Acc=0.4170\n",
      "[Studygroup][138] CNN Loss=1.2839, Acc=0.6356 | MLP Loss=1.9526, Acc=0.4446\n",
      "[Studygroup][139] CNN Loss=1.1918, Acc=0.6382 | MLP Loss=1.9054, Acc=0.4571\n",
      "[Studygroup][140] CNN Loss=1.1965, Acc=0.6416 | MLP Loss=1.9127, Acc=0.4593\n",
      "[Studygroup][141] CNN Loss=1.2209, Acc=0.6393 | MLP Loss=1.9409, Acc=0.4545\n",
      "[Studygroup][142] CNN Loss=1.2142, Acc=0.6449 | MLP Loss=1.9420, Acc=0.4444\n",
      "[Studygroup][143] CNN Loss=1.1828, Acc=0.6416 | MLP Loss=1.9279, Acc=0.4643\n",
      "[Studygroup][144] CNN Loss=1.1938, Acc=0.6502 | MLP Loss=1.9418, Acc=0.4411\n",
      "[Studygroup][145] CNN Loss=1.1757, Acc=0.6412 | MLP Loss=1.9311, Acc=0.4531\n",
      "[Studygroup][146] CNN Loss=1.2162, Acc=0.6407 | MLP Loss=1.9459, Acc=0.4241\n",
      "[Studygroup][147] CNN Loss=1.1668, Acc=0.6380 | MLP Loss=1.9018, Acc=0.4611\n",
      "[Studygroup][148] CNN Loss=1.1568, Acc=0.6465 | MLP Loss=1.9073, Acc=0.4656\n",
      "[Studygroup][149] CNN Loss=1.1882, Acc=0.6389 | MLP Loss=1.9326, Acc=0.4652\n",
      "[Studygroup][150] CNN Loss=1.1805, Acc=0.6515 | MLP Loss=1.9557, Acc=0.4408\n",
      "[Studygroup][151] CNN Loss=1.1890, Acc=0.6479 | MLP Loss=1.9456, Acc=0.4349\n",
      "[Studygroup][152] CNN Loss=1.1460, Acc=0.6520 | MLP Loss=1.9504, Acc=0.4510\n",
      "[Studygroup][153] CNN Loss=1.1927, Acc=0.6408 | MLP Loss=1.9303, Acc=0.4642\n",
      "[Studygroup][154] CNN Loss=1.1661, Acc=0.6460 | MLP Loss=1.9057, Acc=0.4592\n",
      "[Studygroup][155] CNN Loss=1.1783, Acc=0.6380 | MLP Loss=1.9422, Acc=0.4538\n",
      "[Studygroup][156] CNN Loss=1.1367, Acc=0.6513 | MLP Loss=1.9392, Acc=0.4694\n",
      "[Studygroup][157] CNN Loss=1.1967, Acc=0.6453 | MLP Loss=2.0141, Acc=0.4692\n",
      "[Studygroup][158] CNN Loss=1.1590, Acc=0.6416 | MLP Loss=2.0170, Acc=0.4698\n",
      "[Studygroup][159] CNN Loss=1.2042, Acc=0.6363 | MLP Loss=1.9412, Acc=0.4468\n",
      "[Studygroup][160] CNN Loss=1.1746, Acc=0.6395 | MLP Loss=1.9372, Acc=0.4594\n",
      "[Studygroup][161] CNN Loss=1.1731, Acc=0.6430 | MLP Loss=1.9801, Acc=0.4577\n",
      "[Studygroup][162] CNN Loss=1.1718, Acc=0.6405 | MLP Loss=1.9230, Acc=0.4656\n",
      "[Studygroup][163] CNN Loss=1.1376, Acc=0.6463 | MLP Loss=1.9275, Acc=0.4717\n",
      "[Studygroup][164] CNN Loss=1.2471, Acc=0.6386 | MLP Loss=1.9590, Acc=0.4770\n",
      "[Studygroup][165] CNN Loss=1.1938, Acc=0.6476 | MLP Loss=1.9384, Acc=0.4550\n",
      "[Studygroup][166] CNN Loss=1.1774, Acc=0.6498 | MLP Loss=1.9847, Acc=0.4669\n",
      "[Studygroup][167] CNN Loss=1.1371, Acc=0.6431 | MLP Loss=1.9364, Acc=0.4436\n",
      "[Studygroup][168] CNN Loss=1.2324, Acc=0.6352 | MLP Loss=1.9041, Acc=0.4575\n",
      "[Studygroup][169] CNN Loss=1.2316, Acc=0.6387 | MLP Loss=1.8507, Acc=0.4797\n",
      "[Studygroup][170] CNN Loss=1.1554, Acc=0.6539 | MLP Loss=1.8856, Acc=0.4516\n",
      "[Studygroup][171] CNN Loss=1.1916, Acc=0.6470 | MLP Loss=1.8696, Acc=0.4587\n",
      "[Studygroup][172] CNN Loss=1.1465, Acc=0.6409 | MLP Loss=1.8880, Acc=0.4747\n",
      "[Studygroup][173] CNN Loss=1.1522, Acc=0.6512 | MLP Loss=1.8583, Acc=0.4637\n",
      "[Studygroup][174] CNN Loss=1.1323, Acc=0.6405 | MLP Loss=1.9025, Acc=0.4781\n",
      "[Studygroup][175] CNN Loss=1.1526, Acc=0.6358 | MLP Loss=1.9220, Acc=0.4687\n",
      "[Studygroup][176] CNN Loss=1.1674, Acc=0.6528 | MLP Loss=1.8890, Acc=0.4592\n",
      "[Studygroup][177] CNN Loss=1.1317, Acc=0.6538 | MLP Loss=1.8981, Acc=0.4776\n",
      "[Studygroup][178] CNN Loss=1.0813, Acc=0.6350 | MLP Loss=1.9111, Acc=0.4636\n",
      "[Studygroup][179] CNN Loss=1.1211, Acc=0.6430 | MLP Loss=1.8818, Acc=0.4670\n",
      "[Studygroup][180] CNN Loss=1.1432, Acc=0.6455 | MLP Loss=1.8864, Acc=0.4628\n",
      "[Studygroup][181] CNN Loss=1.0922, Acc=0.6504 | MLP Loss=1.8875, Acc=0.4818\n",
      "[Studygroup][182] CNN Loss=1.1486, Acc=0.6461 | MLP Loss=1.9405, Acc=0.4639\n",
      "[Studygroup][183] CNN Loss=1.1424, Acc=0.6408 | MLP Loss=2.0066, Acc=0.4449\n",
      "[Studygroup][184] CNN Loss=1.3028, Acc=0.6386 | MLP Loss=2.0762, Acc=0.4681\n",
      "[Studygroup][185] CNN Loss=1.1064, Acc=0.6452 | MLP Loss=1.8982, Acc=0.4805\n",
      "[Studygroup][186] CNN Loss=1.1427, Acc=0.6509 | MLP Loss=1.8858, Acc=0.4724\n",
      "[Studygroup][187] CNN Loss=1.0932, Acc=0.6511 | MLP Loss=1.8923, Acc=0.4832\n",
      "[Studygroup][188] CNN Loss=1.1259, Acc=0.6516 | MLP Loss=1.9160, Acc=0.4484\n",
      "[Studygroup][189] CNN Loss=1.1613, Acc=0.6443 | MLP Loss=1.8762, Acc=0.4691\n",
      "[Studygroup][190] CNN Loss=1.1655, Acc=0.6389 | MLP Loss=1.9260, Acc=0.4836\n",
      "[Studygroup][191] CNN Loss=1.1444, Acc=0.6488 | MLP Loss=1.8660, Acc=0.4882\n",
      "[Studygroup][192] CNN Loss=1.1173, Acc=0.6512 | MLP Loss=1.8918, Acc=0.4765\n",
      "[Studygroup][193] CNN Loss=1.0983, Acc=0.6467 | MLP Loss=1.9362, Acc=0.4547\n",
      "[Studygroup][194] CNN Loss=1.2374, Acc=0.6542 | MLP Loss=2.0853, Acc=0.4671\n",
      "[Studygroup][195] CNN Loss=1.1251, Acc=0.6411 | MLP Loss=1.8658, Acc=0.4846\n",
      "[Studygroup][196] CNN Loss=1.1102, Acc=0.6387 | MLP Loss=1.8810, Acc=0.4770\n",
      "[Studygroup][197] CNN Loss=1.1015, Acc=0.6488 | MLP Loss=1.8711, Acc=0.4700\n",
      "[Studygroup][198] CNN Loss=1.1389, Acc=0.6503 | MLP Loss=1.8850, Acc=0.4795\n",
      "[Studygroup][199] CNN Loss=1.1109, Acc=0.6479 | MLP Loss=1.8749, Acc=0.4730\n",
      "[Studygroup][200] CNN Loss=1.0913, Acc=0.6512 | MLP Loss=1.8995, Acc=0.4809\n",
      "[Studygroup][201] CNN Loss=1.1254, Acc=0.6500 | MLP Loss=1.8856, Acc=0.4667\n",
      "[Studygroup][202] CNN Loss=1.0968, Acc=0.6555 | MLP Loss=1.8734, Acc=0.4838\n",
      "[Studygroup][203] CNN Loss=1.1858, Acc=0.6323 | MLP Loss=2.0087, Acc=0.4709\n",
      "[Studygroup][204] CNN Loss=1.1394, Acc=0.6542 | MLP Loss=1.8577, Acc=0.4888\n",
      "[Studygroup][205] CNN Loss=1.1227, Acc=0.6515 | MLP Loss=1.9324, Acc=0.4833\n",
      "[Studygroup][206] CNN Loss=1.1414, Acc=0.6400 | MLP Loss=1.9426, Acc=0.4706\n",
      "[Studygroup][207] CNN Loss=1.1008, Acc=0.6522 | MLP Loss=1.8416, Acc=0.4645\n",
      "[Studygroup][208] CNN Loss=1.1523, Acc=0.6506 | MLP Loss=1.8680, Acc=0.4692\n",
      "[Studygroup][209] CNN Loss=1.1440, Acc=0.6461 | MLP Loss=1.8111, Acc=0.4845\n",
      "[Studygroup][210] CNN Loss=1.0996, Acc=0.6579 | MLP Loss=1.8882, Acc=0.4865\n",
      "[Studygroup][211] CNN Loss=1.1144, Acc=0.6555 | MLP Loss=1.9326, Acc=0.4756\n",
      "[Studygroup][212] CNN Loss=1.1422, Acc=0.6529 | MLP Loss=1.9610, Acc=0.4614\n",
      "[Studygroup][213] CNN Loss=1.0984, Acc=0.6546 | MLP Loss=1.8958, Acc=0.4803\n",
      "[Studygroup][214] CNN Loss=1.1123, Acc=0.6440 | MLP Loss=1.8369, Acc=0.4922\n",
      "[Studygroup][215] CNN Loss=1.1134, Acc=0.6529 | MLP Loss=1.9018, Acc=0.4968\n",
      "[Studygroup][216] CNN Loss=1.0964, Acc=0.6452 | MLP Loss=1.9012, Acc=0.4776\n",
      "[Studygroup][217] CNN Loss=1.1265, Acc=0.6596 | MLP Loss=1.8443, Acc=0.4918\n",
      "[Studygroup][218] CNN Loss=1.1318, Acc=0.6544 | MLP Loss=1.8562, Acc=0.4963\n",
      "[Studygroup][219] CNN Loss=1.0988, Acc=0.6501 | MLP Loss=1.8285, Acc=0.4772\n",
      "[Studygroup][220] CNN Loss=1.0736, Acc=0.6523 | MLP Loss=1.8379, Acc=0.4694\n",
      "[Studygroup][221] CNN Loss=1.0901, Acc=0.6551 | MLP Loss=1.8898, Acc=0.4877\n",
      "[Studygroup][222] CNN Loss=1.1401, Acc=0.6490 | MLP Loss=1.8532, Acc=0.4895\n",
      "[Studygroup][223] CNN Loss=1.1014, Acc=0.6561 | MLP Loss=1.8721, Acc=0.4966\n",
      "[Studygroup][224] CNN Loss=1.1433, Acc=0.6516 | MLP Loss=1.9086, Acc=0.4806\n",
      "[Studygroup][225] CNN Loss=1.1512, Acc=0.6487 | MLP Loss=1.8867, Acc=0.4951\n",
      "[Studygroup][226] CNN Loss=1.0987, Acc=0.6567 | MLP Loss=1.8789, Acc=0.4849\n",
      "[Studygroup][227] CNN Loss=1.1064, Acc=0.6538 | MLP Loss=1.8791, Acc=0.4837\n",
      "[Studygroup][228] CNN Loss=1.0948, Acc=0.6522 | MLP Loss=1.8860, Acc=0.4686\n",
      "[Studygroup][229] CNN Loss=1.1517, Acc=0.6544 | MLP Loss=1.9569, Acc=0.4905\n",
      "[Studygroup][230] CNN Loss=1.1104, Acc=0.6470 | MLP Loss=1.8205, Acc=0.4916\n",
      "[Studygroup][231] CNN Loss=1.1148, Acc=0.6523 | MLP Loss=1.8685, Acc=0.4961\n",
      "[Studygroup][232] CNN Loss=1.0753, Acc=0.6526 | MLP Loss=1.9359, Acc=0.4699\n",
      "[Studygroup][233] CNN Loss=1.1637, Acc=0.6447 | MLP Loss=1.9444, Acc=0.4868\n",
      "[Studygroup][234] CNN Loss=1.1156, Acc=0.6564 | MLP Loss=1.8552, Acc=0.5011\n",
      "[Studygroup][235] CNN Loss=1.0864, Acc=0.6522 | MLP Loss=1.8600, Acc=0.4929\n",
      "[Studygroup][236] CNN Loss=1.1283, Acc=0.6525 | MLP Loss=1.8407, Acc=0.4987\n",
      "[Studygroup][237] CNN Loss=1.0856, Acc=0.6520 | MLP Loss=1.8298, Acc=0.4906\n",
      "[Studygroup][238] CNN Loss=1.1056, Acc=0.6582 | MLP Loss=1.9161, Acc=0.4909\n",
      "[Studygroup][239] CNN Loss=1.1053, Acc=0.6582 | MLP Loss=1.8668, Acc=0.4940\n",
      "[Studygroup][240] CNN Loss=1.0766, Acc=0.6513 | MLP Loss=1.8016, Acc=0.4901\n",
      "[Studygroup][241] CNN Loss=1.1033, Acc=0.6471 | MLP Loss=1.8966, Acc=0.4887\n",
      "[Studygroup][242] CNN Loss=1.1227, Acc=0.6482 | MLP Loss=1.8548, Acc=0.5078\n",
      "[Studygroup][243] CNN Loss=1.1013, Acc=0.6568 | MLP Loss=1.8696, Acc=0.4919\n",
      "[Studygroup][244] CNN Loss=1.0557, Acc=0.6573 | MLP Loss=1.8640, Acc=0.5046\n",
      "[Studygroup][245] CNN Loss=1.0847, Acc=0.6603 | MLP Loss=1.8392, Acc=0.5023\n",
      "[Studygroup][246] CNN Loss=1.0189, Acc=0.6492 | MLP Loss=1.8828, Acc=0.4811\n",
      "[Studygroup][247] CNN Loss=1.0653, Acc=0.6576 | MLP Loss=1.8796, Acc=0.4986\n",
      "[Studygroup][248] CNN Loss=1.0945, Acc=0.6530 | MLP Loss=1.8446, Acc=0.4985\n",
      "[Studygroup][249] CNN Loss=1.0856, Acc=0.6447 | MLP Loss=1.8950, Acc=0.4611\n",
      "[Studygroup][250] CNN Loss=1.1018, Acc=0.6540 | MLP Loss=1.8761, Acc=0.5092\n",
      "[Studygroup][251] CNN Loss=1.0519, Acc=0.6435 | MLP Loss=1.8007, Acc=0.4821\n",
      "[Studygroup][252] CNN Loss=1.1017, Acc=0.6532 | MLP Loss=1.8918, Acc=0.4987\n",
      "[Studygroup][253] CNN Loss=1.0201, Acc=0.6583 | MLP Loss=1.8799, Acc=0.4866\n",
      "[Studygroup][254] CNN Loss=1.0051, Acc=0.6424 | MLP Loss=1.8594, Acc=0.4921\n",
      "[Studygroup][255] CNN Loss=1.0212, Acc=0.6412 | MLP Loss=1.8649, Acc=0.5147\n",
      "[Studygroup][256] CNN Loss=1.0821, Acc=0.6537 | MLP Loss=1.8641, Acc=0.5039\n",
      "[Studygroup][257] CNN Loss=1.0639, Acc=0.6555 | MLP Loss=1.8831, Acc=0.4978\n",
      "[Studygroup][258] CNN Loss=1.0968, Acc=0.6526 | MLP Loss=1.8727, Acc=0.5088\n",
      "[Studygroup][259] CNN Loss=1.0720, Acc=0.6459 | MLP Loss=1.9204, Acc=0.5055\n",
      "[Studygroup][260] CNN Loss=1.1238, Acc=0.6506 | MLP Loss=1.9251, Acc=0.5070\n",
      "[Studygroup][261] CNN Loss=1.1445, Acc=0.6508 | MLP Loss=1.8552, Acc=0.5071\n",
      "[Studygroup][262] CNN Loss=1.1156, Acc=0.6520 | MLP Loss=1.8261, Acc=0.5051\n",
      "[Studygroup][263] CNN Loss=1.0819, Acc=0.6487 | MLP Loss=1.8666, Acc=0.5011\n",
      "[Studygroup][264] CNN Loss=1.1533, Acc=0.6463 | MLP Loss=1.8294, Acc=0.5027\n",
      "[Studygroup][265] CNN Loss=1.0668, Acc=0.6601 | MLP Loss=1.8448, Acc=0.4987\n",
      "[Studygroup][266] CNN Loss=1.0190, Acc=0.6477 | MLP Loss=1.8383, Acc=0.5101\n",
      "[Studygroup][267] CNN Loss=1.0943, Acc=0.6452 | MLP Loss=1.8191, Acc=0.5043\n",
      "[Studygroup][268] CNN Loss=1.0969, Acc=0.6568 | MLP Loss=1.8632, Acc=0.4991\n",
      "[Studygroup][269] CNN Loss=1.0655, Acc=0.6500 | MLP Loss=1.8601, Acc=0.4752\n",
      "[Studygroup][270] CNN Loss=1.1200, Acc=0.6521 | MLP Loss=1.8823, Acc=0.4903\n",
      "[Studygroup][271] CNN Loss=1.0610, Acc=0.6581 | MLP Loss=1.8029, Acc=0.5118\n",
      "[Studygroup][272] CNN Loss=1.0610, Acc=0.6556 | MLP Loss=1.8075, Acc=0.5014\n",
      "[Studygroup][273] CNN Loss=1.1097, Acc=0.6533 | MLP Loss=1.8485, Acc=0.4930\n",
      "[Studygroup][274] CNN Loss=1.0622, Acc=0.6579 | MLP Loss=1.7835, Acc=0.5120\n",
      "[Studygroup][275] CNN Loss=1.0601, Acc=0.6482 | MLP Loss=1.8390, Acc=0.4950\n",
      "[Studygroup][276] CNN Loss=1.0256, Acc=0.6581 | MLP Loss=1.9032, Acc=0.5013\n",
      "[Studygroup][277] CNN Loss=1.1452, Acc=0.6472 | MLP Loss=1.9568, Acc=0.4927\n",
      "[Studygroup][278] CNN Loss=1.0669, Acc=0.6551 | MLP Loss=1.7765, Acc=0.5066\n",
      "[Studygroup][279] CNN Loss=1.0705, Acc=0.6598 | MLP Loss=1.8526, Acc=0.5113\n",
      "[Studygroup][280] CNN Loss=1.0424, Acc=0.6444 | MLP Loss=1.7969, Acc=0.5140\n",
      "[Studygroup][281] CNN Loss=1.0537, Acc=0.6574 | MLP Loss=1.8233, Acc=0.5069\n",
      "[Studygroup][282] CNN Loss=1.0585, Acc=0.6531 | MLP Loss=1.8747, Acc=0.4976\n",
      "[Studygroup][283] CNN Loss=1.0398, Acc=0.6552 | MLP Loss=1.8345, Acc=0.5137\n",
      "[Studygroup][284] CNN Loss=1.0913, Acc=0.6555 | MLP Loss=1.9001, Acc=0.4930\n",
      "[Studygroup][285] CNN Loss=1.0345, Acc=0.6568 | MLP Loss=1.8664, Acc=0.5016\n",
      "[Studygroup][286] CNN Loss=1.1118, Acc=0.6444 | MLP Loss=1.8622, Acc=0.5067\n",
      "[Studygroup][287] CNN Loss=1.0768, Acc=0.6523 | MLP Loss=1.8138, Acc=0.4957\n",
      "[Studygroup][288] CNN Loss=1.1484, Acc=0.6526 | MLP Loss=1.8373, Acc=0.5040\n",
      "[Studygroup][289] CNN Loss=1.0986, Acc=0.6583 | MLP Loss=1.8874, Acc=0.5164\n",
      "[Studygroup][290] CNN Loss=1.1579, Acc=0.6557 | MLP Loss=1.9389, Acc=0.4870\n",
      "[Studygroup][291] CNN Loss=1.1441, Acc=0.6505 | MLP Loss=1.8970, Acc=0.5136\n",
      "[Studygroup][292] CNN Loss=1.0677, Acc=0.6579 | MLP Loss=1.8252, Acc=0.5186\n",
      "[Studygroup][293] CNN Loss=1.0217, Acc=0.6564 | MLP Loss=1.8445, Acc=0.5057\n",
      "[Studygroup][294] CNN Loss=1.0619, Acc=0.6546 | MLP Loss=1.8243, Acc=0.5079\n",
      "[Studygroup][295] CNN Loss=1.0718, Acc=0.6512 | MLP Loss=1.8407, Acc=0.4862\n",
      "[Studygroup][296] CNN Loss=1.0603, Acc=0.6569 | MLP Loss=1.8729, Acc=0.5099\n",
      "[Studygroup][297] CNN Loss=1.0303, Acc=0.6603 | MLP Loss=1.8335, Acc=0.5151\n",
      "[Studygroup][298] CNN Loss=1.1335, Acc=0.6587 | MLP Loss=1.8740, Acc=0.5021\n",
      "[Studygroup][299] CNN Loss=1.1206, Acc=0.6532 | MLP Loss=1.8566, Acc=0.5180\n",
      "[Studygroup][300] CNN Loss=1.0820, Acc=0.6568 | MLP Loss=1.7718, Acc=0.5070\n",
      "[Studygroup][301] CNN Loss=1.0117, Acc=0.6550 | MLP Loss=1.8001, Acc=0.4852\n",
      "[Studygroup][302] CNN Loss=1.0345, Acc=0.6539 | MLP Loss=1.8428, Acc=0.5090\n",
      "[Studygroup][303] CNN Loss=1.0453, Acc=0.6565 | MLP Loss=1.8373, Acc=0.4831\n",
      "[Studygroup][304] CNN Loss=1.0770, Acc=0.6526 | MLP Loss=1.8433, Acc=0.5037\n",
      "[Studygroup][305] CNN Loss=1.1009, Acc=0.6533 | MLP Loss=1.8381, Acc=0.4944\n",
      "[Studygroup][306] CNN Loss=1.0393, Acc=0.6593 | MLP Loss=1.8243, Acc=0.5223\n",
      "[Studygroup][307] CNN Loss=1.0389, Acc=0.6531 | MLP Loss=1.8372, Acc=0.5081\n",
      "[Studygroup][308] CNN Loss=1.0162, Acc=0.6512 | MLP Loss=1.8088, Acc=0.5090\n",
      "[Studygroup][309] CNN Loss=1.0556, Acc=0.6543 | MLP Loss=1.8796, Acc=0.5163\n",
      "[Studygroup][310] CNN Loss=1.0600, Acc=0.6623 | MLP Loss=1.8884, Acc=0.5138\n",
      "[Studygroup][311] CNN Loss=1.0754, Acc=0.6495 | MLP Loss=1.7882, Acc=0.5154\n",
      "[Studygroup][312] CNN Loss=1.1124, Acc=0.6559 | MLP Loss=1.8279, Acc=0.5111\n",
      "[Studygroup][313] CNN Loss=1.0895, Acc=0.6528 | MLP Loss=1.8319, Acc=0.5128\n",
      "[Studygroup][314] CNN Loss=1.0586, Acc=0.6613 | MLP Loss=1.8090, Acc=0.5140\n",
      "[Studygroup][315] CNN Loss=1.0352, Acc=0.6601 | MLP Loss=1.7934, Acc=0.5063\n",
      "[Studygroup][316] CNN Loss=1.0553, Acc=0.6585 | MLP Loss=1.8076, Acc=0.5176\n",
      "[Studygroup][317] CNN Loss=0.9825, Acc=0.6517 | MLP Loss=1.8240, Acc=0.4985\n",
      "[Studygroup][318] CNN Loss=1.0609, Acc=0.6575 | MLP Loss=1.8573, Acc=0.5149\n",
      "[Studygroup][319] CNN Loss=1.0247, Acc=0.6628 | MLP Loss=1.8654, Acc=0.5180\n",
      "[Studygroup][320] CNN Loss=1.0781, Acc=0.6486 | MLP Loss=1.8396, Acc=0.5085\n",
      "[Studygroup][321] CNN Loss=1.0124, Acc=0.6530 | MLP Loss=1.8258, Acc=0.5124\n",
      "[Studygroup][322] CNN Loss=1.0007, Acc=0.6593 | MLP Loss=1.7702, Acc=0.5222\n",
      "[Studygroup][323] CNN Loss=1.0170, Acc=0.6609 | MLP Loss=1.8067, Acc=0.4949\n",
      "[Studygroup][324] CNN Loss=1.1087, Acc=0.6599 | MLP Loss=1.9112, Acc=0.5084\n",
      "[Studygroup][325] CNN Loss=1.0809, Acc=0.6513 | MLP Loss=1.7963, Acc=0.5181\n",
      "[Studygroup][326] CNN Loss=1.0143, Acc=0.6666 | MLP Loss=1.8102, Acc=0.5196\n",
      "[Studygroup][327] CNN Loss=1.0368, Acc=0.6608 | MLP Loss=1.8569, Acc=0.5123\n",
      "[Studygroup][328] CNN Loss=1.0383, Acc=0.6545 | MLP Loss=1.8065, Acc=0.5079\n",
      "[Studygroup][329] CNN Loss=1.0319, Acc=0.6570 | MLP Loss=1.8419, Acc=0.5215\n",
      "[Studygroup][330] CNN Loss=1.0237, Acc=0.6591 | MLP Loss=1.8093, Acc=0.5083\n",
      "[Studygroup][331] CNN Loss=1.0056, Acc=0.6627 | MLP Loss=1.8292, Acc=0.5252\n",
      "[Studygroup][332] CNN Loss=1.0494, Acc=0.6606 | MLP Loss=1.8772, Acc=0.5111\n",
      "[Studygroup][333] CNN Loss=1.0685, Acc=0.6607 | MLP Loss=1.8833, Acc=0.5213\n",
      "[Studygroup][334] CNN Loss=1.0555, Acc=0.6529 | MLP Loss=1.8157, Acc=0.5027\n",
      "[Studygroup][335] CNN Loss=1.0534, Acc=0.6601 | MLP Loss=1.8007, Acc=0.5166\n",
      "[Studygroup][336] CNN Loss=1.0679, Acc=0.6588 | MLP Loss=1.8343, Acc=0.5202\n",
      "[Studygroup][337] CNN Loss=1.0164, Acc=0.6534 | MLP Loss=1.8087, Acc=0.5191\n",
      "[Studygroup][338] CNN Loss=1.0778, Acc=0.6554 | MLP Loss=1.7926, Acc=0.5188\n",
      "[Studygroup][339] CNN Loss=1.0858, Acc=0.6532 | MLP Loss=1.8350, Acc=0.5152\n",
      "[Studygroup][340] CNN Loss=1.0487, Acc=0.6624 | MLP Loss=1.7657, Acc=0.5053\n",
      "[Studygroup][341] CNN Loss=1.0386, Acc=0.6572 | MLP Loss=1.8402, Acc=0.5164\n",
      "[Studygroup][342] CNN Loss=1.0238, Acc=0.6485 | MLP Loss=1.7968, Acc=0.4870\n",
      "[Studygroup][343] CNN Loss=1.0967, Acc=0.6613 | MLP Loss=1.8717, Acc=0.5197\n",
      "[Studygroup][344] CNN Loss=1.0699, Acc=0.6539 | MLP Loss=1.8114, Acc=0.5184\n",
      "[Studygroup][345] CNN Loss=1.0393, Acc=0.6674 | MLP Loss=1.8139, Acc=0.5217\n",
      "[Studygroup][346] CNN Loss=1.0687, Acc=0.6619 | MLP Loss=1.8582, Acc=0.5027\n",
      "[Studygroup][347] CNN Loss=1.0703, Acc=0.6633 | MLP Loss=1.7770, Acc=0.5327\n",
      "[Studygroup][348] CNN Loss=1.0287, Acc=0.6550 | MLP Loss=1.7832, Acc=0.5296\n",
      "[Studygroup][349] CNN Loss=1.0410, Acc=0.6569 | MLP Loss=1.7920, Acc=0.5201\n",
      "[Studygroup][350] CNN Loss=1.0034, Acc=0.6580 | MLP Loss=1.7678, Acc=0.5280\n",
      "[Studygroup][351] CNN Loss=1.0642, Acc=0.6473 | MLP Loss=1.8572, Acc=0.5188\n",
      "[Studygroup][352] CNN Loss=1.0846, Acc=0.6527 | MLP Loss=1.7624, Acc=0.5146\n",
      "[Studygroup][353] CNN Loss=1.0350, Acc=0.6558 | MLP Loss=1.8132, Acc=0.5101\n",
      "[Studygroup][354] CNN Loss=1.0299, Acc=0.6575 | MLP Loss=1.8314, Acc=0.5166\n",
      "[Studygroup][355] CNN Loss=1.0499, Acc=0.6483 | MLP Loss=1.8349, Acc=0.5169\n",
      "[Studygroup][356] CNN Loss=1.0717, Acc=0.6602 | MLP Loss=1.7823, Acc=0.5062\n",
      "[Studygroup][357] CNN Loss=1.0216, Acc=0.6561 | MLP Loss=1.7819, Acc=0.5259\n",
      "[Studygroup][358] CNN Loss=1.0068, Acc=0.6597 | MLP Loss=1.7440, Acc=0.5275\n",
      "[Studygroup][359] CNN Loss=1.0082, Acc=0.6611 | MLP Loss=1.8416, Acc=0.5102\n",
      "[Studygroup][360] CNN Loss=1.0138, Acc=0.6577 | MLP Loss=1.7987, Acc=0.5295\n",
      "[Studygroup][361] CNN Loss=1.0406, Acc=0.6567 | MLP Loss=1.9031, Acc=0.5223\n",
      "[Studygroup][362] CNN Loss=1.1502, Acc=0.6557 | MLP Loss=1.9293, Acc=0.5275\n",
      "[Studygroup][363] CNN Loss=0.9605, Acc=0.6571 | MLP Loss=1.7842, Acc=0.5299\n",
      "[Studygroup][364] CNN Loss=1.0179, Acc=0.6514 | MLP Loss=1.7838, Acc=0.5126\n",
      "[Studygroup][365] CNN Loss=0.9549, Acc=0.6552 | MLP Loss=1.8417, Acc=0.5289\n",
      "[Studygroup][366] CNN Loss=0.9684, Acc=0.6573 | MLP Loss=1.7764, Acc=0.5330\n",
      "[Studygroup][367] CNN Loss=1.0116, Acc=0.6563 | MLP Loss=1.8811, Acc=0.5341\n",
      "[Studygroup][368] CNN Loss=1.0589, Acc=0.6634 | MLP Loss=1.8123, Acc=0.5263\n",
      "[Studygroup][369] CNN Loss=1.0214, Acc=0.6616 | MLP Loss=1.8254, Acc=0.5112\n",
      "[Studygroup][370] CNN Loss=0.9919, Acc=0.6623 | MLP Loss=1.8196, Acc=0.5185\n",
      "[Studygroup][371] CNN Loss=1.0085, Acc=0.6518 | MLP Loss=1.7781, Acc=0.5146\n",
      "[Studygroup][372] CNN Loss=1.0130, Acc=0.6530 | MLP Loss=1.7709, Acc=0.5244\n",
      "[Studygroup][373] CNN Loss=0.9815, Acc=0.6643 | MLP Loss=1.8253, Acc=0.5156\n",
      "[Studygroup][374] CNN Loss=1.0637, Acc=0.6576 | MLP Loss=1.8453, Acc=0.5138\n",
      "[Studygroup][375] CNN Loss=1.0279, Acc=0.6595 | MLP Loss=1.7433, Acc=0.5325\n",
      "[Studygroup][376] CNN Loss=0.9737, Acc=0.6598 | MLP Loss=1.8113, Acc=0.5345\n",
      "[Studygroup][377] CNN Loss=1.0078, Acc=0.6517 | MLP Loss=1.8042, Acc=0.5241\n",
      "[Studygroup][378] CNN Loss=1.0172, Acc=0.6536 | MLP Loss=1.8609, Acc=0.5327\n",
      "[Studygroup][379] CNN Loss=1.0045, Acc=0.6615 | MLP Loss=1.8300, Acc=0.5162\n",
      "[Studygroup][380] CNN Loss=1.0048, Acc=0.6535 | MLP Loss=1.8222, Acc=0.5105\n",
      "[Studygroup][381] CNN Loss=0.9835, Acc=0.6680 | MLP Loss=1.8066, Acc=0.5222\n",
      "[Studygroup][382] CNN Loss=1.0070, Acc=0.6630 | MLP Loss=1.8527, Acc=0.5258\n",
      "[Studygroup][383] CNN Loss=1.0366, Acc=0.6584 | MLP Loss=1.8641, Acc=0.5176\n",
      "[Studygroup][384] CNN Loss=0.9272, Acc=0.6673 | MLP Loss=1.8503, Acc=0.5253\n",
      "[Studygroup][385] CNN Loss=1.0139, Acc=0.6599 | MLP Loss=1.8291, Acc=0.5310\n",
      "[Studygroup][386] CNN Loss=0.9851, Acc=0.6603 | MLP Loss=1.7836, Acc=0.5116\n",
      "[Studygroup][387] CNN Loss=0.9948, Acc=0.6562 | MLP Loss=1.8408, Acc=0.5116\n",
      "[Studygroup][388] CNN Loss=1.0314, Acc=0.6587 | MLP Loss=1.7995, Acc=0.5324\n",
      "[Studygroup][389] CNN Loss=1.0658, Acc=0.6557 | MLP Loss=1.8526, Acc=0.5034\n",
      "[Studygroup][390] CNN Loss=1.0109, Acc=0.6566 | MLP Loss=1.8428, Acc=0.5130\n",
      "[Studygroup][391] CNN Loss=1.0151, Acc=0.6609 | MLP Loss=1.8090, Acc=0.5224\n",
      "[Studygroup][392] CNN Loss=1.0151, Acc=0.6626 | MLP Loss=1.8321, Acc=0.5205\n",
      "[Studygroup][393] CNN Loss=0.9973, Acc=0.6528 | MLP Loss=1.8429, Acc=0.5142\n",
      "[Studygroup][394] CNN Loss=0.9901, Acc=0.6600 | MLP Loss=1.7874, Acc=0.5248\n",
      "[Studygroup][395] CNN Loss=0.9702, Acc=0.6638 | MLP Loss=1.8104, Acc=0.5312\n",
      "[Studygroup][396] CNN Loss=1.0116, Acc=0.6600 | MLP Loss=1.8627, Acc=0.5261\n",
      "[Studygroup][397] CNN Loss=0.9920, Acc=0.6562 | MLP Loss=1.7802, Acc=0.5401\n",
      "[Studygroup][398] CNN Loss=0.9816, Acc=0.6599 | MLP Loss=1.7915, Acc=0.5241\n",
      "[Studygroup][399] CNN Loss=1.0019, Acc=0.6603 | MLP Loss=1.7720, Acc=0.5339\n",
      "[Studygroup][400] CNN Loss=1.0374, Acc=0.6616 | MLP Loss=1.7245, Acc=0.5228\n",
      "[Studygroup][401] CNN Loss=1.0050, Acc=0.6597 | MLP Loss=1.7958, Acc=0.5306\n",
      "[Studygroup][402] CNN Loss=0.9734, Acc=0.6624 | MLP Loss=1.8169, Acc=0.5258\n",
      "[Studygroup][403] CNN Loss=0.9568, Acc=0.6619 | MLP Loss=1.7614, Acc=0.5217\n",
      "[Studygroup][404] CNN Loss=1.0248, Acc=0.6575 | MLP Loss=1.8201, Acc=0.5223\n",
      "[Studygroup][405] CNN Loss=1.0120, Acc=0.6579 | MLP Loss=1.7774, Acc=0.5369\n",
      "[Studygroup][406] CNN Loss=0.9517, Acc=0.6641 | MLP Loss=1.7778, Acc=0.5350\n",
      "[Studygroup][407] CNN Loss=0.9332, Acc=0.6578 | MLP Loss=1.8368, Acc=0.5239\n",
      "[Studygroup][408] CNN Loss=0.9801, Acc=0.6668 | MLP Loss=1.7927, Acc=0.5195\n",
      "[Studygroup][409] CNN Loss=1.0107, Acc=0.6532 | MLP Loss=1.8505, Acc=0.5115\n",
      "[Studygroup][410] CNN Loss=1.1464, Acc=0.6476 | MLP Loss=1.8941, Acc=0.5286\n",
      "[Studygroup][411] CNN Loss=0.9846, Acc=0.6675 | MLP Loss=1.7959, Acc=0.5382\n",
      "[Studygroup][412] CNN Loss=0.9311, Acc=0.6652 | MLP Loss=1.7949, Acc=0.5210\n",
      "[Studygroup][413] CNN Loss=1.0401, Acc=0.6469 | MLP Loss=1.8391, Acc=0.5204\n",
      "[Studygroup][414] CNN Loss=1.0324, Acc=0.6518 | MLP Loss=1.7314, Acc=0.5226\n",
      "[Studygroup][415] CNN Loss=1.1098, Acc=0.6576 | MLP Loss=1.7977, Acc=0.5203\n",
      "[Studygroup][416] CNN Loss=1.0246, Acc=0.6601 | MLP Loss=1.7836, Acc=0.5407\n",
      "[Studygroup][417] CNN Loss=0.9790, Acc=0.6655 | MLP Loss=1.7314, Acc=0.5364\n",
      "[Studygroup][418] CNN Loss=0.9373, Acc=0.6637 | MLP Loss=1.7468, Acc=0.5255\n",
      "[Studygroup][419] CNN Loss=0.9760, Acc=0.6635 | MLP Loss=1.7872, Acc=0.5280\n",
      "[Studygroup][420] CNN Loss=0.9679, Acc=0.6587 | MLP Loss=1.7832, Acc=0.5337\n",
      "[Studygroup][421] CNN Loss=0.9938, Acc=0.6668 | MLP Loss=1.7627, Acc=0.5248\n",
      "[Studygroup][422] CNN Loss=0.9837, Acc=0.6556 | MLP Loss=1.8088, Acc=0.5354\n",
      "[Studygroup][423] CNN Loss=0.9655, Acc=0.6665 | MLP Loss=1.7851, Acc=0.5215\n",
      "[Studygroup][424] CNN Loss=0.9683, Acc=0.6543 | MLP Loss=1.7747, Acc=0.5338\n",
      "[Studygroup][425] CNN Loss=0.9637, Acc=0.6642 | MLP Loss=1.8217, Acc=0.5250\n",
      "[Studygroup][426] CNN Loss=0.9310, Acc=0.6567 | MLP Loss=1.7781, Acc=0.5325\n",
      "[Studygroup][427] CNN Loss=0.9560, Acc=0.6557 | MLP Loss=1.8303, Acc=0.5228\n",
      "[Studygroup][428] CNN Loss=0.9438, Acc=0.6619 | MLP Loss=1.8169, Acc=0.5182\n",
      "[Studygroup][429] CNN Loss=1.0070, Acc=0.6596 | MLP Loss=1.8263, Acc=0.5139\n",
      "[Studygroup][430] CNN Loss=0.9997, Acc=0.6638 | MLP Loss=1.8520, Acc=0.5401\n",
      "[Studygroup][431] CNN Loss=1.0681, Acc=0.6606 | MLP Loss=1.8380, Acc=0.5393\n",
      "[Studygroup][432] CNN Loss=0.9911, Acc=0.6626 | MLP Loss=1.7797, Acc=0.5352\n",
      "[Studygroup][433] CNN Loss=1.0106, Acc=0.6618 | MLP Loss=1.8105, Acc=0.5138\n",
      "[Studygroup][434] CNN Loss=1.0739, Acc=0.6589 | MLP Loss=1.9381, Acc=0.5204\n",
      "[Studygroup][435] CNN Loss=0.9809, Acc=0.6618 | MLP Loss=1.8410, Acc=0.5271\n",
      "[Studygroup][436] CNN Loss=0.9607, Acc=0.6608 | MLP Loss=1.8281, Acc=0.5131\n",
      "[Studygroup][437] CNN Loss=0.9735, Acc=0.6660 | MLP Loss=1.9516, Acc=0.5109\n",
      "[Studygroup][438] CNN Loss=1.0290, Acc=0.6567 | MLP Loss=1.8078, Acc=0.5090\n",
      "[Studygroup][439] CNN Loss=0.9986, Acc=0.6697 | MLP Loss=1.7762, Acc=0.5350\n",
      "[Studygroup][440] CNN Loss=1.1087, Acc=0.6549 | MLP Loss=1.7452, Acc=0.5356\n",
      "[Studygroup][441] CNN Loss=0.9835, Acc=0.6594 | MLP Loss=1.7694, Acc=0.5276\n",
      "[Studygroup][442] CNN Loss=1.0139, Acc=0.6613 | MLP Loss=1.7960, Acc=0.5238\n",
      "[Studygroup][443] CNN Loss=1.0644, Acc=0.6613 | MLP Loss=1.8529, Acc=0.5213\n",
      "[Studygroup][444] CNN Loss=1.0081, Acc=0.6535 | MLP Loss=1.7133, Acc=0.5177\n",
      "[Studygroup][445] CNN Loss=0.9856, Acc=0.6658 | MLP Loss=1.7794, Acc=0.5309\n",
      "[Studygroup][446] CNN Loss=0.9564, Acc=0.6639 | MLP Loss=1.7532, Acc=0.5393\n",
      "[Studygroup][447] CNN Loss=0.9893, Acc=0.6648 | MLP Loss=1.7736, Acc=0.5414\n",
      "[Studygroup][448] CNN Loss=0.9832, Acc=0.6560 | MLP Loss=1.7386, Acc=0.5401\n",
      "[Studygroup][449] CNN Loss=0.9881, Acc=0.6609 | MLP Loss=1.7841, Acc=0.5425\n",
      "[Studygroup][450] CNN Loss=1.0054, Acc=0.6524 | MLP Loss=1.7499, Acc=0.5331\n",
      "[Studygroup][451] CNN Loss=0.9904, Acc=0.6636 | MLP Loss=1.7850, Acc=0.5279\n",
      "[Studygroup][452] CNN Loss=0.9987, Acc=0.6597 | MLP Loss=1.8183, Acc=0.5361\n",
      "[Studygroup][453] CNN Loss=0.9755, Acc=0.6503 | MLP Loss=1.7712, Acc=0.5225\n",
      "[Studygroup][454] CNN Loss=1.0101, Acc=0.6627 | MLP Loss=1.7170, Acc=0.5386\n",
      "[Studygroup][455] CNN Loss=1.0035, Acc=0.6636 | MLP Loss=1.7874, Acc=0.5381\n",
      "[Studygroup][456] CNN Loss=1.0506, Acc=0.6561 | MLP Loss=1.8187, Acc=0.5424\n",
      "[Studygroup][457] CNN Loss=0.9775, Acc=0.6586 | MLP Loss=1.7830, Acc=0.5382\n",
      "[Studygroup][458] CNN Loss=0.9677, Acc=0.6680 | MLP Loss=1.8444, Acc=0.5321\n",
      "[Studygroup][459] CNN Loss=1.0427, Acc=0.6654 | MLP Loss=1.8579, Acc=0.5325\n",
      "[Studygroup][460] CNN Loss=0.9833, Acc=0.6660 | MLP Loss=1.7993, Acc=0.5145\n",
      "[Studygroup][461] CNN Loss=0.9842, Acc=0.6613 | MLP Loss=1.7654, Acc=0.5274\n",
      "[Studygroup][462] CNN Loss=1.0084, Acc=0.6708 | MLP Loss=1.8220, Acc=0.5350\n",
      "[Studygroup][463] CNN Loss=0.9679, Acc=0.6603 | MLP Loss=1.8126, Acc=0.5385\n",
      "[Studygroup][464] CNN Loss=1.0096, Acc=0.6518 | MLP Loss=1.7878, Acc=0.5208\n",
      "[Studygroup][465] CNN Loss=0.9729, Acc=0.6682 | MLP Loss=1.7941, Acc=0.5349\n",
      "[Studygroup][466] CNN Loss=1.0107, Acc=0.6605 | MLP Loss=1.7999, Acc=0.5395\n",
      "[Studygroup][467] CNN Loss=0.9675, Acc=0.6634 | MLP Loss=1.7104, Acc=0.5388\n",
      "[Studygroup][468] CNN Loss=0.9988, Acc=0.6605 | MLP Loss=1.7987, Acc=0.5409\n",
      "[Studygroup][469] CNN Loss=1.0058, Acc=0.6660 | MLP Loss=1.8024, Acc=0.5349\n",
      "[Studygroup][470] CNN Loss=0.9280, Acc=0.6618 | MLP Loss=1.7696, Acc=0.5398\n",
      "[Studygroup][471] CNN Loss=1.0332, Acc=0.6600 | MLP Loss=1.8104, Acc=0.5312\n",
      "[Studygroup][472] CNN Loss=1.0019, Acc=0.6680 | MLP Loss=1.8073, Acc=0.5400\n",
      "[Studygroup][473] CNN Loss=1.1244, Acc=0.6597 | MLP Loss=1.7872, Acc=0.5331\n",
      "[Studygroup][474] CNN Loss=1.0140, Acc=0.6652 | MLP Loss=1.7511, Acc=0.5401\n",
      "[Studygroup][475] CNN Loss=0.9790, Acc=0.6626 | MLP Loss=1.7565, Acc=0.5401\n",
      "[Studygroup][476] CNN Loss=1.0303, Acc=0.6648 | MLP Loss=1.8078, Acc=0.5403\n",
      "[Studygroup][477] CNN Loss=0.9887, Acc=0.6565 | MLP Loss=1.6869, Acc=0.5392\n",
      "[Studygroup][478] CNN Loss=0.9763, Acc=0.6576 | MLP Loss=1.7452, Acc=0.5409\n",
      "[Studygroup][479] CNN Loss=1.0097, Acc=0.6653 | MLP Loss=1.7387, Acc=0.5327\n",
      "[Studygroup][480] CNN Loss=0.9311, Acc=0.6659 | MLP Loss=1.7501, Acc=0.5473\n",
      "[Studygroup][481] CNN Loss=0.9769, Acc=0.6653 | MLP Loss=1.7113, Acc=0.5491\n",
      "[Studygroup][482] CNN Loss=0.9836, Acc=0.6687 | MLP Loss=1.8915, Acc=0.5305\n",
      "[Studygroup][483] CNN Loss=0.9408, Acc=0.6617 | MLP Loss=1.8969, Acc=0.5437\n",
      "[Studygroup][484] CNN Loss=0.9751, Acc=0.6693 | MLP Loss=1.8965, Acc=0.5437\n",
      "[Studygroup][485] CNN Loss=0.9727, Acc=0.6627 | MLP Loss=1.8188, Acc=0.5355\n",
      "[Studygroup][486] CNN Loss=0.9579, Acc=0.6611 | MLP Loss=1.7500, Acc=0.5398\n",
      "[Studygroup][487] CNN Loss=0.9559, Acc=0.6633 | MLP Loss=1.7528, Acc=0.5312\n",
      "[Studygroup][488] CNN Loss=1.0187, Acc=0.6503 | MLP Loss=1.8977, Acc=0.5478\n",
      "[Studygroup][489] CNN Loss=1.0079, Acc=0.6604 | MLP Loss=1.7684, Acc=0.5435\n",
      "[Studygroup][490] CNN Loss=0.9763, Acc=0.6672 | MLP Loss=1.7561, Acc=0.5379\n",
      "[Studygroup][491] CNN Loss=1.0777, Acc=0.6511 | MLP Loss=1.7021, Acc=0.5366\n",
      "[Studygroup][492] CNN Loss=0.9980, Acc=0.6650 | MLP Loss=1.7340, Acc=0.5395\n",
      "[Studygroup][493] CNN Loss=0.8972, Acc=0.6677 | MLP Loss=1.7196, Acc=0.5280\n",
      "[Studygroup][494] CNN Loss=0.9570, Acc=0.6667 | MLP Loss=1.7462, Acc=0.5263\n",
      "[Studygroup][495] CNN Loss=0.9315, Acc=0.6660 | MLP Loss=1.7374, Acc=0.5388\n",
      "[Studygroup][496] CNN Loss=0.9784, Acc=0.6650 | MLP Loss=1.7956, Acc=0.5312\n",
      "[Studygroup][497] CNN Loss=1.0652, Acc=0.6564 | MLP Loss=1.7939, Acc=0.5431\n",
      "[Studygroup][498] CNN Loss=1.0139, Acc=0.6625 | MLP Loss=1.7336, Acc=0.5408\n",
      "[Studygroup][499] CNN Loss=1.0319, Acc=0.6565 | MLP Loss=1.8022, Acc=0.5478\n",
      "[Studygroup][500] CNN Loss=0.9533, Acc=0.6538 | MLP Loss=1.7769, Acc=0.5216\n",
      "[Studygroup][501] CNN Loss=1.0181, Acc=0.6532 | MLP Loss=1.7451, Acc=0.5316\n",
      "[Studygroup][502] CNN Loss=1.0013, Acc=0.6634 | MLP Loss=1.7634, Acc=0.5452\n",
      "[Studygroup][503] CNN Loss=0.9500, Acc=0.6651 | MLP Loss=1.7064, Acc=0.5365\n",
      "[Studygroup][504] CNN Loss=0.9936, Acc=0.6628 | MLP Loss=1.7402, Acc=0.5474\n",
      "[Studygroup][505] CNN Loss=0.9607, Acc=0.6660 | MLP Loss=1.7974, Acc=0.5493\n",
      "[Studygroup][506] CNN Loss=0.9587, Acc=0.6624 | MLP Loss=1.8010, Acc=0.5177\n",
      "[Studygroup][507] CNN Loss=1.0887, Acc=0.6624 | MLP Loss=1.7890, Acc=0.5410\n",
      "[Studygroup][508] CNN Loss=0.9956, Acc=0.6633 | MLP Loss=1.7191, Acc=0.5462\n",
      "[Studygroup][509] CNN Loss=0.9635, Acc=0.6678 | MLP Loss=1.7432, Acc=0.5437\n",
      "[Studygroup][510] CNN Loss=0.9624, Acc=0.6687 | MLP Loss=1.7313, Acc=0.5431\n",
      "[Studygroup][511] CNN Loss=0.9671, Acc=0.6652 | MLP Loss=1.7394, Acc=0.5372\n",
      "[Studygroup][512] CNN Loss=0.9214, Acc=0.6656 | MLP Loss=1.7549, Acc=0.5166\n",
      "[Studygroup][513] CNN Loss=0.9609, Acc=0.6681 | MLP Loss=1.8111, Acc=0.5321\n",
      "[Studygroup][514] CNN Loss=0.9745, Acc=0.6624 | MLP Loss=1.7622, Acc=0.5555\n",
      "[Studygroup][515] CNN Loss=0.9983, Acc=0.6739 | MLP Loss=1.8080, Acc=0.5338\n",
      "[Studygroup][516] CNN Loss=1.0777, Acc=0.6704 | MLP Loss=1.7655, Acc=0.5347\n",
      "[Studygroup][517] CNN Loss=1.0333, Acc=0.6682 | MLP Loss=1.7650, Acc=0.5413\n",
      "[Studygroup][518] CNN Loss=0.9713, Acc=0.6692 | MLP Loss=1.7805, Acc=0.5461\n",
      "[Studygroup][519] CNN Loss=0.9328, Acc=0.6677 | MLP Loss=1.7285, Acc=0.5390\n",
      "[Studygroup][520] CNN Loss=0.9859, Acc=0.6683 | MLP Loss=1.7778, Acc=0.5273\n",
      "[Studygroup][521] CNN Loss=1.0020, Acc=0.6547 | MLP Loss=1.8171, Acc=0.5448\n",
      "[Studygroup][522] CNN Loss=1.0398, Acc=0.6729 | MLP Loss=1.7043, Acc=0.5457\n",
      "[Studygroup][523] CNN Loss=0.9348, Acc=0.6721 | MLP Loss=1.7249, Acc=0.5415\n",
      "[Studygroup][524] CNN Loss=1.0268, Acc=0.6644 | MLP Loss=1.7221, Acc=0.5483\n",
      "[Studygroup][525] CNN Loss=0.9847, Acc=0.6634 | MLP Loss=1.7473, Acc=0.5498\n",
      "[Studygroup][526] CNN Loss=0.9580, Acc=0.6636 | MLP Loss=1.7405, Acc=0.5507\n",
      "[Studygroup][527] CNN Loss=0.9908, Acc=0.6658 | MLP Loss=1.7574, Acc=0.5406\n",
      "[Studygroup][528] CNN Loss=0.9993, Acc=0.6668 | MLP Loss=1.7008, Acc=0.5543\n",
      "[Studygroup][529] CNN Loss=0.9089, Acc=0.6637 | MLP Loss=1.7178, Acc=0.5466\n",
      "[Studygroup][530] CNN Loss=0.9691, Acc=0.6672 | MLP Loss=1.7178, Acc=0.5294\n",
      "[Studygroup][531] CNN Loss=0.9655, Acc=0.6723 | MLP Loss=1.7796, Acc=0.5499\n",
      "[Studygroup][532] CNN Loss=0.9619, Acc=0.6692 | MLP Loss=1.8045, Acc=0.5344\n",
      "[Studygroup][533] CNN Loss=1.0470, Acc=0.6581 | MLP Loss=1.7401, Acc=0.5504\n",
      "[Studygroup][534] CNN Loss=1.0508, Acc=0.6683 | MLP Loss=1.6830, Acc=0.5490\n",
      "[Studygroup][535] CNN Loss=0.9790, Acc=0.6696 | MLP Loss=1.6680, Acc=0.5459\n",
      "[Studygroup][536] CNN Loss=0.9972, Acc=0.6651 | MLP Loss=1.7773, Acc=0.5274\n",
      "[Studygroup][537] CNN Loss=1.0037, Acc=0.6764 | MLP Loss=1.7940, Acc=0.5509\n",
      "[Studygroup][538] CNN Loss=0.9745, Acc=0.6679 | MLP Loss=1.7927, Acc=0.5457\n",
      "[Studygroup][539] CNN Loss=1.0103, Acc=0.6670 | MLP Loss=1.7350, Acc=0.5314\n",
      "[Studygroup][540] CNN Loss=0.9537, Acc=0.6645 | MLP Loss=1.6588, Acc=0.5418\n",
      "[Studygroup][541] CNN Loss=1.0332, Acc=0.6594 | MLP Loss=1.6974, Acc=0.5470\n",
      "[Studygroup][542] CNN Loss=0.9570, Acc=0.6675 | MLP Loss=1.7407, Acc=0.5486\n",
      "[Studygroup][543] CNN Loss=0.9374, Acc=0.6629 | MLP Loss=1.7781, Acc=0.5528\n",
      "[Studygroup][544] CNN Loss=0.9111, Acc=0.6675 | MLP Loss=1.7293, Acc=0.5508\n",
      "[Studygroup][545] CNN Loss=0.9366, Acc=0.6625 | MLP Loss=1.7401, Acc=0.5539\n",
      "[Studygroup][546] CNN Loss=0.9755, Acc=0.6625 | MLP Loss=1.7316, Acc=0.5368\n",
      "[Studygroup][547] CNN Loss=0.9933, Acc=0.6739 | MLP Loss=1.8009, Acc=0.5496\n",
      "[Studygroup][548] CNN Loss=0.9770, Acc=0.6708 | MLP Loss=1.7495, Acc=0.5424\n",
      "[Studygroup][549] CNN Loss=0.9412, Acc=0.6698 | MLP Loss=1.7418, Acc=0.5287\n",
      "[Studygroup][550] CNN Loss=0.9427, Acc=0.6684 | MLP Loss=1.7761, Acc=0.5443\n",
      "[Studygroup][551] CNN Loss=0.9329, Acc=0.6629 | MLP Loss=1.7139, Acc=0.5464\n",
      "[Studygroup][552] CNN Loss=0.9612, Acc=0.6559 | MLP Loss=1.7207, Acc=0.5431\n",
      "[Studygroup][553] CNN Loss=0.9998, Acc=0.6709 | MLP Loss=1.8385, Acc=0.5511\n",
      "[Studygroup][554] CNN Loss=0.9693, Acc=0.6678 | MLP Loss=1.7284, Acc=0.5474\n",
      "[Studygroup][555] CNN Loss=0.9221, Acc=0.6603 | MLP Loss=1.8207, Acc=0.5352\n",
      "[Studygroup][556] CNN Loss=0.9973, Acc=0.6721 | MLP Loss=1.7793, Acc=0.5483\n",
      "[Studygroup][557] CNN Loss=0.9471, Acc=0.6693 | MLP Loss=1.7071, Acc=0.5513\n",
      "[Studygroup][558] CNN Loss=1.0053, Acc=0.6688 | MLP Loss=1.7956, Acc=0.5386\n",
      "[Studygroup][559] CNN Loss=0.9434, Acc=0.6640 | MLP Loss=1.7483, Acc=0.5385\n",
      "[Studygroup][560] CNN Loss=1.0055, Acc=0.6708 | MLP Loss=1.8146, Acc=0.5464\n",
      "[Studygroup][561] CNN Loss=1.0275, Acc=0.6689 | MLP Loss=1.7470, Acc=0.5520\n",
      "[Studygroup][562] CNN Loss=0.9372, Acc=0.6671 | MLP Loss=1.7477, Acc=0.5511\n",
      "[Studygroup][563] CNN Loss=0.9568, Acc=0.6679 | MLP Loss=1.7998, Acc=0.5303\n",
      "[Studygroup][564] CNN Loss=0.9129, Acc=0.6694 | MLP Loss=1.7712, Acc=0.5516\n",
      "[Studygroup][565] CNN Loss=0.9629, Acc=0.6658 | MLP Loss=1.7996, Acc=0.5486\n",
      "[Studygroup][566] CNN Loss=0.9252, Acc=0.6627 | MLP Loss=1.6851, Acc=0.5454\n",
      "[Studygroup][567] CNN Loss=0.9127, Acc=0.6707 | MLP Loss=1.7682, Acc=0.5527\n",
      "[Studygroup][568] CNN Loss=0.9309, Acc=0.6605 | MLP Loss=1.7742, Acc=0.5335\n",
      "[Studygroup][569] CNN Loss=0.9772, Acc=0.6641 | MLP Loss=1.7850, Acc=0.5486\n",
      "[Studygroup][570] CNN Loss=0.8827, Acc=0.6738 | MLP Loss=1.7990, Acc=0.5585\n",
      "[Studygroup][571] CNN Loss=0.9136, Acc=0.6703 | MLP Loss=1.7966, Acc=0.5442\n",
      "[Studygroup][572] CNN Loss=0.9622, Acc=0.6610 | MLP Loss=1.7960, Acc=0.5457\n",
      "[Studygroup][573] CNN Loss=1.0189, Acc=0.6656 | MLP Loss=1.7485, Acc=0.5518\n",
      "[Studygroup][574] CNN Loss=0.9643, Acc=0.6676 | MLP Loss=1.7373, Acc=0.5497\n",
      "[Studygroup][575] CNN Loss=0.9879, Acc=0.6579 | MLP Loss=1.6759, Acc=0.5479\n",
      "[Studygroup][576] CNN Loss=0.9637, Acc=0.6656 | MLP Loss=1.7293, Acc=0.5440\n",
      "[Studygroup][577] CNN Loss=0.9719, Acc=0.6697 | MLP Loss=1.7928, Acc=0.5298\n",
      "[Studygroup][578] CNN Loss=1.0005, Acc=0.6608 | MLP Loss=1.8389, Acc=0.5275\n",
      "[Studygroup][579] CNN Loss=0.9143, Acc=0.6613 | MLP Loss=1.7958, Acc=0.5533\n",
      "[Studygroup][580] CNN Loss=0.9569, Acc=0.6697 | MLP Loss=1.7741, Acc=0.5270\n",
      "[Studygroup][581] CNN Loss=0.9269, Acc=0.6585 | MLP Loss=1.7052, Acc=0.5437\n",
      "[Studygroup][582] CNN Loss=1.0400, Acc=0.6650 | MLP Loss=1.7284, Acc=0.5530\n",
      "[Studygroup][583] CNN Loss=0.9551, Acc=0.6672 | MLP Loss=1.7455, Acc=0.5354\n",
      "[Studygroup][584] CNN Loss=0.8927, Acc=0.6711 | MLP Loss=1.7502, Acc=0.5413\n",
      "[Studygroup][585] CNN Loss=0.9586, Acc=0.6734 | MLP Loss=1.7870, Acc=0.5546\n",
      "[Studygroup][586] CNN Loss=0.9118, Acc=0.6747 | MLP Loss=1.7462, Acc=0.5469\n",
      "[Studygroup][587] CNN Loss=0.9433, Acc=0.6710 | MLP Loss=1.6889, Acc=0.5484\n",
      "[Studygroup][588] CNN Loss=0.9400, Acc=0.6633 | MLP Loss=1.7634, Acc=0.5522\n",
      "[Studygroup][589] CNN Loss=1.0343, Acc=0.6607 | MLP Loss=1.7064, Acc=0.5375\n",
      "[Studygroup][590] CNN Loss=0.9849, Acc=0.6626 | MLP Loss=1.7100, Acc=0.5474\n",
      "[Studygroup][591] CNN Loss=0.9387, Acc=0.6701 | MLP Loss=1.7263, Acc=0.5508\n",
      "[Studygroup][592] CNN Loss=0.9713, Acc=0.6594 | MLP Loss=1.7335, Acc=0.5572\n",
      "[Studygroup][593] CNN Loss=0.9589, Acc=0.6719 | MLP Loss=1.7223, Acc=0.5448\n",
      "[Studygroup][594] CNN Loss=1.0004, Acc=0.6635 | MLP Loss=1.8161, Acc=0.5270\n",
      "[Studygroup][595] CNN Loss=0.9329, Acc=0.6574 | MLP Loss=1.7012, Acc=0.5555\n",
      "[Studygroup][596] CNN Loss=1.0263, Acc=0.6607 | MLP Loss=1.7154, Acc=0.5477\n",
      "[Studygroup][597] CNN Loss=1.0008, Acc=0.6630 | MLP Loss=1.7137, Acc=0.5394\n",
      "[Studygroup][598] CNN Loss=0.9694, Acc=0.6705 | MLP Loss=1.7493, Acc=0.5464\n",
      "[Studygroup][599] CNN Loss=0.9479, Acc=0.6725 | MLP Loss=1.7576, Acc=0.5497\n",
      "[Studygroup][600] CNN Loss=0.9766, Acc=0.6665 | MLP Loss=1.7212, Acc=0.5515\n",
      "[Studygroup][601] CNN Loss=0.9645, Acc=0.6747 | MLP Loss=1.6887, Acc=0.5509\n",
      "[Studygroup][602] CNN Loss=0.9570, Acc=0.6623 | MLP Loss=1.7373, Acc=0.5512\n",
      "[Studygroup][603] CNN Loss=0.9763, Acc=0.6658 | MLP Loss=1.8192, Acc=0.5490\n",
      "[Studygroup][604] CNN Loss=0.9242, Acc=0.6658 | MLP Loss=1.7963, Acc=0.5444\n",
      "[Studygroup][605] CNN Loss=0.9511, Acc=0.6713 | MLP Loss=1.7889, Acc=0.5542\n",
      "[Studygroup][606] CNN Loss=1.0567, Acc=0.6567 | MLP Loss=1.7579, Acc=0.5394\n",
      "[Studygroup][607] CNN Loss=0.9746, Acc=0.6642 | MLP Loss=1.7134, Acc=0.5544\n",
      "[Studygroup][608] CNN Loss=0.9427, Acc=0.6728 | MLP Loss=1.7715, Acc=0.5612\n",
      "[Studygroup][609] CNN Loss=0.9516, Acc=0.6615 | MLP Loss=1.7497, Acc=0.5346\n",
      "[Studygroup][610] CNN Loss=0.9797, Acc=0.6677 | MLP Loss=1.7615, Acc=0.5573\n",
      "[Studygroup][611] CNN Loss=0.9401, Acc=0.6713 | MLP Loss=1.7138, Acc=0.5422\n",
      "[Studygroup][612] CNN Loss=0.9681, Acc=0.6680 | MLP Loss=1.7766, Acc=0.5583\n",
      "[Studygroup][613] CNN Loss=0.9144, Acc=0.6675 | MLP Loss=1.7130, Acc=0.5315\n",
      "[Studygroup][614] CNN Loss=0.9809, Acc=0.6667 | MLP Loss=1.8825, Acc=0.5467\n",
      "[Studygroup][615] CNN Loss=1.0013, Acc=0.6704 | MLP Loss=1.7611, Acc=0.5414\n",
      "[Studygroup][616] CNN Loss=0.9743, Acc=0.6683 | MLP Loss=1.7351, Acc=0.5526\n",
      "[Studygroup][617] CNN Loss=0.8827, Acc=0.6745 | MLP Loss=1.6946, Acc=0.5488\n",
      "[Studygroup][618] CNN Loss=0.9558, Acc=0.6669 | MLP Loss=1.7086, Acc=0.5465\n",
      "[Studygroup][619] CNN Loss=0.9976, Acc=0.6618 | MLP Loss=1.7263, Acc=0.5550\n",
      "[Studygroup][620] CNN Loss=0.9857, Acc=0.6700 | MLP Loss=1.7191, Acc=0.5527\n",
      "[Studygroup][621] CNN Loss=0.9512, Acc=0.6661 | MLP Loss=1.6630, Acc=0.5491\n",
      "[Studygroup][622] CNN Loss=0.8860, Acc=0.6748 | MLP Loss=1.7445, Acc=0.5603\n",
      "[Studygroup][623] CNN Loss=0.9162, Acc=0.6767 | MLP Loss=1.7570, Acc=0.5475\n",
      "[Studygroup][624] CNN Loss=0.9336, Acc=0.6664 | MLP Loss=1.7783, Acc=0.5516\n",
      "[Studygroup][625] CNN Loss=0.9780, Acc=0.6620 | MLP Loss=1.7781, Acc=0.5623\n",
      "[Studygroup][626] CNN Loss=0.9587, Acc=0.6624 | MLP Loss=1.6657, Acc=0.5515\n",
      "[Studygroup][627] CNN Loss=0.9628, Acc=0.6548 | MLP Loss=1.7501, Acc=0.5597\n",
      "[Studygroup][628] CNN Loss=0.9586, Acc=0.6710 | MLP Loss=1.7114, Acc=0.5543\n",
      "[Studygroup][629] CNN Loss=0.9134, Acc=0.6652 | MLP Loss=1.7128, Acc=0.5613\n",
      "[Studygroup][630] CNN Loss=0.8964, Acc=0.6713 | MLP Loss=1.7102, Acc=0.5511\n",
      "[Studygroup][631] CNN Loss=0.9527, Acc=0.6662 | MLP Loss=1.7379, Acc=0.5424\n",
      "[Studygroup][632] CNN Loss=0.9538, Acc=0.6646 | MLP Loss=1.6846, Acc=0.5493\n",
      "[Studygroup][633] CNN Loss=1.0021, Acc=0.6659 | MLP Loss=1.7361, Acc=0.5608\n",
      "[Studygroup][634] CNN Loss=0.9363, Acc=0.6653 | MLP Loss=1.7468, Acc=0.5467\n",
      "[Studygroup][635] CNN Loss=0.9615, Acc=0.6698 | MLP Loss=1.7547, Acc=0.5563\n",
      "[Studygroup][636] CNN Loss=0.9807, Acc=0.6669 | MLP Loss=1.7294, Acc=0.5603\n",
      "[Studygroup][637] CNN Loss=0.9499, Acc=0.6660 | MLP Loss=1.7937, Acc=0.5373\n",
      "[Studygroup][638] CNN Loss=0.9133, Acc=0.6713 | MLP Loss=1.7257, Acc=0.5498\n",
      "[Studygroup][639] CNN Loss=1.0142, Acc=0.6584 | MLP Loss=1.7320, Acc=0.5526\n",
      "[Studygroup][640] CNN Loss=0.9545, Acc=0.6636 | MLP Loss=1.7516, Acc=0.5492\n",
      "[Studygroup][641] CNN Loss=0.9747, Acc=0.6725 | MLP Loss=1.7069, Acc=0.5564\n",
      "[Studygroup][642] CNN Loss=0.9022, Acc=0.6655 | MLP Loss=1.6975, Acc=0.5513\n",
      "[Studygroup][643] CNN Loss=1.0012, Acc=0.6695 | MLP Loss=1.7968, Acc=0.5540\n",
      "[Studygroup][644] CNN Loss=0.9667, Acc=0.6613 | MLP Loss=1.7306, Acc=0.5433\n",
      "[Studygroup][645] CNN Loss=0.9557, Acc=0.6689 | MLP Loss=1.7304, Acc=0.5571\n",
      "[Studygroup][646] CNN Loss=0.9355, Acc=0.6620 | MLP Loss=1.7324, Acc=0.5583\n",
      "[Studygroup][647] CNN Loss=0.9116, Acc=0.6729 | MLP Loss=1.6672, Acc=0.5528\n",
      "[Studygroup][648] CNN Loss=0.9663, Acc=0.6584 | MLP Loss=1.6749, Acc=0.5387\n",
      "[Studygroup][649] CNN Loss=0.9350, Acc=0.6694 | MLP Loss=1.7059, Acc=0.5413\n",
      "[Studygroup][650] CNN Loss=0.9554, Acc=0.6652 | MLP Loss=1.7230, Acc=0.5533\n",
      "[Studygroup][651] CNN Loss=0.8716, Acc=0.6743 | MLP Loss=1.6725, Acc=0.5540\n",
      "[Studygroup][652] CNN Loss=0.9715, Acc=0.6609 | MLP Loss=1.7709, Acc=0.5530\n",
      "[Studygroup][653] CNN Loss=0.9205, Acc=0.6748 | MLP Loss=1.7660, Acc=0.5565\n",
      "[Studygroup][654] CNN Loss=0.9725, Acc=0.6547 | MLP Loss=1.7122, Acc=0.5573\n",
      "[Studygroup][655] CNN Loss=1.0043, Acc=0.6667 | MLP Loss=1.7240, Acc=0.5606\n",
      "[Studygroup][656] CNN Loss=0.9072, Acc=0.6728 | MLP Loss=1.7065, Acc=0.5507\n",
      "[Studygroup][657] CNN Loss=0.8728, Acc=0.6723 | MLP Loss=1.7110, Acc=0.5606\n",
      "[Studygroup][658] CNN Loss=0.9601, Acc=0.6598 | MLP Loss=1.7062, Acc=0.5662\n",
      "[Studygroup][659] CNN Loss=0.9348, Acc=0.6732 | MLP Loss=1.7543, Acc=0.5613\n",
      "[Studygroup][660] CNN Loss=0.8956, Acc=0.6679 | MLP Loss=1.7584, Acc=0.5382\n",
      "[Studygroup][661] CNN Loss=1.0140, Acc=0.6676 | MLP Loss=1.8162, Acc=0.5582\n",
      "[Studygroup][662] CNN Loss=0.9893, Acc=0.6698 | MLP Loss=1.7178, Acc=0.5631\n",
      "[Studygroup][663] CNN Loss=0.9129, Acc=0.6689 | MLP Loss=1.7072, Acc=0.5538\n",
      "[Studygroup][664] CNN Loss=0.9429, Acc=0.6703 | MLP Loss=1.6614, Acc=0.5557\n",
      "[Studygroup][665] CNN Loss=1.0044, Acc=0.6497 | MLP Loss=1.7247, Acc=0.5350\n",
      "[Studygroup][666] CNN Loss=0.9850, Acc=0.6661 | MLP Loss=1.7787, Acc=0.5453\n",
      "[Studygroup][667] CNN Loss=0.9286, Acc=0.6672 | MLP Loss=1.7205, Acc=0.5510\n",
      "[Studygroup][668] CNN Loss=0.9334, Acc=0.6715 | MLP Loss=1.7066, Acc=0.5577\n",
      "[Studygroup][669] CNN Loss=0.9816, Acc=0.6537 | MLP Loss=1.6528, Acc=0.5505\n",
      "[Studygroup][670] CNN Loss=0.9648, Acc=0.6678 | MLP Loss=1.6714, Acc=0.5516\n",
      "[Studygroup][671] CNN Loss=1.0653, Acc=0.6671 | MLP Loss=1.8107, Acc=0.5598\n",
      "[Studygroup][672] CNN Loss=0.9556, Acc=0.6666 | MLP Loss=1.6961, Acc=0.5640\n",
      "[Studygroup][673] CNN Loss=0.9399, Acc=0.6663 | MLP Loss=1.7002, Acc=0.5582\n",
      "[Studygroup][674] CNN Loss=0.9726, Acc=0.6547 | MLP Loss=1.7162, Acc=0.5489\n",
      "[Studygroup][675] CNN Loss=0.9760, Acc=0.6679 | MLP Loss=1.7653, Acc=0.5434\n",
      "[Studygroup][676] CNN Loss=0.9605, Acc=0.6613 | MLP Loss=1.6896, Acc=0.5606\n",
      "[Studygroup][677] CNN Loss=0.9244, Acc=0.6644 | MLP Loss=1.7341, Acc=0.5627\n",
      "[Studygroup][678] CNN Loss=0.9427, Acc=0.6696 | MLP Loss=1.7489, Acc=0.5568\n",
      "[Studygroup][679] CNN Loss=0.8929, Acc=0.6576 | MLP Loss=1.7353, Acc=0.5509\n",
      "[Studygroup][680] CNN Loss=1.0072, Acc=0.6716 | MLP Loss=1.7104, Acc=0.5561\n",
      "[Studygroup][681] CNN Loss=0.9187, Acc=0.6734 | MLP Loss=1.7378, Acc=0.5597\n",
      "[Studygroup][682] CNN Loss=0.8256, Acc=0.6728 | MLP Loss=1.6770, Acc=0.5589\n",
      "[Studygroup][683] CNN Loss=0.8802, Acc=0.6703 | MLP Loss=1.7282, Acc=0.5552\n",
      "[Studygroup][684] CNN Loss=0.8555, Acc=0.6714 | MLP Loss=1.7762, Acc=0.5598\n",
      "[Studygroup][685] CNN Loss=0.9298, Acc=0.6630 | MLP Loss=1.7382, Acc=0.5479\n",
      "[Studygroup][686] CNN Loss=0.9716, Acc=0.6675 | MLP Loss=1.8806, Acc=0.5168\n",
      "[Studygroup][687] CNN Loss=1.0348, Acc=0.6508 | MLP Loss=1.9181, Acc=0.5586\n",
      "[Studygroup][688] CNN Loss=0.9838, Acc=0.6697 | MLP Loss=1.6464, Acc=0.5539\n",
      "[Studygroup][689] CNN Loss=0.9441, Acc=0.6715 | MLP Loss=1.6821, Acc=0.5644\n",
      "[Studygroup][690] CNN Loss=1.0304, Acc=0.6711 | MLP Loss=1.7200, Acc=0.5475\n",
      "[Studygroup][691] CNN Loss=0.8963, Acc=0.6759 | MLP Loss=1.7786, Acc=0.5587\n",
      "[Studygroup][692] CNN Loss=0.8783, Acc=0.6655 | MLP Loss=1.6946, Acc=0.5494\n",
      "[Studygroup][693] CNN Loss=0.9499, Acc=0.6664 | MLP Loss=1.7396, Acc=0.5515\n",
      "[Studygroup][694] CNN Loss=0.9875, Acc=0.6639 | MLP Loss=1.6944, Acc=0.5553\n",
      "[Studygroup][695] CNN Loss=0.9449, Acc=0.6707 | MLP Loss=1.7207, Acc=0.5394\n",
      "[Studygroup][696] CNN Loss=0.8869, Acc=0.6768 | MLP Loss=1.8001, Acc=0.5658\n",
      "[Studygroup][697] CNN Loss=0.9432, Acc=0.6634 | MLP Loss=1.6804, Acc=0.5575\n",
      "[Studygroup][698] CNN Loss=0.9367, Acc=0.6699 | MLP Loss=1.7744, Acc=0.5571\n",
      "[Studygroup][699] CNN Loss=0.9810, Acc=0.6708 | MLP Loss=1.7644, Acc=0.5530\n",
      "[Studygroup][700] CNN Loss=0.9479, Acc=0.6704 | MLP Loss=1.7553, Acc=0.5665\n",
      "[Studygroup][701] CNN Loss=0.9205, Acc=0.6695 | MLP Loss=1.7309, Acc=0.5540\n",
      "[Studygroup][702] CNN Loss=0.9310, Acc=0.6724 | MLP Loss=1.8073, Acc=0.5646\n",
      "[Studygroup][703] CNN Loss=0.9517, Acc=0.6728 | MLP Loss=1.7144, Acc=0.5615\n",
      "[Studygroup][704] CNN Loss=0.9160, Acc=0.6733 | MLP Loss=1.6403, Acc=0.5689\n",
      "[Studygroup][705] CNN Loss=0.9265, Acc=0.6692 | MLP Loss=1.7000, Acc=0.5548\n",
      "[Studygroup][706] CNN Loss=0.9036, Acc=0.6660 | MLP Loss=1.7142, Acc=0.5451\n",
      "[Studygroup][707] CNN Loss=0.9316, Acc=0.6666 | MLP Loss=1.8015, Acc=0.5624\n",
      "[Studygroup][708] CNN Loss=0.9634, Acc=0.6620 | MLP Loss=1.7915, Acc=0.5605\n",
      "[Studygroup][709] CNN Loss=0.9576, Acc=0.6700 | MLP Loss=1.7599, Acc=0.5595\n",
      "[Studygroup][710] CNN Loss=0.9824, Acc=0.6678 | MLP Loss=1.7791, Acc=0.5491\n",
      "[Studygroup][711] CNN Loss=0.8972, Acc=0.6660 | MLP Loss=1.7586, Acc=0.5664\n",
      "[Studygroup][712] CNN Loss=0.9733, Acc=0.6710 | MLP Loss=1.7625, Acc=0.5604\n",
      "[Studygroup][713] CNN Loss=0.8856, Acc=0.6706 | MLP Loss=1.6593, Acc=0.5603\n",
      "[Studygroup][714] CNN Loss=0.9399, Acc=0.6681 | MLP Loss=1.6767, Acc=0.5607\n",
      "[Studygroup][715] CNN Loss=0.9177, Acc=0.6705 | MLP Loss=1.7641, Acc=0.5526\n",
      "[Studygroup][716] CNN Loss=0.9610, Acc=0.6690 | MLP Loss=1.6963, Acc=0.5570\n",
      "[Studygroup][717] CNN Loss=0.9436, Acc=0.6623 | MLP Loss=1.6566, Acc=0.5671\n",
      "[Studygroup][718] CNN Loss=0.9158, Acc=0.6704 | MLP Loss=1.6497, Acc=0.5661\n",
      "[Studygroup][719] CNN Loss=0.9469, Acc=0.6673 | MLP Loss=1.7292, Acc=0.5654\n",
      "[Studygroup][720] CNN Loss=0.9584, Acc=0.6672 | MLP Loss=1.6709, Acc=0.5624\n",
      "[Studygroup][721] CNN Loss=0.9228, Acc=0.6689 | MLP Loss=1.7021, Acc=0.5610\n",
      "[Studygroup][722] CNN Loss=0.8645, Acc=0.6677 | MLP Loss=1.7553, Acc=0.5579\n",
      "[Studygroup][723] CNN Loss=0.9128, Acc=0.6713 | MLP Loss=1.7656, Acc=0.5624\n",
      "[Studygroup][724] CNN Loss=0.9084, Acc=0.6659 | MLP Loss=1.7696, Acc=0.5472\n",
      "[Studygroup][725] CNN Loss=0.9238, Acc=0.6656 | MLP Loss=1.7564, Acc=0.5469\n",
      "[Studygroup][726] CNN Loss=0.9835, Acc=0.6670 | MLP Loss=1.6642, Acc=0.5459\n",
      "[Studygroup][727] CNN Loss=0.9903, Acc=0.6624 | MLP Loss=1.7446, Acc=0.5545\n",
      "[Studygroup][728] CNN Loss=0.9490, Acc=0.6603 | MLP Loss=1.7993, Acc=0.5510\n",
      "[Studygroup][729] CNN Loss=0.9374, Acc=0.6661 | MLP Loss=1.7095, Acc=0.5467\n",
      "[Studygroup][730] CNN Loss=0.9480, Acc=0.6645 | MLP Loss=1.6914, Acc=0.5514\n",
      "[Studygroup][731] CNN Loss=0.9139, Acc=0.6690 | MLP Loss=1.6961, Acc=0.5558\n",
      "[Studygroup][732] CNN Loss=0.9366, Acc=0.6719 | MLP Loss=1.7367, Acc=0.5516\n",
      "[Studygroup][733] CNN Loss=0.9612, Acc=0.6711 | MLP Loss=1.6789, Acc=0.5701\n",
      "[Studygroup][734] CNN Loss=0.9353, Acc=0.6618 | MLP Loss=1.6478, Acc=0.5608\n",
      "[Studygroup][735] CNN Loss=0.9119, Acc=0.6752 | MLP Loss=1.6335, Acc=0.5681\n",
      "[Studygroup][736] CNN Loss=0.9079, Acc=0.6745 | MLP Loss=1.7314, Acc=0.5597\n",
      "[Studygroup][737] CNN Loss=0.9574, Acc=0.6665 | MLP Loss=1.7196, Acc=0.5633\n",
      "[Studygroup][738] CNN Loss=0.9304, Acc=0.6717 | MLP Loss=1.7069, Acc=0.5682\n",
      "[Studygroup][739] CNN Loss=0.9986, Acc=0.6674 | MLP Loss=1.6988, Acc=0.5612\n",
      "[Studygroup][740] CNN Loss=0.9284, Acc=0.6639 | MLP Loss=1.6654, Acc=0.5696\n",
      "[Studygroup][741] CNN Loss=0.9489, Acc=0.6680 | MLP Loss=1.6276, Acc=0.5547\n",
      "[Studygroup][742] CNN Loss=0.9124, Acc=0.6664 | MLP Loss=1.6548, Acc=0.5561\n",
      "[Studygroup][743] CNN Loss=0.9006, Acc=0.6711 | MLP Loss=1.7415, Acc=0.5627\n",
      "[Studygroup][744] CNN Loss=0.8966, Acc=0.6724 | MLP Loss=1.6341, Acc=0.5503\n",
      "[Studygroup][745] CNN Loss=0.9126, Acc=0.6684 | MLP Loss=1.7077, Acc=0.5701\n",
      "[Studygroup][746] CNN Loss=0.9255, Acc=0.6610 | MLP Loss=1.6932, Acc=0.5663\n",
      "[Studygroup][747] CNN Loss=0.9486, Acc=0.6705 | MLP Loss=1.6889, Acc=0.5619\n",
      "[Studygroup][748] CNN Loss=0.9246, Acc=0.6730 | MLP Loss=1.7268, Acc=0.5653\n",
      "[Studygroup][749] CNN Loss=0.9103, Acc=0.6711 | MLP Loss=1.6944, Acc=0.5693\n",
      "[Studygroup][750] CNN Loss=0.9038, Acc=0.6731 | MLP Loss=1.7585, Acc=0.5541\n",
      "[Studygroup][751] CNN Loss=0.8966, Acc=0.6618 | MLP Loss=1.7385, Acc=0.5562\n",
      "[Studygroup][752] CNN Loss=0.9773, Acc=0.6675 | MLP Loss=1.7306, Acc=0.5594\n",
      "[Studygroup][753] CNN Loss=0.9592, Acc=0.6614 | MLP Loss=1.7095, Acc=0.5624\n",
      "[Studygroup][754] CNN Loss=0.9297, Acc=0.6688 | MLP Loss=1.7317, Acc=0.5655\n",
      "[Studygroup][755] CNN Loss=0.9289, Acc=0.6760 | MLP Loss=1.6891, Acc=0.5632\n",
      "[Studygroup][756] CNN Loss=1.0056, Acc=0.6641 | MLP Loss=1.7187, Acc=0.5638\n",
      "[Studygroup][757] CNN Loss=0.8891, Acc=0.6691 | MLP Loss=1.6828, Acc=0.5591\n",
      "[Studygroup][758] CNN Loss=1.0266, Acc=0.6593 | MLP Loss=1.7539, Acc=0.5546\n",
      "[Studygroup][759] CNN Loss=0.9518, Acc=0.6734 | MLP Loss=1.6872, Acc=0.5668\n",
      "[Studygroup][760] CNN Loss=0.9575, Acc=0.6693 | MLP Loss=1.7182, Acc=0.5698\n",
      "[Studygroup][761] CNN Loss=0.9710, Acc=0.6701 | MLP Loss=1.6898, Acc=0.5664\n",
      "[Studygroup][762] CNN Loss=0.9218, Acc=0.6725 | MLP Loss=1.6853, Acc=0.5609\n",
      "[Studygroup][763] CNN Loss=0.9248, Acc=0.6720 | MLP Loss=1.6374, Acc=0.5717\n",
      "[Studygroup][764] CNN Loss=0.8995, Acc=0.6718 | MLP Loss=1.7012, Acc=0.5601\n",
      "[Studygroup][765] CNN Loss=0.9618, Acc=0.6684 | MLP Loss=1.7594, Acc=0.5542\n",
      "[Studygroup][766] CNN Loss=1.0230, Acc=0.6651 | MLP Loss=1.6956, Acc=0.5632\n",
      "[Studygroup][767] CNN Loss=0.8712, Acc=0.6674 | MLP Loss=1.6747, Acc=0.5643\n",
      "[Studygroup][768] CNN Loss=0.8631, Acc=0.6729 | MLP Loss=1.6833, Acc=0.5627\n",
      "[Studygroup][769] CNN Loss=0.9882, Acc=0.6599 | MLP Loss=1.6852, Acc=0.5612\n",
      "[Studygroup][770] CNN Loss=0.8946, Acc=0.6669 | MLP Loss=1.6649, Acc=0.5390\n",
      "[Studygroup][771] CNN Loss=0.8989, Acc=0.6785 | MLP Loss=1.6841, Acc=0.5645\n",
      "[Studygroup][772] CNN Loss=0.8648, Acc=0.6675 | MLP Loss=1.7501, Acc=0.5681\n",
      "[Studygroup][773] CNN Loss=0.9101, Acc=0.6600 | MLP Loss=1.6682, Acc=0.5680\n",
      "[Studygroup][774] CNN Loss=0.9463, Acc=0.6666 | MLP Loss=1.6071, Acc=0.5661\n",
      "[Studygroup][775] CNN Loss=0.9290, Acc=0.6695 | MLP Loss=1.6434, Acc=0.5554\n",
      "[Studygroup][776] CNN Loss=0.8991, Acc=0.6678 | MLP Loss=1.7302, Acc=0.5604\n",
      "[Studygroup][777] CNN Loss=0.9297, Acc=0.6683 | MLP Loss=1.7656, Acc=0.5495\n",
      "[Studygroup][778] CNN Loss=0.9917, Acc=0.6715 | MLP Loss=1.8337, Acc=0.5641\n",
      "[Studygroup][779] CNN Loss=0.9447, Acc=0.6586 | MLP Loss=1.7325, Acc=0.5523\n",
      "[Studygroup][780] CNN Loss=0.9243, Acc=0.6740 | MLP Loss=1.6949, Acc=0.5332\n",
      "[Studygroup][781] CNN Loss=0.9245, Acc=0.6730 | MLP Loss=1.8311, Acc=0.5522\n",
      "[Studygroup][782] CNN Loss=1.0011, Acc=0.6700 | MLP Loss=1.6757, Acc=0.5566\n",
      "[Studygroup][783] CNN Loss=0.9371, Acc=0.6683 | MLP Loss=1.7628, Acc=0.5518\n",
      "[Studygroup][784] CNN Loss=0.9422, Acc=0.6704 | MLP Loss=1.6912, Acc=0.5688\n",
      "[Studygroup][785] CNN Loss=0.9309, Acc=0.6717 | MLP Loss=1.7089, Acc=0.5688\n",
      "[Studygroup][786] CNN Loss=0.9028, Acc=0.6703 | MLP Loss=1.6678, Acc=0.5624\n",
      "[Studygroup][787] CNN Loss=0.9382, Acc=0.6626 | MLP Loss=1.7049, Acc=0.5628\n",
      "[Studygroup][788] CNN Loss=0.9430, Acc=0.6710 | MLP Loss=1.7394, Acc=0.5479\n",
      "[Studygroup][789] CNN Loss=0.8973, Acc=0.6677 | MLP Loss=1.6911, Acc=0.5629\n",
      "[Studygroup][790] CNN Loss=1.0000, Acc=0.6734 | MLP Loss=1.7311, Acc=0.5670\n",
      "[Studygroup][791] CNN Loss=0.9025, Acc=0.6664 | MLP Loss=1.6859, Acc=0.5665\n",
      "[Studygroup][792] CNN Loss=0.9500, Acc=0.6671 | MLP Loss=1.7123, Acc=0.5563\n",
      "[Studygroup][793] CNN Loss=0.9865, Acc=0.6672 | MLP Loss=1.6768, Acc=0.5581\n",
      "[Studygroup][794] CNN Loss=0.9385, Acc=0.6666 | MLP Loss=1.7131, Acc=0.5576\n",
      "[Studygroup][795] CNN Loss=0.8896, Acc=0.6754 | MLP Loss=1.6718, Acc=0.5668\n",
      "[Studygroup][796] CNN Loss=0.9560, Acc=0.6766 | MLP Loss=1.6549, Acc=0.5603\n",
      "[Studygroup][797] CNN Loss=0.9297, Acc=0.6743 | MLP Loss=1.5940, Acc=0.5650\n",
      "[Studygroup][798] CNN Loss=0.8721, Acc=0.6722 | MLP Loss=1.7103, Acc=0.5652\n",
      "[Studygroup][799] CNN Loss=0.8991, Acc=0.6714 | MLP Loss=1.6816, Acc=0.5568\n",
      "[Studygroup][800] CNN Loss=0.8884, Acc=0.6687 | MLP Loss=1.6789, Acc=0.5643\n",
      "[Studygroup][801] CNN Loss=0.9634, Acc=0.6749 | MLP Loss=1.7473, Acc=0.5668\n",
      "[Studygroup][802] CNN Loss=0.9182, Acc=0.6739 | MLP Loss=1.7347, Acc=0.5646\n",
      "[Studygroup][803] CNN Loss=0.8713, Acc=0.6724 | MLP Loss=1.7550, Acc=0.5674\n",
      "[Studygroup][804] CNN Loss=0.9325, Acc=0.6690 | MLP Loss=1.7341, Acc=0.5553\n",
      "[Studygroup][805] CNN Loss=0.9686, Acc=0.6753 | MLP Loss=1.7682, Acc=0.5671\n",
      "[Studygroup][806] CNN Loss=0.9951, Acc=0.6695 | MLP Loss=1.7016, Acc=0.5577\n",
      "[Studygroup][807] CNN Loss=0.9142, Acc=0.6720 | MLP Loss=1.7118, Acc=0.5669\n",
      "[Studygroup][808] CNN Loss=0.9208, Acc=0.6674 | MLP Loss=1.6986, Acc=0.5668\n",
      "[Studygroup][809] CNN Loss=0.9279, Acc=0.6775 | MLP Loss=1.7446, Acc=0.5720\n",
      "[Studygroup][810] CNN Loss=0.9795, Acc=0.6737 | MLP Loss=1.7606, Acc=0.5565\n",
      "[Studygroup][811] CNN Loss=0.8735, Acc=0.6723 | MLP Loss=1.6799, Acc=0.5682\n",
      "[Studygroup][812] CNN Loss=0.8909, Acc=0.6627 | MLP Loss=1.7586, Acc=0.5644\n",
      "[Studygroup][813] CNN Loss=0.9389, Acc=0.6765 | MLP Loss=1.7814, Acc=0.5614\n",
      "[Studygroup][814] CNN Loss=0.9150, Acc=0.6733 | MLP Loss=1.7110, Acc=0.5577\n",
      "[Studygroup][815] CNN Loss=1.0031, Acc=0.6708 | MLP Loss=1.7722, Acc=0.5543\n",
      "[Studygroup][816] CNN Loss=0.9232, Acc=0.6665 | MLP Loss=1.7098, Acc=0.5680\n",
      "[Studygroup][817] CNN Loss=0.8553, Acc=0.6702 | MLP Loss=1.6749, Acc=0.5578\n",
      "[Studygroup][818] CNN Loss=0.8722, Acc=0.6767 | MLP Loss=1.7284, Acc=0.5674\n",
      "[Studygroup][819] CNN Loss=0.9066, Acc=0.6726 | MLP Loss=1.6950, Acc=0.5552\n",
      "[Studygroup][820] CNN Loss=0.9055, Acc=0.6748 | MLP Loss=1.7218, Acc=0.5619\n",
      "[Studygroup][821] CNN Loss=0.8919, Acc=0.6711 | MLP Loss=1.7164, Acc=0.5589\n",
      "[Studygroup][822] CNN Loss=1.0021, Acc=0.6710 | MLP Loss=1.6833, Acc=0.5714\n",
      "[Studygroup][823] CNN Loss=0.8635, Acc=0.6745 | MLP Loss=1.6792, Acc=0.5426\n",
      "[Studygroup][824] CNN Loss=0.9724, Acc=0.6746 | MLP Loss=1.8066, Acc=0.5541\n",
      "[Studygroup][825] CNN Loss=0.9435, Acc=0.6754 | MLP Loss=1.7349, Acc=0.5679\n",
      "[Studygroup][826] CNN Loss=0.9766, Acc=0.6758 | MLP Loss=1.6762, Acc=0.5725\n",
      "[Studygroup][827] CNN Loss=0.9056, Acc=0.6707 | MLP Loss=1.6770, Acc=0.5635\n",
      "[Studygroup][828] CNN Loss=0.8790, Acc=0.6690 | MLP Loss=1.6521, Acc=0.5695\n",
      "[Studygroup][829] CNN Loss=0.8511, Acc=0.6770 | MLP Loss=1.6791, Acc=0.5650\n",
      "[Studygroup][830] CNN Loss=1.0029, Acc=0.6676 | MLP Loss=1.6538, Acc=0.5660\n",
      "[Studygroup][831] CNN Loss=0.9360, Acc=0.6606 | MLP Loss=1.6458, Acc=0.5703\n",
      "[Studygroup][832] CNN Loss=0.9771, Acc=0.6660 | MLP Loss=1.6668, Acc=0.5592\n",
      "[Studygroup][833] CNN Loss=0.9383, Acc=0.6562 | MLP Loss=1.6557, Acc=0.5712\n",
      "[Studygroup][834] CNN Loss=0.9228, Acc=0.6731 | MLP Loss=1.6373, Acc=0.5635\n",
      "[Studygroup][835] CNN Loss=0.9049, Acc=0.6772 | MLP Loss=1.7457, Acc=0.5639\n",
      "[Studygroup][836] CNN Loss=0.9496, Acc=0.6747 | MLP Loss=1.6647, Acc=0.5742\n",
      "[Studygroup][837] CNN Loss=0.8983, Acc=0.6737 | MLP Loss=1.6737, Acc=0.5724\n",
      "[Studygroup][838] CNN Loss=0.8820, Acc=0.6777 | MLP Loss=1.6903, Acc=0.5698\n",
      "[Studygroup][839] CNN Loss=0.8944, Acc=0.6726 | MLP Loss=1.7129, Acc=0.5684\n",
      "[Studygroup][840] CNN Loss=0.9946, Acc=0.6752 | MLP Loss=1.6152, Acc=0.5621\n",
      "[Studygroup][841] CNN Loss=0.9170, Acc=0.6728 | MLP Loss=1.7397, Acc=0.5532\n",
      "[Studygroup][842] CNN Loss=0.9112, Acc=0.6683 | MLP Loss=1.7313, Acc=0.5681\n",
      "[Studygroup][843] CNN Loss=0.9675, Acc=0.6611 | MLP Loss=1.7415, Acc=0.5683\n",
      "[Studygroup][844] CNN Loss=0.9252, Acc=0.6714 | MLP Loss=1.6498, Acc=0.5694\n",
      "[Studygroup][845] CNN Loss=0.8979, Acc=0.6737 | MLP Loss=1.6875, Acc=0.5714\n",
      "[Studygroup][846] CNN Loss=0.9485, Acc=0.6722 | MLP Loss=1.6839, Acc=0.5554\n",
      "[Studygroup][847] CNN Loss=0.9743, Acc=0.6721 | MLP Loss=1.7339, Acc=0.5545\n",
      "[Studygroup][848] CNN Loss=0.8994, Acc=0.6711 | MLP Loss=1.7497, Acc=0.5670\n",
      "[Studygroup][849] CNN Loss=0.8765, Acc=0.6834 | MLP Loss=1.6836, Acc=0.5537\n",
      "[Studygroup][850] CNN Loss=0.9254, Acc=0.6637 | MLP Loss=1.7484, Acc=0.5569\n",
      "[Studygroup][851] CNN Loss=1.0444, Acc=0.6701 | MLP Loss=1.7685, Acc=0.5685\n",
      "[Studygroup][852] CNN Loss=0.8670, Acc=0.6739 | MLP Loss=1.6894, Acc=0.5659\n",
      "[Studygroup][853] CNN Loss=0.9423, Acc=0.6701 | MLP Loss=1.7122, Acc=0.5643\n",
      "[Studygroup][854] CNN Loss=0.9402, Acc=0.6733 | MLP Loss=1.6190, Acc=0.5752\n",
      "[Studygroup][855] CNN Loss=0.8553, Acc=0.6746 | MLP Loss=1.6270, Acc=0.5722\n",
      "[Studygroup][856] CNN Loss=0.8304, Acc=0.6747 | MLP Loss=1.6562, Acc=0.5729\n",
      "[Studygroup][857] CNN Loss=0.9039, Acc=0.6710 | MLP Loss=1.6755, Acc=0.5755\n",
      "[Studygroup][858] CNN Loss=0.9265, Acc=0.6719 | MLP Loss=1.7032, Acc=0.5591\n",
      "[Studygroup][859] CNN Loss=0.9467, Acc=0.6733 | MLP Loss=1.7760, Acc=0.5737\n",
      "[Studygroup][860] CNN Loss=1.0348, Acc=0.6736 | MLP Loss=1.7369, Acc=0.5634\n",
      "[Studygroup][861] CNN Loss=0.9601, Acc=0.6760 | MLP Loss=1.6437, Acc=0.5685\n",
      "[Studygroup][862] CNN Loss=0.9309, Acc=0.6572 | MLP Loss=1.7202, Acc=0.5541\n",
      "[Studygroup][863] CNN Loss=1.0799, Acc=0.6708 | MLP Loss=1.8728, Acc=0.5499\n",
      "[Studygroup][864] CNN Loss=0.9058, Acc=0.6764 | MLP Loss=1.7366, Acc=0.5677\n",
      "[Studygroup][865] CNN Loss=0.9692, Acc=0.6692 | MLP Loss=1.6830, Acc=0.5689\n",
      "[Studygroup][866] CNN Loss=0.9435, Acc=0.6697 | MLP Loss=1.7019, Acc=0.5751\n",
      "[Studygroup][867] CNN Loss=0.9478, Acc=0.6720 | MLP Loss=1.6291, Acc=0.5703\n",
      "[Studygroup][868] CNN Loss=0.9319, Acc=0.6717 | MLP Loss=1.6865, Acc=0.5612\n",
      "[Studygroup][869] CNN Loss=0.8530, Acc=0.6709 | MLP Loss=1.6993, Acc=0.5612\n",
      "[Studygroup][870] CNN Loss=0.9124, Acc=0.6788 | MLP Loss=1.7183, Acc=0.5575\n",
      "[Studygroup][871] CNN Loss=0.9385, Acc=0.6691 | MLP Loss=1.8054, Acc=0.5587\n",
      "[Studygroup][872] CNN Loss=0.9144, Acc=0.6754 | MLP Loss=1.7534, Acc=0.5567\n",
      "[Studygroup][873] CNN Loss=0.9053, Acc=0.6715 | MLP Loss=1.7458, Acc=0.5602\n",
      "[Studygroup][874] CNN Loss=0.8850, Acc=0.6743 | MLP Loss=1.7515, Acc=0.5743\n",
      "[Studygroup][875] CNN Loss=0.8950, Acc=0.6698 | MLP Loss=1.6933, Acc=0.5725\n",
      "[Studygroup][876] CNN Loss=0.9572, Acc=0.6693 | MLP Loss=1.7290, Acc=0.5476\n",
      "[Studygroup][877] CNN Loss=0.8568, Acc=0.6770 | MLP Loss=1.7299, Acc=0.5694\n",
      "[Studygroup][878] CNN Loss=0.8360, Acc=0.6767 | MLP Loss=1.7583, Acc=0.5693\n",
      "[Studygroup][879] CNN Loss=0.8757, Acc=0.6677 | MLP Loss=1.7104, Acc=0.5713\n",
      "[Studygroup][880] CNN Loss=0.8872, Acc=0.6739 | MLP Loss=1.7398, Acc=0.5727\n",
      "[Studygroup][881] CNN Loss=0.8630, Acc=0.6703 | MLP Loss=1.6706, Acc=0.5643\n",
      "[Studygroup][882] CNN Loss=1.0244, Acc=0.6701 | MLP Loss=1.7551, Acc=0.5690\n",
      "[Studygroup][883] CNN Loss=0.9291, Acc=0.6745 | MLP Loss=1.7402, Acc=0.5760\n",
      "[Studygroup][884] CNN Loss=0.8951, Acc=0.6749 | MLP Loss=1.7066, Acc=0.5757\n",
      "[Studygroup][885] CNN Loss=0.9676, Acc=0.6731 | MLP Loss=1.7193, Acc=0.5684\n",
      "[Studygroup][886] CNN Loss=0.8913, Acc=0.6804 | MLP Loss=1.6815, Acc=0.5713\n",
      "[Studygroup][887] CNN Loss=1.0352, Acc=0.6600 | MLP Loss=1.7567, Acc=0.5660\n",
      "[Studygroup][888] CNN Loss=0.9689, Acc=0.6749 | MLP Loss=1.7301, Acc=0.5666\n",
      "[Studygroup][889] CNN Loss=0.9940, Acc=0.6684 | MLP Loss=1.7319, Acc=0.5687\n",
      "[Studygroup][890] CNN Loss=0.9312, Acc=0.6715 | MLP Loss=1.6911, Acc=0.5659\n",
      "[Studygroup][891] CNN Loss=0.9159, Acc=0.6752 | MLP Loss=1.6930, Acc=0.5708\n",
      "[Studygroup][892] CNN Loss=0.9280, Acc=0.6699 | MLP Loss=1.8177, Acc=0.5554\n",
      "[Studygroup][893] CNN Loss=0.9723, Acc=0.6688 | MLP Loss=1.7968, Acc=0.5602\n",
      "[Studygroup][894] CNN Loss=0.9079, Acc=0.6757 | MLP Loss=1.7646, Acc=0.5673\n",
      "[Studygroup][895] CNN Loss=0.8815, Acc=0.6757 | MLP Loss=1.6887, Acc=0.5591\n",
      "[Studygroup][896] CNN Loss=0.9491, Acc=0.6753 | MLP Loss=1.7012, Acc=0.5603\n",
      "[Studygroup][897] CNN Loss=0.9474, Acc=0.6630 | MLP Loss=1.6534, Acc=0.5726\n",
      "[Studygroup][898] CNN Loss=0.9413, Acc=0.6782 | MLP Loss=1.6558, Acc=0.5579\n",
      "[Studygroup][899] CNN Loss=0.8740, Acc=0.6715 | MLP Loss=1.6201, Acc=0.5665\n",
      "[Studygroup][900] CNN Loss=0.9876, Acc=0.6733 | MLP Loss=1.6307, Acc=0.5675\n",
      "[Studygroup][901] CNN Loss=0.9479, Acc=0.6775 | MLP Loss=1.6761, Acc=0.5791\n",
      "[Studygroup][902] CNN Loss=0.8578, Acc=0.6760 | MLP Loss=1.6126, Acc=0.5726\n",
      "[Studygroup][903] CNN Loss=0.9207, Acc=0.6754 | MLP Loss=1.7174, Acc=0.5586\n",
      "[Studygroup][904] CNN Loss=0.9145, Acc=0.6786 | MLP Loss=1.7098, Acc=0.5745\n",
      "[Studygroup][905] CNN Loss=0.8876, Acc=0.6734 | MLP Loss=1.7110, Acc=0.5738\n",
      "[Studygroup][906] CNN Loss=0.9309, Acc=0.6676 | MLP Loss=1.7022, Acc=0.5655\n",
      "[Studygroup][907] CNN Loss=0.9156, Acc=0.6763 | MLP Loss=1.7504, Acc=0.5766\n",
      "[Studygroup][908] CNN Loss=0.8343, Acc=0.6826 | MLP Loss=1.7367, Acc=0.5706\n",
      "[Studygroup][909] CNN Loss=0.9547, Acc=0.6738 | MLP Loss=1.7238, Acc=0.5466\n",
      "[Studygroup][910] CNN Loss=0.9709, Acc=0.6737 | MLP Loss=1.8456, Acc=0.5556\n",
      "[Studygroup][911] CNN Loss=0.9102, Acc=0.6689 | MLP Loss=1.6784, Acc=0.5746\n",
      "[Studygroup][912] CNN Loss=0.8847, Acc=0.6670 | MLP Loss=1.6700, Acc=0.5632\n",
      "[Studygroup][913] CNN Loss=0.8934, Acc=0.6691 | MLP Loss=1.7311, Acc=0.5731\n",
      "[Studygroup][914] CNN Loss=0.9351, Acc=0.6714 | MLP Loss=1.7019, Acc=0.5694\n",
      "[Studygroup][915] CNN Loss=0.9286, Acc=0.6791 | MLP Loss=1.6551, Acc=0.5711\n",
      "[Studygroup][916] CNN Loss=0.8900, Acc=0.6724 | MLP Loss=1.7008, Acc=0.5628\n",
      "[Studygroup][917] CNN Loss=1.0136, Acc=0.6784 | MLP Loss=1.7858, Acc=0.5699\n",
      "[Studygroup][918] CNN Loss=0.9937, Acc=0.6707 | MLP Loss=1.7935, Acc=0.5705\n",
      "[Studygroup][919] CNN Loss=0.9387, Acc=0.6577 | MLP Loss=1.6521, Acc=0.5588\n",
      "[Studygroup][920] CNN Loss=0.9568, Acc=0.6696 | MLP Loss=1.6690, Acc=0.5650\n",
      "[Studygroup][921] CNN Loss=0.8994, Acc=0.6696 | MLP Loss=1.6455, Acc=0.5707\n",
      "[Studygroup][922] CNN Loss=0.9468, Acc=0.6745 | MLP Loss=1.6809, Acc=0.5654\n",
      "[Studygroup][923] CNN Loss=0.9604, Acc=0.6748 | MLP Loss=1.7024, Acc=0.5712\n",
      "[Studygroup][924] CNN Loss=0.8900, Acc=0.6744 | MLP Loss=1.7395, Acc=0.5612\n",
      "[Studygroup][925] CNN Loss=0.9016, Acc=0.6766 | MLP Loss=1.7765, Acc=0.5545\n",
      "[Studygroup][926] CNN Loss=0.8953, Acc=0.6794 | MLP Loss=1.6916, Acc=0.5641\n",
      "[Studygroup][927] CNN Loss=0.9247, Acc=0.6751 | MLP Loss=1.7383, Acc=0.5637\n",
      "[Studygroup][928] CNN Loss=0.9161, Acc=0.6683 | MLP Loss=1.6248, Acc=0.5678\n",
      "[Studygroup][929] CNN Loss=0.8440, Acc=0.6752 | MLP Loss=1.6541, Acc=0.5726\n",
      "[Studygroup][930] CNN Loss=1.0003, Acc=0.6727 | MLP Loss=1.7085, Acc=0.5785\n",
      "[Studygroup][931] CNN Loss=0.8873, Acc=0.6761 | MLP Loss=1.6648, Acc=0.5656\n",
      "[Studygroup][932] CNN Loss=0.9308, Acc=0.6711 | MLP Loss=1.6875, Acc=0.5659\n",
      "[Studygroup][933] CNN Loss=0.8584, Acc=0.6752 | MLP Loss=1.7054, Acc=0.5732\n",
      "[Studygroup][934] CNN Loss=0.8503, Acc=0.6805 | MLP Loss=1.7102, Acc=0.5766\n",
      "[Studygroup][935] CNN Loss=0.8247, Acc=0.6751 | MLP Loss=1.6665, Acc=0.5763\n",
      "[Studygroup][936] CNN Loss=0.8898, Acc=0.6679 | MLP Loss=1.7339, Acc=0.5592\n",
      "[Studygroup][937] CNN Loss=0.9805, Acc=0.6765 | MLP Loss=1.7428, Acc=0.5704\n",
      "[Studygroup][938] CNN Loss=0.8785, Acc=0.6708 | MLP Loss=1.6992, Acc=0.5699\n",
      "[Studygroup][939] CNN Loss=0.9735, Acc=0.6552 | MLP Loss=1.7265, Acc=0.5718\n",
      "[Studygroup][940] CNN Loss=0.9725, Acc=0.6715 | MLP Loss=1.6395, Acc=0.5683\n",
      "[Studygroup][941] CNN Loss=0.9619, Acc=0.6670 | MLP Loss=1.7135, Acc=0.5800\n",
      "[Studygroup][942] CNN Loss=0.9341, Acc=0.6689 | MLP Loss=1.6536, Acc=0.5532\n",
      "[Studygroup][943] CNN Loss=0.9838, Acc=0.6589 | MLP Loss=1.7604, Acc=0.5702\n",
      "[Studygroup][944] CNN Loss=0.9792, Acc=0.6662 | MLP Loss=1.6751, Acc=0.5761\n",
      "[Studygroup][945] CNN Loss=0.8735, Acc=0.6754 | MLP Loss=1.6568, Acc=0.5763\n",
      "[Studygroup][946] CNN Loss=0.9800, Acc=0.6677 | MLP Loss=1.6900, Acc=0.5675\n",
      "[Studygroup][947] CNN Loss=0.9026, Acc=0.6725 | MLP Loss=1.5899, Acc=0.5708\n",
      "[Studygroup][948] CNN Loss=0.9087, Acc=0.6807 | MLP Loss=1.6296, Acc=0.5748\n",
      "[Studygroup][949] CNN Loss=0.8523, Acc=0.6801 | MLP Loss=1.6426, Acc=0.5748\n",
      "[Studygroup][950] CNN Loss=0.9274, Acc=0.6659 | MLP Loss=1.7586, Acc=0.5583\n",
      "[Studygroup][951] CNN Loss=0.9042, Acc=0.6742 | MLP Loss=1.7557, Acc=0.5728\n",
      "[Studygroup][952] CNN Loss=0.8760, Acc=0.6747 | MLP Loss=1.6853, Acc=0.5803\n",
      "[Studygroup][953] CNN Loss=0.9069, Acc=0.6743 | MLP Loss=1.6784, Acc=0.5719\n",
      "[Studygroup][954] CNN Loss=0.9530, Acc=0.6759 | MLP Loss=1.6635, Acc=0.5695\n",
      "[Studygroup][955] CNN Loss=0.9030, Acc=0.6653 | MLP Loss=1.6591, Acc=0.5630\n",
      "[Studygroup][956] CNN Loss=0.9173, Acc=0.6718 | MLP Loss=1.6759, Acc=0.5688\n",
      "[Studygroup][957] CNN Loss=0.9368, Acc=0.6785 | MLP Loss=1.6630, Acc=0.5662\n",
      "[Studygroup][958] CNN Loss=0.9368, Acc=0.6753 | MLP Loss=1.6419, Acc=0.5627\n",
      "[Studygroup][959] CNN Loss=0.8556, Acc=0.6697 | MLP Loss=1.6490, Acc=0.5740\n",
      "[Studygroup][960] CNN Loss=0.8768, Acc=0.6771 | MLP Loss=1.6207, Acc=0.5749\n",
      "[Studygroup][961] CNN Loss=0.9036, Acc=0.6774 | MLP Loss=1.6310, Acc=0.5641\n",
      "[Studygroup][962] CNN Loss=0.8519, Acc=0.6753 | MLP Loss=1.7382, Acc=0.5762\n",
      "[Studygroup][963] CNN Loss=0.8862, Acc=0.6784 | MLP Loss=1.6456, Acc=0.5706\n",
      "[Studygroup][964] CNN Loss=0.8784, Acc=0.6713 | MLP Loss=1.6666, Acc=0.5784\n",
      "[Studygroup][965] CNN Loss=0.8832, Acc=0.6746 | MLP Loss=1.6136, Acc=0.5673\n",
      "[Studygroup][966] CNN Loss=0.8447, Acc=0.6728 | MLP Loss=1.6647, Acc=0.5761\n",
      "[Studygroup][967] CNN Loss=0.9624, Acc=0.6715 | MLP Loss=1.6281, Acc=0.5729\n",
      "[Studygroup][968] CNN Loss=0.8263, Acc=0.6745 | MLP Loss=1.6543, Acc=0.5652\n",
      "[Studygroup][969] CNN Loss=0.8534, Acc=0.6726 | MLP Loss=1.6953, Acc=0.5722\n",
      "[Studygroup][970] CNN Loss=0.8686, Acc=0.6761 | MLP Loss=1.7096, Acc=0.5875\n",
      "[Studygroup][971] CNN Loss=0.8384, Acc=0.6740 | MLP Loss=1.6096, Acc=0.5819\n",
      "[Studygroup][972] CNN Loss=0.8613, Acc=0.6738 | MLP Loss=1.6281, Acc=0.5638\n",
      "[Studygroup][973] CNN Loss=0.8391, Acc=0.6719 | MLP Loss=1.7244, Acc=0.5728\n",
      "[Studygroup][974] CNN Loss=0.9462, Acc=0.6678 | MLP Loss=1.7419, Acc=0.5731\n",
      "[Studygroup][975] CNN Loss=0.9367, Acc=0.6719 | MLP Loss=1.7876, Acc=0.5873\n",
      "[Studygroup][976] CNN Loss=0.9875, Acc=0.6675 | MLP Loss=1.6507, Acc=0.5690\n",
      "[Studygroup][977] CNN Loss=0.8556, Acc=0.6755 | MLP Loss=1.6614, Acc=0.5771\n",
      "[Studygroup][978] CNN Loss=0.8514, Acc=0.6801 | MLP Loss=1.6604, Acc=0.5665\n",
      "[Studygroup][979] CNN Loss=0.8981, Acc=0.6627 | MLP Loss=1.7132, Acc=0.5757\n",
      "[Studygroup][980] CNN Loss=1.0448, Acc=0.6634 | MLP Loss=1.6719, Acc=0.5660\n",
      "[Studygroup][981] CNN Loss=0.9961, Acc=0.6729 | MLP Loss=1.6952, Acc=0.5752\n",
      "[Studygroup][982] CNN Loss=0.9116, Acc=0.6760 | MLP Loss=1.6594, Acc=0.5746\n",
      "[Studygroup][983] CNN Loss=0.8886, Acc=0.6803 | MLP Loss=1.7565, Acc=0.5705\n",
      "[Studygroup][984] CNN Loss=0.8774, Acc=0.6768 | MLP Loss=1.6899, Acc=0.5539\n",
      "[Studygroup][985] CNN Loss=0.9004, Acc=0.6795 | MLP Loss=1.7640, Acc=0.5719\n",
      "[Studygroup][986] CNN Loss=0.9307, Acc=0.6700 | MLP Loss=1.7719, Acc=0.5742\n",
      "[Studygroup][987] CNN Loss=1.0052, Acc=0.6745 | MLP Loss=1.7272, Acc=0.5704\n",
      "[Studygroup][988] CNN Loss=0.9284, Acc=0.6736 | MLP Loss=1.6326, Acc=0.5700\n",
      "[Studygroup][989] CNN Loss=0.8843, Acc=0.6776 | MLP Loss=1.6428, Acc=0.5727\n",
      "[Studygroup][990] CNN Loss=0.8505, Acc=0.6790 | MLP Loss=1.6306, Acc=0.5674\n",
      "[Studygroup][991] CNN Loss=0.8581, Acc=0.6698 | MLP Loss=1.6381, Acc=0.5647\n",
      "[Studygroup][992] CNN Loss=0.9409, Acc=0.6771 | MLP Loss=1.6952, Acc=0.5841\n",
      "[Studygroup][993] CNN Loss=0.9843, Acc=0.6724 | MLP Loss=1.6623, Acc=0.5703\n",
      "[Studygroup][994] CNN Loss=0.9635, Acc=0.6761 | MLP Loss=1.7389, Acc=0.5771\n",
      "[Studygroup][995] CNN Loss=0.8761, Acc=0.6771 | MLP Loss=1.6995, Acc=0.5683\n",
      "[Studygroup][996] CNN Loss=0.8524, Acc=0.6707 | MLP Loss=1.7349, Acc=0.5568\n",
      "[Studygroup][997] CNN Loss=0.9036, Acc=0.6686 | MLP Loss=1.7503, Acc=0.5613\n",
      "[Studygroup][998] CNN Loss=1.0338, Acc=0.6666 | MLP Loss=1.7530, Acc=0.5745\n",
      "[Studygroup][999] CNN Loss=0.9258, Acc=0.6731 | MLP Loss=1.6616, Acc=0.5775\n",
      "[Studygroup][1000] CNN Loss=0.9064, Acc=0.6700 | MLP Loss=1.6858, Acc=0.5723\n",
      "[Studygroup][1001] CNN Loss=0.9192, Acc=0.6784 | MLP Loss=1.6793, Acc=0.5757\n",
      "[Studygroup][1002] CNN Loss=0.9551, Acc=0.6734 | MLP Loss=1.6841, Acc=0.5831\n",
      "[Studygroup][1003] CNN Loss=0.9693, Acc=0.6599 | MLP Loss=1.5977, Acc=0.5779\n",
      "[Studygroup][1004] CNN Loss=0.9171, Acc=0.6746 | MLP Loss=1.5822, Acc=0.5694\n",
      "[Studygroup][1005] CNN Loss=0.8623, Acc=0.6754 | MLP Loss=1.6258, Acc=0.5645\n",
      "[Studygroup][1006] CNN Loss=0.9505, Acc=0.6714 | MLP Loss=1.5908, Acc=0.5808\n",
      "[Studygroup][1007] CNN Loss=0.8187, Acc=0.6803 | MLP Loss=1.6284, Acc=0.5729\n",
      "[Studygroup][1008] CNN Loss=0.9817, Acc=0.6811 | MLP Loss=1.6792, Acc=0.5681\n",
      "[Studygroup][1009] CNN Loss=0.9578, Acc=0.6701 | MLP Loss=1.6435, Acc=0.5695\n",
      "[Studygroup][1010] CNN Loss=0.8405, Acc=0.6726 | MLP Loss=1.6299, Acc=0.5752\n",
      "[Studygroup][1011] CNN Loss=0.9110, Acc=0.6747 | MLP Loss=1.6649, Acc=0.5830\n",
      "[Studygroup][1012] CNN Loss=0.9501, Acc=0.6754 | MLP Loss=1.6377, Acc=0.5627\n",
      "[Studygroup][1013] CNN Loss=0.9332, Acc=0.6673 | MLP Loss=1.6337, Acc=0.5698\n",
      "[Studygroup][1014] CNN Loss=0.9731, Acc=0.6748 | MLP Loss=1.5988, Acc=0.5789\n",
      "[Studygroup][1015] CNN Loss=1.1356, Acc=0.6630 | MLP Loss=1.7164, Acc=0.5685\n",
      "[Studygroup][1016] CNN Loss=0.9457, Acc=0.6787 | MLP Loss=1.5746, Acc=0.5767\n",
      "[Studygroup][1017] CNN Loss=0.8688, Acc=0.6853 | MLP Loss=1.5719, Acc=0.5783\n",
      "[Studygroup][1018] CNN Loss=0.8361, Acc=0.6794 | MLP Loss=1.6462, Acc=0.5816\n",
      "[Studygroup][1019] CNN Loss=0.8190, Acc=0.6737 | MLP Loss=1.6380, Acc=0.5815\n",
      "[Studygroup][1020] CNN Loss=0.9402, Acc=0.6726 | MLP Loss=1.7524, Acc=0.5735\n",
      "[Studygroup][1021] CNN Loss=0.9882, Acc=0.6749 | MLP Loss=1.7917, Acc=0.5694\n",
      "[Studygroup][1022] CNN Loss=0.9335, Acc=0.6807 | MLP Loss=1.7678, Acc=0.5660\n",
      "[Studygroup][1023] CNN Loss=0.9502, Acc=0.6826 | MLP Loss=1.7432, Acc=0.5688\n",
      "[Studygroup][1024] CNN Loss=0.9048, Acc=0.6754 | MLP Loss=1.7006, Acc=0.5826\n",
      "[Studygroup][1025] CNN Loss=0.9436, Acc=0.6748 | MLP Loss=1.6577, Acc=0.5751\n",
      "[Studygroup][1026] CNN Loss=0.9191, Acc=0.6774 | MLP Loss=1.6258, Acc=0.5800\n",
      "[Studygroup][1027] CNN Loss=0.8073, Acc=0.6814 | MLP Loss=1.6774, Acc=0.5714\n",
      "[Studygroup][1028] CNN Loss=0.9065, Acc=0.6778 | MLP Loss=1.6666, Acc=0.5759\n",
      "[Studygroup][1029] CNN Loss=0.8994, Acc=0.6777 | MLP Loss=1.6307, Acc=0.5698\n",
      "[Studygroup][1030] CNN Loss=1.0803, Acc=0.6755 | MLP Loss=1.6677, Acc=0.5731\n",
      "[Studygroup][1031] CNN Loss=0.9770, Acc=0.6749 | MLP Loss=1.6923, Acc=0.5696\n",
      "[Studygroup][1032] CNN Loss=0.9778, Acc=0.6777 | MLP Loss=1.6387, Acc=0.5774\n",
      "[Studygroup][1033] CNN Loss=0.9450, Acc=0.6760 | MLP Loss=1.5861, Acc=0.5732\n",
      "[Studygroup][1034] CNN Loss=0.9086, Acc=0.6764 | MLP Loss=1.6358, Acc=0.5786\n",
      "[Studygroup][1035] CNN Loss=0.8736, Acc=0.6867 | MLP Loss=1.6617, Acc=0.5725\n",
      "[Studygroup][1036] CNN Loss=0.8686, Acc=0.6839 | MLP Loss=1.6519, Acc=0.5776\n",
      "[Studygroup][1037] CNN Loss=0.8451, Acc=0.6838 | MLP Loss=1.6917, Acc=0.5766\n",
      "[Studygroup][1038] CNN Loss=0.8669, Acc=0.6829 | MLP Loss=1.7716, Acc=0.5713\n",
      "[Studygroup][1039] CNN Loss=0.8762, Acc=0.6810 | MLP Loss=1.6178, Acc=0.5784\n",
      "[Studygroup][1040] CNN Loss=0.9209, Acc=0.6747 | MLP Loss=1.7926, Acc=0.5741\n",
      "[Studygroup][1041] CNN Loss=0.9515, Acc=0.6817 | MLP Loss=1.6915, Acc=0.5647\n",
      "[Studygroup][1042] CNN Loss=1.0337, Acc=0.6746 | MLP Loss=1.7524, Acc=0.5669\n",
      "[Studygroup][1043] CNN Loss=0.9520, Acc=0.6785 | MLP Loss=1.6737, Acc=0.5789\n",
      "[Studygroup][1044] CNN Loss=1.0267, Acc=0.6725 | MLP Loss=1.6695, Acc=0.5757\n",
      "[Studygroup][1045] CNN Loss=0.8492, Acc=0.6768 | MLP Loss=1.6349, Acc=0.5783\n",
      "[Studygroup][1046] CNN Loss=0.9087, Acc=0.6828 | MLP Loss=1.6551, Acc=0.5685\n",
      "[Studygroup][1047] CNN Loss=0.8559, Acc=0.6779 | MLP Loss=1.6346, Acc=0.5821\n",
      "[Studygroup][1048] CNN Loss=0.9215, Acc=0.6689 | MLP Loss=1.6772, Acc=0.5597\n",
      "[Studygroup][1049] CNN Loss=0.9479, Acc=0.6797 | MLP Loss=1.8133, Acc=0.5741\n",
      "[Studygroup][1050] CNN Loss=0.9086, Acc=0.6735 | MLP Loss=1.6873, Acc=0.5812\n",
      "[Studygroup][1051] CNN Loss=0.9328, Acc=0.6783 | MLP Loss=1.6605, Acc=0.5745\n",
      "[Studygroup][1052] CNN Loss=0.9012, Acc=0.6766 | MLP Loss=1.6846, Acc=0.5816\n",
      "[Studygroup][1053] CNN Loss=0.8755, Acc=0.6860 | MLP Loss=1.6370, Acc=0.5789\n",
      "[Studygroup][1054] CNN Loss=0.8831, Acc=0.6805 | MLP Loss=1.6360, Acc=0.5725\n",
      "[Studygroup][1055] CNN Loss=0.8220, Acc=0.6845 | MLP Loss=1.7456, Acc=0.5701\n",
      "[Studygroup][1056] CNN Loss=0.9049, Acc=0.6811 | MLP Loss=1.6857, Acc=0.5795\n",
      "[Studygroup][1057] CNN Loss=0.8883, Acc=0.6770 | MLP Loss=1.6662, Acc=0.5798\n",
      "[Studygroup][1058] CNN Loss=0.9156, Acc=0.6753 | MLP Loss=1.6616, Acc=0.5715\n",
      "[Studygroup][1059] CNN Loss=0.9245, Acc=0.6791 | MLP Loss=1.6064, Acc=0.5767\n",
      "[Studygroup][1060] CNN Loss=0.9239, Acc=0.6804 | MLP Loss=1.6316, Acc=0.5715\n",
      "[Studygroup][1061] CNN Loss=0.8863, Acc=0.6833 | MLP Loss=1.6760, Acc=0.5739\n",
      "[Studygroup][1062] CNN Loss=0.9349, Acc=0.6815 | MLP Loss=1.6215, Acc=0.5789\n",
      "[Studygroup][1063] CNN Loss=0.9017, Acc=0.6842 | MLP Loss=1.6536, Acc=0.5723\n",
      "[Studygroup][1064] CNN Loss=0.8772, Acc=0.6808 | MLP Loss=1.7555, Acc=0.5737\n",
      "[Studygroup][1065] CNN Loss=0.9264, Acc=0.6804 | MLP Loss=1.6658, Acc=0.5806\n",
      "[Studygroup][1066] CNN Loss=0.9028, Acc=0.6810 | MLP Loss=1.7148, Acc=0.5813\n",
      "[Studygroup][1067] CNN Loss=0.8996, Acc=0.6754 | MLP Loss=1.6932, Acc=0.5780\n",
      "[Studygroup][1068] CNN Loss=0.9016, Acc=0.6814 | MLP Loss=1.6689, Acc=0.5688\n",
      "[Studygroup][1069] CNN Loss=0.8774, Acc=0.6746 | MLP Loss=1.6680, Acc=0.5763\n",
      "[Studygroup][1070] CNN Loss=0.9437, Acc=0.6731 | MLP Loss=1.6199, Acc=0.5819\n",
      "[Studygroup][1071] CNN Loss=1.0010, Acc=0.6663 | MLP Loss=1.6604, Acc=0.5770\n",
      "[Studygroup][1072] CNN Loss=0.9391, Acc=0.6741 | MLP Loss=1.6039, Acc=0.5821\n",
      "[Studygroup][1073] CNN Loss=0.8880, Acc=0.6782 | MLP Loss=1.6274, Acc=0.5817\n",
      "[Studygroup][1074] CNN Loss=0.9389, Acc=0.6770 | MLP Loss=1.7285, Acc=0.5730\n",
      "[Studygroup][1075] CNN Loss=0.8658, Acc=0.6712 | MLP Loss=1.7228, Acc=0.5700\n",
      "[Studygroup][1076] CNN Loss=0.9165, Acc=0.6784 | MLP Loss=1.6812, Acc=0.5841\n",
      "[Studygroup][1077] CNN Loss=0.8570, Acc=0.6734 | MLP Loss=1.6856, Acc=0.5705\n",
      "[Studygroup][1078] CNN Loss=0.9573, Acc=0.6700 | MLP Loss=1.6639, Acc=0.5866\n",
      "[Studygroup][1079] CNN Loss=0.9040, Acc=0.6780 | MLP Loss=1.6685, Acc=0.5763\n",
      "[Studygroup][1080] CNN Loss=0.8331, Acc=0.6738 | MLP Loss=1.6548, Acc=0.5770\n",
      "[Studygroup][1081] CNN Loss=0.8880, Acc=0.6771 | MLP Loss=1.6781, Acc=0.5785\n",
      "[Studygroup][1082] CNN Loss=1.0073, Acc=0.6795 | MLP Loss=1.6669, Acc=0.5547\n",
      "[Studygroup][1083] CNN Loss=0.9130, Acc=0.6696 | MLP Loss=1.6449, Acc=0.5743\n",
      "[Studygroup][1084] CNN Loss=0.8775, Acc=0.6774 | MLP Loss=1.6210, Acc=0.5742\n",
      "[Studygroup][1085] CNN Loss=0.8978, Acc=0.6676 | MLP Loss=1.6442, Acc=0.5822\n",
      "[Studygroup][1086] CNN Loss=0.9883, Acc=0.6753 | MLP Loss=1.6667, Acc=0.5760\n",
      "[Studygroup][1087] CNN Loss=0.8479, Acc=0.6715 | MLP Loss=1.6255, Acc=0.5782\n",
      "[Studygroup][1088] CNN Loss=0.8718, Acc=0.6730 | MLP Loss=1.6887, Acc=0.5662\n",
      "[Studygroup][1089] CNN Loss=0.8870, Acc=0.6676 | MLP Loss=1.7096, Acc=0.5654\n",
      "[Studygroup][1090] CNN Loss=0.8890, Acc=0.6705 | MLP Loss=1.7186, Acc=0.5699\n",
      "[Studygroup][1091] CNN Loss=0.9264, Acc=0.6793 | MLP Loss=1.6490, Acc=0.5791\n",
      "[Studygroup][1092] CNN Loss=0.9019, Acc=0.6730 | MLP Loss=1.7027, Acc=0.5784\n",
      "[Studygroup][1093] CNN Loss=0.8912, Acc=0.6712 | MLP Loss=1.6548, Acc=0.5598\n",
      "[Studygroup][1094] CNN Loss=0.8595, Acc=0.6747 | MLP Loss=1.6655, Acc=0.5738\n",
      "[Studygroup][1095] CNN Loss=0.8801, Acc=0.6619 | MLP Loss=1.6268, Acc=0.5802\n",
      "[Studygroup][1096] CNN Loss=0.9762, Acc=0.6703 | MLP Loss=1.6047, Acc=0.5725\n",
      "[Studygroup][1097] CNN Loss=1.0404, Acc=0.6716 | MLP Loss=1.6573, Acc=0.5705\n",
      "[Studygroup][1098] CNN Loss=0.9738, Acc=0.6718 | MLP Loss=1.5565, Acc=0.5737\n",
      "[Studygroup][1099] CNN Loss=0.8360, Acc=0.6768 | MLP Loss=1.6713, Acc=0.5740\n",
      "[Studygroup][1100] CNN Loss=0.9441, Acc=0.6711 | MLP Loss=1.7483, Acc=0.5668\n",
      "[Studygroup][1101] CNN Loss=0.8916, Acc=0.6724 | MLP Loss=1.6922, Acc=0.5813\n",
      "[Studygroup][1102] CNN Loss=0.8468, Acc=0.6762 | MLP Loss=1.6428, Acc=0.5854\n",
      "[Studygroup][1103] CNN Loss=0.8811, Acc=0.6736 | MLP Loss=1.6679, Acc=0.5752\n",
      "[Studygroup][1104] CNN Loss=0.9179, Acc=0.6756 | MLP Loss=1.6546, Acc=0.5573\n",
      "[Studygroup][1105] CNN Loss=0.9062, Acc=0.6798 | MLP Loss=1.7170, Acc=0.5673\n",
      "[Studygroup][1106] CNN Loss=0.8917, Acc=0.6718 | MLP Loss=1.7351, Acc=0.5763\n",
      "[Studygroup][1107] CNN Loss=0.8490, Acc=0.6758 | MLP Loss=1.6699, Acc=0.5859\n",
      "[Studygroup][1108] CNN Loss=0.8320, Acc=0.6770 | MLP Loss=1.6076, Acc=0.5938\n",
      "[Studygroup][1109] CNN Loss=0.9572, Acc=0.6799 | MLP Loss=1.7171, Acc=0.5645\n",
      "[Studygroup][1110] CNN Loss=0.9661, Acc=0.6704 | MLP Loss=1.7465, Acc=0.5683\n",
      "[Studygroup][1111] CNN Loss=0.8729, Acc=0.6781 | MLP Loss=1.6049, Acc=0.5615\n",
      "[Studygroup][1112] CNN Loss=1.0065, Acc=0.6639 | MLP Loss=1.7656, Acc=0.5638\n",
      "[Studygroup][1113] CNN Loss=1.0079, Acc=0.6706 | MLP Loss=1.6280, Acc=0.5707\n",
      "[Studygroup][1114] CNN Loss=0.9728, Acc=0.6558 | MLP Loss=1.6277, Acc=0.5830\n",
      "[Studygroup][1115] CNN Loss=0.8610, Acc=0.6739 | MLP Loss=1.6742, Acc=0.5616\n",
      "[Studygroup][1116] CNN Loss=0.9578, Acc=0.6683 | MLP Loss=1.7120, Acc=0.5613\n",
      "[Studygroup][1117] CNN Loss=0.8610, Acc=0.6804 | MLP Loss=1.7370, Acc=0.5725\n",
      "[Studygroup][1118] CNN Loss=0.8580, Acc=0.6825 | MLP Loss=1.6980, Acc=0.5797\n",
      "[Studygroup][1119] CNN Loss=0.9394, Acc=0.6740 | MLP Loss=1.6971, Acc=0.5634\n",
      "[Studygroup][1120] CNN Loss=0.9728, Acc=0.6760 | MLP Loss=1.7503, Acc=0.5695\n",
      "[Studygroup][1121] CNN Loss=1.0212, Acc=0.6789 | MLP Loss=1.7100, Acc=0.5787\n",
      "[Studygroup][1122] CNN Loss=0.9143, Acc=0.6652 | MLP Loss=1.6175, Acc=0.5807\n",
      "[Studygroup][1123] CNN Loss=0.8401, Acc=0.6781 | MLP Loss=1.5753, Acc=0.5713\n",
      "[Studygroup][1124] CNN Loss=0.8589, Acc=0.6738 | MLP Loss=1.6566, Acc=0.5828\n",
      "[Studygroup][1125] CNN Loss=0.9082, Acc=0.6717 | MLP Loss=1.6292, Acc=0.5691\n",
      "[Studygroup][1126] CNN Loss=1.0603, Acc=0.6686 | MLP Loss=1.6715, Acc=0.5805\n",
      "[Studygroup][1127] CNN Loss=0.9340, Acc=0.6719 | MLP Loss=1.6185, Acc=0.5672\n",
      "[Studygroup][1128] CNN Loss=0.9081, Acc=0.6698 | MLP Loss=1.6330, Acc=0.5807\n",
      "[Studygroup][1129] CNN Loss=0.9086, Acc=0.6805 | MLP Loss=1.6876, Acc=0.5849\n",
      "[Studygroup][1130] CNN Loss=0.8282, Acc=0.6752 | MLP Loss=1.6369, Acc=0.5775\n",
      "[Studygroup][1131] CNN Loss=0.9249, Acc=0.6738 | MLP Loss=1.6338, Acc=0.5727\n",
      "[Studygroup][1132] CNN Loss=0.9149, Acc=0.6744 | MLP Loss=1.6215, Acc=0.5778\n",
      "[Studygroup][1133] CNN Loss=0.8196, Acc=0.6790 | MLP Loss=1.6212, Acc=0.5718\n",
      "[Studygroup][1134] CNN Loss=0.8871, Acc=0.6720 | MLP Loss=1.6857, Acc=0.5827\n",
      "[Studygroup][1135] CNN Loss=0.9056, Acc=0.6795 | MLP Loss=1.6853, Acc=0.5783\n",
      "[Studygroup][1136] CNN Loss=0.9233, Acc=0.6810 | MLP Loss=1.6913, Acc=0.5741\n",
      "[Studygroup][1137] CNN Loss=1.0384, Acc=0.6705 | MLP Loss=1.6652, Acc=0.5788\n",
      "[Studygroup][1138] CNN Loss=0.9067, Acc=0.6740 | MLP Loss=1.7166, Acc=0.5583\n",
      "[Studygroup][1139] CNN Loss=0.9339, Acc=0.6733 | MLP Loss=1.6602, Acc=0.5784\n",
      "[Studygroup][1140] CNN Loss=0.9101, Acc=0.6784 | MLP Loss=1.5894, Acc=0.5797\n",
      "[Studygroup][1141] CNN Loss=0.9012, Acc=0.6733 | MLP Loss=1.6142, Acc=0.5815\n",
      "[Studygroup][1142] CNN Loss=0.9291, Acc=0.6780 | MLP Loss=1.6708, Acc=0.5587\n",
      "[Studygroup][1143] CNN Loss=0.9177, Acc=0.6697 | MLP Loss=1.7221, Acc=0.5779\n",
      "[Studygroup][1144] CNN Loss=0.8944, Acc=0.6773 | MLP Loss=1.5889, Acc=0.5689\n",
      "[Studygroup][1145] CNN Loss=0.9229, Acc=0.6712 | MLP Loss=1.6345, Acc=0.5820\n",
      "[Studygroup][1146] CNN Loss=0.9156, Acc=0.6755 | MLP Loss=1.6335, Acc=0.5864\n",
      "[Studygroup][1147] CNN Loss=0.9310, Acc=0.6599 | MLP Loss=1.6100, Acc=0.5781\n",
      "[Studygroup][1148] CNN Loss=0.9241, Acc=0.6776 | MLP Loss=1.5771, Acc=0.5782\n",
      "[Studygroup][1149] CNN Loss=0.8785, Acc=0.6765 | MLP Loss=1.6328, Acc=0.5799\n",
      "[Studygroup][1150] CNN Loss=0.9217, Acc=0.6771 | MLP Loss=1.6576, Acc=0.5748\n",
      "[Studygroup][1151] CNN Loss=0.9255, Acc=0.6748 | MLP Loss=1.6425, Acc=0.5815\n",
      "[Studygroup][1152] CNN Loss=0.9312, Acc=0.6629 | MLP Loss=1.6766, Acc=0.5662\n",
      "[Studygroup][1153] CNN Loss=1.0440, Acc=0.6787 | MLP Loss=1.7375, Acc=0.5763\n",
      "[Studygroup][1154] CNN Loss=0.9249, Acc=0.6756 | MLP Loss=1.6593, Acc=0.5866\n",
      "[Studygroup][1155] CNN Loss=0.9378, Acc=0.6819 | MLP Loss=1.5967, Acc=0.5864\n",
      "[Studygroup][1156] CNN Loss=0.8637, Acc=0.6780 | MLP Loss=1.6538, Acc=0.5770\n",
      "[Studygroup][1157] CNN Loss=0.9207, Acc=0.6680 | MLP Loss=1.7265, Acc=0.5784\n",
      "[Studygroup][1158] CNN Loss=0.8704, Acc=0.6744 | MLP Loss=1.6437, Acc=0.5844\n",
      "[Studygroup][1159] CNN Loss=0.8501, Acc=0.6782 | MLP Loss=1.5838, Acc=0.5678\n",
      "[Studygroup][1160] CNN Loss=0.9504, Acc=0.6736 | MLP Loss=1.6937, Acc=0.5868\n",
      "[Studygroup][1161] CNN Loss=0.9756, Acc=0.6722 | MLP Loss=1.6242, Acc=0.5710\n",
      "[Studygroup][1162] CNN Loss=0.9548, Acc=0.6767 | MLP Loss=1.6517, Acc=0.5763\n",
      "[Studygroup][1163] CNN Loss=0.8635, Acc=0.6801 | MLP Loss=1.6668, Acc=0.5756\n",
      "[Studygroup][1164] CNN Loss=0.8819, Acc=0.6818 | MLP Loss=1.6540, Acc=0.5800\n",
      "[Studygroup][1165] CNN Loss=0.9210, Acc=0.6748 | MLP Loss=1.5691, Acc=0.5723\n",
      "[Studygroup][1166] CNN Loss=0.8584, Acc=0.6776 | MLP Loss=1.6001, Acc=0.5758\n",
      "[Studygroup][1167] CNN Loss=0.9250, Acc=0.6730 | MLP Loss=1.7092, Acc=0.5781\n",
      "[Studygroup][1168] CNN Loss=0.8891, Acc=0.6769 | MLP Loss=1.6181, Acc=0.5863\n",
      "[Studygroup][1169] CNN Loss=0.8573, Acc=0.6801 | MLP Loss=1.6554, Acc=0.5846\n",
      "[Studygroup][1170] CNN Loss=0.8447, Acc=0.6727 | MLP Loss=1.6138, Acc=0.5849\n",
      "[Studygroup][1171] CNN Loss=0.9571, Acc=0.6780 | MLP Loss=1.6144, Acc=0.5856\n",
      "[Studygroup][1172] CNN Loss=0.8902, Acc=0.6692 | MLP Loss=1.6620, Acc=0.5784\n",
      "[Studygroup][1173] CNN Loss=0.8832, Acc=0.6767 | MLP Loss=1.6707, Acc=0.5833\n",
      "[Studygroup][1174] CNN Loss=1.0201, Acc=0.6698 | MLP Loss=1.6427, Acc=0.5809\n",
      "[Studygroup][1175] CNN Loss=0.9598, Acc=0.6678 | MLP Loss=1.6748, Acc=0.5804\n",
      "[Studygroup][1176] CNN Loss=0.9339, Acc=0.6637 | MLP Loss=1.6415, Acc=0.5831\n",
      "[Studygroup][1177] CNN Loss=0.8758, Acc=0.6763 | MLP Loss=1.5981, Acc=0.5738\n",
      "[Studygroup][1178] CNN Loss=0.9093, Acc=0.6716 | MLP Loss=1.6646, Acc=0.5585\n",
      "[Studygroup][1179] CNN Loss=0.9210, Acc=0.6781 | MLP Loss=1.7622, Acc=0.5628\n",
      "[Studygroup][1180] CNN Loss=0.8645, Acc=0.6788 | MLP Loss=1.6633, Acc=0.5862\n",
      "[Studygroup][1181] CNN Loss=0.9564, Acc=0.6782 | MLP Loss=1.6739, Acc=0.5809\n",
      "[Studygroup][1182] CNN Loss=0.9498, Acc=0.6757 | MLP Loss=1.6195, Acc=0.5721\n",
      "[Studygroup][1183] CNN Loss=0.8824, Acc=0.6678 | MLP Loss=1.6499, Acc=0.5787\n",
      "[Studygroup][1184] CNN Loss=0.8448, Acc=0.6785 | MLP Loss=1.6059, Acc=0.5756\n",
      "[Studygroup][1185] CNN Loss=0.9443, Acc=0.6771 | MLP Loss=1.6193, Acc=0.5819\n",
      "[Studygroup][1186] CNN Loss=0.9143, Acc=0.6770 | MLP Loss=1.6327, Acc=0.5675\n",
      "[Studygroup][1187] CNN Loss=0.8728, Acc=0.6765 | MLP Loss=1.6773, Acc=0.5810\n",
      "[Studygroup][1188] CNN Loss=0.8833, Acc=0.6804 | MLP Loss=1.6085, Acc=0.5889\n",
      "[Studygroup][1189] CNN Loss=0.9431, Acc=0.6742 | MLP Loss=1.6819, Acc=0.5812\n",
      "[Studygroup][1190] CNN Loss=0.9370, Acc=0.6787 | MLP Loss=1.6684, Acc=0.5821\n",
      "[Studygroup][1191] CNN Loss=0.8889, Acc=0.6832 | MLP Loss=1.6331, Acc=0.5733\n",
      "[Studygroup][1192] CNN Loss=0.8362, Acc=0.6800 | MLP Loss=1.6673, Acc=0.5726\n",
      "[Studygroup][1193] CNN Loss=0.8648, Acc=0.6786 | MLP Loss=1.7084, Acc=0.5681\n",
      "[Studygroup][1194] CNN Loss=0.9084, Acc=0.6777 | MLP Loss=1.7044, Acc=0.5697\n",
      "[Studygroup][1195] CNN Loss=0.9511, Acc=0.6750 | MLP Loss=1.7433, Acc=0.5667\n",
      "[Studygroup][1196] CNN Loss=0.9011, Acc=0.6790 | MLP Loss=1.6743, Acc=0.5713\n",
      "[Studygroup][1197] CNN Loss=0.8841, Acc=0.6771 | MLP Loss=1.7648, Acc=0.5695\n",
      "[Studygroup][1198] CNN Loss=0.8565, Acc=0.6760 | MLP Loss=1.6721, Acc=0.5774\n",
      "[Studygroup][1199] CNN Loss=0.8324, Acc=0.6811 | MLP Loss=1.6724, Acc=0.5834\n",
      "[Studygroup][1200] CNN Loss=0.9345, Acc=0.6724 | MLP Loss=1.7071, Acc=0.5774\n",
      "[Studygroup][1201] CNN Loss=0.8909, Acc=0.6804 | MLP Loss=1.6576, Acc=0.5826\n",
      "[Studygroup][1202] CNN Loss=0.9035, Acc=0.6792 | MLP Loss=1.5990, Acc=0.5870\n",
      "[Studygroup][1203] CNN Loss=0.8662, Acc=0.6794 | MLP Loss=1.6072, Acc=0.5792\n",
      "[Studygroup][1204] CNN Loss=0.8145, Acc=0.6835 | MLP Loss=1.6694, Acc=0.5780\n",
      "[Studygroup][1205] CNN Loss=0.9408, Acc=0.6840 | MLP Loss=1.6416, Acc=0.5772\n",
      "[Studygroup][1206] CNN Loss=0.9191, Acc=0.6761 | MLP Loss=1.6944, Acc=0.5802\n",
      "[Studygroup][1207] CNN Loss=0.8410, Acc=0.6794 | MLP Loss=1.5842, Acc=0.5766\n",
      "[Studygroup][1208] CNN Loss=0.8590, Acc=0.6827 | MLP Loss=1.5938, Acc=0.5869\n",
      "[Studygroup][1209] CNN Loss=1.0633, Acc=0.6741 | MLP Loss=1.7650, Acc=0.5743\n",
      "[Studygroup][1210] CNN Loss=0.9932, Acc=0.6738 | MLP Loss=1.8487, Acc=0.5571\n",
      "[Studygroup][1211] CNN Loss=0.9295, Acc=0.6739 | MLP Loss=1.8064, Acc=0.5656\n",
      "[Studygroup][1212] CNN Loss=0.9868, Acc=0.6556 | MLP Loss=1.6963, Acc=0.5722\n",
      "[Studygroup][1213] CNN Loss=0.9071, Acc=0.6788 | MLP Loss=1.6541, Acc=0.5609\n",
      "[Studygroup][1214] CNN Loss=0.9736, Acc=0.6745 | MLP Loss=1.6002, Acc=0.5790\n",
      "[Studygroup][1215] CNN Loss=1.0021, Acc=0.6766 | MLP Loss=1.7193, Acc=0.5854\n",
      "[Studygroup][1216] CNN Loss=0.9397, Acc=0.6771 | MLP Loss=1.6335, Acc=0.5783\n",
      "[Studygroup][1217] CNN Loss=0.8835, Acc=0.6833 | MLP Loss=1.6273, Acc=0.5815\n",
      "[Studygroup][1218] CNN Loss=0.9378, Acc=0.6634 | MLP Loss=1.6866, Acc=0.5843\n",
      "[Studygroup][1219] CNN Loss=0.8740, Acc=0.6757 | MLP Loss=1.6281, Acc=0.5752\n",
      "[Studygroup][1220] CNN Loss=0.8801, Acc=0.6749 | MLP Loss=1.5622, Acc=0.5827\n",
      "[Studygroup][1221] CNN Loss=0.8386, Acc=0.6729 | MLP Loss=1.6299, Acc=0.5725\n",
      "[Studygroup][1222] CNN Loss=0.9116, Acc=0.6752 | MLP Loss=1.6331, Acc=0.5874\n",
      "[Studygroup][1223] CNN Loss=0.9154, Acc=0.6737 | MLP Loss=1.6065, Acc=0.5868\n",
      "[Studygroup][1224] CNN Loss=0.8594, Acc=0.6769 | MLP Loss=1.6018, Acc=0.5850\n",
      "[Studygroup][1225] CNN Loss=0.8612, Acc=0.6733 | MLP Loss=1.6580, Acc=0.5861\n",
      "[Studygroup][1226] CNN Loss=1.0275, Acc=0.6587 | MLP Loss=1.8005, Acc=0.5692\n",
      "[Studygroup][1227] CNN Loss=0.9034, Acc=0.6756 | MLP Loss=1.8482, Acc=0.5739\n",
      "[Studygroup][1228] CNN Loss=0.8864, Acc=0.6759 | MLP Loss=1.6529, Acc=0.5760\n",
      "[Studygroup][1229] CNN Loss=0.8865, Acc=0.6794 | MLP Loss=1.7088, Acc=0.5776\n",
      "[Studygroup][1230] CNN Loss=0.9789, Acc=0.6812 | MLP Loss=1.6515, Acc=0.5796\n",
      "[Studygroup][1231] CNN Loss=0.8875, Acc=0.6712 | MLP Loss=1.6670, Acc=0.5770\n",
      "[Studygroup][1232] CNN Loss=0.9604, Acc=0.6670 | MLP Loss=1.7199, Acc=0.5739\n",
      "[Studygroup][1233] CNN Loss=0.8985, Acc=0.6826 | MLP Loss=1.6893, Acc=0.5808\n",
      "[Studygroup][1234] CNN Loss=0.9294, Acc=0.6802 | MLP Loss=1.5762, Acc=0.5867\n",
      "[Studygroup][1235] CNN Loss=0.9198, Acc=0.6778 | MLP Loss=1.6077, Acc=0.5895\n",
      "[Studygroup][1236] CNN Loss=0.9168, Acc=0.6690 | MLP Loss=1.6830, Acc=0.5733\n",
      "[Studygroup][1237] CNN Loss=0.8796, Acc=0.6688 | MLP Loss=1.6711, Acc=0.5790\n",
      "[Studygroup][1238] CNN Loss=0.9090, Acc=0.6825 | MLP Loss=1.7153, Acc=0.5827\n",
      "[Studygroup][1239] CNN Loss=0.9132, Acc=0.6774 | MLP Loss=1.6674, Acc=0.5866\n",
      "[Studygroup][1240] CNN Loss=1.0178, Acc=0.6682 | MLP Loss=1.6460, Acc=0.5770\n",
      "[Studygroup][1241] CNN Loss=0.8461, Acc=0.6758 | MLP Loss=1.6296, Acc=0.5728\n",
      "[Studygroup][1242] CNN Loss=0.8498, Acc=0.6761 | MLP Loss=1.6268, Acc=0.5836\n",
      "[Studygroup][1243] CNN Loss=0.8896, Acc=0.6697 | MLP Loss=1.6192, Acc=0.5775\n",
      "[Studygroup][1244] CNN Loss=0.8482, Acc=0.6800 | MLP Loss=1.6674, Acc=0.5881\n",
      "[Studygroup][1245] CNN Loss=0.9472, Acc=0.6833 | MLP Loss=1.6783, Acc=0.5843\n",
      "[Studygroup][1246] CNN Loss=0.9252, Acc=0.6788 | MLP Loss=1.6659, Acc=0.5945\n",
      "[Studygroup][1247] CNN Loss=1.0482, Acc=0.6746 | MLP Loss=1.7402, Acc=0.5852\n",
      "[Studygroup][1248] CNN Loss=0.8678, Acc=0.6765 | MLP Loss=1.6386, Acc=0.5873\n",
      "[Studygroup][1249] CNN Loss=0.8751, Acc=0.6779 | MLP Loss=1.6793, Acc=0.5792\n",
      "[Studygroup][1250] CNN Loss=0.8538, Acc=0.6721 | MLP Loss=1.6972, Acc=0.5856\n",
      "[Studygroup][1251] CNN Loss=0.8480, Acc=0.6796 | MLP Loss=1.6627, Acc=0.5729\n",
      "[Studygroup][1252] CNN Loss=0.8825, Acc=0.6794 | MLP Loss=1.6142, Acc=0.5918\n",
      "[Studygroup][1253] CNN Loss=0.8500, Acc=0.6783 | MLP Loss=1.6348, Acc=0.5789\n",
      "[Studygroup][1254] CNN Loss=0.8369, Acc=0.6797 | MLP Loss=1.7281, Acc=0.5761\n",
      "[Studygroup][1255] CNN Loss=0.9599, Acc=0.6777 | MLP Loss=1.8312, Acc=0.5717\n",
      "[Studygroup][1256] CNN Loss=0.8931, Acc=0.6781 | MLP Loss=1.6492, Acc=0.5801\n",
      "[Studygroup][1257] CNN Loss=0.9292, Acc=0.6778 | MLP Loss=1.6873, Acc=0.5950\n",
      "[Studygroup][1258] CNN Loss=0.8654, Acc=0.6745 | MLP Loss=1.6058, Acc=0.5709\n",
      "[Studygroup][1259] CNN Loss=0.9013, Acc=0.6723 | MLP Loss=1.6508, Acc=0.5787\n",
      "[Studygroup][1260] CNN Loss=0.8661, Acc=0.6820 | MLP Loss=1.6649, Acc=0.5880\n",
      "[Studygroup][1261] CNN Loss=0.9543, Acc=0.6753 | MLP Loss=1.6033, Acc=0.5696\n",
      "[Studygroup][1262] CNN Loss=0.8680, Acc=0.6733 | MLP Loss=1.7207, Acc=0.5897\n",
      "[Studygroup][1263] CNN Loss=0.9154, Acc=0.6739 | MLP Loss=1.6690, Acc=0.5798\n",
      "[Studygroup][1264] CNN Loss=0.9238, Acc=0.6789 | MLP Loss=1.6890, Acc=0.5833\n",
      "[Studygroup][1265] CNN Loss=0.8837, Acc=0.6768 | MLP Loss=1.6774, Acc=0.5782\n",
      "[Studygroup][1266] CNN Loss=1.0147, Acc=0.6642 | MLP Loss=1.6570, Acc=0.5622\n",
      "[Studygroup][1267] CNN Loss=0.9352, Acc=0.6691 | MLP Loss=1.6226, Acc=0.5855\n",
      "[Studygroup][1268] CNN Loss=0.8706, Acc=0.6820 | MLP Loss=1.7611, Acc=0.5756\n",
      "[Studygroup][1269] CNN Loss=0.8765, Acc=0.6701 | MLP Loss=1.6973, Acc=0.5781\n",
      "[Studygroup][1270] CNN Loss=0.8365, Acc=0.6808 | MLP Loss=1.6151, Acc=0.5817\n",
      "[Studygroup][1271] CNN Loss=0.8457, Acc=0.6805 | MLP Loss=1.6732, Acc=0.5840\n",
      "[Studygroup][1272] CNN Loss=0.9294, Acc=0.6730 | MLP Loss=1.6760, Acc=0.5766\n",
      "[Studygroup][1273] CNN Loss=0.8598, Acc=0.6780 | MLP Loss=1.8465, Acc=0.5672\n",
      "[Studygroup][1274] CNN Loss=0.9048, Acc=0.6769 | MLP Loss=1.7940, Acc=0.5864\n",
      "[Studygroup][1275] CNN Loss=0.9170, Acc=0.6699 | MLP Loss=1.5803, Acc=0.5900\n",
      "[Studygroup][1276] CNN Loss=0.9263, Acc=0.6781 | MLP Loss=1.5571, Acc=0.5817\n",
      "[Studygroup][1277] CNN Loss=0.9174, Acc=0.6742 | MLP Loss=1.6492, Acc=0.5867\n",
      "[Studygroup][1278] CNN Loss=0.8467, Acc=0.6711 | MLP Loss=1.5763, Acc=0.5859\n",
      "[Studygroup][1279] CNN Loss=0.8685, Acc=0.6818 | MLP Loss=1.6674, Acc=0.5844\n",
      "[Studygroup][1280] CNN Loss=0.9209, Acc=0.6746 | MLP Loss=1.6262, Acc=0.5751\n",
      "[Studygroup][1281] CNN Loss=0.9061, Acc=0.6787 | MLP Loss=1.6365, Acc=0.5867\n",
      "[Studygroup][1282] CNN Loss=0.8582, Acc=0.6730 | MLP Loss=1.6466, Acc=0.5780\n",
      "[Studygroup][1283] CNN Loss=0.9972, Acc=0.6757 | MLP Loss=1.5687, Acc=0.5899\n",
      "[Studygroup][1284] CNN Loss=0.8999, Acc=0.6799 | MLP Loss=1.5795, Acc=0.5821\n",
      "[Studygroup][1285] CNN Loss=0.8775, Acc=0.6755 | MLP Loss=1.6329, Acc=0.5785\n",
      "[Studygroup][1286] CNN Loss=0.9479, Acc=0.6715 | MLP Loss=1.6056, Acc=0.5888\n",
      "[Studygroup][1287] CNN Loss=0.8359, Acc=0.6789 | MLP Loss=1.5733, Acc=0.5722\n",
      "[Studygroup][1288] CNN Loss=0.8755, Acc=0.6807 | MLP Loss=1.5990, Acc=0.5761\n",
      "[Studygroup][1289] CNN Loss=0.8496, Acc=0.6751 | MLP Loss=1.5707, Acc=0.5875\n",
      "[Studygroup][1290] CNN Loss=0.8433, Acc=0.6852 | MLP Loss=1.6193, Acc=0.5884\n",
      "[Studygroup][1291] CNN Loss=0.8634, Acc=0.6780 | MLP Loss=1.8003, Acc=0.5811\n",
      "[Studygroup][1292] CNN Loss=0.8510, Acc=0.6799 | MLP Loss=1.6796, Acc=0.5838\n",
      "[Studygroup][1293] CNN Loss=0.8417, Acc=0.6805 | MLP Loss=1.7246, Acc=0.5778\n",
      "[Studygroup][1294] CNN Loss=0.8254, Acc=0.6763 | MLP Loss=1.6070, Acc=0.5938\n",
      "[Studygroup][1295] CNN Loss=0.9232, Acc=0.6571 | MLP Loss=1.6311, Acc=0.5833\n",
      "[Studygroup][1296] CNN Loss=0.9273, Acc=0.6755 | MLP Loss=1.6860, Acc=0.5846\n",
      "[Studygroup][1297] CNN Loss=0.9086, Acc=0.6760 | MLP Loss=1.6308, Acc=0.5799\n",
      "[Studygroup][1298] CNN Loss=0.9068, Acc=0.6804 | MLP Loss=1.6641, Acc=0.5793\n",
      "[Studygroup][1299] CNN Loss=0.8824, Acc=0.6793 | MLP Loss=1.6817, Acc=0.5884\n",
      "[Studygroup][1300] CNN Loss=0.8122, Acc=0.6822 | MLP Loss=1.5981, Acc=0.5890\n",
      "[Studygroup][1301] CNN Loss=0.9722, Acc=0.6751 | MLP Loss=1.6880, Acc=0.5795\n",
      "[Studygroup][1302] CNN Loss=0.8623, Acc=0.6799 | MLP Loss=1.6785, Acc=0.5821\n",
      "[Studygroup][1303] CNN Loss=0.9352, Acc=0.6781 | MLP Loss=1.7064, Acc=0.5850\n",
      "[Studygroup][1304] CNN Loss=0.7844, Acc=0.6815 | MLP Loss=1.5902, Acc=0.5863\n",
      "[Studygroup][1305] CNN Loss=0.8413, Acc=0.6838 | MLP Loss=1.6541, Acc=0.5836\n",
      "[Studygroup][1306] CNN Loss=0.9098, Acc=0.6715 | MLP Loss=1.6321, Acc=0.5810\n",
      "[Studygroup][1307] CNN Loss=0.8744, Acc=0.6779 | MLP Loss=1.6484, Acc=0.5869\n",
      "[Studygroup][1308] CNN Loss=0.9553, Acc=0.6651 | MLP Loss=1.6334, Acc=0.5811\n",
      "[Studygroup][1309] CNN Loss=0.9232, Acc=0.6788 | MLP Loss=1.6518, Acc=0.5706\n",
      "[Studygroup][1310] CNN Loss=0.8495, Acc=0.6802 | MLP Loss=1.7058, Acc=0.5842\n",
      "[Studygroup][1311] CNN Loss=0.9237, Acc=0.6730 | MLP Loss=1.6520, Acc=0.5702\n",
      "[Studygroup][1312] CNN Loss=0.9048, Acc=0.6820 | MLP Loss=1.6424, Acc=0.5708\n",
      "[Studygroup][1313] CNN Loss=0.8940, Acc=0.6744 | MLP Loss=1.6259, Acc=0.5760\n",
      "[Studygroup][1314] CNN Loss=0.8636, Acc=0.6734 | MLP Loss=1.6820, Acc=0.5902\n",
      "[Studygroup][1315] CNN Loss=0.8928, Acc=0.6770 | MLP Loss=1.6700, Acc=0.5830\n",
      "[Studygroup][1316] CNN Loss=0.8803, Acc=0.6828 | MLP Loss=1.7521, Acc=0.5861\n",
      "[Studygroup][1317] CNN Loss=0.8231, Acc=0.6822 | MLP Loss=1.6784, Acc=0.5848\n",
      "[Studygroup][1318] CNN Loss=0.8061, Acc=0.6769 | MLP Loss=1.6658, Acc=0.5769\n",
      "[Studygroup][1319] CNN Loss=0.9250, Acc=0.6757 | MLP Loss=1.6704, Acc=0.5845\n",
      "[Studygroup][1320] CNN Loss=1.0623, Acc=0.6709 | MLP Loss=1.7430, Acc=0.5901\n",
      "[Studygroup][1321] CNN Loss=0.8523, Acc=0.6707 | MLP Loss=1.6511, Acc=0.5779\n",
      "[Studygroup][1322] CNN Loss=0.9428, Acc=0.6738 | MLP Loss=1.6930, Acc=0.5800\n",
      "[Studygroup][1323] CNN Loss=0.9113, Acc=0.6792 | MLP Loss=1.6231, Acc=0.5766\n",
      "[Studygroup][1324] CNN Loss=0.9105, Acc=0.6806 | MLP Loss=1.6637, Acc=0.5828\n",
      "[Studygroup][1325] CNN Loss=0.8598, Acc=0.6744 | MLP Loss=1.6781, Acc=0.5775\n",
      "[Studygroup][1326] CNN Loss=0.8430, Acc=0.6792 | MLP Loss=1.5976, Acc=0.5911\n",
      "[Studygroup][1327] CNN Loss=0.8421, Acc=0.6739 | MLP Loss=1.6106, Acc=0.5888\n",
      "[Studygroup][1328] CNN Loss=0.9032, Acc=0.6834 | MLP Loss=1.6453, Acc=0.5788\n",
      "[Studygroup][1329] CNN Loss=0.9306, Acc=0.6784 | MLP Loss=1.6744, Acc=0.5788\n",
      "[Studygroup][1330] CNN Loss=0.9945, Acc=0.6753 | MLP Loss=1.7207, Acc=0.5730\n",
      "[Studygroup][1331] CNN Loss=0.9030, Acc=0.6778 | MLP Loss=1.6572, Acc=0.5865\n",
      "[Studygroup][1332] CNN Loss=0.8411, Acc=0.6814 | MLP Loss=1.6732, Acc=0.5853\n",
      "[Studygroup][1333] CNN Loss=0.8172, Acc=0.6771 | MLP Loss=1.6584, Acc=0.5742\n",
      "[Studygroup][1334] CNN Loss=0.8352, Acc=0.6784 | MLP Loss=1.6902, Acc=0.5747\n",
      "[Studygroup][1335] CNN Loss=0.9380, Acc=0.6797 | MLP Loss=1.7086, Acc=0.5881\n",
      "[Studygroup][1336] CNN Loss=0.8563, Acc=0.6776 | MLP Loss=1.6958, Acc=0.5908\n",
      "[Studygroup][1337] CNN Loss=0.8552, Acc=0.6729 | MLP Loss=1.7296, Acc=0.5892\n",
      "[Studygroup][1338] CNN Loss=0.9060, Acc=0.6742 | MLP Loss=1.6184, Acc=0.5876\n",
      "[Studygroup][1339] CNN Loss=0.8463, Acc=0.6813 | MLP Loss=1.7375, Acc=0.5859\n",
      "[Studygroup][1340] CNN Loss=0.9765, Acc=0.6856 | MLP Loss=1.7399, Acc=0.5861\n",
      "[Studygroup][1341] CNN Loss=0.7734, Acc=0.6789 | MLP Loss=1.7428, Acc=0.5886\n",
      "[Studygroup][1342] CNN Loss=0.9218, Acc=0.6673 | MLP Loss=1.6861, Acc=0.5864\n",
      "[Studygroup][1343] CNN Loss=0.9546, Acc=0.6813 | MLP Loss=1.6367, Acc=0.5917\n",
      "[Studygroup][1344] CNN Loss=0.9346, Acc=0.6734 | MLP Loss=1.7602, Acc=0.5848\n",
      "[Studygroup][1345] CNN Loss=1.0752, Acc=0.6726 | MLP Loss=1.7211, Acc=0.5705\n",
      "[Studygroup][1346] CNN Loss=0.9018, Acc=0.6817 | MLP Loss=1.6368, Acc=0.5808\n",
      "[Studygroup][1347] CNN Loss=0.8633, Acc=0.6714 | MLP Loss=1.6900, Acc=0.5893\n",
      "[Studygroup][1348] CNN Loss=0.8020, Acc=0.6833 | MLP Loss=1.7286, Acc=0.5817\n",
      "[Studygroup][1349] CNN Loss=0.9015, Acc=0.6786 | MLP Loss=1.7971, Acc=0.5892\n",
      "[Studygroup][1350] CNN Loss=0.8945, Acc=0.6801 | MLP Loss=1.6199, Acc=0.5771\n",
      "[Studygroup][1351] CNN Loss=0.8971, Acc=0.6811 | MLP Loss=1.6439, Acc=0.5920\n",
      "[Studygroup][1352] CNN Loss=0.9037, Acc=0.6793 | MLP Loss=1.6634, Acc=0.5828\n",
      "[Studygroup][1353] CNN Loss=0.9132, Acc=0.6760 | MLP Loss=1.6517, Acc=0.5917\n",
      "[Studygroup][1354] CNN Loss=0.7898, Acc=0.6708 | MLP Loss=1.5550, Acc=0.5928\n",
      "[Studygroup][1355] CNN Loss=0.8833, Acc=0.6787 | MLP Loss=1.6644, Acc=0.5865\n",
      "[Studygroup][1356] CNN Loss=0.9609, Acc=0.6707 | MLP Loss=1.6726, Acc=0.5708\n",
      "[Studygroup][1357] CNN Loss=1.0081, Acc=0.6730 | MLP Loss=1.9176, Acc=0.5684\n",
      "[Studygroup][1358] CNN Loss=1.0394, Acc=0.6722 | MLP Loss=1.6912, Acc=0.5826\n",
      "[Studygroup][1359] CNN Loss=0.9119, Acc=0.6660 | MLP Loss=1.6801, Acc=0.5844\n",
      "[Studygroup][1360] CNN Loss=1.0056, Acc=0.6736 | MLP Loss=1.6843, Acc=0.5668\n",
      "[Studygroup][1361] CNN Loss=0.8933, Acc=0.6763 | MLP Loss=1.6863, Acc=0.5908\n",
      "[Studygroup][1362] CNN Loss=0.9126, Acc=0.6733 | MLP Loss=1.6244, Acc=0.5734\n",
      "[Studygroup][1363] CNN Loss=0.8869, Acc=0.6776 | MLP Loss=1.6830, Acc=0.5707\n",
      "[Studygroup][1364] CNN Loss=0.8810, Acc=0.6768 | MLP Loss=1.6170, Acc=0.5832\n",
      "[Studygroup][1365] CNN Loss=0.8750, Acc=0.6741 | MLP Loss=1.7802, Acc=0.5795\n",
      "[Studygroup][1366] CNN Loss=0.9249, Acc=0.6816 | MLP Loss=1.7048, Acc=0.5773\n",
      "[Studygroup][1367] CNN Loss=0.8762, Acc=0.6734 | MLP Loss=1.5886, Acc=0.5904\n",
      "[Studygroup][1368] CNN Loss=0.8487, Acc=0.6774 | MLP Loss=1.6344, Acc=0.5880\n",
      "[Studygroup][1369] CNN Loss=0.8895, Acc=0.6700 | MLP Loss=1.6678, Acc=0.5845\n",
      "[Studygroup][1370] CNN Loss=0.9020, Acc=0.6771 | MLP Loss=1.6324, Acc=0.5796\n",
      "[Studygroup][1371] CNN Loss=0.8404, Acc=0.6698 | MLP Loss=1.6180, Acc=0.5875\n",
      "[Studygroup][1372] CNN Loss=0.8611, Acc=0.6739 | MLP Loss=1.6120, Acc=0.5908\n",
      "[Studygroup][1373] CNN Loss=0.8461, Acc=0.6792 | MLP Loss=1.6076, Acc=0.5801\n",
      "[Studygroup][1374] CNN Loss=0.8787, Acc=0.6773 | MLP Loss=1.6375, Acc=0.5673\n",
      "[Studygroup][1375] CNN Loss=0.8992, Acc=0.6659 | MLP Loss=1.6650, Acc=0.5888\n",
      "[Studygroup][1376] CNN Loss=0.9257, Acc=0.6755 | MLP Loss=1.6859, Acc=0.5830\n",
      "[Studygroup][1377] CNN Loss=0.9198, Acc=0.6795 | MLP Loss=1.7168, Acc=0.5848\n",
      "[Studygroup][1378] CNN Loss=0.8735, Acc=0.6711 | MLP Loss=1.6677, Acc=0.5839\n",
      "[Studygroup][1379] CNN Loss=0.7824, Acc=0.6786 | MLP Loss=1.6088, Acc=0.5868\n",
      "[Studygroup][1380] CNN Loss=0.9524, Acc=0.6701 | MLP Loss=1.6532, Acc=0.5774\n",
      "[Studygroup][1381] CNN Loss=0.9569, Acc=0.6804 | MLP Loss=1.5663, Acc=0.5867\n",
      "[Studygroup][1382] CNN Loss=0.8951, Acc=0.6760 | MLP Loss=1.6274, Acc=0.5879\n",
      "[Studygroup][1383] CNN Loss=0.8826, Acc=0.6832 | MLP Loss=1.6009, Acc=0.5954\n",
      "[Studygroup][1384] CNN Loss=0.7904, Acc=0.6856 | MLP Loss=1.5352, Acc=0.5832\n",
      "[Studygroup][1385] CNN Loss=0.8495, Acc=0.6774 | MLP Loss=1.5766, Acc=0.5879\n",
      "[Studygroup][1386] CNN Loss=0.8810, Acc=0.6773 | MLP Loss=1.6002, Acc=0.5895\n",
      "[Studygroup][1387] CNN Loss=0.9663, Acc=0.6834 | MLP Loss=1.5878, Acc=0.5874\n",
      "[Studygroup][1388] CNN Loss=0.8880, Acc=0.6748 | MLP Loss=1.6280, Acc=0.5862\n",
      "[Studygroup][1389] CNN Loss=0.8493, Acc=0.6804 | MLP Loss=1.6337, Acc=0.5855\n",
      "[Studygroup][1390] CNN Loss=0.8669, Acc=0.6727 | MLP Loss=1.5987, Acc=0.5882\n",
      "[Studygroup][1391] CNN Loss=0.9242, Acc=0.6795 | MLP Loss=1.5689, Acc=0.5840\n",
      "[Studygroup][1392] CNN Loss=1.0030, Acc=0.6727 | MLP Loss=1.6835, Acc=0.5777\n",
      "[Studygroup][1393] CNN Loss=1.0625, Acc=0.6704 | MLP Loss=1.7295, Acc=0.5887\n",
      "[Studygroup][1394] CNN Loss=0.9345, Acc=0.6773 | MLP Loss=1.6214, Acc=0.5795\n",
      "[Studygroup][1395] CNN Loss=0.9164, Acc=0.6761 | MLP Loss=1.6330, Acc=0.5785\n",
      "[Studygroup][1396] CNN Loss=0.8932, Acc=0.6781 | MLP Loss=1.6147, Acc=0.5801\n",
      "[Studygroup][1397] CNN Loss=0.7961, Acc=0.6806 | MLP Loss=1.6185, Acc=0.5851\n",
      "[Studygroup][1398] CNN Loss=0.8787, Acc=0.6761 | MLP Loss=1.6128, Acc=0.5840\n",
      "[Studygroup][1399] CNN Loss=0.8547, Acc=0.6803 | MLP Loss=1.7420, Acc=0.5824\n",
      "[Studygroup][1400] CNN Loss=0.9246, Acc=0.6749 | MLP Loss=1.5786, Acc=0.5897\n",
      "[Studygroup][1401] CNN Loss=0.9101, Acc=0.6785 | MLP Loss=1.6479, Acc=0.5849\n",
      "[Studygroup][1402] CNN Loss=0.9268, Acc=0.6765 | MLP Loss=1.5837, Acc=0.5873\n",
      "[Studygroup][1403] CNN Loss=0.9003, Acc=0.6724 | MLP Loss=1.5975, Acc=0.5908\n",
      "[Studygroup][1404] CNN Loss=0.8542, Acc=0.6742 | MLP Loss=1.7151, Acc=0.5833\n",
      "[Studygroup][1405] CNN Loss=0.8942, Acc=0.6780 | MLP Loss=1.6106, Acc=0.5823\n",
      "[Studygroup][1406] CNN Loss=0.9596, Acc=0.6723 | MLP Loss=1.7788, Acc=0.5743\n",
      "[Studygroup][1407] CNN Loss=0.9212, Acc=0.6842 | MLP Loss=1.7065, Acc=0.5784\n",
      "[Studygroup][1408] CNN Loss=0.8648, Acc=0.6767 | MLP Loss=1.6717, Acc=0.5861\n",
      "[Studygroup][1409] CNN Loss=0.9158, Acc=0.6739 | MLP Loss=1.6601, Acc=0.5926\n",
      "[Studygroup][1410] CNN Loss=0.9117, Acc=0.6797 | MLP Loss=1.6957, Acc=0.5868\n",
      "[Studygroup][1411] CNN Loss=0.9202, Acc=0.6760 | MLP Loss=1.6946, Acc=0.5801\n",
      "[Studygroup][1412] CNN Loss=0.8764, Acc=0.6590 | MLP Loss=1.6408, Acc=0.5806\n",
      "[Studygroup][1413] CNN Loss=1.0393, Acc=0.6787 | MLP Loss=1.7223, Acc=0.5767\n",
      "[Studygroup][1414] CNN Loss=0.9362, Acc=0.6777 | MLP Loss=1.6055, Acc=0.5855\n",
      "[Studygroup][1415] CNN Loss=0.9704, Acc=0.6795 | MLP Loss=1.6336, Acc=0.5872\n",
      "[Studygroup][1416] CNN Loss=0.8821, Acc=0.6762 | MLP Loss=1.5902, Acc=0.5871\n",
      "[Studygroup][1417] CNN Loss=0.8887, Acc=0.6748 | MLP Loss=1.5731, Acc=0.5846\n",
      "[Studygroup][1418] CNN Loss=1.0044, Acc=0.6742 | MLP Loss=1.6265, Acc=0.5898\n",
      "[Studygroup][1419] CNN Loss=0.8484, Acc=0.6786 | MLP Loss=1.6471, Acc=0.5786\n",
      "[Studygroup][1420] CNN Loss=0.8818, Acc=0.6721 | MLP Loss=1.7256, Acc=0.5863\n",
      "[Studygroup][1421] CNN Loss=0.9639, Acc=0.6739 | MLP Loss=1.6991, Acc=0.5820\n",
      "[Studygroup][1422] CNN Loss=0.9741, Acc=0.6702 | MLP Loss=1.6776, Acc=0.5792\n",
      "[Studygroup][1423] CNN Loss=0.9765, Acc=0.6778 | MLP Loss=1.5811, Acc=0.5886\n",
      "[Studygroup][1424] CNN Loss=0.9465, Acc=0.6802 | MLP Loss=1.5784, Acc=0.5672\n",
      "[Studygroup][1425] CNN Loss=0.9541, Acc=0.6720 | MLP Loss=1.6821, Acc=0.5791\n",
      "[Studygroup][1426] CNN Loss=0.9681, Acc=0.6734 | MLP Loss=1.6201, Acc=0.5742\n",
      "[Studygroup][1427] CNN Loss=0.9488, Acc=0.6830 | MLP Loss=1.6697, Acc=0.5829\n",
      "[Studygroup][1428] CNN Loss=0.9789, Acc=0.6786 | MLP Loss=1.5951, Acc=0.5847\n",
      "[Studygroup][1429] CNN Loss=0.9560, Acc=0.6719 | MLP Loss=1.6453, Acc=0.5776\n",
      "[Studygroup][1430] CNN Loss=0.9501, Acc=0.6759 | MLP Loss=1.5339, Acc=0.5935\n",
      "[Studygroup][1431] CNN Loss=0.8029, Acc=0.6795 | MLP Loss=1.5732, Acc=0.5825\n",
      "[Studygroup][1432] CNN Loss=0.8776, Acc=0.6698 | MLP Loss=1.6499, Acc=0.5720\n",
      "[Studygroup][1433] CNN Loss=0.8894, Acc=0.6688 | MLP Loss=1.9242, Acc=0.5553\n",
      "[Studygroup][1434] CNN Loss=0.8921, Acc=0.6728 | MLP Loss=1.6864, Acc=0.5781\n",
      "[Studygroup][1435] CNN Loss=0.9487, Acc=0.6718 | MLP Loss=1.6784, Acc=0.5636\n",
      "[Studygroup][1436] CNN Loss=0.9410, Acc=0.6776 | MLP Loss=1.6179, Acc=0.5867\n",
      "[Studygroup][1437] CNN Loss=0.8546, Acc=0.6735 | MLP Loss=1.6018, Acc=0.5872\n",
      "[Studygroup][1438] CNN Loss=0.8591, Acc=0.6751 | MLP Loss=1.7110, Acc=0.5841\n",
      "[Studygroup][1439] CNN Loss=0.8930, Acc=0.6747 | MLP Loss=1.6319, Acc=0.5938\n",
      "[Studygroup][1440] CNN Loss=0.9111, Acc=0.6829 | MLP Loss=1.6316, Acc=0.5842\n",
      "[Studygroup][1441] CNN Loss=0.8692, Acc=0.6813 | MLP Loss=1.6610, Acc=0.5826\n",
      "[Studygroup][1442] CNN Loss=0.9150, Acc=0.6795 | MLP Loss=1.6090, Acc=0.5801\n",
      "[Studygroup][1443] CNN Loss=0.8773, Acc=0.6824 | MLP Loss=1.5723, Acc=0.5868\n",
      "[Studygroup][1444] CNN Loss=0.9513, Acc=0.6794 | MLP Loss=1.6625, Acc=0.5922\n",
      "[Studygroup][1445] CNN Loss=0.8637, Acc=0.6836 | MLP Loss=1.6178, Acc=0.5937\n",
      "[Studygroup][1446] CNN Loss=0.8388, Acc=0.6824 | MLP Loss=1.6217, Acc=0.5733\n",
      "[Studygroup][1447] CNN Loss=0.9530, Acc=0.6657 | MLP Loss=1.6243, Acc=0.5756\n",
      "[Studygroup][1448] CNN Loss=0.9465, Acc=0.6767 | MLP Loss=1.6563, Acc=0.5817\n",
      "[Studygroup][1449] CNN Loss=0.8891, Acc=0.6752 | MLP Loss=1.6614, Acc=0.5778\n",
      "[Studygroup][1450] CNN Loss=0.9236, Acc=0.6753 | MLP Loss=1.5948, Acc=0.5882\n",
      "[Studygroup][1451] CNN Loss=1.0082, Acc=0.6752 | MLP Loss=1.6143, Acc=0.5911\n",
      "[Studygroup][1452] CNN Loss=0.9089, Acc=0.6817 | MLP Loss=1.6374, Acc=0.5919\n",
      "[Studygroup][1453] CNN Loss=1.0014, Acc=0.6826 | MLP Loss=1.6317, Acc=0.5857\n",
      "[Studygroup][1454] CNN Loss=0.9466, Acc=0.6889 | MLP Loss=1.6701, Acc=0.5893\n",
      "[Studygroup][1455] CNN Loss=0.7893, Acc=0.6853 | MLP Loss=1.6897, Acc=0.5810\n",
      "[Studygroup][1456] CNN Loss=0.8540, Acc=0.6784 | MLP Loss=1.6972, Acc=0.5797\n",
      "[Studygroup][1457] CNN Loss=0.8876, Acc=0.6841 | MLP Loss=1.7089, Acc=0.5868\n",
      "[Studygroup][1458] CNN Loss=0.9792, Acc=0.6826 | MLP Loss=1.6398, Acc=0.5849\n",
      "[Studygroup][1459] CNN Loss=0.8332, Acc=0.6855 | MLP Loss=1.5743, Acc=0.5882\n",
      "[Studygroup][1460] CNN Loss=0.7725, Acc=0.6786 | MLP Loss=1.5588, Acc=0.5885\n",
      "[Studygroup][1461] CNN Loss=0.8871, Acc=0.6781 | MLP Loss=1.6188, Acc=0.5812\n",
      "[Studygroup][1462] CNN Loss=0.9302, Acc=0.6728 | MLP Loss=1.6372, Acc=0.5932\n",
      "[Studygroup][1463] CNN Loss=0.8945, Acc=0.6788 | MLP Loss=1.6536, Acc=0.5898\n",
      "[Studygroup][1464] CNN Loss=0.8481, Acc=0.6751 | MLP Loss=1.6271, Acc=0.5901\n",
      "[Studygroup][1465] CNN Loss=0.8882, Acc=0.6762 | MLP Loss=1.6619, Acc=0.5885\n",
      "[Studygroup][1466] CNN Loss=0.8980, Acc=0.6795 | MLP Loss=1.5952, Acc=0.5584\n",
      "[Studygroup][1467] CNN Loss=0.7846, Acc=0.6843 | MLP Loss=1.6228, Acc=0.5843\n",
      "[Studygroup][1468] CNN Loss=0.8399, Acc=0.6830 | MLP Loss=1.5781, Acc=0.5837\n",
      "[Studygroup][1469] CNN Loss=0.8291, Acc=0.6822 | MLP Loss=1.8409, Acc=0.5704\n",
      "[Studygroup][1470] CNN Loss=0.8878, Acc=0.6786 | MLP Loss=1.9229, Acc=0.5772\n",
      "[Studygroup][1471] CNN Loss=0.9949, Acc=0.6759 | MLP Loss=1.7988, Acc=0.5744\n",
      "[Studygroup][1472] CNN Loss=0.9156, Acc=0.6835 | MLP Loss=1.6603, Acc=0.5877\n",
      "[Studygroup][1473] CNN Loss=0.8841, Acc=0.6832 | MLP Loss=1.6467, Acc=0.5889\n",
      "[Studygroup][1474] CNN Loss=0.8673, Acc=0.6820 | MLP Loss=1.6203, Acc=0.5865\n",
      "[Studygroup][1475] CNN Loss=0.8386, Acc=0.6857 | MLP Loss=1.6723, Acc=0.5858\n",
      "[Studygroup][1476] CNN Loss=0.9748, Acc=0.6812 | MLP Loss=1.6698, Acc=0.5894\n",
      "[Studygroup][1477] CNN Loss=0.8243, Acc=0.6809 | MLP Loss=1.5601, Acc=0.5828\n",
      "[Studygroup][1478] CNN Loss=0.8924, Acc=0.6825 | MLP Loss=1.6713, Acc=0.5914\n",
      "[Studygroup][1479] CNN Loss=0.9230, Acc=0.6826 | MLP Loss=1.6022, Acc=0.5748\n",
      "[Studygroup][1480] CNN Loss=0.8113, Acc=0.6914 | MLP Loss=1.6064, Acc=0.5855\n",
      "[Studygroup][1481] CNN Loss=0.7777, Acc=0.6858 | MLP Loss=1.7992, Acc=0.5835\n",
      "[Studygroup][1482] CNN Loss=0.7870, Acc=0.6810 | MLP Loss=1.7507, Acc=0.5899\n",
      "[Studygroup][1483] CNN Loss=0.9529, Acc=0.6628 | MLP Loss=1.7335, Acc=0.5804\n",
      "[Studygroup][1484] CNN Loss=1.0059, Acc=0.6802 | MLP Loss=1.5691, Acc=0.5696\n",
      "[Studygroup][1485] CNN Loss=0.8788, Acc=0.6821 | MLP Loss=1.5898, Acc=0.5933\n",
      "[Studygroup][1486] CNN Loss=0.8858, Acc=0.6827 | MLP Loss=1.5981, Acc=0.5909\n",
      "[Studygroup][1487] CNN Loss=0.8691, Acc=0.6837 | MLP Loss=1.7235, Acc=0.5947\n",
      "[Studygroup][1488] CNN Loss=0.9557, Acc=0.6782 | MLP Loss=1.6417, Acc=0.5900\n",
      "[Studygroup][1489] CNN Loss=1.0110, Acc=0.6765 | MLP Loss=1.6259, Acc=0.5809\n",
      "[Studygroup][1490] CNN Loss=0.8201, Acc=0.6847 | MLP Loss=1.5878, Acc=0.5922\n",
      "[Studygroup][1491] CNN Loss=0.8517, Acc=0.6798 | MLP Loss=1.6302, Acc=0.5913\n",
      "[Studygroup][1492] CNN Loss=0.8925, Acc=0.6848 | MLP Loss=1.7125, Acc=0.5742\n",
      "[Studygroup][1493] CNN Loss=0.8244, Acc=0.6835 | MLP Loss=1.7092, Acc=0.5830\n",
      "[Studygroup][1494] CNN Loss=0.8954, Acc=0.6849 | MLP Loss=1.6434, Acc=0.5930\n",
      "[Studygroup][1495] CNN Loss=0.8655, Acc=0.6823 | MLP Loss=1.5932, Acc=0.5915\n",
      "[Studygroup][1496] CNN Loss=0.8421, Acc=0.6843 | MLP Loss=1.6300, Acc=0.5894\n",
      "[Studygroup][1497] CNN Loss=0.8549, Acc=0.6814 | MLP Loss=1.6108, Acc=0.5916\n",
      "[Studygroup][1498] CNN Loss=0.9407, Acc=0.6815 | MLP Loss=1.6186, Acc=0.5864\n",
      "[Studygroup][1499] CNN Loss=0.8940, Acc=0.6662 | MLP Loss=1.7049, Acc=0.5799\n",
      "[Studygroup][1500] CNN Loss=0.8273, Acc=0.6770 | MLP Loss=1.6634, Acc=0.5787\n",
      "[Studygroup][1501] CNN Loss=0.9515, Acc=0.6725 | MLP Loss=1.7077, Acc=0.5929\n",
      "[Studygroup][1502] CNN Loss=0.9044, Acc=0.6705 | MLP Loss=1.6902, Acc=0.5918\n",
      "[Studygroup][1503] CNN Loss=0.9216, Acc=0.6582 | MLP Loss=1.6593, Acc=0.5902\n",
      "[Studygroup][1504] CNN Loss=0.9966, Acc=0.6739 | MLP Loss=1.6491, Acc=0.5807\n",
      "[Studygroup][1505] CNN Loss=0.9675, Acc=0.6804 | MLP Loss=1.5408, Acc=0.5830\n",
      "[Studygroup][1506] CNN Loss=0.9585, Acc=0.6774 | MLP Loss=1.5739, Acc=0.5894\n",
      "[Studygroup][1507] CNN Loss=0.9251, Acc=0.6793 | MLP Loss=1.6054, Acc=0.5850\n",
      "[Studygroup][1508] CNN Loss=0.8331, Acc=0.6838 | MLP Loss=1.5981, Acc=0.5823\n",
      "[Studygroup][1509] CNN Loss=0.8762, Acc=0.6808 | MLP Loss=1.6046, Acc=0.5900\n",
      "[Studygroup][1510] CNN Loss=0.8018, Acc=0.6849 | MLP Loss=1.5938, Acc=0.5909\n",
      "[Studygroup][1511] CNN Loss=0.8396, Acc=0.6794 | MLP Loss=1.5756, Acc=0.5868\n",
      "[Studygroup][1512] CNN Loss=0.8941, Acc=0.6811 | MLP Loss=1.6523, Acc=0.5617\n",
      "[Studygroup][1513] CNN Loss=0.8332, Acc=0.6787 | MLP Loss=1.6372, Acc=0.5885\n",
      "[Studygroup][1514] CNN Loss=0.8803, Acc=0.6780 | MLP Loss=1.6542, Acc=0.5905\n",
      "[Studygroup][1515] CNN Loss=1.0037, Acc=0.6757 | MLP Loss=1.6176, Acc=0.5801\n",
      "[Studygroup][1516] CNN Loss=0.9236, Acc=0.6831 | MLP Loss=1.6102, Acc=0.5870\n",
      "[Studygroup][1517] CNN Loss=0.8882, Acc=0.6807 | MLP Loss=1.6602, Acc=0.5784\n",
      "[Studygroup][1518] CNN Loss=0.9108, Acc=0.6845 | MLP Loss=1.5650, Acc=0.5864\n",
      "[Studygroup][1519] CNN Loss=0.8547, Acc=0.6796 | MLP Loss=1.6233, Acc=0.5846\n",
      "[Studygroup][1520] CNN Loss=0.8515, Acc=0.6826 | MLP Loss=1.6019, Acc=0.5892\n",
      "[Studygroup][1521] CNN Loss=0.8450, Acc=0.6808 | MLP Loss=1.5615, Acc=0.5917\n",
      "[Studygroup][1522] CNN Loss=0.8569, Acc=0.6887 | MLP Loss=1.6551, Acc=0.5814\n",
      "[Studygroup][1523] CNN Loss=0.8040, Acc=0.6887 | MLP Loss=1.6430, Acc=0.5916\n",
      "[Studygroup][1524] CNN Loss=0.9092, Acc=0.6814 | MLP Loss=1.5968, Acc=0.5805\n",
      "[Studygroup][1525] CNN Loss=0.8913, Acc=0.6821 | MLP Loss=1.5996, Acc=0.5894\n",
      "[Studygroup][1526] CNN Loss=0.9217, Acc=0.6781 | MLP Loss=1.5940, Acc=0.5785\n",
      "[Studygroup][1527] CNN Loss=0.8634, Acc=0.6833 | MLP Loss=1.5722, Acc=0.5955\n",
      "[Studygroup][1528] CNN Loss=0.8766, Acc=0.6862 | MLP Loss=1.6245, Acc=0.5830\n",
      "[Studygroup][1529] CNN Loss=0.9219, Acc=0.6772 | MLP Loss=1.7475, Acc=0.5623\n",
      "[Studygroup][1530] CNN Loss=0.9015, Acc=0.6900 | MLP Loss=1.6564, Acc=0.5813\n",
      "[Studygroup][1531] CNN Loss=0.9175, Acc=0.6797 | MLP Loss=1.7062, Acc=0.5818\n",
      "[Studygroup][1532] CNN Loss=0.9197, Acc=0.6819 | MLP Loss=1.7152, Acc=0.5851\n",
      "[Studygroup][1533] CNN Loss=0.8962, Acc=0.6756 | MLP Loss=1.7233, Acc=0.5722\n",
      "[Studygroup][1534] CNN Loss=0.9040, Acc=0.6852 | MLP Loss=1.7580, Acc=0.5823\n",
      "[Studygroup][1535] CNN Loss=0.9380, Acc=0.6813 | MLP Loss=1.7660, Acc=0.5801\n",
      "[Studygroup][1536] CNN Loss=0.9818, Acc=0.6779 | MLP Loss=1.6905, Acc=0.5819\n",
      "[Studygroup][1537] CNN Loss=1.0243, Acc=0.6713 | MLP Loss=1.6431, Acc=0.5750\n",
      "[Studygroup][1538] CNN Loss=1.0242, Acc=0.6722 | MLP Loss=1.6011, Acc=0.5906\n",
      "[Studygroup][1539] CNN Loss=0.9038, Acc=0.6678 | MLP Loss=1.6946, Acc=0.5763\n",
      "[Studygroup][1540] CNN Loss=0.9071, Acc=0.6746 | MLP Loss=1.6875, Acc=0.5922\n",
      "[Studygroup][1541] CNN Loss=0.9810, Acc=0.6798 | MLP Loss=1.7057, Acc=0.5845\n",
      "[Studygroup][1542] CNN Loss=0.9777, Acc=0.6743 | MLP Loss=1.6481, Acc=0.5866\n",
      "[Studygroup][1543] CNN Loss=0.8441, Acc=0.6841 | MLP Loss=1.6520, Acc=0.5810\n",
      "[Studygroup][1544] CNN Loss=0.9212, Acc=0.6760 | MLP Loss=1.5831, Acc=0.5869\n",
      "[Studygroup][1545] CNN Loss=0.8424, Acc=0.6789 | MLP Loss=1.5325, Acc=0.5874\n",
      "[Studygroup][1546] CNN Loss=0.8777, Acc=0.6785 | MLP Loss=1.7140, Acc=0.5802\n",
      "[Studygroup][1547] CNN Loss=0.8939, Acc=0.6857 | MLP Loss=1.6216, Acc=0.5920\n",
      "[Studygroup][1548] CNN Loss=0.9588, Acc=0.6698 | MLP Loss=1.6747, Acc=0.5691\n",
      "[Studygroup][1549] CNN Loss=0.9663, Acc=0.6842 | MLP Loss=1.6960, Acc=0.5954\n",
      "[Studygroup][1550] CNN Loss=0.9461, Acc=0.6806 | MLP Loss=1.7350, Acc=0.5822\n",
      "[Studygroup][1551] CNN Loss=0.9067, Acc=0.6786 | MLP Loss=1.7333, Acc=0.5764\n",
      "[Studygroup][1552] CNN Loss=0.8088, Acc=0.6825 | MLP Loss=1.6636, Acc=0.5849\n",
      "[Studygroup][1553] CNN Loss=0.8451, Acc=0.6887 | MLP Loss=1.7376, Acc=0.5799\n",
      "[Studygroup][1554] CNN Loss=0.8260, Acc=0.6853 | MLP Loss=1.7512, Acc=0.5767\n",
      "[Studygroup][1555] CNN Loss=0.8613, Acc=0.6703 | MLP Loss=1.6910, Acc=0.5752\n",
      "[Studygroup][1556] CNN Loss=1.0031, Acc=0.6760 | MLP Loss=1.6997, Acc=0.5875\n",
      "[Studygroup][1557] CNN Loss=0.8894, Acc=0.6798 | MLP Loss=1.6389, Acc=0.5787\n",
      "[Studygroup][1558] CNN Loss=0.8611, Acc=0.6838 | MLP Loss=1.6140, Acc=0.5874\n",
      "[Studygroup][1559] CNN Loss=0.8984, Acc=0.6813 | MLP Loss=1.6660, Acc=0.5961\n",
      "[Studygroup][1560] CNN Loss=0.8115, Acc=0.6839 | MLP Loss=1.6534, Acc=0.5912\n",
      "[Studygroup][1561] CNN Loss=0.8797, Acc=0.6776 | MLP Loss=1.7205, Acc=0.5814\n",
      "[Studygroup][1562] CNN Loss=0.8611, Acc=0.6811 | MLP Loss=1.6910, Acc=0.5940\n",
      "[Studygroup][1563] CNN Loss=0.9409, Acc=0.6779 | MLP Loss=1.6885, Acc=0.5938\n",
      "[Studygroup][1564] CNN Loss=0.8810, Acc=0.6747 | MLP Loss=1.6930, Acc=0.5785\n",
      "[Studygroup][1565] CNN Loss=0.8962, Acc=0.6766 | MLP Loss=1.7426, Acc=0.5799\n",
      "[Studygroup][1566] CNN Loss=0.9451, Acc=0.6765 | MLP Loss=1.7906, Acc=0.5876\n",
      "[Studygroup][1567] CNN Loss=0.9591, Acc=0.6790 | MLP Loss=1.6234, Acc=0.5848\n",
      "[Studygroup][1568] CNN Loss=0.8822, Acc=0.6801 | MLP Loss=1.6634, Acc=0.5828\n",
      "[Studygroup][1569] CNN Loss=0.8793, Acc=0.6733 | MLP Loss=1.6891, Acc=0.5949\n",
      "[Studygroup][1570] CNN Loss=0.8707, Acc=0.6804 | MLP Loss=1.6671, Acc=0.5851\n",
      "[Studygroup][1571] CNN Loss=0.8167, Acc=0.6773 | MLP Loss=1.6990, Acc=0.5898\n",
      "[Studygroup][1572] CNN Loss=0.8220, Acc=0.6813 | MLP Loss=1.6296, Acc=0.5784\n",
      "[Studygroup][1573] CNN Loss=0.7760, Acc=0.6779 | MLP Loss=1.6511, Acc=0.5824\n",
      "[Studygroup][1574] CNN Loss=0.7660, Acc=0.6842 | MLP Loss=1.7305, Acc=0.5804\n",
      "[Studygroup][1575] CNN Loss=0.9694, Acc=0.6792 | MLP Loss=1.7747, Acc=0.5748\n",
      "[Studygroup][1576] CNN Loss=0.8216, Acc=0.6864 | MLP Loss=1.6438, Acc=0.5818\n",
      "[Studygroup][1577] CNN Loss=0.8592, Acc=0.6889 | MLP Loss=1.6235, Acc=0.5909\n",
      "[Studygroup][1578] CNN Loss=0.7998, Acc=0.6872 | MLP Loss=1.6703, Acc=0.5897\n",
      "[Studygroup][1579] CNN Loss=0.8578, Acc=0.6784 | MLP Loss=1.5972, Acc=0.5821\n",
      "[Studygroup][1580] CNN Loss=0.9069, Acc=0.6835 | MLP Loss=1.6912, Acc=0.5894\n",
      "[Studygroup][1581] CNN Loss=0.8518, Acc=0.6831 | MLP Loss=1.6592, Acc=0.5942\n",
      "[Studygroup][1582] CNN Loss=0.9433, Acc=0.6818 | MLP Loss=1.5806, Acc=0.5934\n",
      "[Studygroup][1583] CNN Loss=0.8806, Acc=0.6860 | MLP Loss=1.6963, Acc=0.5847\n",
      "[Studygroup][1584] CNN Loss=0.9067, Acc=0.6757 | MLP Loss=1.6779, Acc=0.5906\n",
      "[Studygroup][1585] CNN Loss=0.8802, Acc=0.6754 | MLP Loss=1.6918, Acc=0.5926\n",
      "[Studygroup][1586] CNN Loss=0.8894, Acc=0.6776 | MLP Loss=1.6939, Acc=0.5926\n",
      "[Studygroup][1587] CNN Loss=0.8532, Acc=0.6796 | MLP Loss=1.6255, Acc=0.5845\n",
      "[Studygroup][1588] CNN Loss=1.0463, Acc=0.6686 | MLP Loss=1.7131, Acc=0.5818\n",
      "[Studygroup][1589] CNN Loss=1.0114, Acc=0.6819 | MLP Loss=1.6243, Acc=0.5929\n",
      "[Studygroup][1590] CNN Loss=0.8900, Acc=0.6820 | MLP Loss=1.6259, Acc=0.5925\n",
      "[Studygroup][1591] CNN Loss=0.9615, Acc=0.6794 | MLP Loss=1.5790, Acc=0.5932\n",
      "[Studygroup][1592] CNN Loss=0.9698, Acc=0.6734 | MLP Loss=1.5920, Acc=0.5941\n",
      "[Studygroup][1593] CNN Loss=1.0397, Acc=0.6753 | MLP Loss=1.5865, Acc=0.5878\n",
      "[Studygroup][1594] CNN Loss=0.8821, Acc=0.6848 | MLP Loss=1.6455, Acc=0.5802\n",
      "[Studygroup][1595] CNN Loss=0.8972, Acc=0.6829 | MLP Loss=1.6284, Acc=0.5834\n",
      "[Studygroup][1596] CNN Loss=0.8789, Acc=0.6762 | MLP Loss=1.6215, Acc=0.5887\n",
      "[Studygroup][1597] CNN Loss=0.8984, Acc=0.6737 | MLP Loss=1.6492, Acc=0.5880\n",
      "[Studygroup][1598] CNN Loss=0.8422, Acc=0.6832 | MLP Loss=1.5894, Acc=0.5859\n",
      "[Studygroup][1599] CNN Loss=0.9950, Acc=0.6810 | MLP Loss=1.6143, Acc=0.5907\n",
      "[Studygroup][1600] CNN Loss=0.8948, Acc=0.6747 | MLP Loss=1.5824, Acc=0.5954\n",
      "[Studygroup][1601] CNN Loss=0.9176, Acc=0.6744 | MLP Loss=1.6434, Acc=0.5815\n",
      "[Studygroup][1602] CNN Loss=0.8476, Acc=0.6816 | MLP Loss=1.6701, Acc=0.5917\n",
      "[Studygroup][1603] CNN Loss=0.9034, Acc=0.6881 | MLP Loss=1.6683, Acc=0.5864\n",
      "[Studygroup][1604] CNN Loss=0.8807, Acc=0.6792 | MLP Loss=1.6450, Acc=0.5798\n",
      "[Studygroup][1605] CNN Loss=0.9400, Acc=0.6796 | MLP Loss=1.6978, Acc=0.5626\n",
      "[Studygroup][1606] CNN Loss=0.9878, Acc=0.6873 | MLP Loss=1.7299, Acc=0.5880\n",
      "[Studygroup][1607] CNN Loss=0.8195, Acc=0.6816 | MLP Loss=1.6310, Acc=0.5844\n",
      "[Studygroup][1608] CNN Loss=0.9142, Acc=0.6779 | MLP Loss=1.6490, Acc=0.5917\n",
      "[Studygroup][1609] CNN Loss=0.9670, Acc=0.6879 | MLP Loss=1.6365, Acc=0.5890\n",
      "[Studygroup][1610] CNN Loss=0.9313, Acc=0.6794 | MLP Loss=1.6071, Acc=0.5964\n",
      "[Studygroup][1611] CNN Loss=0.8838, Acc=0.6792 | MLP Loss=1.6427, Acc=0.5923\n",
      "[Studygroup][1612] CNN Loss=0.8321, Acc=0.6813 | MLP Loss=1.6004, Acc=0.5938\n",
      "[Studygroup][1613] CNN Loss=0.9371, Acc=0.6796 | MLP Loss=1.6036, Acc=0.5938\n",
      "[Studygroup][1614] CNN Loss=0.9090, Acc=0.6872 | MLP Loss=1.6043, Acc=0.5774\n",
      "[Studygroup][1615] CNN Loss=0.9456, Acc=0.6781 | MLP Loss=1.8691, Acc=0.5807\n",
      "[Studygroup][1616] CNN Loss=0.8857, Acc=0.6819 | MLP Loss=1.7263, Acc=0.5818\n",
      "[Studygroup][1617] CNN Loss=0.8173, Acc=0.6826 | MLP Loss=1.6557, Acc=0.5923\n",
      "[Studygroup][1618] CNN Loss=0.8964, Acc=0.6736 | MLP Loss=1.6417, Acc=0.5868\n",
      "[Studygroup][1619] CNN Loss=0.9224, Acc=0.6800 | MLP Loss=1.5956, Acc=0.5921\n",
      "[Studygroup][1620] CNN Loss=0.8042, Acc=0.6835 | MLP Loss=1.5979, Acc=0.5966\n",
      "[Studygroup][1621] CNN Loss=0.8685, Acc=0.6841 | MLP Loss=1.5916, Acc=0.5869\n",
      "[Studygroup][1622] CNN Loss=0.8711, Acc=0.6686 | MLP Loss=1.5969, Acc=0.5804\n",
      "[Studygroup][1623] CNN Loss=0.8818, Acc=0.6825 | MLP Loss=1.6409, Acc=0.5969\n",
      "[Studygroup][1624] CNN Loss=0.9375, Acc=0.6727 | MLP Loss=1.5674, Acc=0.5860\n",
      "[Studygroup][1625] CNN Loss=0.8974, Acc=0.6766 | MLP Loss=1.5675, Acc=0.5863\n",
      "[Studygroup][1626] CNN Loss=0.8424, Acc=0.6836 | MLP Loss=1.6177, Acc=0.5926\n",
      "[Studygroup][1627] CNN Loss=0.8738, Acc=0.6821 | MLP Loss=1.7062, Acc=0.5813\n",
      "[Studygroup][1628] CNN Loss=0.8997, Acc=0.6718 | MLP Loss=1.6682, Acc=0.5862\n",
      "[Studygroup][1629] CNN Loss=0.9279, Acc=0.6788 | MLP Loss=1.7065, Acc=0.5950\n",
      "[Studygroup][1630] CNN Loss=0.8829, Acc=0.6841 | MLP Loss=1.6397, Acc=0.5947\n",
      "[Studygroup][1631] CNN Loss=0.8686, Acc=0.6755 | MLP Loss=1.6065, Acc=0.5939\n",
      "[Studygroup][1632] CNN Loss=0.9263, Acc=0.6793 | MLP Loss=1.5530, Acc=0.5936\n",
      "[Studygroup][1633] CNN Loss=0.8845, Acc=0.6748 | MLP Loss=1.5657, Acc=0.5870\n",
      "[Studygroup][1634] CNN Loss=0.8765, Acc=0.6765 | MLP Loss=1.6156, Acc=0.5871\n",
      "[Studygroup][1635] CNN Loss=0.9197, Acc=0.6789 | MLP Loss=1.5294, Acc=0.5861\n",
      "[Studygroup][1636] CNN Loss=0.8524, Acc=0.6855 | MLP Loss=1.6739, Acc=0.5921\n",
      "[Studygroup][1637] CNN Loss=0.9171, Acc=0.6783 | MLP Loss=1.6126, Acc=0.5865\n",
      "[Studygroup][1638] CNN Loss=0.9315, Acc=0.6740 | MLP Loss=1.5795, Acc=0.5839\n",
      "[Studygroup][1639] CNN Loss=0.8144, Acc=0.6809 | MLP Loss=1.5976, Acc=0.5839\n",
      "[Studygroup][1640] CNN Loss=0.8533, Acc=0.6822 | MLP Loss=1.6602, Acc=0.5822\n",
      "[Studygroup][1641] CNN Loss=0.8692, Acc=0.6765 | MLP Loss=1.6223, Acc=0.5946\n",
      "[Studygroup][1642] CNN Loss=0.8913, Acc=0.6812 | MLP Loss=1.5888, Acc=0.5877\n",
      "[Studygroup][1643] CNN Loss=0.8415, Acc=0.6801 | MLP Loss=1.5869, Acc=0.5903\n",
      "[Studygroup][1644] CNN Loss=0.9504, Acc=0.6725 | MLP Loss=1.5814, Acc=0.5801\n",
      "[Studygroup][1645] CNN Loss=0.8736, Acc=0.6836 | MLP Loss=1.5776, Acc=0.5912\n",
      "[Studygroup][1646] CNN Loss=1.0269, Acc=0.6727 | MLP Loss=1.6266, Acc=0.5841\n",
      "[Studygroup][1647] CNN Loss=0.9189, Acc=0.6780 | MLP Loss=1.6247, Acc=0.5925\n",
      "[Studygroup][1648] CNN Loss=0.8345, Acc=0.6637 | MLP Loss=1.6435, Acc=0.5623\n",
      "[Studygroup][1649] CNN Loss=1.0785, Acc=0.6742 | MLP Loss=1.9972, Acc=0.5853\n",
      "[Studygroup][1650] CNN Loss=0.9324, Acc=0.6762 | MLP Loss=1.7122, Acc=0.5871\n",
      "[Studygroup][1651] CNN Loss=0.9080, Acc=0.6761 | MLP Loss=1.6487, Acc=0.5898\n",
      "[Studygroup][1652] CNN Loss=0.8294, Acc=0.6797 | MLP Loss=1.6727, Acc=0.5888\n",
      "[Studygroup][1653] CNN Loss=0.8203, Acc=0.6759 | MLP Loss=1.6035, Acc=0.5913\n",
      "[Studygroup][1654] CNN Loss=0.8643, Acc=0.6765 | MLP Loss=1.6455, Acc=0.5959\n",
      "[Studygroup][1655] CNN Loss=0.9509, Acc=0.6828 | MLP Loss=1.6105, Acc=0.5918\n",
      "[Studygroup][1656] CNN Loss=0.8666, Acc=0.6832 | MLP Loss=1.6010, Acc=0.5935\n",
      "[Studygroup][1657] CNN Loss=0.8996, Acc=0.6839 | MLP Loss=1.6735, Acc=0.5963\n",
      "[Studygroup][1658] CNN Loss=0.8712, Acc=0.6848 | MLP Loss=1.6337, Acc=0.5917\n",
      "[Studygroup][1659] CNN Loss=0.8633, Acc=0.6792 | MLP Loss=1.6422, Acc=0.5843\n",
      "[Studygroup][1660] CNN Loss=0.9919, Acc=0.6658 | MLP Loss=1.5978, Acc=0.5701\n",
      "[Studygroup][1661] CNN Loss=0.9350, Acc=0.6770 | MLP Loss=1.5735, Acc=0.5863\n",
      "[Studygroup][1662] CNN Loss=0.9495, Acc=0.6765 | MLP Loss=1.6029, Acc=0.5878\n",
      "[Studygroup][1663] CNN Loss=0.9289, Acc=0.6693 | MLP Loss=1.6910, Acc=0.5878\n",
      "[Studygroup][1664] CNN Loss=1.0055, Acc=0.6813 | MLP Loss=1.6118, Acc=0.5855\n",
      "[Studygroup][1665] CNN Loss=0.9322, Acc=0.6792 | MLP Loss=1.7069, Acc=0.5838\n",
      "[Studygroup][1666] CNN Loss=0.8452, Acc=0.6778 | MLP Loss=1.5771, Acc=0.5930\n",
      "[Studygroup][1667] CNN Loss=0.8447, Acc=0.6828 | MLP Loss=1.6065, Acc=0.5844\n",
      "[Studygroup][1668] CNN Loss=0.8001, Acc=0.6776 | MLP Loss=1.6334, Acc=0.5827\n",
      "[Studygroup][1669] CNN Loss=0.9421, Acc=0.6793 | MLP Loss=1.6721, Acc=0.5856\n",
      "[Studygroup][1670] CNN Loss=0.8335, Acc=0.6820 | MLP Loss=1.5926, Acc=0.5874\n",
      "[Studygroup][1671] CNN Loss=0.8297, Acc=0.6841 | MLP Loss=1.6570, Acc=0.5824\n",
      "[Studygroup][1672] CNN Loss=0.8816, Acc=0.6827 | MLP Loss=1.5892, Acc=0.5903\n",
      "[Studygroup][1673] CNN Loss=0.9400, Acc=0.6823 | MLP Loss=1.5149, Acc=0.5790\n",
      "[Studygroup][1674] CNN Loss=0.9626, Acc=0.6771 | MLP Loss=1.5642, Acc=0.5927\n",
      "[Studygroup][1675] CNN Loss=0.9205, Acc=0.6824 | MLP Loss=1.6385, Acc=0.5845\n",
      "[Studygroup][1676] CNN Loss=0.8175, Acc=0.6816 | MLP Loss=1.6403, Acc=0.5910\n",
      "[Studygroup][1677] CNN Loss=0.8197, Acc=0.6788 | MLP Loss=1.6144, Acc=0.5930\n",
      "[Studygroup][1678] CNN Loss=0.9043, Acc=0.6809 | MLP Loss=1.6792, Acc=0.5881\n",
      "[Studygroup][1679] CNN Loss=0.8829, Acc=0.6812 | MLP Loss=1.6838, Acc=0.5847\n",
      "[Studygroup][1680] CNN Loss=0.9160, Acc=0.6729 | MLP Loss=1.5996, Acc=0.5914\n",
      "[Studygroup][1681] CNN Loss=0.8986, Acc=0.6841 | MLP Loss=1.6641, Acc=0.5824\n",
      "[Studygroup][1682] CNN Loss=0.9065, Acc=0.6772 | MLP Loss=1.6766, Acc=0.5847\n",
      "[Studygroup][1683] CNN Loss=0.8952, Acc=0.6797 | MLP Loss=1.6618, Acc=0.5871\n",
      "[Studygroup][1684] CNN Loss=0.8661, Acc=0.6822 | MLP Loss=1.6162, Acc=0.5872\n",
      "[Studygroup][1685] CNN Loss=0.8133, Acc=0.6872 | MLP Loss=1.6718, Acc=0.5949\n",
      "[Studygroup][1686] CNN Loss=0.8660, Acc=0.6840 | MLP Loss=1.6412, Acc=0.5972\n",
      "[Studygroup][1687] CNN Loss=0.9058, Acc=0.6719 | MLP Loss=1.6405, Acc=0.5796\n",
      "[Studygroup][1688] CNN Loss=1.0252, Acc=0.6686 | MLP Loss=1.6797, Acc=0.5935\n",
      "[Studygroup][1689] CNN Loss=0.8816, Acc=0.6795 | MLP Loss=1.6513, Acc=0.5950\n",
      "[Studygroup][1690] CNN Loss=0.8171, Acc=0.6854 | MLP Loss=1.6178, Acc=0.5911\n",
      "[Studygroup][1691] CNN Loss=0.8730, Acc=0.6797 | MLP Loss=1.6574, Acc=0.5870\n",
      "[Studygroup][1692] CNN Loss=0.9063, Acc=0.6785 | MLP Loss=1.6071, Acc=0.5878\n",
      "[Studygroup][1693] CNN Loss=1.0773, Acc=0.6768 | MLP Loss=1.6258, Acc=0.5932\n",
      "[Studygroup][1694] CNN Loss=0.9089, Acc=0.6814 | MLP Loss=1.6368, Acc=0.5823\n",
      "[Studygroup][1695] CNN Loss=0.9236, Acc=0.6810 | MLP Loss=1.5650, Acc=0.5918\n",
      "[Studygroup][1696] CNN Loss=0.9083, Acc=0.6850 | MLP Loss=1.5781, Acc=0.5961\n",
      "[Studygroup][1697] CNN Loss=0.7955, Acc=0.6824 | MLP Loss=1.5789, Acc=0.5932\n",
      "[Studygroup][1698] CNN Loss=0.8925, Acc=0.6799 | MLP Loss=1.5908, Acc=0.5915\n",
      "[Studygroup][1699] CNN Loss=0.8664, Acc=0.6845 | MLP Loss=1.6770, Acc=0.5960\n",
      "[Studygroup][1700] CNN Loss=0.8626, Acc=0.6810 | MLP Loss=1.7036, Acc=0.5995\n",
      "[Studygroup][1701] CNN Loss=0.8592, Acc=0.6766 | MLP Loss=1.6736, Acc=0.5904\n",
      "[Studygroup][1702] CNN Loss=0.8823, Acc=0.6809 | MLP Loss=1.6895, Acc=0.5955\n",
      "[Studygroup][1703] CNN Loss=0.9421, Acc=0.6777 | MLP Loss=1.6048, Acc=0.5883\n",
      "[Studygroup][1704] CNN Loss=0.9126, Acc=0.6836 | MLP Loss=1.6576, Acc=0.5922\n",
      "[Studygroup][1705] CNN Loss=0.7999, Acc=0.6834 | MLP Loss=1.6388, Acc=0.5933\n",
      "[Studygroup][1706] CNN Loss=0.8868, Acc=0.6825 | MLP Loss=1.7003, Acc=0.5798\n",
      "[Studygroup][1707] CNN Loss=0.8619, Acc=0.6760 | MLP Loss=1.6580, Acc=0.5934\n",
      "[Studygroup][1708] CNN Loss=0.8282, Acc=0.6869 | MLP Loss=1.6151, Acc=0.5976\n",
      "[Studygroup][1709] CNN Loss=0.8319, Acc=0.6757 | MLP Loss=1.5635, Acc=0.5980\n",
      "[Studygroup][1710] CNN Loss=0.8922, Acc=0.6746 | MLP Loss=1.6344, Acc=0.5909\n",
      "[Studygroup][1711] CNN Loss=0.8389, Acc=0.6777 | MLP Loss=1.6315, Acc=0.5782\n",
      "[Studygroup][1712] CNN Loss=0.9027, Acc=0.6798 | MLP Loss=1.6728, Acc=0.5914\n",
      "[Studygroup][1713] CNN Loss=0.8644, Acc=0.6796 | MLP Loss=1.6344, Acc=0.5910\n",
      "[Studygroup][1714] CNN Loss=0.9043, Acc=0.6739 | MLP Loss=1.5966, Acc=0.5900\n",
      "[Studygroup][1715] CNN Loss=0.8145, Acc=0.6725 | MLP Loss=1.6292, Acc=0.5908\n",
      "[Studygroup][1716] CNN Loss=0.8434, Acc=0.6781 | MLP Loss=1.6109, Acc=0.5906\n",
      "[Studygroup][1717] CNN Loss=0.9153, Acc=0.6807 | MLP Loss=1.6446, Acc=0.5946\n",
      "[Studygroup][1718] CNN Loss=0.8693, Acc=0.6760 | MLP Loss=1.5919, Acc=0.5915\n",
      "[Studygroup][1719] CNN Loss=0.8412, Acc=0.6763 | MLP Loss=1.6665, Acc=0.5951\n",
      "[Studygroup][1720] CNN Loss=0.8273, Acc=0.6804 | MLP Loss=1.6627, Acc=0.5879\n",
      "[Studygroup][1721] CNN Loss=0.8230, Acc=0.6785 | MLP Loss=1.5581, Acc=0.5888\n",
      "[Studygroup][1722] CNN Loss=0.9498, Acc=0.6752 | MLP Loss=1.6298, Acc=0.5906\n",
      "[Studygroup][1723] CNN Loss=0.8928, Acc=0.6747 | MLP Loss=1.6721, Acc=0.5829\n",
      "[Studygroup][1724] CNN Loss=0.8751, Acc=0.6794 | MLP Loss=1.6451, Acc=0.5998\n",
      "[Studygroup][1725] CNN Loss=0.8789, Acc=0.6820 | MLP Loss=1.6325, Acc=0.5851\n",
      "[Studygroup][1726] CNN Loss=1.0769, Acc=0.6697 | MLP Loss=1.6754, Acc=0.5873\n",
      "[Studygroup][1727] CNN Loss=0.9512, Acc=0.6780 | MLP Loss=1.5416, Acc=0.5926\n",
      "[Studygroup][1728] CNN Loss=0.8768, Acc=0.6814 | MLP Loss=1.6366, Acc=0.5669\n",
      "[Studygroup][1729] CNN Loss=0.9309, Acc=0.6738 | MLP Loss=1.6133, Acc=0.5939\n",
      "[Studygroup][1730] CNN Loss=0.9405, Acc=0.6774 | MLP Loss=1.8189, Acc=0.5863\n",
      "[Studygroup][1731] CNN Loss=0.9636, Acc=0.6802 | MLP Loss=1.7726, Acc=0.5732\n",
      "[Studygroup][1732] CNN Loss=0.8318, Acc=0.6782 | MLP Loss=1.6485, Acc=0.5886\n",
      "[Studygroup][1733] CNN Loss=0.8394, Acc=0.6815 | MLP Loss=1.5743, Acc=0.5965\n",
      "[Studygroup][1734] CNN Loss=0.9200, Acc=0.6798 | MLP Loss=1.6266, Acc=0.5980\n",
      "[Studygroup][1735] CNN Loss=0.8667, Acc=0.6788 | MLP Loss=1.6167, Acc=0.5893\n",
      "[Studygroup][1736] CNN Loss=0.8439, Acc=0.6805 | MLP Loss=1.5912, Acc=0.5899\n",
      "[Studygroup][1737] CNN Loss=0.8526, Acc=0.6730 | MLP Loss=1.6722, Acc=0.5838\n",
      "[Studygroup][1738] CNN Loss=0.9175, Acc=0.6805 | MLP Loss=1.7284, Acc=0.5965\n",
      "[Studygroup][1739] CNN Loss=0.8880, Acc=0.6772 | MLP Loss=1.6661, Acc=0.5961\n",
      "[Studygroup][1740] CNN Loss=0.9039, Acc=0.6797 | MLP Loss=1.6982, Acc=0.5890\n",
      "[Studygroup][1741] CNN Loss=1.0112, Acc=0.6754 | MLP Loss=1.6072, Acc=0.5890\n",
      "[Studygroup][1742] CNN Loss=0.9100, Acc=0.6737 | MLP Loss=1.6013, Acc=0.5828\n",
      "[Studygroup][1743] CNN Loss=0.9047, Acc=0.6827 | MLP Loss=1.5702, Acc=0.5970\n",
      "[Studygroup][1744] CNN Loss=0.9000, Acc=0.6814 | MLP Loss=1.5850, Acc=0.5880\n",
      "[Studygroup][1745] CNN Loss=0.9340, Acc=0.6787 | MLP Loss=1.6894, Acc=0.5816\n",
      "[Studygroup][1746] CNN Loss=1.0314, Acc=0.6737 | MLP Loss=1.6480, Acc=0.5935\n",
      "[Studygroup][1747] CNN Loss=0.8909, Acc=0.6707 | MLP Loss=1.6146, Acc=0.5956\n",
      "[Studygroup][1748] CNN Loss=0.9407, Acc=0.6786 | MLP Loss=1.6151, Acc=0.5897\n",
      "[Studygroup][1749] CNN Loss=0.9054, Acc=0.6825 | MLP Loss=1.5770, Acc=0.5860\n",
      "[Studygroup][1750] CNN Loss=0.9501, Acc=0.6830 | MLP Loss=1.6610, Acc=0.5956\n",
      "[Studygroup][1751] CNN Loss=0.8753, Acc=0.6799 | MLP Loss=1.6136, Acc=0.5856\n",
      "[Studygroup][1752] CNN Loss=0.8328, Acc=0.6817 | MLP Loss=1.6446, Acc=0.5900\n",
      "[Studygroup][1753] CNN Loss=0.9378, Acc=0.6772 | MLP Loss=1.6114, Acc=0.5908\n",
      "[Studygroup][1754] CNN Loss=0.8875, Acc=0.6769 | MLP Loss=1.5914, Acc=0.5869\n",
      "[Studygroup][1755] CNN Loss=1.0802, Acc=0.6756 | MLP Loss=1.6832, Acc=0.5859\n",
      "[Studygroup][1756] CNN Loss=0.9053, Acc=0.6721 | MLP Loss=1.6227, Acc=0.5883\n",
      "[Studygroup][1757] CNN Loss=0.9153, Acc=0.6752 | MLP Loss=1.5600, Acc=0.5833\n",
      "[Studygroup][1758] CNN Loss=0.8737, Acc=0.6801 | MLP Loss=1.6230, Acc=0.5961\n",
      "[Studygroup][1759] CNN Loss=0.9760, Acc=0.6797 | MLP Loss=1.5928, Acc=0.5891\n",
      "[Studygroup][1760] CNN Loss=0.8722, Acc=0.6846 | MLP Loss=1.5543, Acc=0.5936\n",
      "[Studygroup][1761] CNN Loss=0.8685, Acc=0.6737 | MLP Loss=1.5810, Acc=0.5930\n",
      "[Studygroup][1762] CNN Loss=0.8429, Acc=0.6845 | MLP Loss=1.5940, Acc=0.5838\n",
      "[Studygroup][1763] CNN Loss=0.8436, Acc=0.6782 | MLP Loss=1.5276, Acc=0.5806\n",
      "[Studygroup][1764] CNN Loss=0.8338, Acc=0.6865 | MLP Loss=1.6610, Acc=0.5910\n",
      "[Studygroup][1765] CNN Loss=0.7568, Acc=0.6774 | MLP Loss=1.6411, Acc=0.5928\n",
      "[Studygroup][1766] CNN Loss=0.9101, Acc=0.6784 | MLP Loss=1.6444, Acc=0.5870\n",
      "[Studygroup][1767] CNN Loss=0.9680, Acc=0.6788 | MLP Loss=1.7397, Acc=0.5943\n",
      "[Studygroup][1768] CNN Loss=1.0018, Acc=0.6777 | MLP Loss=1.6157, Acc=0.5883\n",
      "[Studygroup][1769] CNN Loss=0.9174, Acc=0.6816 | MLP Loss=1.5926, Acc=0.5836\n",
      "[Studygroup][1770] CNN Loss=0.8123, Acc=0.6797 | MLP Loss=1.6096, Acc=0.5929\n",
      "[Studygroup][1771] CNN Loss=0.8957, Acc=0.6699 | MLP Loss=1.6554, Acc=0.5932\n",
      "[Studygroup][1772] CNN Loss=0.9444, Acc=0.6762 | MLP Loss=1.5835, Acc=0.5923\n",
      "[Studygroup][1773] CNN Loss=0.8083, Acc=0.6823 | MLP Loss=1.6313, Acc=0.5898\n",
      "[Studygroup][1774] CNN Loss=0.9952, Acc=0.6859 | MLP Loss=1.5773, Acc=0.5773\n",
      "[Studygroup][1775] CNN Loss=0.9489, Acc=0.6812 | MLP Loss=1.5796, Acc=0.5886\n",
      "[Studygroup][1776] CNN Loss=0.9073, Acc=0.6820 | MLP Loss=1.7132, Acc=0.5853\n",
      "[Studygroup][1777] CNN Loss=0.9852, Acc=0.6735 | MLP Loss=1.6273, Acc=0.5964\n",
      "[Studygroup][1778] CNN Loss=0.8887, Acc=0.6809 | MLP Loss=1.5933, Acc=0.5881\n",
      "[Studygroup][1779] CNN Loss=0.9338, Acc=0.6840 | MLP Loss=1.5885, Acc=0.5755\n",
      "[Studygroup][1780] CNN Loss=0.8445, Acc=0.6821 | MLP Loss=1.6677, Acc=0.5977\n",
      "[Studygroup][1781] CNN Loss=0.9246, Acc=0.6868 | MLP Loss=1.5770, Acc=0.5940\n",
      "[Studygroup][1782] CNN Loss=0.8784, Acc=0.6822 | MLP Loss=1.6339, Acc=0.5943\n",
      "[Studygroup][1783] CNN Loss=0.8608, Acc=0.6731 | MLP Loss=1.5448, Acc=0.5955\n",
      "[Studygroup][1784] CNN Loss=0.7939, Acc=0.6813 | MLP Loss=1.6085, Acc=0.5913\n",
      "[Studygroup][1785] CNN Loss=0.8020, Acc=0.6731 | MLP Loss=1.6236, Acc=0.5918\n",
      "[Studygroup][1786] CNN Loss=0.8075, Acc=0.6812 | MLP Loss=1.6484, Acc=0.5863\n",
      "[Studygroup][1787] CNN Loss=0.8329, Acc=0.6796 | MLP Loss=1.6714, Acc=0.5948\n",
      "[Studygroup][1788] CNN Loss=0.8098, Acc=0.6821 | MLP Loss=1.6476, Acc=0.5849\n",
      "[Studygroup][1789] CNN Loss=0.9088, Acc=0.6735 | MLP Loss=1.6249, Acc=0.5941\n",
      "[Studygroup][1790] CNN Loss=0.8550, Acc=0.6809 | MLP Loss=1.6534, Acc=0.5925\n",
      "[Studygroup][1791] CNN Loss=0.9430, Acc=0.6703 | MLP Loss=1.6095, Acc=0.5747\n",
      "[Studygroup][1792] CNN Loss=0.9900, Acc=0.6759 | MLP Loss=1.5706, Acc=0.5917\n",
      "[Studygroup][1793] CNN Loss=0.8887, Acc=0.6772 | MLP Loss=1.4947, Acc=0.5877\n",
      "[Studygroup][1794] CNN Loss=0.8955, Acc=0.6769 | MLP Loss=1.5719, Acc=0.5901\n",
      "[Studygroup][1795] CNN Loss=0.8874, Acc=0.6667 | MLP Loss=1.6287, Acc=0.5933\n",
      "[Studygroup][1796] CNN Loss=0.9058, Acc=0.6787 | MLP Loss=1.5721, Acc=0.5806\n",
      "[Studygroup][1797] CNN Loss=0.8708, Acc=0.6842 | MLP Loss=1.6164, Acc=0.5802\n",
      "[Studygroup][1798] CNN Loss=0.9311, Acc=0.6734 | MLP Loss=1.6491, Acc=0.5854\n",
      "[Studygroup][1799] CNN Loss=0.9297, Acc=0.6805 | MLP Loss=1.6100, Acc=0.5914\n",
      "[Studygroup][1800] CNN Loss=0.8131, Acc=0.6796 | MLP Loss=1.6466, Acc=0.5890\n",
      "[Studygroup][1801] CNN Loss=0.9074, Acc=0.6571 | MLP Loss=1.6211, Acc=0.5872\n",
      "[Studygroup][1802] CNN Loss=0.9926, Acc=0.6621 | MLP Loss=1.6235, Acc=0.5950\n",
      "[Studygroup][1803] CNN Loss=0.8735, Acc=0.6809 | MLP Loss=1.5801, Acc=0.5943\n",
      "[Studygroup][1804] CNN Loss=0.7727, Acc=0.6796 | MLP Loss=1.6270, Acc=0.5905\n",
      "[Studygroup][1805] CNN Loss=0.8812, Acc=0.6829 | MLP Loss=1.6369, Acc=0.5931\n",
      "[Studygroup][1806] CNN Loss=0.8703, Acc=0.6791 | MLP Loss=1.6434, Acc=0.5881\n",
      "[Studygroup][1807] CNN Loss=0.8576, Acc=0.6802 | MLP Loss=1.6057, Acc=0.5887\n",
      "[Studygroup][1808] CNN Loss=0.9710, Acc=0.6612 | MLP Loss=1.6359, Acc=0.5727\n",
      "[Studygroup][1809] CNN Loss=0.9577, Acc=0.6814 | MLP Loss=1.5997, Acc=0.5876\n",
      "[Studygroup][1810] CNN Loss=0.9282, Acc=0.6818 | MLP Loss=1.5491, Acc=0.5750\n",
      "[Studygroup][1811] CNN Loss=0.8525, Acc=0.6819 | MLP Loss=1.6042, Acc=0.5837\n",
      "[Studygroup][1812] CNN Loss=0.8502, Acc=0.6805 | MLP Loss=1.6463, Acc=0.5885\n",
      "[Studygroup][1813] CNN Loss=0.9109, Acc=0.6807 | MLP Loss=1.5839, Acc=0.5798\n",
      "[Studygroup][1814] CNN Loss=0.9634, Acc=0.6749 | MLP Loss=1.7447, Acc=0.5846\n",
      "[Studygroup][1815] CNN Loss=0.8726, Acc=0.6791 | MLP Loss=1.6768, Acc=0.5881\n",
      "[Studygroup][1816] CNN Loss=0.8166, Acc=0.6771 | MLP Loss=1.6340, Acc=0.5918\n",
      "[Studygroup][1817] CNN Loss=0.9064, Acc=0.6800 | MLP Loss=1.6325, Acc=0.5603\n",
      "[Studygroup][1818] CNN Loss=0.7947, Acc=0.6855 | MLP Loss=1.5771, Acc=0.5903\n",
      "[Studygroup][1819] CNN Loss=0.8655, Acc=0.6796 | MLP Loss=1.6226, Acc=0.5907\n",
      "[Studygroup][1820] CNN Loss=0.8786, Acc=0.6802 | MLP Loss=1.6041, Acc=0.5926\n",
      "[Studygroup][1821] CNN Loss=0.9256, Acc=0.6673 | MLP Loss=1.6111, Acc=0.5861\n",
      "[Studygroup][1822] CNN Loss=0.9519, Acc=0.6840 | MLP Loss=1.6436, Acc=0.5880\n",
      "[Studygroup][1823] CNN Loss=0.9780, Acc=0.6792 | MLP Loss=1.6750, Acc=0.5884\n",
      "[Studygroup][1824] CNN Loss=0.9225, Acc=0.6775 | MLP Loss=1.6541, Acc=0.5909\n",
      "[Studygroup][1825] CNN Loss=0.8198, Acc=0.6833 | MLP Loss=1.6505, Acc=0.5919\n",
      "[Studygroup][1826] CNN Loss=0.8329, Acc=0.6863 | MLP Loss=1.6717, Acc=0.5917\n",
      "[Studygroup][1827] CNN Loss=0.8184, Acc=0.6824 | MLP Loss=1.6533, Acc=0.5877\n",
      "[Studygroup][1828] CNN Loss=0.8163, Acc=0.6804 | MLP Loss=1.6466, Acc=0.5943\n",
      "[Studygroup][1829] CNN Loss=0.8845, Acc=0.6895 | MLP Loss=1.5708, Acc=0.5946\n",
      "[Studygroup][1830] CNN Loss=0.8557, Acc=0.6807 | MLP Loss=1.6207, Acc=0.5947\n",
      "[Studygroup][1831] CNN Loss=0.9358, Acc=0.6828 | MLP Loss=1.6052, Acc=0.5906\n",
      "[Studygroup][1832] CNN Loss=0.8520, Acc=0.6865 | MLP Loss=1.6094, Acc=0.5882\n",
      "[Studygroup][1833] CNN Loss=1.1357, Acc=0.6832 | MLP Loss=1.5950, Acc=0.5966\n",
      "[Studygroup][1834] CNN Loss=0.8864, Acc=0.6813 | MLP Loss=1.6468, Acc=0.5982\n",
      "[Studygroup][1835] CNN Loss=0.8779, Acc=0.6843 | MLP Loss=1.6329, Acc=0.5853\n",
      "[Studygroup][1836] CNN Loss=0.9699, Acc=0.6730 | MLP Loss=1.6756, Acc=0.5956\n",
      "[Studygroup][1837] CNN Loss=0.8564, Acc=0.6839 | MLP Loss=1.6241, Acc=0.5851\n",
      "[Studygroup][1838] CNN Loss=0.9270, Acc=0.6838 | MLP Loss=1.8817, Acc=0.5801\n",
      "[Studygroup][1839] CNN Loss=0.8865, Acc=0.6781 | MLP Loss=1.6492, Acc=0.5884\n",
      "[Studygroup][1840] CNN Loss=0.8941, Acc=0.6823 | MLP Loss=1.5698, Acc=0.5954\n",
      "[Studygroup][1841] CNN Loss=0.9165, Acc=0.6794 | MLP Loss=1.5896, Acc=0.6016\n",
      "[Studygroup][1842] CNN Loss=0.8991, Acc=0.6848 | MLP Loss=1.6031, Acc=0.5898\n",
      "[Studygroup][1843] CNN Loss=0.9208, Acc=0.6851 | MLP Loss=1.5023, Acc=0.5968\n",
      "[Studygroup][1844] CNN Loss=0.8822, Acc=0.6757 | MLP Loss=1.6010, Acc=0.5917\n",
      "[Studygroup][1845] CNN Loss=0.8201, Acc=0.6869 | MLP Loss=1.5571, Acc=0.5933\n",
      "[Studygroup][1846] CNN Loss=0.8326, Acc=0.6786 | MLP Loss=1.5934, Acc=0.5896\n",
      "[Studygroup][1847] CNN Loss=0.9166, Acc=0.6740 | MLP Loss=1.6323, Acc=0.5962\n",
      "[Studygroup][1848] CNN Loss=0.8518, Acc=0.6783 | MLP Loss=1.5652, Acc=0.5967\n",
      "[Studygroup][1849] CNN Loss=0.8918, Acc=0.6820 | MLP Loss=1.6114, Acc=0.5840\n",
      "[Studygroup][1850] CNN Loss=0.8557, Acc=0.6784 | MLP Loss=1.5697, Acc=0.5944\n",
      "[Studygroup][1851] CNN Loss=0.8793, Acc=0.6823 | MLP Loss=1.5809, Acc=0.6001\n",
      "[Studygroup][1852] CNN Loss=0.8897, Acc=0.6771 | MLP Loss=1.6698, Acc=0.5946\n",
      "[Studygroup][1853] CNN Loss=0.8501, Acc=0.6740 | MLP Loss=1.6011, Acc=0.5878\n",
      "[Studygroup][1854] CNN Loss=0.8238, Acc=0.6851 | MLP Loss=1.6802, Acc=0.5896\n",
      "[Studygroup][1855] CNN Loss=0.8044, Acc=0.6859 | MLP Loss=1.7159, Acc=0.5751\n",
      "[Studygroup][1856] CNN Loss=0.8588, Acc=0.6823 | MLP Loss=1.7043, Acc=0.5932\n",
      "[Studygroup][1857] CNN Loss=0.8515, Acc=0.6796 | MLP Loss=1.6495, Acc=0.5849\n",
      "[Studygroup][1858] CNN Loss=0.8996, Acc=0.6753 | MLP Loss=1.8202, Acc=0.5771\n",
      "[Studygroup][1859] CNN Loss=0.8677, Acc=0.6766 | MLP Loss=1.6929, Acc=0.5850\n",
      "[Studygroup][1860] CNN Loss=0.9105, Acc=0.6716 | MLP Loss=1.6314, Acc=0.5934\n",
      "[Studygroup][1861] CNN Loss=0.8779, Acc=0.6743 | MLP Loss=1.5907, Acc=0.5723\n",
      "[Studygroup][1862] CNN Loss=0.9312, Acc=0.6822 | MLP Loss=1.7566, Acc=0.5936\n",
      "[Studygroup][1863] CNN Loss=0.8873, Acc=0.6776 | MLP Loss=1.6842, Acc=0.5975\n",
      "[Studygroup][1864] CNN Loss=0.8229, Acc=0.6839 | MLP Loss=1.6793, Acc=0.5969\n",
      "[Studygroup][1865] CNN Loss=0.8637, Acc=0.6826 | MLP Loss=1.6073, Acc=0.5926\n",
      "[Studygroup][1866] CNN Loss=0.9792, Acc=0.6644 | MLP Loss=1.5318, Acc=0.5974\n",
      "[Studygroup][1867] CNN Loss=0.9204, Acc=0.6825 | MLP Loss=1.5484, Acc=0.5993\n",
      "[Studygroup][1868] CNN Loss=0.8196, Acc=0.6781 | MLP Loss=1.5991, Acc=0.5982\n",
      "[Studygroup][1869] CNN Loss=0.8138, Acc=0.6819 | MLP Loss=1.5526, Acc=0.5948\n",
      "[Studygroup][1870] CNN Loss=0.8986, Acc=0.6807 | MLP Loss=1.6170, Acc=0.5881\n",
      "[Studygroup][1871] CNN Loss=0.8543, Acc=0.6788 | MLP Loss=1.6780, Acc=0.5858\n",
      "[Studygroup][1872] CNN Loss=0.7975, Acc=0.6745 | MLP Loss=1.5629, Acc=0.5850\n",
      "[Studygroup][1873] CNN Loss=0.8441, Acc=0.6820 | MLP Loss=1.6691, Acc=0.5936\n",
      "[Studygroup][1874] CNN Loss=0.9187, Acc=0.6835 | MLP Loss=1.5804, Acc=0.5911\n",
      "[Studygroup][1875] CNN Loss=0.8783, Acc=0.6753 | MLP Loss=1.5935, Acc=0.5831\n",
      "[Studygroup][1876] CNN Loss=0.8993, Acc=0.6724 | MLP Loss=1.6393, Acc=0.5865\n",
      "[Studygroup][1877] CNN Loss=0.9304, Acc=0.6794 | MLP Loss=1.5474, Acc=0.5996\n",
      "[Studygroup][1878] CNN Loss=0.9320, Acc=0.6767 | MLP Loss=1.5859, Acc=0.5925\n",
      "[Studygroup][1879] CNN Loss=0.8740, Acc=0.6759 | MLP Loss=1.6190, Acc=0.5836\n",
      "[Studygroup][1880] CNN Loss=0.9628, Acc=0.6790 | MLP Loss=1.6321, Acc=0.5960\n",
      "[Studygroup][1881] CNN Loss=0.9343, Acc=0.6769 | MLP Loss=1.6764, Acc=0.5855\n",
      "[Studygroup][1882] CNN Loss=0.9106, Acc=0.6803 | MLP Loss=1.6742, Acc=0.5944\n",
      "[Studygroup][1883] CNN Loss=0.9276, Acc=0.6816 | MLP Loss=1.6454, Acc=0.5831\n",
      "[Studygroup][1884] CNN Loss=0.8295, Acc=0.6768 | MLP Loss=1.6288, Acc=0.5880\n",
      "[Studygroup][1885] CNN Loss=0.9690, Acc=0.6824 | MLP Loss=1.6238, Acc=0.5871\n",
      "[Studygroup][1886] CNN Loss=0.9734, Acc=0.6822 | MLP Loss=1.5360, Acc=0.5953\n",
      "[Studygroup][1887] CNN Loss=0.9084, Acc=0.6865 | MLP Loss=1.5550, Acc=0.5950\n",
      "[Studygroup][1888] CNN Loss=0.8120, Acc=0.6749 | MLP Loss=1.6304, Acc=0.5927\n",
      "[Studygroup][1889] CNN Loss=0.8590, Acc=0.6815 | MLP Loss=1.6226, Acc=0.5951\n",
      "[Studygroup][1890] CNN Loss=0.8787, Acc=0.6781 | MLP Loss=1.5538, Acc=0.5983\n",
      "[Studygroup][1891] CNN Loss=0.8787, Acc=0.6714 | MLP Loss=1.6796, Acc=0.5879\n",
      "[Studygroup][1892] CNN Loss=0.9764, Acc=0.6772 | MLP Loss=1.8201, Acc=0.5782\n",
      "[Studygroup][1893] CNN Loss=0.9549, Acc=0.6764 | MLP Loss=1.7946, Acc=0.5844\n",
      "[Studygroup][1894] CNN Loss=0.9339, Acc=0.6747 | MLP Loss=1.6406, Acc=0.5899\n",
      "[Studygroup][1895] CNN Loss=1.0400, Acc=0.6675 | MLP Loss=1.7035, Acc=0.5879\n",
      "[Studygroup][1896] CNN Loss=0.9595, Acc=0.6748 | MLP Loss=1.6359, Acc=0.5962\n",
      "[Studygroup][1897] CNN Loss=0.8422, Acc=0.6753 | MLP Loss=1.5647, Acc=0.5965\n",
      "[Studygroup][1898] CNN Loss=0.8768, Acc=0.6745 | MLP Loss=1.6317, Acc=0.5950\n",
      "[Studygroup][1899] CNN Loss=0.8879, Acc=0.6782 | MLP Loss=1.5669, Acc=0.5884\n",
      "[Studygroup][1900] CNN Loss=0.8723, Acc=0.6795 | MLP Loss=1.6267, Acc=0.5936\n",
      "[Studygroup][1901] CNN Loss=0.8118, Acc=0.6831 | MLP Loss=1.7159, Acc=0.5967\n",
      "[Studygroup][1902] CNN Loss=0.8606, Acc=0.6803 | MLP Loss=1.6320, Acc=0.5907\n",
      "[Studygroup][1903] CNN Loss=0.9027, Acc=0.6709 | MLP Loss=1.6888, Acc=0.5909\n",
      "[Studygroup][1904] CNN Loss=1.0940, Acc=0.6667 | MLP Loss=1.6266, Acc=0.5849\n",
      "[Studygroup][1905] CNN Loss=0.9051, Acc=0.6823 | MLP Loss=1.6207, Acc=0.5950\n",
      "[Studygroup][1906] CNN Loss=0.8893, Acc=0.6811 | MLP Loss=1.6654, Acc=0.5939\n",
      "[Studygroup][1907] CNN Loss=0.8695, Acc=0.6802 | MLP Loss=1.7929, Acc=0.5829\n",
      "[Studygroup][1908] CNN Loss=1.1133, Acc=0.6738 | MLP Loss=1.7943, Acc=0.5854\n",
      "[Studygroup][1909] CNN Loss=0.9279, Acc=0.6703 | MLP Loss=1.6459, Acc=0.5918\n",
      "[Studygroup][1910] CNN Loss=0.8746, Acc=0.6810 | MLP Loss=1.6367, Acc=0.5856\n",
      "[Studygroup][1911] CNN Loss=0.9974, Acc=0.6782 | MLP Loss=1.5933, Acc=0.5964\n",
      "[Studygroup][1912] CNN Loss=0.8329, Acc=0.6813 | MLP Loss=1.6498, Acc=0.5879\n",
      "[Studygroup][1913] CNN Loss=0.9129, Acc=0.6752 | MLP Loss=1.6586, Acc=0.5977\n",
      "[Studygroup][1914] CNN Loss=0.9157, Acc=0.6788 | MLP Loss=1.6705, Acc=0.5895\n",
      "[Studygroup][1915] CNN Loss=0.8636, Acc=0.6728 | MLP Loss=1.6833, Acc=0.5903\n",
      "[Studygroup][1916] CNN Loss=0.8971, Acc=0.6747 | MLP Loss=1.6489, Acc=0.5971\n",
      "[Studygroup][1917] CNN Loss=0.8928, Acc=0.6783 | MLP Loss=1.6059, Acc=0.5862\n",
      "[Studygroup][1918] CNN Loss=0.8373, Acc=0.6798 | MLP Loss=1.6210, Acc=0.5843\n",
      "[Studygroup][1919] CNN Loss=0.8937, Acc=0.6859 | MLP Loss=1.6654, Acc=0.5909\n",
      "[Studygroup][1920] CNN Loss=0.8645, Acc=0.6776 | MLP Loss=1.5716, Acc=0.5903\n",
      "[Studygroup][1921] CNN Loss=0.8699, Acc=0.6791 | MLP Loss=1.6023, Acc=0.5845\n",
      "[Studygroup][1922] CNN Loss=0.8742, Acc=0.6775 | MLP Loss=1.7248, Acc=0.5960\n",
      "[Studygroup][1923] CNN Loss=0.8630, Acc=0.6760 | MLP Loss=1.6259, Acc=0.5936\n",
      "[Studygroup][1924] CNN Loss=0.8397, Acc=0.6840 | MLP Loss=1.6561, Acc=0.5963\n",
      "[Studygroup][1925] CNN Loss=0.9268, Acc=0.6827 | MLP Loss=1.7020, Acc=0.5829\n",
      "[Studygroup][1926] CNN Loss=0.9161, Acc=0.6756 | MLP Loss=1.6417, Acc=0.5978\n",
      "[Studygroup][1927] CNN Loss=0.8991, Acc=0.6788 | MLP Loss=1.6175, Acc=0.5860\n",
      "[Studygroup][1928] CNN Loss=0.9514, Acc=0.6777 | MLP Loss=1.6295, Acc=0.5793\n",
      "[Studygroup][1929] CNN Loss=0.8070, Acc=0.6840 | MLP Loss=1.6053, Acc=0.5920\n",
      "[Studygroup][1930] CNN Loss=0.9061, Acc=0.6789 | MLP Loss=1.6227, Acc=0.5918\n",
      "[Studygroup][1931] CNN Loss=0.8710, Acc=0.6770 | MLP Loss=1.5895, Acc=0.5879\n",
      "[Studygroup][1932] CNN Loss=0.8699, Acc=0.6698 | MLP Loss=1.6492, Acc=0.5968\n",
      "[Studygroup][1933] CNN Loss=1.0796, Acc=0.6670 | MLP Loss=1.7048, Acc=0.5883\n",
      "[Studygroup][1934] CNN Loss=0.8589, Acc=0.6734 | MLP Loss=1.6446, Acc=0.5881\n",
      "[Studygroup][1935] CNN Loss=0.9515, Acc=0.6802 | MLP Loss=1.6509, Acc=0.5944\n",
      "[Studygroup][1936] CNN Loss=0.8221, Acc=0.6773 | MLP Loss=1.6225, Acc=0.5931\n",
      "[Studygroup][1937] CNN Loss=0.8451, Acc=0.6784 | MLP Loss=1.7898, Acc=0.5775\n",
      "[Studygroup][1938] CNN Loss=1.0150, Acc=0.6771 | MLP Loss=1.7794, Acc=0.5860\n",
      "[Studygroup][1939] CNN Loss=0.8349, Acc=0.6800 | MLP Loss=1.6064, Acc=0.5990\n",
      "[Studygroup][1940] CNN Loss=0.8167, Acc=0.6784 | MLP Loss=1.6855, Acc=0.5940\n",
      "[Studygroup][1941] CNN Loss=0.8608, Acc=0.6752 | MLP Loss=1.6546, Acc=0.5967\n",
      "[Studygroup][1942] CNN Loss=0.8011, Acc=0.6721 | MLP Loss=1.6351, Acc=0.5918\n",
      "[Studygroup][1943] CNN Loss=0.9776, Acc=0.6834 | MLP Loss=1.8074, Acc=0.5888\n",
      "[Studygroup][1944] CNN Loss=0.9752, Acc=0.6769 | MLP Loss=1.6635, Acc=0.5963\n",
      "[Studygroup][1945] CNN Loss=0.8963, Acc=0.6787 | MLP Loss=1.6615, Acc=0.5942\n",
      "[Studygroup][1946] CNN Loss=0.8041, Acc=0.6822 | MLP Loss=1.6214, Acc=0.5966\n",
      "[Studygroup][1947] CNN Loss=0.9753, Acc=0.6759 | MLP Loss=1.6722, Acc=0.5909\n",
      "[Studygroup][1948] CNN Loss=1.1343, Acc=0.6748 | MLP Loss=1.7495, Acc=0.5835\n",
      "[Studygroup][1949] CNN Loss=0.9155, Acc=0.6824 | MLP Loss=1.7326, Acc=0.5958\n",
      "[Studygroup][1950] CNN Loss=0.9429, Acc=0.6766 | MLP Loss=1.6524, Acc=0.5907\n",
      "[Studygroup][1951] CNN Loss=0.8339, Acc=0.6759 | MLP Loss=1.6196, Acc=0.5914\n",
      "[Studygroup][1952] CNN Loss=0.9061, Acc=0.6783 | MLP Loss=1.7124, Acc=0.5806\n",
      "[Studygroup][1953] CNN Loss=0.9573, Acc=0.6735 | MLP Loss=1.7454, Acc=0.5819\n",
      "[Studygroup][1954] CNN Loss=0.8739, Acc=0.6775 | MLP Loss=1.6284, Acc=0.5936\n",
      "[Studygroup][1955] CNN Loss=0.8482, Acc=0.6808 | MLP Loss=1.5487, Acc=0.5993\n",
      "[Studygroup][1956] CNN Loss=0.9185, Acc=0.6731 | MLP Loss=1.5638, Acc=0.5964\n",
      "[Studygroup][1957] CNN Loss=1.0250, Acc=0.6744 | MLP Loss=1.6002, Acc=0.5933\n",
      "[Studygroup][1958] CNN Loss=0.8611, Acc=0.6827 | MLP Loss=1.6526, Acc=0.5906\n",
      "[Studygroup][1959] CNN Loss=1.0015, Acc=0.6745 | MLP Loss=1.6355, Acc=0.5908\n",
      "[Studygroup][1960] CNN Loss=0.8212, Acc=0.6854 | MLP Loss=1.6609, Acc=0.5952\n",
      "[Studygroup][1961] CNN Loss=0.8108, Acc=0.6779 | MLP Loss=1.6304, Acc=0.5906\n",
      "[Studygroup][1962] CNN Loss=0.8452, Acc=0.6739 | MLP Loss=1.5983, Acc=0.5930\n",
      "[Studygroup][1963] CNN Loss=0.8314, Acc=0.6823 | MLP Loss=1.6394, Acc=0.5978\n",
      "[Studygroup][1964] CNN Loss=0.9015, Acc=0.6745 | MLP Loss=1.6651, Acc=0.5961\n",
      "[Studygroup][1965] CNN Loss=0.8699, Acc=0.6769 | MLP Loss=1.5225, Acc=0.6020\n",
      "[Studygroup][1966] CNN Loss=0.8900, Acc=0.6737 | MLP Loss=1.5631, Acc=0.6023\n",
      "[Studygroup][1967] CNN Loss=0.7776, Acc=0.6799 | MLP Loss=1.6194, Acc=0.5932\n",
      "[Studygroup][1968] CNN Loss=0.8521, Acc=0.6777 | MLP Loss=1.6155, Acc=0.5886\n",
      "[Studygroup][1969] CNN Loss=0.7738, Acc=0.6870 | MLP Loss=1.7434, Acc=0.5801\n",
      "[Studygroup][1970] CNN Loss=0.9160, Acc=0.6788 | MLP Loss=1.6245, Acc=0.5889\n",
      "[Studygroup][1971] CNN Loss=0.9332, Acc=0.6763 | MLP Loss=1.5729, Acc=0.6001\n",
      "[Studygroup][1972] CNN Loss=0.8850, Acc=0.6667 | MLP Loss=1.5604, Acc=0.5925\n",
      "[Studygroup][1973] CNN Loss=0.9492, Acc=0.6774 | MLP Loss=1.6087, Acc=0.5805\n",
      "[Studygroup][1974] CNN Loss=0.8487, Acc=0.6653 | MLP Loss=1.5942, Acc=0.5868\n",
      "[Studygroup][1975] CNN Loss=0.9100, Acc=0.6828 | MLP Loss=1.5909, Acc=0.6041\n",
      "[Studygroup][1976] CNN Loss=0.9217, Acc=0.6728 | MLP Loss=1.6210, Acc=0.5823\n",
      "[Studygroup][1977] CNN Loss=0.8185, Acc=0.6746 | MLP Loss=1.7581, Acc=0.5990\n",
      "[Studygroup][1978] CNN Loss=0.9001, Acc=0.6798 | MLP Loss=1.6538, Acc=0.5968\n",
      "[Studygroup][1979] CNN Loss=0.8981, Acc=0.6782 | MLP Loss=1.5426, Acc=0.5991\n",
      "[Studygroup][1980] CNN Loss=0.8900, Acc=0.6758 | MLP Loss=1.6613, Acc=0.5999\n",
      "[Studygroup][1981] CNN Loss=0.9095, Acc=0.6746 | MLP Loss=1.6441, Acc=0.5916\n",
      "[Studygroup][1982] CNN Loss=0.9274, Acc=0.6773 | MLP Loss=1.5768, Acc=0.5949\n",
      "[Studygroup][1983] CNN Loss=0.9008, Acc=0.6838 | MLP Loss=1.6924, Acc=0.5901\n",
      "[Studygroup][1984] CNN Loss=0.9077, Acc=0.6724 | MLP Loss=1.5807, Acc=0.5931\n",
      "[Studygroup][1985] CNN Loss=0.8438, Acc=0.6805 | MLP Loss=1.5615, Acc=0.5930\n",
      "[Studygroup][1986] CNN Loss=0.8359, Acc=0.6774 | MLP Loss=1.5595, Acc=0.5836\n",
      "[Studygroup][1987] CNN Loss=0.8708, Acc=0.6749 | MLP Loss=1.6743, Acc=0.5799\n",
      "[Studygroup][1988] CNN Loss=0.8315, Acc=0.6725 | MLP Loss=1.5491, Acc=0.5878\n",
      "[Studygroup][1989] CNN Loss=0.9115, Acc=0.6788 | MLP Loss=1.5847, Acc=0.5893\n",
      "[Studygroup][1990] CNN Loss=0.8822, Acc=0.6800 | MLP Loss=1.5447, Acc=0.5935\n",
      "[Studygroup][1991] CNN Loss=0.7548, Acc=0.6869 | MLP Loss=1.5665, Acc=0.5960\n",
      "[Studygroup][1992] CNN Loss=0.8896, Acc=0.6815 | MLP Loss=1.6667, Acc=0.5969\n",
      "[Studygroup][1993] CNN Loss=0.7558, Acc=0.6821 | MLP Loss=1.6579, Acc=0.5862\n",
      "[Studygroup][1994] CNN Loss=0.8297, Acc=0.6807 | MLP Loss=1.6996, Acc=0.5925\n",
      "[Studygroup][1995] CNN Loss=0.8074, Acc=0.6702 | MLP Loss=1.5914, Acc=0.5880\n",
      "[Studygroup][1996] CNN Loss=0.9173, Acc=0.6698 | MLP Loss=1.6084, Acc=0.6010\n",
      "[Studygroup][1997] CNN Loss=1.0161, Acc=0.6706 | MLP Loss=1.6433, Acc=0.5956\n",
      "[Studygroup][1998] CNN Loss=0.8744, Acc=0.6743 | MLP Loss=1.6241, Acc=0.5808\n",
      "[Studygroup][1999] CNN Loss=0.8699, Acc=0.6777 | MLP Loss=1.6950, Acc=0.6007\n"
     ]
    }
   ],
   "source": [
    "cnn_sg = CNN_CIFAR().to(device)\n",
    "cnn_sg.load_state_dict(cnn_init_state)\n",
    "mlp_sg = MLP_CIFAR().to(device)\n",
    "mlp_sg.load_state_dict(mlp_init_state)\n",
    "\n",
    "opt_cnn_sg = torch.optim.Adam(cnn_sg.parameters(), lr=1e-3)\n",
    "opt_mlp_sg = torch.optim.Adam(mlp_sg.parameters(), lr=1e-3)\n",
    "\n",
    "train_studygroup(\n",
    "    cnn_sg,\n",
    "    mlp_sg,\n",
    "    opt_cnn_sg,\n",
    "    opt_mlp_sg,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    epochs,\n",
    "    logs[\"studygroup_cnn\"],\n",
    "    logs[\"studygroup_mlp\"],\n",
    "    T=2.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c1eb4a-a9d9-4338-8ff7-fa2e8973129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(logs[\"baseline_cnn\"][\"test_acc\"], label=\"Baseline CNN\")\n",
    "plt.plot(logs[\"baseline_mlp\"][\"test_acc\"], label=\"Baseline MLP\")\n",
    "plt.plot(logs[\"studygroup_cnn\"][\"test_acc\"], label=\"Studygroup CNN\")\n",
    "plt.plot(logs[\"studygroup_mlp\"][\"test_acc\"], label=\"Studygroup MLP\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"MNIST Test Accuracy Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f87409c4-b6d8-4b93-8d26-b2ed53864235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6612\n",
      "0.5827\n",
      "0.6914\n",
      "0.6041\n"
     ]
    }
   ],
   "source": [
    "print(max(logs[\"baseline_cnn\"][\"test_acc\"]))\n",
    "print(max(logs[\"baseline_mlp\"][\"test_acc\"]))\n",
    "print(max(logs[\"studygroup_cnn\"][\"test_acc\"]))\n",
    "print(max(logs[\"studygroup_mlp\"][\"test_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7f6df1b-0aa5-4f97-8397-f5e1d625fa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(logs[\"baseline_cnn\"][\"train_loss\"], label=\"Baseline CNN\")\n",
    "plt.plot(logs[\"studygroup_cnn\"][\"train_loss\"], label=\"Studygroup CNN\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"CNN Training Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de53d230-ace4-4bc9-ac0c-3a98717fc5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa7e7029dcf41f89dfc5b08e7ff3d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Studygroup][00] CNN Loss=2.2355, Acc=0.3047 | MLP Loss=2.3225, Acc=0.1517\n",
      "[Studygroup][01] CNN Loss=2.1588, Acc=0.3265 | MLP Loss=2.3237, Acc=0.1737\n",
      "[Studygroup][02] CNN Loss=2.0872, Acc=0.3771 | MLP Loss=2.3209, Acc=0.1813\n",
      "[Studygroup][03] CNN Loss=2.0331, Acc=0.4177 | MLP Loss=2.2904, Acc=0.2197\n",
      "[Studygroup][04] CNN Loss=2.0037, Acc=0.4272 | MLP Loss=2.2989, Acc=0.2402\n",
      "[Studygroup][05] CNN Loss=1.9726, Acc=0.4460 | MLP Loss=2.2842, Acc=0.2358\n",
      "[Studygroup][06] CNN Loss=1.9538, Acc=0.4307 | MLP Loss=2.2853, Acc=0.2357\n",
      "[Studygroup][07] CNN Loss=1.9539, Acc=0.4573 | MLP Loss=2.2411, Acc=0.2738\n",
      "[Studygroup][08] CNN Loss=1.8953, Acc=0.4784 | MLP Loss=2.2271, Acc=0.2687\n",
      "[Studygroup][09] CNN Loss=1.9072, Acc=0.4771 | MLP Loss=2.2585, Acc=0.2656\n",
      "[Studygroup][10] CNN Loss=1.8909, Acc=0.4932 | MLP Loss=2.2296, Acc=0.2464\n",
      "[Studygroup][11] CNN Loss=1.8503, Acc=0.4679 | MLP Loss=2.1946, Acc=0.2421\n",
      "[Studygroup][12] CNN Loss=1.8781, Acc=0.4757 | MLP Loss=2.2229, Acc=0.2639\n",
      "[Studygroup][13] CNN Loss=1.8610, Acc=0.5217 | MLP Loss=2.2012, Acc=0.2545\n",
      "[Studygroup][14] CNN Loss=1.8455, Acc=0.4940 | MLP Loss=2.1551, Acc=0.2464\n",
      "[Studygroup][15] CNN Loss=1.7701, Acc=0.5241 | MLP Loss=2.1710, Acc=0.3004\n",
      "[Studygroup][16] CNN Loss=1.7985, Acc=0.4974 | MLP Loss=2.1611, Acc=0.2957\n",
      "[Studygroup][17] CNN Loss=1.7703, Acc=0.5289 | MLP Loss=2.1684, Acc=0.2916\n",
      "[Studygroup][18] CNN Loss=1.7370, Acc=0.5342 | MLP Loss=2.1847, Acc=0.3042\n",
      "[Studygroup][19] CNN Loss=1.7731, Acc=0.5446 | MLP Loss=2.1628, Acc=0.2993\n",
      "[Studygroup][20] CNN Loss=1.7365, Acc=0.5544 | MLP Loss=2.1304, Acc=0.3129\n",
      "[Studygroup][21] CNN Loss=1.7467, Acc=0.5307 | MLP Loss=2.1614, Acc=0.3035\n",
      "[Studygroup][22] CNN Loss=1.7338, Acc=0.5517 | MLP Loss=2.1476, Acc=0.3224\n",
      "[Studygroup][23] CNN Loss=1.6996, Acc=0.5456 | MLP Loss=2.1730, Acc=0.3058\n",
      "[Studygroup][24] CNN Loss=1.7224, Acc=0.5310 | MLP Loss=2.1883, Acc=0.2893\n",
      "[Studygroup][25] CNN Loss=1.7046, Acc=0.5373 | MLP Loss=2.1591, Acc=0.3187\n",
      "[Studygroup][26] CNN Loss=1.6783, Acc=0.5653 | MLP Loss=2.1219, Acc=0.3221\n",
      "[Studygroup][27] CNN Loss=1.6800, Acc=0.5349 | MLP Loss=2.0958, Acc=0.3193\n",
      "[Studygroup][28] CNN Loss=1.6369, Acc=0.5684 | MLP Loss=2.0890, Acc=0.3320\n",
      "[Studygroup][29] CNN Loss=1.6096, Acc=0.5518 | MLP Loss=2.0934, Acc=0.3144\n",
      "[Studygroup][30] CNN Loss=1.5677, Acc=0.5518 | MLP Loss=2.0871, Acc=0.3065\n",
      "[Studygroup][31] CNN Loss=1.6129, Acc=0.5759 | MLP Loss=2.1145, Acc=0.3252\n",
      "[Studygroup][32] CNN Loss=1.5855, Acc=0.5815 | MLP Loss=2.1041, Acc=0.3349\n",
      "[Studygroup][33] CNN Loss=1.5573, Acc=0.5541 | MLP Loss=2.0966, Acc=0.3293\n",
      "[Studygroup][34] CNN Loss=1.5650, Acc=0.5702 | MLP Loss=2.0645, Acc=0.3244\n",
      "[Studygroup][35] CNN Loss=1.5654, Acc=0.5868 | MLP Loss=2.0777, Acc=0.3117\n",
      "[Studygroup][36] CNN Loss=1.5373, Acc=0.5502 | MLP Loss=2.0637, Acc=0.3154\n",
      "[Studygroup][37] CNN Loss=1.6108, Acc=0.5878 | MLP Loss=2.1598, Acc=0.3570\n",
      "[Studygroup][38] CNN Loss=1.5318, Acc=0.5605 | MLP Loss=2.0491, Acc=0.3337\n",
      "[Studygroup][39] CNN Loss=1.5375, Acc=0.5667 | MLP Loss=2.0913, Acc=0.3481\n",
      "[Studygroup][40] CNN Loss=1.5249, Acc=0.5697 | MLP Loss=2.0755, Acc=0.3507\n",
      "[Studygroup][41] CNN Loss=1.4904, Acc=0.5910 | MLP Loss=2.0666, Acc=0.3454\n",
      "[Studygroup][42] CNN Loss=1.5093, Acc=0.5856 | MLP Loss=2.0668, Acc=0.3256\n",
      "[Studygroup][43] CNN Loss=1.5128, Acc=0.5858 | MLP Loss=2.0743, Acc=0.3352\n",
      "[Studygroup][44] CNN Loss=1.5019, Acc=0.5892 | MLP Loss=2.0869, Acc=0.3340\n",
      "[Studygroup][45] CNN Loss=1.5414, Acc=0.5912 | MLP Loss=2.0993, Acc=0.3415\n",
      "[Studygroup][46] CNN Loss=1.4392, Acc=0.5974 | MLP Loss=2.0346, Acc=0.3516\n",
      "[Studygroup][47] CNN Loss=1.5095, Acc=0.5873 | MLP Loss=2.0754, Acc=0.3508\n",
      "[Studygroup][48] CNN Loss=1.4889, Acc=0.5966 | MLP Loss=2.0323, Acc=0.3777\n",
      "[Studygroup][49] CNN Loss=1.4581, Acc=0.5706 | MLP Loss=2.0320, Acc=0.3565\n",
      "[Studygroup][50] CNN Loss=1.4846, Acc=0.5886 | MLP Loss=2.0485, Acc=0.3248\n",
      "[Studygroup][51] CNN Loss=1.4606, Acc=0.6039 | MLP Loss=2.0530, Acc=0.3561\n",
      "[Studygroup][52] CNN Loss=1.4407, Acc=0.5986 | MLP Loss=2.0493, Acc=0.3373\n",
      "[Studygroup][53] CNN Loss=1.4418, Acc=0.6116 | MLP Loss=2.0329, Acc=0.3713\n",
      "[Studygroup][54] CNN Loss=1.4021, Acc=0.6106 | MLP Loss=2.0113, Acc=0.3613\n",
      "[Studygroup][55] CNN Loss=1.4410, Acc=0.6173 | MLP Loss=2.0549, Acc=0.3571\n",
      "[Studygroup][56] CNN Loss=1.4331, Acc=0.5964 | MLP Loss=2.0362, Acc=0.3797\n",
      "[Studygroup][57] CNN Loss=1.4384, Acc=0.6132 | MLP Loss=1.9963, Acc=0.3697\n",
      "[Studygroup][58] CNN Loss=1.4181, Acc=0.6073 | MLP Loss=2.0278, Acc=0.3479\n",
      "[Studygroup][59] CNN Loss=1.4135, Acc=0.6138 | MLP Loss=2.0415, Acc=0.3969\n",
      "[Studygroup][60] CNN Loss=1.4164, Acc=0.6126 | MLP Loss=2.0447, Acc=0.3880\n",
      "[Studygroup][61] CNN Loss=1.3986, Acc=0.6111 | MLP Loss=2.0412, Acc=0.3784\n",
      "[Studygroup][62] CNN Loss=1.3884, Acc=0.6112 | MLP Loss=2.0040, Acc=0.4121\n",
      "[Studygroup][63] CNN Loss=1.3926, Acc=0.6187 | MLP Loss=1.9756, Acc=0.3985\n",
      "[Studygroup][64] CNN Loss=1.3960, Acc=0.6080 | MLP Loss=1.9982, Acc=0.3585\n",
      "[Studygroup][65] CNN Loss=1.4072, Acc=0.6155 | MLP Loss=2.0194, Acc=0.3656\n",
      "[Studygroup][66] CNN Loss=1.4092, Acc=0.6143 | MLP Loss=2.0521, Acc=0.3811\n",
      "[Studygroup][67] CNN Loss=1.3938, Acc=0.6102 | MLP Loss=2.0068, Acc=0.4051\n",
      "[Studygroup][68] CNN Loss=1.3644, Acc=0.6188 | MLP Loss=1.9636, Acc=0.4131\n",
      "[Studygroup][69] CNN Loss=1.3226, Acc=0.6074 | MLP Loss=2.0095, Acc=0.3978\n",
      "[Studygroup][70] CNN Loss=1.3613, Acc=0.6061 | MLP Loss=1.9991, Acc=0.4074\n",
      "[Studygroup][71] CNN Loss=1.3889, Acc=0.5977 | MLP Loss=2.0063, Acc=0.4089\n",
      "[Studygroup][72] CNN Loss=1.3944, Acc=0.6170 | MLP Loss=2.0111, Acc=0.4069\n",
      "[Studygroup][73] CNN Loss=1.3730, Acc=0.6241 | MLP Loss=2.0140, Acc=0.3965\n",
      "[Studygroup][74] CNN Loss=1.3953, Acc=0.6160 | MLP Loss=1.9924, Acc=0.4014\n",
      "[Studygroup][75] CNN Loss=1.3887, Acc=0.6020 | MLP Loss=1.9713, Acc=0.3791\n",
      "[Studygroup][76] CNN Loss=1.3614, Acc=0.6202 | MLP Loss=2.0219, Acc=0.3940\n",
      "[Studygroup][77] CNN Loss=1.3528, Acc=0.6250 | MLP Loss=2.0324, Acc=0.4035\n",
      "[Studygroup][78] CNN Loss=1.3956, Acc=0.6129 | MLP Loss=1.9925, Acc=0.3980\n",
      "[Studygroup][79] CNN Loss=1.3240, Acc=0.6297 | MLP Loss=1.9665, Acc=0.4066\n",
      "[Studygroup][80] CNN Loss=1.3317, Acc=0.6138 | MLP Loss=1.9301, Acc=0.4232\n",
      "[Studygroup][81] CNN Loss=1.3350, Acc=0.6250 | MLP Loss=1.9490, Acc=0.4219\n",
      "[Studygroup][82] CNN Loss=1.3335, Acc=0.6044 | MLP Loss=1.9621, Acc=0.4075\n",
      "[Studygroup][83] CNN Loss=1.2946, Acc=0.6049 | MLP Loss=1.9782, Acc=0.4053\n",
      "[Studygroup][84] CNN Loss=1.3393, Acc=0.6295 | MLP Loss=1.9962, Acc=0.4138\n",
      "[Studygroup][85] CNN Loss=1.3314, Acc=0.6127 | MLP Loss=2.0121, Acc=0.4018\n",
      "[Studygroup][86] CNN Loss=1.3444, Acc=0.6228 | MLP Loss=1.9398, Acc=0.4280\n",
      "[Studygroup][87] CNN Loss=1.3013, Acc=0.6299 | MLP Loss=1.9829, Acc=0.4164\n",
      "[Studygroup][88] CNN Loss=1.2979, Acc=0.6331 | MLP Loss=1.9706, Acc=0.4253\n",
      "[Studygroup][89] CNN Loss=1.3198, Acc=0.6206 | MLP Loss=1.9517, Acc=0.4123\n",
      "[Studygroup][90] CNN Loss=1.3424, Acc=0.6294 | MLP Loss=1.9371, Acc=0.4176\n",
      "[Studygroup][91] CNN Loss=1.2840, Acc=0.6270 | MLP Loss=1.9535, Acc=0.4127\n",
      "[Studygroup][92] CNN Loss=1.3075, Acc=0.6164 | MLP Loss=1.9345, Acc=0.4311\n",
      "[Studygroup][93] CNN Loss=1.2667, Acc=0.6341 | MLP Loss=1.9774, Acc=0.4349\n",
      "[Studygroup][94] CNN Loss=1.2728, Acc=0.6229 | MLP Loss=1.9727, Acc=0.4268\n",
      "[Studygroup][95] CNN Loss=1.3062, Acc=0.6274 | MLP Loss=1.9829, Acc=0.4223\n",
      "[Studygroup][96] CNN Loss=1.3012, Acc=0.6152 | MLP Loss=1.9274, Acc=0.4199\n",
      "[Studygroup][97] CNN Loss=1.2690, Acc=0.6304 | MLP Loss=1.9556, Acc=0.3977\n",
      "[Studygroup][98] CNN Loss=1.2970, Acc=0.6273 | MLP Loss=1.9927, Acc=0.4079\n",
      "[Studygroup][99] CNN Loss=1.2615, Acc=0.6291 | MLP Loss=1.9703, Acc=0.4000\n",
      "[Studygroup][100] CNN Loss=1.3184, Acc=0.6295 | MLP Loss=1.9906, Acc=0.4139\n",
      "[Studygroup][101] CNN Loss=1.3074, Acc=0.6230 | MLP Loss=1.9884, Acc=0.4135\n",
      "[Studygroup][102] CNN Loss=1.2444, Acc=0.6199 | MLP Loss=1.9562, Acc=0.4241\n",
      "[Studygroup][103] CNN Loss=1.2688, Acc=0.6330 | MLP Loss=1.8931, Acc=0.4332\n",
      "[Studygroup][104] CNN Loss=1.2653, Acc=0.6317 | MLP Loss=1.9417, Acc=0.4335\n",
      "[Studygroup][105] CNN Loss=1.2966, Acc=0.6270 | MLP Loss=1.9134, Acc=0.4236\n",
      "[Studygroup][106] CNN Loss=1.2552, Acc=0.6150 | MLP Loss=1.9381, Acc=0.4316\n",
      "[Studygroup][107] CNN Loss=1.2543, Acc=0.6351 | MLP Loss=1.9820, Acc=0.4391\n",
      "[Studygroup][108] CNN Loss=1.2586, Acc=0.6316 | MLP Loss=1.9945, Acc=0.4263\n",
      "[Studygroup][109] CNN Loss=1.2539, Acc=0.6283 | MLP Loss=1.9374, Acc=0.4414\n",
      "[Studygroup][110] CNN Loss=1.2314, Acc=0.6393 | MLP Loss=1.9184, Acc=0.4351\n",
      "[Studygroup][111] CNN Loss=1.2400, Acc=0.6469 | MLP Loss=1.9585, Acc=0.4373\n",
      "[Studygroup][112] CNN Loss=1.2297, Acc=0.6246 | MLP Loss=1.9606, Acc=0.4529\n",
      "[Studygroup][113] CNN Loss=1.2293, Acc=0.6297 | MLP Loss=1.9459, Acc=0.4412\n",
      "[Studygroup][114] CNN Loss=1.2577, Acc=0.6214 | MLP Loss=1.9704, Acc=0.4464\n",
      "[Studygroup][115] CNN Loss=1.2214, Acc=0.6448 | MLP Loss=1.9215, Acc=0.4415\n",
      "[Studygroup][116] CNN Loss=1.2449, Acc=0.6338 | MLP Loss=1.9499, Acc=0.4490\n",
      "[Studygroup][117] CNN Loss=1.1943, Acc=0.6297 | MLP Loss=1.8791, Acc=0.4102\n",
      "[Studygroup][118] CNN Loss=1.1982, Acc=0.6330 | MLP Loss=1.9406, Acc=0.4191\n",
      "[Studygroup][119] CNN Loss=1.2625, Acc=0.6404 | MLP Loss=1.9669, Acc=0.4360\n",
      "[Studygroup][120] CNN Loss=1.2143, Acc=0.6288 | MLP Loss=1.9116, Acc=0.4268\n",
      "[Studygroup][121] CNN Loss=1.2014, Acc=0.6270 | MLP Loss=1.9514, Acc=0.4362\n",
      "[Studygroup][122] CNN Loss=1.2463, Acc=0.6335 | MLP Loss=2.0215, Acc=0.4330\n",
      "[Studygroup][123] CNN Loss=1.2604, Acc=0.6278 | MLP Loss=1.9311, Acc=0.4487\n",
      "[Studygroup][124] CNN Loss=1.2686, Acc=0.6391 | MLP Loss=1.9408, Acc=0.4424\n",
      "[Studygroup][125] CNN Loss=1.2455, Acc=0.6324 | MLP Loss=1.9481, Acc=0.4400\n",
      "[Studygroup][126] CNN Loss=1.1775, Acc=0.6434 | MLP Loss=1.9508, Acc=0.4518\n",
      "[Studygroup][127] CNN Loss=1.2569, Acc=0.6416 | MLP Loss=1.9290, Acc=0.4551\n",
      "[Studygroup][128] CNN Loss=1.1812, Acc=0.6368 | MLP Loss=1.9220, Acc=0.4554\n",
      "[Studygroup][129] CNN Loss=1.2564, Acc=0.6419 | MLP Loss=1.9857, Acc=0.4599\n",
      "[Studygroup][130] CNN Loss=1.1907, Acc=0.6472 | MLP Loss=1.9329, Acc=0.4411\n",
      "[Studygroup][131] CNN Loss=1.2053, Acc=0.6381 | MLP Loss=1.9324, Acc=0.4542\n",
      "[Studygroup][132] CNN Loss=1.2003, Acc=0.6186 | MLP Loss=1.9753, Acc=0.4250\n",
      "[Studygroup][133] CNN Loss=1.2130, Acc=0.6444 | MLP Loss=1.9181, Acc=0.4577\n",
      "[Studygroup][134] CNN Loss=1.2635, Acc=0.6493 | MLP Loss=1.9776, Acc=0.4481\n",
      "[Studygroup][135] CNN Loss=1.1820, Acc=0.6334 | MLP Loss=1.9139, Acc=0.4364\n",
      "[Studygroup][136] CNN Loss=1.2501, Acc=0.6451 | MLP Loss=1.9241, Acc=0.4473\n",
      "[Studygroup][137] CNN Loss=1.2174, Acc=0.6470 | MLP Loss=1.9281, Acc=0.4170\n",
      "[Studygroup][138] CNN Loss=1.2839, Acc=0.6356 | MLP Loss=1.9526, Acc=0.4446\n",
      "[Studygroup][139] CNN Loss=1.1918, Acc=0.6382 | MLP Loss=1.9054, Acc=0.4571\n",
      "[Studygroup][140] CNN Loss=1.1965, Acc=0.6416 | MLP Loss=1.9127, Acc=0.4593\n",
      "[Studygroup][141] CNN Loss=1.2209, Acc=0.6393 | MLP Loss=1.9409, Acc=0.4545\n",
      "[Studygroup][142] CNN Loss=1.2142, Acc=0.6449 | MLP Loss=1.9420, Acc=0.4444\n",
      "[Studygroup][143] CNN Loss=1.1828, Acc=0.6416 | MLP Loss=1.9279, Acc=0.4643\n",
      "[Studygroup][144] CNN Loss=1.1938, Acc=0.6502 | MLP Loss=1.9418, Acc=0.4411\n",
      "[Studygroup][145] CNN Loss=1.1757, Acc=0.6412 | MLP Loss=1.9311, Acc=0.4531\n",
      "[Studygroup][146] CNN Loss=1.2162, Acc=0.6407 | MLP Loss=1.9459, Acc=0.4241\n",
      "[Studygroup][147] CNN Loss=1.1668, Acc=0.6380 | MLP Loss=1.9018, Acc=0.4611\n",
      "[Studygroup][148] CNN Loss=1.1568, Acc=0.6465 | MLP Loss=1.9073, Acc=0.4656\n",
      "[Studygroup][149] CNN Loss=1.1882, Acc=0.6389 | MLP Loss=1.9326, Acc=0.4652\n",
      "[Studygroup][150] CNN Loss=1.1805, Acc=0.6515 | MLP Loss=1.9557, Acc=0.4408\n",
      "[Studygroup][151] CNN Loss=1.1890, Acc=0.6479 | MLP Loss=1.9456, Acc=0.4349\n",
      "[Studygroup][152] CNN Loss=1.1460, Acc=0.6520 | MLP Loss=1.9504, Acc=0.4510\n",
      "[Studygroup][153] CNN Loss=1.1927, Acc=0.6408 | MLP Loss=1.9303, Acc=0.4642\n",
      "[Studygroup][154] CNN Loss=1.1661, Acc=0.6460 | MLP Loss=1.9057, Acc=0.4592\n",
      "[Studygroup][155] CNN Loss=1.1783, Acc=0.6380 | MLP Loss=1.9422, Acc=0.4538\n",
      "[Studygroup][156] CNN Loss=1.1367, Acc=0.6513 | MLP Loss=1.9392, Acc=0.4694\n",
      "[Studygroup][157] CNN Loss=1.1967, Acc=0.6453 | MLP Loss=2.0141, Acc=0.4692\n",
      "[Studygroup][158] CNN Loss=1.1590, Acc=0.6416 | MLP Loss=2.0170, Acc=0.4698\n",
      "[Studygroup][159] CNN Loss=1.2042, Acc=0.6363 | MLP Loss=1.9412, Acc=0.4468\n",
      "[Studygroup][160] CNN Loss=1.1746, Acc=0.6395 | MLP Loss=1.9372, Acc=0.4594\n",
      "[Studygroup][161] CNN Loss=1.1731, Acc=0.6430 | MLP Loss=1.9801, Acc=0.4577\n",
      "[Studygroup][162] CNN Loss=1.1718, Acc=0.6405 | MLP Loss=1.9230, Acc=0.4656\n",
      "[Studygroup][163] CNN Loss=1.1376, Acc=0.6463 | MLP Loss=1.9275, Acc=0.4717\n",
      "[Studygroup][164] CNN Loss=1.2471, Acc=0.6386 | MLP Loss=1.9590, Acc=0.4770\n",
      "[Studygroup][165] CNN Loss=1.1938, Acc=0.6476 | MLP Loss=1.9384, Acc=0.4550\n",
      "[Studygroup][166] CNN Loss=1.1774, Acc=0.6498 | MLP Loss=1.9847, Acc=0.4669\n",
      "[Studygroup][167] CNN Loss=1.1371, Acc=0.6431 | MLP Loss=1.9364, Acc=0.4436\n",
      "[Studygroup][168] CNN Loss=1.2324, Acc=0.6352 | MLP Loss=1.9041, Acc=0.4575\n",
      "[Studygroup][169] CNN Loss=1.2316, Acc=0.6387 | MLP Loss=1.8507, Acc=0.4797\n",
      "[Studygroup][170] CNN Loss=1.1554, Acc=0.6539 | MLP Loss=1.8856, Acc=0.4516\n",
      "[Studygroup][171] CNN Loss=1.1916, Acc=0.6470 | MLP Loss=1.8696, Acc=0.4587\n",
      "[Studygroup][172] CNN Loss=1.1465, Acc=0.6409 | MLP Loss=1.8880, Acc=0.4747\n",
      "[Studygroup][173] CNN Loss=1.1522, Acc=0.6512 | MLP Loss=1.8583, Acc=0.4637\n",
      "[Studygroup][174] CNN Loss=1.1323, Acc=0.6405 | MLP Loss=1.9025, Acc=0.4781\n",
      "[Studygroup][175] CNN Loss=1.1526, Acc=0.6358 | MLP Loss=1.9220, Acc=0.4687\n",
      "[Studygroup][176] CNN Loss=1.1674, Acc=0.6528 | MLP Loss=1.8890, Acc=0.4592\n",
      "[Studygroup][177] CNN Loss=1.1317, Acc=0.6538 | MLP Loss=1.8981, Acc=0.4776\n",
      "[Studygroup][178] CNN Loss=1.0813, Acc=0.6350 | MLP Loss=1.9111, Acc=0.4636\n",
      "[Studygroup][179] CNN Loss=1.1211, Acc=0.6430 | MLP Loss=1.8818, Acc=0.4670\n",
      "[Studygroup][180] CNN Loss=1.1432, Acc=0.6455 | MLP Loss=1.8864, Acc=0.4628\n",
      "[Studygroup][181] CNN Loss=1.0922, Acc=0.6504 | MLP Loss=1.8875, Acc=0.4818\n",
      "[Studygroup][182] CNN Loss=1.1486, Acc=0.6461 | MLP Loss=1.9405, Acc=0.4639\n",
      "[Studygroup][183] CNN Loss=1.1424, Acc=0.6408 | MLP Loss=2.0066, Acc=0.4449\n",
      "[Studygroup][184] CNN Loss=1.3028, Acc=0.6386 | MLP Loss=2.0762, Acc=0.4681\n",
      "[Studygroup][185] CNN Loss=1.1064, Acc=0.6452 | MLP Loss=1.8982, Acc=0.4805\n",
      "[Studygroup][186] CNN Loss=1.1427, Acc=0.6509 | MLP Loss=1.8858, Acc=0.4724\n",
      "[Studygroup][187] CNN Loss=1.0932, Acc=0.6511 | MLP Loss=1.8923, Acc=0.4832\n",
      "[Studygroup][188] CNN Loss=1.1259, Acc=0.6516 | MLP Loss=1.9160, Acc=0.4484\n",
      "[Studygroup][189] CNN Loss=1.1613, Acc=0.6443 | MLP Loss=1.8762, Acc=0.4691\n",
      "[Studygroup][190] CNN Loss=1.1655, Acc=0.6389 | MLP Loss=1.9260, Acc=0.4836\n",
      "[Studygroup][191] CNN Loss=1.1444, Acc=0.6488 | MLP Loss=1.8660, Acc=0.4882\n",
      "[Studygroup][192] CNN Loss=1.1173, Acc=0.6512 | MLP Loss=1.8918, Acc=0.4765\n",
      "[Studygroup][193] CNN Loss=1.0983, Acc=0.6467 | MLP Loss=1.9362, Acc=0.4547\n",
      "[Studygroup][194] CNN Loss=1.2374, Acc=0.6542 | MLP Loss=2.0853, Acc=0.4671\n",
      "[Studygroup][195] CNN Loss=1.1251, Acc=0.6411 | MLP Loss=1.8658, Acc=0.4846\n",
      "[Studygroup][196] CNN Loss=1.1102, Acc=0.6387 | MLP Loss=1.8810, Acc=0.4770\n",
      "[Studygroup][197] CNN Loss=1.1015, Acc=0.6488 | MLP Loss=1.8711, Acc=0.4700\n",
      "[Studygroup][198] CNN Loss=1.1389, Acc=0.6503 | MLP Loss=1.8850, Acc=0.4795\n",
      "[Studygroup][199] CNN Loss=1.1109, Acc=0.6479 | MLP Loss=1.8749, Acc=0.4730\n",
      "[Studygroup][200] CNN Loss=1.0913, Acc=0.6512 | MLP Loss=1.8995, Acc=0.4809\n",
      "[Studygroup][201] CNN Loss=1.1254, Acc=0.6500 | MLP Loss=1.8856, Acc=0.4667\n",
      "[Studygroup][202] CNN Loss=1.0968, Acc=0.6555 | MLP Loss=1.8734, Acc=0.4838\n",
      "[Studygroup][203] CNN Loss=1.1858, Acc=0.6323 | MLP Loss=2.0087, Acc=0.4709\n",
      "[Studygroup][204] CNN Loss=1.1394, Acc=0.6542 | MLP Loss=1.8577, Acc=0.4888\n",
      "[Studygroup][205] CNN Loss=1.1227, Acc=0.6515 | MLP Loss=1.9324, Acc=0.4833\n",
      "[Studygroup][206] CNN Loss=1.1414, Acc=0.6400 | MLP Loss=1.9426, Acc=0.4706\n",
      "[Studygroup][207] CNN Loss=1.1008, Acc=0.6522 | MLP Loss=1.8416, Acc=0.4645\n",
      "[Studygroup][208] CNN Loss=1.1523, Acc=0.6506 | MLP Loss=1.8680, Acc=0.4692\n",
      "[Studygroup][209] CNN Loss=1.1440, Acc=0.6461 | MLP Loss=1.8111, Acc=0.4845\n",
      "[Studygroup][210] CNN Loss=1.0996, Acc=0.6579 | MLP Loss=1.8882, Acc=0.4865\n",
      "[Studygroup][211] CNN Loss=1.1144, Acc=0.6555 | MLP Loss=1.9326, Acc=0.4756\n",
      "[Studygroup][212] CNN Loss=1.1422, Acc=0.6529 | MLP Loss=1.9610, Acc=0.4614\n",
      "[Studygroup][213] CNN Loss=1.0984, Acc=0.6546 | MLP Loss=1.8958, Acc=0.4803\n",
      "[Studygroup][214] CNN Loss=1.1123, Acc=0.6440 | MLP Loss=1.8369, Acc=0.4922\n",
      "[Studygroup][215] CNN Loss=1.1134, Acc=0.6529 | MLP Loss=1.9018, Acc=0.4968\n",
      "[Studygroup][216] CNN Loss=1.0964, Acc=0.6452 | MLP Loss=1.9012, Acc=0.4776\n",
      "[Studygroup][217] CNN Loss=1.1265, Acc=0.6596 | MLP Loss=1.8443, Acc=0.4918\n",
      "[Studygroup][218] CNN Loss=1.1318, Acc=0.6544 | MLP Loss=1.8562, Acc=0.4963\n",
      "[Studygroup][219] CNN Loss=1.0988, Acc=0.6501 | MLP Loss=1.8285, Acc=0.4772\n",
      "[Studygroup][220] CNN Loss=1.0736, Acc=0.6523 | MLP Loss=1.8379, Acc=0.4694\n",
      "[Studygroup][221] CNN Loss=1.0901, Acc=0.6551 | MLP Loss=1.8898, Acc=0.4877\n",
      "[Studygroup][222] CNN Loss=1.1401, Acc=0.6490 | MLP Loss=1.8532, Acc=0.4895\n",
      "[Studygroup][223] CNN Loss=1.1014, Acc=0.6561 | MLP Loss=1.8721, Acc=0.4966\n",
      "[Studygroup][224] CNN Loss=1.1433, Acc=0.6516 | MLP Loss=1.9086, Acc=0.4806\n",
      "[Studygroup][225] CNN Loss=1.1512, Acc=0.6487 | MLP Loss=1.8867, Acc=0.4951\n",
      "[Studygroup][226] CNN Loss=1.0987, Acc=0.6567 | MLP Loss=1.8789, Acc=0.4849\n",
      "[Studygroup][227] CNN Loss=1.1064, Acc=0.6538 | MLP Loss=1.8791, Acc=0.4837\n",
      "[Studygroup][228] CNN Loss=1.0948, Acc=0.6522 | MLP Loss=1.8860, Acc=0.4686\n",
      "[Studygroup][229] CNN Loss=1.1517, Acc=0.6544 | MLP Loss=1.9569, Acc=0.4905\n",
      "[Studygroup][230] CNN Loss=1.1104, Acc=0.6470 | MLP Loss=1.8205, Acc=0.4916\n",
      "[Studygroup][231] CNN Loss=1.1148, Acc=0.6523 | MLP Loss=1.8685, Acc=0.4961\n",
      "[Studygroup][232] CNN Loss=1.0753, Acc=0.6526 | MLP Loss=1.9359, Acc=0.4699\n",
      "[Studygroup][233] CNN Loss=1.1637, Acc=0.6447 | MLP Loss=1.9444, Acc=0.4868\n",
      "[Studygroup][234] CNN Loss=1.1156, Acc=0.6564 | MLP Loss=1.8552, Acc=0.5011\n",
      "[Studygroup][235] CNN Loss=1.0864, Acc=0.6522 | MLP Loss=1.8600, Acc=0.4929\n",
      "[Studygroup][236] CNN Loss=1.1283, Acc=0.6525 | MLP Loss=1.8407, Acc=0.4987\n",
      "[Studygroup][237] CNN Loss=1.0856, Acc=0.6520 | MLP Loss=1.8298, Acc=0.4906\n",
      "[Studygroup][238] CNN Loss=1.1056, Acc=0.6582 | MLP Loss=1.9161, Acc=0.4909\n",
      "[Studygroup][239] CNN Loss=1.1053, Acc=0.6582 | MLP Loss=1.8668, Acc=0.4940\n",
      "[Studygroup][240] CNN Loss=1.0766, Acc=0.6513 | MLP Loss=1.8016, Acc=0.4901\n",
      "[Studygroup][241] CNN Loss=1.1033, Acc=0.6471 | MLP Loss=1.8966, Acc=0.4887\n",
      "[Studygroup][242] CNN Loss=1.1227, Acc=0.6482 | MLP Loss=1.8548, Acc=0.5078\n",
      "[Studygroup][243] CNN Loss=1.1013, Acc=0.6568 | MLP Loss=1.8696, Acc=0.4919\n",
      "[Studygroup][244] CNN Loss=1.0557, Acc=0.6573 | MLP Loss=1.8640, Acc=0.5046\n",
      "[Studygroup][245] CNN Loss=1.0847, Acc=0.6603 | MLP Loss=1.8392, Acc=0.5023\n",
      "[Studygroup][246] CNN Loss=1.0189, Acc=0.6492 | MLP Loss=1.8828, Acc=0.4811\n",
      "[Studygroup][247] CNN Loss=1.0653, Acc=0.6576 | MLP Loss=1.8796, Acc=0.4986\n",
      "[Studygroup][248] CNN Loss=1.0945, Acc=0.6530 | MLP Loss=1.8446, Acc=0.4985\n",
      "[Studygroup][249] CNN Loss=1.0856, Acc=0.6447 | MLP Loss=1.8950, Acc=0.4611\n",
      "[Studygroup][250] CNN Loss=1.1018, Acc=0.6540 | MLP Loss=1.8761, Acc=0.5092\n",
      "[Studygroup][251] CNN Loss=1.0519, Acc=0.6435 | MLP Loss=1.8007, Acc=0.4821\n",
      "[Studygroup][252] CNN Loss=1.1017, Acc=0.6532 | MLP Loss=1.8918, Acc=0.4987\n",
      "[Studygroup][253] CNN Loss=1.0201, Acc=0.6583 | MLP Loss=1.8799, Acc=0.4866\n",
      "[Studygroup][254] CNN Loss=1.0051, Acc=0.6424 | MLP Loss=1.8594, Acc=0.4921\n",
      "[Studygroup][255] CNN Loss=1.0212, Acc=0.6412 | MLP Loss=1.8649, Acc=0.5147\n",
      "[Studygroup][256] CNN Loss=1.0821, Acc=0.6537 | MLP Loss=1.8641, Acc=0.5039\n",
      "[Studygroup][257] CNN Loss=1.0639, Acc=0.6555 | MLP Loss=1.8831, Acc=0.4978\n",
      "[Studygroup][258] CNN Loss=1.0968, Acc=0.6526 | MLP Loss=1.8727, Acc=0.5088\n",
      "[Studygroup][259] CNN Loss=1.0720, Acc=0.6459 | MLP Loss=1.9204, Acc=0.5055\n",
      "[Studygroup][260] CNN Loss=1.1238, Acc=0.6506 | MLP Loss=1.9251, Acc=0.5070\n",
      "[Studygroup][261] CNN Loss=1.1445, Acc=0.6508 | MLP Loss=1.8552, Acc=0.5071\n",
      "[Studygroup][262] CNN Loss=1.1156, Acc=0.6520 | MLP Loss=1.8261, Acc=0.5051\n",
      "[Studygroup][263] CNN Loss=1.0819, Acc=0.6487 | MLP Loss=1.8666, Acc=0.5011\n",
      "[Studygroup][264] CNN Loss=1.1533, Acc=0.6463 | MLP Loss=1.8294, Acc=0.5027\n",
      "[Studygroup][265] CNN Loss=1.0668, Acc=0.6601 | MLP Loss=1.8448, Acc=0.4987\n",
      "[Studygroup][266] CNN Loss=1.0190, Acc=0.6477 | MLP Loss=1.8383, Acc=0.5101\n",
      "[Studygroup][267] CNN Loss=1.0943, Acc=0.6452 | MLP Loss=1.8191, Acc=0.5043\n",
      "[Studygroup][268] CNN Loss=1.0969, Acc=0.6568 | MLP Loss=1.8632, Acc=0.4991\n",
      "[Studygroup][269] CNN Loss=1.0655, Acc=0.6500 | MLP Loss=1.8601, Acc=0.4752\n",
      "[Studygroup][270] CNN Loss=1.1200, Acc=0.6521 | MLP Loss=1.8823, Acc=0.4903\n",
      "[Studygroup][271] CNN Loss=1.0610, Acc=0.6581 | MLP Loss=1.8029, Acc=0.5118\n",
      "[Studygroup][272] CNN Loss=1.0610, Acc=0.6556 | MLP Loss=1.8075, Acc=0.5014\n",
      "[Studygroup][273] CNN Loss=1.1097, Acc=0.6533 | MLP Loss=1.8485, Acc=0.4930\n",
      "[Studygroup][274] CNN Loss=1.0622, Acc=0.6579 | MLP Loss=1.7835, Acc=0.5120\n",
      "[Studygroup][275] CNN Loss=1.0601, Acc=0.6482 | MLP Loss=1.8390, Acc=0.4950\n",
      "[Studygroup][276] CNN Loss=1.0256, Acc=0.6581 | MLP Loss=1.9032, Acc=0.5013\n",
      "[Studygroup][277] CNN Loss=1.1452, Acc=0.6472 | MLP Loss=1.9568, Acc=0.4927\n",
      "[Studygroup][278] CNN Loss=1.0669, Acc=0.6551 | MLP Loss=1.7765, Acc=0.5066\n",
      "[Studygroup][279] CNN Loss=1.0705, Acc=0.6598 | MLP Loss=1.8526, Acc=0.5113\n",
      "[Studygroup][280] CNN Loss=1.0424, Acc=0.6444 | MLP Loss=1.7969, Acc=0.5140\n",
      "[Studygroup][281] CNN Loss=1.0537, Acc=0.6574 | MLP Loss=1.8233, Acc=0.5069\n",
      "[Studygroup][282] CNN Loss=1.0585, Acc=0.6531 | MLP Loss=1.8747, Acc=0.4976\n",
      "[Studygroup][283] CNN Loss=1.0398, Acc=0.6552 | MLP Loss=1.8345, Acc=0.5137\n",
      "[Studygroup][284] CNN Loss=1.0913, Acc=0.6555 | MLP Loss=1.9001, Acc=0.4930\n",
      "[Studygroup][285] CNN Loss=1.0345, Acc=0.6568 | MLP Loss=1.8664, Acc=0.5016\n",
      "[Studygroup][286] CNN Loss=1.1118, Acc=0.6444 | MLP Loss=1.8622, Acc=0.5067\n",
      "[Studygroup][287] CNN Loss=1.0768, Acc=0.6523 | MLP Loss=1.8138, Acc=0.4957\n",
      "[Studygroup][288] CNN Loss=1.1484, Acc=0.6526 | MLP Loss=1.8373, Acc=0.5040\n",
      "[Studygroup][289] CNN Loss=1.0986, Acc=0.6583 | MLP Loss=1.8874, Acc=0.5164\n",
      "[Studygroup][290] CNN Loss=1.1579, Acc=0.6557 | MLP Loss=1.9389, Acc=0.4870\n",
      "[Studygroup][291] CNN Loss=1.1441, Acc=0.6505 | MLP Loss=1.8970, Acc=0.5136\n",
      "[Studygroup][292] CNN Loss=1.0677, Acc=0.6579 | MLP Loss=1.8252, Acc=0.5186\n",
      "[Studygroup][293] CNN Loss=1.0217, Acc=0.6564 | MLP Loss=1.8445, Acc=0.5057\n",
      "[Studygroup][294] CNN Loss=1.0619, Acc=0.6546 | MLP Loss=1.8243, Acc=0.5079\n",
      "[Studygroup][295] CNN Loss=1.0718, Acc=0.6512 | MLP Loss=1.8407, Acc=0.4862\n",
      "[Studygroup][296] CNN Loss=1.0603, Acc=0.6569 | MLP Loss=1.8729, Acc=0.5099\n",
      "[Studygroup][297] CNN Loss=1.0303, Acc=0.6603 | MLP Loss=1.8335, Acc=0.5151\n",
      "[Studygroup][298] CNN Loss=1.1335, Acc=0.6587 | MLP Loss=1.8740, Acc=0.5021\n",
      "[Studygroup][299] CNN Loss=1.1206, Acc=0.6532 | MLP Loss=1.8566, Acc=0.5180\n",
      "[Studygroup][300] CNN Loss=1.0820, Acc=0.6568 | MLP Loss=1.7718, Acc=0.5070\n",
      "[Studygroup][301] CNN Loss=1.0117, Acc=0.6550 | MLP Loss=1.8001, Acc=0.4852\n",
      "[Studygroup][302] CNN Loss=1.0345, Acc=0.6539 | MLP Loss=1.8428, Acc=0.5090\n",
      "[Studygroup][303] CNN Loss=1.0453, Acc=0.6565 | MLP Loss=1.8373, Acc=0.4831\n",
      "[Studygroup][304] CNN Loss=1.0770, Acc=0.6526 | MLP Loss=1.8433, Acc=0.5037\n",
      "[Studygroup][305] CNN Loss=1.1009, Acc=0.6533 | MLP Loss=1.8381, Acc=0.4944\n",
      "[Studygroup][306] CNN Loss=1.0393, Acc=0.6593 | MLP Loss=1.8243, Acc=0.5223\n",
      "[Studygroup][307] CNN Loss=1.0389, Acc=0.6531 | MLP Loss=1.8372, Acc=0.5081\n",
      "[Studygroup][308] CNN Loss=1.0162, Acc=0.6512 | MLP Loss=1.8088, Acc=0.5090\n",
      "[Studygroup][309] CNN Loss=1.0556, Acc=0.6543 | MLP Loss=1.8796, Acc=0.5163\n",
      "[Studygroup][310] CNN Loss=1.0600, Acc=0.6623 | MLP Loss=1.8884, Acc=0.5138\n",
      "[Studygroup][311] CNN Loss=1.0754, Acc=0.6495 | MLP Loss=1.7882, Acc=0.5154\n",
      "[Studygroup][312] CNN Loss=1.1124, Acc=0.6559 | MLP Loss=1.8279, Acc=0.5111\n",
      "[Studygroup][313] CNN Loss=1.0895, Acc=0.6528 | MLP Loss=1.8319, Acc=0.5128\n",
      "[Studygroup][314] CNN Loss=1.0586, Acc=0.6613 | MLP Loss=1.8090, Acc=0.5140\n",
      "[Studygroup][315] CNN Loss=1.0352, Acc=0.6601 | MLP Loss=1.7934, Acc=0.5063\n",
      "[Studygroup][316] CNN Loss=1.0553, Acc=0.6585 | MLP Loss=1.8076, Acc=0.5176\n",
      "[Studygroup][317] CNN Loss=0.9825, Acc=0.6517 | MLP Loss=1.8240, Acc=0.4985\n",
      "[Studygroup][318] CNN Loss=1.0609, Acc=0.6575 | MLP Loss=1.8573, Acc=0.5149\n",
      "[Studygroup][319] CNN Loss=1.0247, Acc=0.6628 | MLP Loss=1.8654, Acc=0.5180\n",
      "[Studygroup][320] CNN Loss=1.0781, Acc=0.6486 | MLP Loss=1.8396, Acc=0.5085\n",
      "[Studygroup][321] CNN Loss=1.0124, Acc=0.6530 | MLP Loss=1.8258, Acc=0.5124\n",
      "[Studygroup][322] CNN Loss=1.0007, Acc=0.6593 | MLP Loss=1.7702, Acc=0.5222\n",
      "[Studygroup][323] CNN Loss=1.0170, Acc=0.6609 | MLP Loss=1.8067, Acc=0.4949\n",
      "[Studygroup][324] CNN Loss=1.1087, Acc=0.6599 | MLP Loss=1.9112, Acc=0.5084\n",
      "[Studygroup][325] CNN Loss=1.0809, Acc=0.6513 | MLP Loss=1.7963, Acc=0.5181\n",
      "[Studygroup][326] CNN Loss=1.0143, Acc=0.6666 | MLP Loss=1.8102, Acc=0.5196\n",
      "[Studygroup][327] CNN Loss=1.0368, Acc=0.6608 | MLP Loss=1.8569, Acc=0.5123\n",
      "[Studygroup][328] CNN Loss=1.0383, Acc=0.6545 | MLP Loss=1.8065, Acc=0.5079\n",
      "[Studygroup][329] CNN Loss=1.0319, Acc=0.6570 | MLP Loss=1.8419, Acc=0.5215\n",
      "[Studygroup][330] CNN Loss=1.0237, Acc=0.6591 | MLP Loss=1.8093, Acc=0.5083\n",
      "[Studygroup][331] CNN Loss=1.0056, Acc=0.6627 | MLP Loss=1.8292, Acc=0.5252\n",
      "[Studygroup][332] CNN Loss=1.0494, Acc=0.6606 | MLP Loss=1.8772, Acc=0.5111\n",
      "[Studygroup][333] CNN Loss=1.0685, Acc=0.6607 | MLP Loss=1.8833, Acc=0.5213\n",
      "[Studygroup][334] CNN Loss=1.0555, Acc=0.6529 | MLP Loss=1.8157, Acc=0.5027\n",
      "[Studygroup][335] CNN Loss=1.0534, Acc=0.6601 | MLP Loss=1.8007, Acc=0.5166\n",
      "[Studygroup][336] CNN Loss=1.0679, Acc=0.6588 | MLP Loss=1.8343, Acc=0.5202\n",
      "[Studygroup][337] CNN Loss=1.0164, Acc=0.6534 | MLP Loss=1.8087, Acc=0.5191\n",
      "[Studygroup][338] CNN Loss=1.0778, Acc=0.6554 | MLP Loss=1.7926, Acc=0.5188\n",
      "[Studygroup][339] CNN Loss=1.0858, Acc=0.6532 | MLP Loss=1.8350, Acc=0.5152\n",
      "[Studygroup][340] CNN Loss=1.0487, Acc=0.6624 | MLP Loss=1.7657, Acc=0.5053\n",
      "[Studygroup][341] CNN Loss=1.0386, Acc=0.6572 | MLP Loss=1.8402, Acc=0.5164\n",
      "[Studygroup][342] CNN Loss=1.0238, Acc=0.6485 | MLP Loss=1.7968, Acc=0.4870\n",
      "[Studygroup][343] CNN Loss=1.0967, Acc=0.6613 | MLP Loss=1.8717, Acc=0.5197\n",
      "[Studygroup][344] CNN Loss=1.0699, Acc=0.6539 | MLP Loss=1.8114, Acc=0.5184\n",
      "[Studygroup][345] CNN Loss=1.0393, Acc=0.6674 | MLP Loss=1.8139, Acc=0.5217\n",
      "[Studygroup][346] CNN Loss=1.0687, Acc=0.6619 | MLP Loss=1.8582, Acc=0.5027\n",
      "[Studygroup][347] CNN Loss=1.0703, Acc=0.6633 | MLP Loss=1.7770, Acc=0.5327\n",
      "[Studygroup][348] CNN Loss=1.0287, Acc=0.6550 | MLP Loss=1.7832, Acc=0.5296\n",
      "[Studygroup][349] CNN Loss=1.0410, Acc=0.6569 | MLP Loss=1.7920, Acc=0.5201\n",
      "[Studygroup][350] CNN Loss=1.0034, Acc=0.6580 | MLP Loss=1.7678, Acc=0.5280\n",
      "[Studygroup][351] CNN Loss=1.0642, Acc=0.6473 | MLP Loss=1.8572, Acc=0.5188\n",
      "[Studygroup][352] CNN Loss=1.0846, Acc=0.6527 | MLP Loss=1.7624, Acc=0.5146\n",
      "[Studygroup][353] CNN Loss=1.0350, Acc=0.6558 | MLP Loss=1.8132, Acc=0.5101\n",
      "[Studygroup][354] CNN Loss=1.0299, Acc=0.6575 | MLP Loss=1.8314, Acc=0.5166\n",
      "[Studygroup][355] CNN Loss=1.0499, Acc=0.6483 | MLP Loss=1.8349, Acc=0.5169\n",
      "[Studygroup][356] CNN Loss=1.0717, Acc=0.6602 | MLP Loss=1.7823, Acc=0.5062\n",
      "[Studygroup][357] CNN Loss=1.0216, Acc=0.6561 | MLP Loss=1.7819, Acc=0.5259\n",
      "[Studygroup][358] CNN Loss=1.0068, Acc=0.6597 | MLP Loss=1.7440, Acc=0.5275\n",
      "[Studygroup][359] CNN Loss=1.0082, Acc=0.6611 | MLP Loss=1.8416, Acc=0.5102\n",
      "[Studygroup][360] CNN Loss=1.0138, Acc=0.6577 | MLP Loss=1.7987, Acc=0.5295\n",
      "[Studygroup][361] CNN Loss=1.0406, Acc=0.6567 | MLP Loss=1.9031, Acc=0.5223\n",
      "[Studygroup][362] CNN Loss=1.1502, Acc=0.6557 | MLP Loss=1.9293, Acc=0.5275\n",
      "[Studygroup][363] CNN Loss=0.9605, Acc=0.6571 | MLP Loss=1.7842, Acc=0.5299\n",
      "[Studygroup][364] CNN Loss=1.0179, Acc=0.6514 | MLP Loss=1.7838, Acc=0.5126\n",
      "[Studygroup][365] CNN Loss=0.9549, Acc=0.6552 | MLP Loss=1.8417, Acc=0.5289\n",
      "[Studygroup][366] CNN Loss=0.9684, Acc=0.6573 | MLP Loss=1.7764, Acc=0.5330\n",
      "[Studygroup][367] CNN Loss=1.0116, Acc=0.6563 | MLP Loss=1.8811, Acc=0.5341\n",
      "[Studygroup][368] CNN Loss=1.0589, Acc=0.6634 | MLP Loss=1.8123, Acc=0.5263\n",
      "[Studygroup][369] CNN Loss=1.0214, Acc=0.6616 | MLP Loss=1.8254, Acc=0.5112\n",
      "[Studygroup][370] CNN Loss=0.9919, Acc=0.6623 | MLP Loss=1.8196, Acc=0.5185\n",
      "[Studygroup][371] CNN Loss=1.0085, Acc=0.6518 | MLP Loss=1.7781, Acc=0.5146\n",
      "[Studygroup][372] CNN Loss=1.0130, Acc=0.6530 | MLP Loss=1.7709, Acc=0.5244\n",
      "[Studygroup][373] CNN Loss=0.9815, Acc=0.6643 | MLP Loss=1.8253, Acc=0.5156\n",
      "[Studygroup][374] CNN Loss=1.0637, Acc=0.6576 | MLP Loss=1.8453, Acc=0.5138\n",
      "[Studygroup][375] CNN Loss=1.0279, Acc=0.6595 | MLP Loss=1.7433, Acc=0.5325\n",
      "[Studygroup][376] CNN Loss=0.9737, Acc=0.6598 | MLP Loss=1.8113, Acc=0.5345\n",
      "[Studygroup][377] CNN Loss=1.0078, Acc=0.6517 | MLP Loss=1.8042, Acc=0.5241\n",
      "[Studygroup][378] CNN Loss=1.0172, Acc=0.6536 | MLP Loss=1.8609, Acc=0.5327\n",
      "[Studygroup][379] CNN Loss=1.0045, Acc=0.6615 | MLP Loss=1.8300, Acc=0.5162\n",
      "[Studygroup][380] CNN Loss=1.0048, Acc=0.6535 | MLP Loss=1.8222, Acc=0.5105\n",
      "[Studygroup][381] CNN Loss=0.9835, Acc=0.6680 | MLP Loss=1.8066, Acc=0.5222\n",
      "[Studygroup][382] CNN Loss=1.0070, Acc=0.6630 | MLP Loss=1.8527, Acc=0.5258\n",
      "[Studygroup][383] CNN Loss=1.0366, Acc=0.6584 | MLP Loss=1.8641, Acc=0.5176\n",
      "[Studygroup][384] CNN Loss=0.9272, Acc=0.6673 | MLP Loss=1.8503, Acc=0.5253\n",
      "[Studygroup][385] CNN Loss=1.0139, Acc=0.6599 | MLP Loss=1.8291, Acc=0.5310\n",
      "[Studygroup][386] CNN Loss=0.9851, Acc=0.6603 | MLP Loss=1.7836, Acc=0.5116\n",
      "[Studygroup][387] CNN Loss=0.9948, Acc=0.6562 | MLP Loss=1.8408, Acc=0.5116\n",
      "[Studygroup][388] CNN Loss=1.0314, Acc=0.6587 | MLP Loss=1.7995, Acc=0.5324\n",
      "[Studygroup][389] CNN Loss=1.0658, Acc=0.6557 | MLP Loss=1.8526, Acc=0.5034\n",
      "[Studygroup][390] CNN Loss=1.0109, Acc=0.6566 | MLP Loss=1.8428, Acc=0.5130\n",
      "[Studygroup][391] CNN Loss=1.0151, Acc=0.6609 | MLP Loss=1.8090, Acc=0.5224\n",
      "[Studygroup][392] CNN Loss=1.0151, Acc=0.6626 | MLP Loss=1.8321, Acc=0.5205\n",
      "[Studygroup][393] CNN Loss=0.9973, Acc=0.6528 | MLP Loss=1.8429, Acc=0.5142\n",
      "[Studygroup][394] CNN Loss=0.9901, Acc=0.6600 | MLP Loss=1.7874, Acc=0.5248\n",
      "[Studygroup][395] CNN Loss=0.9702, Acc=0.6638 | MLP Loss=1.8104, Acc=0.5312\n",
      "[Studygroup][396] CNN Loss=1.0116, Acc=0.6600 | MLP Loss=1.8627, Acc=0.5261\n",
      "[Studygroup][397] CNN Loss=0.9920, Acc=0.6562 | MLP Loss=1.7802, Acc=0.5401\n",
      "[Studygroup][398] CNN Loss=0.9816, Acc=0.6599 | MLP Loss=1.7915, Acc=0.5241\n",
      "[Studygroup][399] CNN Loss=1.0019, Acc=0.6603 | MLP Loss=1.7720, Acc=0.5339\n",
      "[Studygroup][400] CNN Loss=1.0374, Acc=0.6616 | MLP Loss=1.7245, Acc=0.5228\n",
      "[Studygroup][401] CNN Loss=1.0050, Acc=0.6597 | MLP Loss=1.7958, Acc=0.5306\n",
      "[Studygroup][402] CNN Loss=0.9734, Acc=0.6624 | MLP Loss=1.8169, Acc=0.5258\n",
      "[Studygroup][403] CNN Loss=0.9568, Acc=0.6619 | MLP Loss=1.7614, Acc=0.5217\n",
      "[Studygroup][404] CNN Loss=1.0248, Acc=0.6575 | MLP Loss=1.8201, Acc=0.5223\n",
      "[Studygroup][405] CNN Loss=1.0120, Acc=0.6579 | MLP Loss=1.7774, Acc=0.5369\n",
      "[Studygroup][406] CNN Loss=0.9517, Acc=0.6641 | MLP Loss=1.7778, Acc=0.5350\n",
      "[Studygroup][407] CNN Loss=0.9332, Acc=0.6578 | MLP Loss=1.8368, Acc=0.5239\n",
      "[Studygroup][408] CNN Loss=0.9801, Acc=0.6668 | MLP Loss=1.7927, Acc=0.5195\n",
      "[Studygroup][409] CNN Loss=1.0107, Acc=0.6532 | MLP Loss=1.8505, Acc=0.5115\n",
      "[Studygroup][410] CNN Loss=1.1464, Acc=0.6476 | MLP Loss=1.8941, Acc=0.5286\n",
      "[Studygroup][411] CNN Loss=0.9846, Acc=0.6675 | MLP Loss=1.7959, Acc=0.5382\n",
      "[Studygroup][412] CNN Loss=0.9311, Acc=0.6652 | MLP Loss=1.7949, Acc=0.5210\n",
      "[Studygroup][413] CNN Loss=1.0401, Acc=0.6469 | MLP Loss=1.8391, Acc=0.5204\n",
      "[Studygroup][414] CNN Loss=1.0324, Acc=0.6518 | MLP Loss=1.7314, Acc=0.5226\n",
      "[Studygroup][415] CNN Loss=1.1098, Acc=0.6576 | MLP Loss=1.7977, Acc=0.5203\n",
      "[Studygroup][416] CNN Loss=1.0246, Acc=0.6601 | MLP Loss=1.7836, Acc=0.5407\n",
      "[Studygroup][417] CNN Loss=0.9790, Acc=0.6655 | MLP Loss=1.7314, Acc=0.5364\n",
      "[Studygroup][418] CNN Loss=0.9373, Acc=0.6637 | MLP Loss=1.7468, Acc=0.5255\n",
      "[Studygroup][419] CNN Loss=0.9760, Acc=0.6635 | MLP Loss=1.7872, Acc=0.5280\n",
      "[Studygroup][420] CNN Loss=0.9679, Acc=0.6587 | MLP Loss=1.7832, Acc=0.5337\n",
      "[Studygroup][421] CNN Loss=0.9938, Acc=0.6668 | MLP Loss=1.7627, Acc=0.5248\n",
      "[Studygroup][422] CNN Loss=0.9837, Acc=0.6556 | MLP Loss=1.8088, Acc=0.5354\n",
      "[Studygroup][423] CNN Loss=0.9655, Acc=0.6665 | MLP Loss=1.7851, Acc=0.5215\n",
      "[Studygroup][424] CNN Loss=0.9683, Acc=0.6543 | MLP Loss=1.7747, Acc=0.5338\n",
      "[Studygroup][425] CNN Loss=0.9637, Acc=0.6642 | MLP Loss=1.8217, Acc=0.5250\n",
      "[Studygroup][426] CNN Loss=0.9310, Acc=0.6567 | MLP Loss=1.7781, Acc=0.5325\n",
      "[Studygroup][427] CNN Loss=0.9560, Acc=0.6557 | MLP Loss=1.8303, Acc=0.5228\n",
      "[Studygroup][428] CNN Loss=0.9438, Acc=0.6619 | MLP Loss=1.8169, Acc=0.5182\n",
      "[Studygroup][429] CNN Loss=1.0070, Acc=0.6596 | MLP Loss=1.8263, Acc=0.5139\n",
      "[Studygroup][430] CNN Loss=0.9997, Acc=0.6638 | MLP Loss=1.8520, Acc=0.5401\n",
      "[Studygroup][431] CNN Loss=1.0681, Acc=0.6606 | MLP Loss=1.8380, Acc=0.5393\n",
      "[Studygroup][432] CNN Loss=0.9911, Acc=0.6626 | MLP Loss=1.7797, Acc=0.5352\n",
      "[Studygroup][433] CNN Loss=1.0106, Acc=0.6618 | MLP Loss=1.8105, Acc=0.5138\n",
      "[Studygroup][434] CNN Loss=1.0739, Acc=0.6589 | MLP Loss=1.9381, Acc=0.5204\n",
      "[Studygroup][435] CNN Loss=0.9809, Acc=0.6618 | MLP Loss=1.8410, Acc=0.5271\n",
      "[Studygroup][436] CNN Loss=0.9607, Acc=0.6608 | MLP Loss=1.8281, Acc=0.5131\n",
      "[Studygroup][437] CNN Loss=0.9735, Acc=0.6660 | MLP Loss=1.9516, Acc=0.5109\n",
      "[Studygroup][438] CNN Loss=1.0290, Acc=0.6567 | MLP Loss=1.8078, Acc=0.5090\n",
      "[Studygroup][439] CNN Loss=0.9986, Acc=0.6697 | MLP Loss=1.7762, Acc=0.5350\n",
      "[Studygroup][440] CNN Loss=1.1087, Acc=0.6549 | MLP Loss=1.7452, Acc=0.5356\n",
      "[Studygroup][441] CNN Loss=0.9835, Acc=0.6594 | MLP Loss=1.7694, Acc=0.5276\n",
      "[Studygroup][442] CNN Loss=1.0139, Acc=0.6613 | MLP Loss=1.7960, Acc=0.5238\n",
      "[Studygroup][443] CNN Loss=1.0644, Acc=0.6613 | MLP Loss=1.8529, Acc=0.5213\n",
      "[Studygroup][444] CNN Loss=1.0081, Acc=0.6535 | MLP Loss=1.7133, Acc=0.5177\n",
      "[Studygroup][445] CNN Loss=0.9856, Acc=0.6658 | MLP Loss=1.7794, Acc=0.5309\n",
      "[Studygroup][446] CNN Loss=0.9564, Acc=0.6639 | MLP Loss=1.7532, Acc=0.5393\n",
      "[Studygroup][447] CNN Loss=0.9893, Acc=0.6648 | MLP Loss=1.7736, Acc=0.5414\n",
      "[Studygroup][448] CNN Loss=0.9832, Acc=0.6560 | MLP Loss=1.7386, Acc=0.5401\n",
      "[Studygroup][449] CNN Loss=0.9881, Acc=0.6609 | MLP Loss=1.7841, Acc=0.5425\n",
      "[Studygroup][450] CNN Loss=1.0054, Acc=0.6524 | MLP Loss=1.7499, Acc=0.5331\n",
      "[Studygroup][451] CNN Loss=0.9904, Acc=0.6636 | MLP Loss=1.7850, Acc=0.5279\n",
      "[Studygroup][452] CNN Loss=0.9987, Acc=0.6597 | MLP Loss=1.8183, Acc=0.5361\n",
      "[Studygroup][453] CNN Loss=0.9755, Acc=0.6503 | MLP Loss=1.7712, Acc=0.5225\n",
      "[Studygroup][454] CNN Loss=1.0101, Acc=0.6627 | MLP Loss=1.7170, Acc=0.5386\n",
      "[Studygroup][455] CNN Loss=1.0035, Acc=0.6636 | MLP Loss=1.7874, Acc=0.5381\n",
      "[Studygroup][456] CNN Loss=1.0506, Acc=0.6561 | MLP Loss=1.8187, Acc=0.5424\n",
      "[Studygroup][457] CNN Loss=0.9775, Acc=0.6586 | MLP Loss=1.7830, Acc=0.5382\n",
      "[Studygroup][458] CNN Loss=0.9677, Acc=0.6680 | MLP Loss=1.8444, Acc=0.5321\n",
      "[Studygroup][459] CNN Loss=1.0427, Acc=0.6654 | MLP Loss=1.8579, Acc=0.5325\n",
      "[Studygroup][460] CNN Loss=0.9833, Acc=0.6660 | MLP Loss=1.7993, Acc=0.5145\n",
      "[Studygroup][461] CNN Loss=0.9842, Acc=0.6613 | MLP Loss=1.7654, Acc=0.5274\n",
      "[Studygroup][462] CNN Loss=1.0084, Acc=0.6708 | MLP Loss=1.8220, Acc=0.5350\n",
      "[Studygroup][463] CNN Loss=0.9679, Acc=0.6603 | MLP Loss=1.8126, Acc=0.5385\n",
      "[Studygroup][464] CNN Loss=1.0096, Acc=0.6518 | MLP Loss=1.7878, Acc=0.5208\n",
      "[Studygroup][465] CNN Loss=0.9729, Acc=0.6682 | MLP Loss=1.7941, Acc=0.5349\n",
      "[Studygroup][466] CNN Loss=1.0107, Acc=0.6605 | MLP Loss=1.7999, Acc=0.5395\n",
      "[Studygroup][467] CNN Loss=0.9675, Acc=0.6634 | MLP Loss=1.7104, Acc=0.5388\n",
      "[Studygroup][468] CNN Loss=0.9988, Acc=0.6605 | MLP Loss=1.7987, Acc=0.5409\n",
      "[Studygroup][469] CNN Loss=1.0058, Acc=0.6660 | MLP Loss=1.8024, Acc=0.5349\n",
      "[Studygroup][470] CNN Loss=0.9280, Acc=0.6618 | MLP Loss=1.7696, Acc=0.5398\n",
      "[Studygroup][471] CNN Loss=1.0332, Acc=0.6600 | MLP Loss=1.8104, Acc=0.5312\n",
      "[Studygroup][472] CNN Loss=1.0019, Acc=0.6680 | MLP Loss=1.8073, Acc=0.5400\n",
      "[Studygroup][473] CNN Loss=1.1244, Acc=0.6597 | MLP Loss=1.7872, Acc=0.5331\n",
      "[Studygroup][474] CNN Loss=1.0140, Acc=0.6652 | MLP Loss=1.7511, Acc=0.5401\n",
      "[Studygroup][475] CNN Loss=0.9790, Acc=0.6626 | MLP Loss=1.7565, Acc=0.5401\n",
      "[Studygroup][476] CNN Loss=1.0303, Acc=0.6648 | MLP Loss=1.8078, Acc=0.5403\n",
      "[Studygroup][477] CNN Loss=0.9887, Acc=0.6565 | MLP Loss=1.6869, Acc=0.5392\n",
      "[Studygroup][478] CNN Loss=0.9763, Acc=0.6576 | MLP Loss=1.7452, Acc=0.5409\n",
      "[Studygroup][479] CNN Loss=1.0097, Acc=0.6653 | MLP Loss=1.7387, Acc=0.5327\n",
      "[Studygroup][480] CNN Loss=0.9311, Acc=0.6659 | MLP Loss=1.7501, Acc=0.5473\n",
      "[Studygroup][481] CNN Loss=0.9769, Acc=0.6653 | MLP Loss=1.7113, Acc=0.5491\n",
      "[Studygroup][482] CNN Loss=0.9836, Acc=0.6687 | MLP Loss=1.8915, Acc=0.5305\n",
      "[Studygroup][483] CNN Loss=0.9408, Acc=0.6617 | MLP Loss=1.8969, Acc=0.5437\n",
      "[Studygroup][484] CNN Loss=0.9751, Acc=0.6693 | MLP Loss=1.8965, Acc=0.5437\n",
      "[Studygroup][485] CNN Loss=0.9727, Acc=0.6627 | MLP Loss=1.8188, Acc=0.5355\n",
      "[Studygroup][486] CNN Loss=0.9579, Acc=0.6611 | MLP Loss=1.7500, Acc=0.5398\n",
      "[Studygroup][487] CNN Loss=0.9559, Acc=0.6633 | MLP Loss=1.7528, Acc=0.5312\n",
      "[Studygroup][488] CNN Loss=1.0187, Acc=0.6503 | MLP Loss=1.8977, Acc=0.5478\n",
      "[Studygroup][489] CNN Loss=1.0079, Acc=0.6604 | MLP Loss=1.7684, Acc=0.5435\n",
      "[Studygroup][490] CNN Loss=0.9763, Acc=0.6672 | MLP Loss=1.7561, Acc=0.5379\n",
      "[Studygroup][491] CNN Loss=1.0777, Acc=0.6511 | MLP Loss=1.7021, Acc=0.5366\n",
      "[Studygroup][492] CNN Loss=0.9980, Acc=0.6650 | MLP Loss=1.7340, Acc=0.5395\n",
      "[Studygroup][493] CNN Loss=0.8972, Acc=0.6677 | MLP Loss=1.7196, Acc=0.5280\n",
      "[Studygroup][494] CNN Loss=0.9570, Acc=0.6667 | MLP Loss=1.7462, Acc=0.5263\n",
      "[Studygroup][495] CNN Loss=0.9315, Acc=0.6660 | MLP Loss=1.7374, Acc=0.5388\n",
      "[Studygroup][496] CNN Loss=0.9784, Acc=0.6650 | MLP Loss=1.7956, Acc=0.5312\n",
      "[Studygroup][497] CNN Loss=1.0652, Acc=0.6564 | MLP Loss=1.7939, Acc=0.5431\n",
      "[Studygroup][498] CNN Loss=1.0139, Acc=0.6625 | MLP Loss=1.7336, Acc=0.5408\n",
      "[Studygroup][499] CNN Loss=1.0319, Acc=0.6565 | MLP Loss=1.8022, Acc=0.5478\n",
      "[Studygroup][500] CNN Loss=0.9533, Acc=0.6538 | MLP Loss=1.7769, Acc=0.5216\n",
      "[Studygroup][501] CNN Loss=1.0181, Acc=0.6532 | MLP Loss=1.7451, Acc=0.5316\n",
      "[Studygroup][502] CNN Loss=1.0013, Acc=0.6634 | MLP Loss=1.7634, Acc=0.5452\n",
      "[Studygroup][503] CNN Loss=0.9500, Acc=0.6651 | MLP Loss=1.7064, Acc=0.5365\n",
      "[Studygroup][504] CNN Loss=0.9936, Acc=0.6628 | MLP Loss=1.7402, Acc=0.5474\n",
      "[Studygroup][505] CNN Loss=0.9607, Acc=0.6660 | MLP Loss=1.7974, Acc=0.5493\n",
      "[Studygroup][506] CNN Loss=0.9587, Acc=0.6624 | MLP Loss=1.8010, Acc=0.5177\n",
      "[Studygroup][507] CNN Loss=1.0887, Acc=0.6624 | MLP Loss=1.7890, Acc=0.5410\n",
      "[Studygroup][508] CNN Loss=0.9956, Acc=0.6633 | MLP Loss=1.7191, Acc=0.5462\n",
      "[Studygroup][509] CNN Loss=0.9635, Acc=0.6678 | MLP Loss=1.7432, Acc=0.5437\n",
      "[Studygroup][510] CNN Loss=0.9624, Acc=0.6687 | MLP Loss=1.7313, Acc=0.5431\n",
      "[Studygroup][511] CNN Loss=0.9671, Acc=0.6652 | MLP Loss=1.7394, Acc=0.5372\n",
      "[Studygroup][512] CNN Loss=0.9214, Acc=0.6656 | MLP Loss=1.7549, Acc=0.5166\n",
      "[Studygroup][513] CNN Loss=0.9609, Acc=0.6681 | MLP Loss=1.8111, Acc=0.5321\n",
      "[Studygroup][514] CNN Loss=0.9745, Acc=0.6624 | MLP Loss=1.7622, Acc=0.5555\n",
      "[Studygroup][515] CNN Loss=0.9983, Acc=0.6739 | MLP Loss=1.8080, Acc=0.5338\n",
      "[Studygroup][516] CNN Loss=1.0777, Acc=0.6704 | MLP Loss=1.7655, Acc=0.5347\n",
      "[Studygroup][517] CNN Loss=1.0333, Acc=0.6682 | MLP Loss=1.7650, Acc=0.5413\n",
      "[Studygroup][518] CNN Loss=0.9713, Acc=0.6692 | MLP Loss=1.7805, Acc=0.5461\n",
      "[Studygroup][519] CNN Loss=0.9328, Acc=0.6677 | MLP Loss=1.7285, Acc=0.5390\n",
      "[Studygroup][520] CNN Loss=0.9859, Acc=0.6683 | MLP Loss=1.7778, Acc=0.5273\n",
      "[Studygroup][521] CNN Loss=1.0020, Acc=0.6547 | MLP Loss=1.8171, Acc=0.5448\n",
      "[Studygroup][522] CNN Loss=1.0398, Acc=0.6729 | MLP Loss=1.7043, Acc=0.5457\n",
      "[Studygroup][523] CNN Loss=0.9348, Acc=0.6721 | MLP Loss=1.7249, Acc=0.5415\n",
      "[Studygroup][524] CNN Loss=1.0268, Acc=0.6644 | MLP Loss=1.7221, Acc=0.5483\n",
      "[Studygroup][525] CNN Loss=0.9847, Acc=0.6634 | MLP Loss=1.7473, Acc=0.5498\n",
      "[Studygroup][526] CNN Loss=0.9580, Acc=0.6636 | MLP Loss=1.7405, Acc=0.5507\n",
      "[Studygroup][527] CNN Loss=0.9908, Acc=0.6658 | MLP Loss=1.7574, Acc=0.5406\n",
      "[Studygroup][528] CNN Loss=0.9993, Acc=0.6668 | MLP Loss=1.7008, Acc=0.5543\n",
      "[Studygroup][529] CNN Loss=0.9089, Acc=0.6637 | MLP Loss=1.7178, Acc=0.5466\n",
      "[Studygroup][530] CNN Loss=0.9691, Acc=0.6672 | MLP Loss=1.7178, Acc=0.5294\n",
      "[Studygroup][531] CNN Loss=0.9655, Acc=0.6723 | MLP Loss=1.7796, Acc=0.5499\n",
      "[Studygroup][532] CNN Loss=0.9619, Acc=0.6692 | MLP Loss=1.8045, Acc=0.5344\n",
      "[Studygroup][533] CNN Loss=1.0470, Acc=0.6581 | MLP Loss=1.7401, Acc=0.5504\n",
      "[Studygroup][534] CNN Loss=1.0508, Acc=0.6683 | MLP Loss=1.6830, Acc=0.5490\n",
      "[Studygroup][535] CNN Loss=0.9790, Acc=0.6696 | MLP Loss=1.6680, Acc=0.5459\n",
      "[Studygroup][536] CNN Loss=0.9972, Acc=0.6651 | MLP Loss=1.7773, Acc=0.5274\n",
      "[Studygroup][537] CNN Loss=1.0037, Acc=0.6764 | MLP Loss=1.7940, Acc=0.5509\n",
      "[Studygroup][538] CNN Loss=0.9745, Acc=0.6679 | MLP Loss=1.7927, Acc=0.5457\n",
      "[Studygroup][539] CNN Loss=1.0103, Acc=0.6670 | MLP Loss=1.7350, Acc=0.5314\n",
      "[Studygroup][540] CNN Loss=0.9537, Acc=0.6645 | MLP Loss=1.6588, Acc=0.5418\n",
      "[Studygroup][541] CNN Loss=1.0332, Acc=0.6594 | MLP Loss=1.6974, Acc=0.5470\n",
      "[Studygroup][542] CNN Loss=0.9570, Acc=0.6675 | MLP Loss=1.7407, Acc=0.5486\n",
      "[Studygroup][543] CNN Loss=0.9374, Acc=0.6629 | MLP Loss=1.7781, Acc=0.5528\n",
      "[Studygroup][544] CNN Loss=0.9111, Acc=0.6675 | MLP Loss=1.7293, Acc=0.5508\n",
      "[Studygroup][545] CNN Loss=0.9366, Acc=0.6625 | MLP Loss=1.7401, Acc=0.5539\n",
      "[Studygroup][546] CNN Loss=0.9755, Acc=0.6625 | MLP Loss=1.7316, Acc=0.5368\n",
      "[Studygroup][547] CNN Loss=0.9933, Acc=0.6739 | MLP Loss=1.8009, Acc=0.5496\n",
      "[Studygroup][548] CNN Loss=0.9770, Acc=0.6708 | MLP Loss=1.7495, Acc=0.5424\n",
      "[Studygroup][549] CNN Loss=0.9412, Acc=0.6698 | MLP Loss=1.7418, Acc=0.5287\n",
      "[Studygroup][550] CNN Loss=0.9427, Acc=0.6684 | MLP Loss=1.7761, Acc=0.5443\n",
      "[Studygroup][551] CNN Loss=0.9329, Acc=0.6629 | MLP Loss=1.7139, Acc=0.5464\n",
      "[Studygroup][552] CNN Loss=0.9612, Acc=0.6559 | MLP Loss=1.7207, Acc=0.5431\n",
      "[Studygroup][553] CNN Loss=0.9998, Acc=0.6709 | MLP Loss=1.8385, Acc=0.5511\n",
      "[Studygroup][554] CNN Loss=0.9693, Acc=0.6678 | MLP Loss=1.7284, Acc=0.5474\n",
      "[Studygroup][555] CNN Loss=0.9221, Acc=0.6603 | MLP Loss=1.8207, Acc=0.5352\n",
      "[Studygroup][556] CNN Loss=0.9973, Acc=0.6721 | MLP Loss=1.7793, Acc=0.5483\n",
      "[Studygroup][557] CNN Loss=0.9471, Acc=0.6693 | MLP Loss=1.7071, Acc=0.5513\n",
      "[Studygroup][558] CNN Loss=1.0053, Acc=0.6688 | MLP Loss=1.7956, Acc=0.5386\n",
      "[Studygroup][559] CNN Loss=0.9434, Acc=0.6640 | MLP Loss=1.7483, Acc=0.5385\n",
      "[Studygroup][560] CNN Loss=1.0055, Acc=0.6708 | MLP Loss=1.8146, Acc=0.5464\n",
      "[Studygroup][561] CNN Loss=1.0275, Acc=0.6689 | MLP Loss=1.7470, Acc=0.5520\n",
      "[Studygroup][562] CNN Loss=0.9372, Acc=0.6671 | MLP Loss=1.7477, Acc=0.5511\n",
      "[Studygroup][563] CNN Loss=0.9568, Acc=0.6679 | MLP Loss=1.7998, Acc=0.5303\n",
      "[Studygroup][564] CNN Loss=0.9129, Acc=0.6694 | MLP Loss=1.7712, Acc=0.5516\n",
      "[Studygroup][565] CNN Loss=0.9629, Acc=0.6658 | MLP Loss=1.7996, Acc=0.5486\n",
      "[Studygroup][566] CNN Loss=0.9252, Acc=0.6627 | MLP Loss=1.6851, Acc=0.5454\n",
      "[Studygroup][567] CNN Loss=0.9127, Acc=0.6707 | MLP Loss=1.7682, Acc=0.5527\n",
      "[Studygroup][568] CNN Loss=0.9309, Acc=0.6605 | MLP Loss=1.7742, Acc=0.5335\n",
      "[Studygroup][569] CNN Loss=0.9772, Acc=0.6641 | MLP Loss=1.7850, Acc=0.5486\n",
      "[Studygroup][570] CNN Loss=0.8827, Acc=0.6738 | MLP Loss=1.7990, Acc=0.5585\n",
      "[Studygroup][571] CNN Loss=0.9136, Acc=0.6703 | MLP Loss=1.7966, Acc=0.5442\n",
      "[Studygroup][572] CNN Loss=0.9622, Acc=0.6610 | MLP Loss=1.7960, Acc=0.5457\n",
      "[Studygroup][573] CNN Loss=1.0189, Acc=0.6656 | MLP Loss=1.7485, Acc=0.5518\n",
      "[Studygroup][574] CNN Loss=0.9643, Acc=0.6676 | MLP Loss=1.7373, Acc=0.5497\n",
      "[Studygroup][575] CNN Loss=0.9879, Acc=0.6579 | MLP Loss=1.6759, Acc=0.5479\n",
      "[Studygroup][576] CNN Loss=0.9637, Acc=0.6656 | MLP Loss=1.7293, Acc=0.5440\n",
      "[Studygroup][577] CNN Loss=0.9719, Acc=0.6697 | MLP Loss=1.7928, Acc=0.5298\n",
      "[Studygroup][578] CNN Loss=1.0005, Acc=0.6608 | MLP Loss=1.8389, Acc=0.5275\n",
      "[Studygroup][579] CNN Loss=0.9143, Acc=0.6613 | MLP Loss=1.7958, Acc=0.5533\n",
      "[Studygroup][580] CNN Loss=0.9569, Acc=0.6697 | MLP Loss=1.7741, Acc=0.5270\n",
      "[Studygroup][581] CNN Loss=0.9269, Acc=0.6585 | MLP Loss=1.7052, Acc=0.5437\n",
      "[Studygroup][582] CNN Loss=1.0400, Acc=0.6650 | MLP Loss=1.7284, Acc=0.5530\n",
      "[Studygroup][583] CNN Loss=0.9551, Acc=0.6672 | MLP Loss=1.7455, Acc=0.5354\n",
      "[Studygroup][584] CNN Loss=0.8927, Acc=0.6711 | MLP Loss=1.7502, Acc=0.5413\n",
      "[Studygroup][585] CNN Loss=0.9586, Acc=0.6734 | MLP Loss=1.7870, Acc=0.5546\n",
      "[Studygroup][586] CNN Loss=0.9118, Acc=0.6747 | MLP Loss=1.7462, Acc=0.5469\n",
      "[Studygroup][587] CNN Loss=0.9433, Acc=0.6710 | MLP Loss=1.6889, Acc=0.5484\n",
      "[Studygroup][588] CNN Loss=0.9400, Acc=0.6633 | MLP Loss=1.7634, Acc=0.5522\n",
      "[Studygroup][589] CNN Loss=1.0343, Acc=0.6607 | MLP Loss=1.7064, Acc=0.5375\n",
      "[Studygroup][590] CNN Loss=0.9849, Acc=0.6626 | MLP Loss=1.7100, Acc=0.5474\n",
      "[Studygroup][591] CNN Loss=0.9387, Acc=0.6701 | MLP Loss=1.7263, Acc=0.5508\n",
      "[Studygroup][592] CNN Loss=0.9713, Acc=0.6594 | MLP Loss=1.7335, Acc=0.5572\n",
      "[Studygroup][593] CNN Loss=0.9589, Acc=0.6719 | MLP Loss=1.7223, Acc=0.5448\n",
      "[Studygroup][594] CNN Loss=1.0004, Acc=0.6635 | MLP Loss=1.8161, Acc=0.5270\n",
      "[Studygroup][595] CNN Loss=0.9329, Acc=0.6574 | MLP Loss=1.7012, Acc=0.5555\n",
      "[Studygroup][596] CNN Loss=1.0263, Acc=0.6607 | MLP Loss=1.7154, Acc=0.5477\n",
      "[Studygroup][597] CNN Loss=1.0008, Acc=0.6630 | MLP Loss=1.7137, Acc=0.5394\n",
      "[Studygroup][598] CNN Loss=0.9694, Acc=0.6705 | MLP Loss=1.7493, Acc=0.5464\n",
      "[Studygroup][599] CNN Loss=0.9479, Acc=0.6725 | MLP Loss=1.7576, Acc=0.5497\n",
      "[Studygroup][600] CNN Loss=0.9766, Acc=0.6665 | MLP Loss=1.7212, Acc=0.5515\n",
      "[Studygroup][601] CNN Loss=0.9645, Acc=0.6747 | MLP Loss=1.6887, Acc=0.5509\n",
      "[Studygroup][602] CNN Loss=0.9570, Acc=0.6623 | MLP Loss=1.7373, Acc=0.5512\n",
      "[Studygroup][603] CNN Loss=0.9763, Acc=0.6658 | MLP Loss=1.8192, Acc=0.5490\n",
      "[Studygroup][604] CNN Loss=0.9242, Acc=0.6658 | MLP Loss=1.7963, Acc=0.5444\n",
      "[Studygroup][605] CNN Loss=0.9511, Acc=0.6713 | MLP Loss=1.7889, Acc=0.5542\n",
      "[Studygroup][606] CNN Loss=1.0567, Acc=0.6567 | MLP Loss=1.7579, Acc=0.5394\n",
      "[Studygroup][607] CNN Loss=0.9746, Acc=0.6642 | MLP Loss=1.7134, Acc=0.5544\n",
      "[Studygroup][608] CNN Loss=0.9427, Acc=0.6728 | MLP Loss=1.7715, Acc=0.5612\n",
      "[Studygroup][609] CNN Loss=0.9516, Acc=0.6615 | MLP Loss=1.7497, Acc=0.5346\n",
      "[Studygroup][610] CNN Loss=0.9797, Acc=0.6677 | MLP Loss=1.7615, Acc=0.5573\n",
      "[Studygroup][611] CNN Loss=0.9401, Acc=0.6713 | MLP Loss=1.7138, Acc=0.5422\n",
      "[Studygroup][612] CNN Loss=0.9681, Acc=0.6680 | MLP Loss=1.7766, Acc=0.5583\n",
      "[Studygroup][613] CNN Loss=0.9144, Acc=0.6675 | MLP Loss=1.7130, Acc=0.5315\n",
      "[Studygroup][614] CNN Loss=0.9809, Acc=0.6667 | MLP Loss=1.8825, Acc=0.5467\n",
      "[Studygroup][615] CNN Loss=1.0013, Acc=0.6704 | MLP Loss=1.7611, Acc=0.5414\n",
      "[Studygroup][616] CNN Loss=0.9743, Acc=0.6683 | MLP Loss=1.7351, Acc=0.5526\n",
      "[Studygroup][617] CNN Loss=0.8827, Acc=0.6745 | MLP Loss=1.6946, Acc=0.5488\n",
      "[Studygroup][618] CNN Loss=0.9558, Acc=0.6669 | MLP Loss=1.7086, Acc=0.5465\n",
      "[Studygroup][619] CNN Loss=0.9976, Acc=0.6618 | MLP Loss=1.7263, Acc=0.5550\n",
      "[Studygroup][620] CNN Loss=0.9857, Acc=0.6700 | MLP Loss=1.7191, Acc=0.5527\n",
      "[Studygroup][621] CNN Loss=0.9512, Acc=0.6661 | MLP Loss=1.6630, Acc=0.5491\n",
      "[Studygroup][622] CNN Loss=0.8860, Acc=0.6748 | MLP Loss=1.7445, Acc=0.5603\n",
      "[Studygroup][623] CNN Loss=0.9162, Acc=0.6767 | MLP Loss=1.7570, Acc=0.5475\n",
      "[Studygroup][624] CNN Loss=0.9336, Acc=0.6664 | MLP Loss=1.7783, Acc=0.5516\n",
      "[Studygroup][625] CNN Loss=0.9780, Acc=0.6620 | MLP Loss=1.7781, Acc=0.5623\n",
      "[Studygroup][626] CNN Loss=0.9587, Acc=0.6624 | MLP Loss=1.6657, Acc=0.5515\n",
      "[Studygroup][627] CNN Loss=0.9628, Acc=0.6548 | MLP Loss=1.7501, Acc=0.5597\n",
      "[Studygroup][628] CNN Loss=0.9586, Acc=0.6710 | MLP Loss=1.7114, Acc=0.5543\n",
      "[Studygroup][629] CNN Loss=0.9134, Acc=0.6652 | MLP Loss=1.7128, Acc=0.5613\n",
      "[Studygroup][630] CNN Loss=0.8964, Acc=0.6713 | MLP Loss=1.7102, Acc=0.5511\n",
      "[Studygroup][631] CNN Loss=0.9527, Acc=0.6662 | MLP Loss=1.7379, Acc=0.5424\n",
      "[Studygroup][632] CNN Loss=0.9538, Acc=0.6646 | MLP Loss=1.6846, Acc=0.5493\n",
      "[Studygroup][633] CNN Loss=1.0021, Acc=0.6659 | MLP Loss=1.7361, Acc=0.5608\n",
      "[Studygroup][634] CNN Loss=0.9363, Acc=0.6653 | MLP Loss=1.7468, Acc=0.5467\n",
      "[Studygroup][635] CNN Loss=0.9615, Acc=0.6698 | MLP Loss=1.7547, Acc=0.5563\n",
      "[Studygroup][636] CNN Loss=0.9807, Acc=0.6669 | MLP Loss=1.7294, Acc=0.5603\n",
      "[Studygroup][637] CNN Loss=0.9499, Acc=0.6660 | MLP Loss=1.7937, Acc=0.5373\n",
      "[Studygroup][638] CNN Loss=0.9133, Acc=0.6713 | MLP Loss=1.7257, Acc=0.5498\n",
      "[Studygroup][639] CNN Loss=1.0142, Acc=0.6584 | MLP Loss=1.7320, Acc=0.5526\n",
      "[Studygroup][640] CNN Loss=0.9545, Acc=0.6636 | MLP Loss=1.7516, Acc=0.5492\n",
      "[Studygroup][641] CNN Loss=0.9747, Acc=0.6725 | MLP Loss=1.7069, Acc=0.5564\n",
      "[Studygroup][642] CNN Loss=0.9022, Acc=0.6655 | MLP Loss=1.6975, Acc=0.5513\n",
      "[Studygroup][643] CNN Loss=1.0012, Acc=0.6695 | MLP Loss=1.7968, Acc=0.5540\n",
      "[Studygroup][644] CNN Loss=0.9667, Acc=0.6613 | MLP Loss=1.7306, Acc=0.5433\n",
      "[Studygroup][645] CNN Loss=0.9557, Acc=0.6689 | MLP Loss=1.7304, Acc=0.5571\n",
      "[Studygroup][646] CNN Loss=0.9355, Acc=0.6620 | MLP Loss=1.7324, Acc=0.5583\n",
      "[Studygroup][647] CNN Loss=0.9116, Acc=0.6729 | MLP Loss=1.6672, Acc=0.5528\n",
      "[Studygroup][648] CNN Loss=0.9663, Acc=0.6584 | MLP Loss=1.6749, Acc=0.5387\n",
      "[Studygroup][649] CNN Loss=0.9350, Acc=0.6694 | MLP Loss=1.7059, Acc=0.5413\n",
      "[Studygroup][650] CNN Loss=0.9554, Acc=0.6652 | MLP Loss=1.7230, Acc=0.5533\n",
      "[Studygroup][651] CNN Loss=0.8716, Acc=0.6743 | MLP Loss=1.6725, Acc=0.5540\n",
      "[Studygroup][652] CNN Loss=0.9715, Acc=0.6609 | MLP Loss=1.7709, Acc=0.5530\n",
      "[Studygroup][653] CNN Loss=0.9205, Acc=0.6748 | MLP Loss=1.7660, Acc=0.5565\n",
      "[Studygroup][654] CNN Loss=0.9725, Acc=0.6547 | MLP Loss=1.7122, Acc=0.5573\n",
      "[Studygroup][655] CNN Loss=1.0043, Acc=0.6667 | MLP Loss=1.7240, Acc=0.5606\n",
      "[Studygroup][656] CNN Loss=0.9072, Acc=0.6728 | MLP Loss=1.7065, Acc=0.5507\n",
      "[Studygroup][657] CNN Loss=0.8728, Acc=0.6723 | MLP Loss=1.7110, Acc=0.5606\n",
      "[Studygroup][658] CNN Loss=0.9601, Acc=0.6598 | MLP Loss=1.7062, Acc=0.5662\n",
      "[Studygroup][659] CNN Loss=0.9348, Acc=0.6732 | MLP Loss=1.7543, Acc=0.5613\n",
      "[Studygroup][660] CNN Loss=0.8956, Acc=0.6679 | MLP Loss=1.7584, Acc=0.5382\n",
      "[Studygroup][661] CNN Loss=1.0140, Acc=0.6676 | MLP Loss=1.8162, Acc=0.5582\n",
      "[Studygroup][662] CNN Loss=0.9893, Acc=0.6698 | MLP Loss=1.7178, Acc=0.5631\n",
      "[Studygroup][663] CNN Loss=0.9129, Acc=0.6689 | MLP Loss=1.7072, Acc=0.5538\n",
      "[Studygroup][664] CNN Loss=0.9429, Acc=0.6703 | MLP Loss=1.6614, Acc=0.5557\n",
      "[Studygroup][665] CNN Loss=1.0044, Acc=0.6497 | MLP Loss=1.7247, Acc=0.5350\n",
      "[Studygroup][666] CNN Loss=0.9850, Acc=0.6661 | MLP Loss=1.7787, Acc=0.5453\n",
      "[Studygroup][667] CNN Loss=0.9286, Acc=0.6672 | MLP Loss=1.7205, Acc=0.5510\n",
      "[Studygroup][668] CNN Loss=0.9334, Acc=0.6715 | MLP Loss=1.7066, Acc=0.5577\n",
      "[Studygroup][669] CNN Loss=0.9816, Acc=0.6537 | MLP Loss=1.6528, Acc=0.5505\n",
      "[Studygroup][670] CNN Loss=0.9648, Acc=0.6678 | MLP Loss=1.6714, Acc=0.5516\n",
      "[Studygroup][671] CNN Loss=1.0653, Acc=0.6671 | MLP Loss=1.8107, Acc=0.5598\n",
      "[Studygroup][672] CNN Loss=0.9556, Acc=0.6666 | MLP Loss=1.6961, Acc=0.5640\n",
      "[Studygroup][673] CNN Loss=0.9399, Acc=0.6663 | MLP Loss=1.7002, Acc=0.5582\n",
      "[Studygroup][674] CNN Loss=0.9726, Acc=0.6547 | MLP Loss=1.7162, Acc=0.5489\n",
      "[Studygroup][675] CNN Loss=0.9760, Acc=0.6679 | MLP Loss=1.7653, Acc=0.5434\n",
      "[Studygroup][676] CNN Loss=0.9605, Acc=0.6613 | MLP Loss=1.6896, Acc=0.5606\n",
      "[Studygroup][677] CNN Loss=0.9244, Acc=0.6644 | MLP Loss=1.7341, Acc=0.5627\n",
      "[Studygroup][678] CNN Loss=0.9427, Acc=0.6696 | MLP Loss=1.7489, Acc=0.5568\n",
      "[Studygroup][679] CNN Loss=0.8929, Acc=0.6576 | MLP Loss=1.7353, Acc=0.5509\n",
      "[Studygroup][680] CNN Loss=1.0072, Acc=0.6716 | MLP Loss=1.7104, Acc=0.5561\n",
      "[Studygroup][681] CNN Loss=0.9187, Acc=0.6734 | MLP Loss=1.7378, Acc=0.5597\n",
      "[Studygroup][682] CNN Loss=0.8256, Acc=0.6728 | MLP Loss=1.6770, Acc=0.5589\n",
      "[Studygroup][683] CNN Loss=0.8802, Acc=0.6703 | MLP Loss=1.7282, Acc=0.5552\n",
      "[Studygroup][684] CNN Loss=0.8555, Acc=0.6714 | MLP Loss=1.7762, Acc=0.5598\n",
      "[Studygroup][685] CNN Loss=0.9298, Acc=0.6630 | MLP Loss=1.7382, Acc=0.5479\n",
      "[Studygroup][686] CNN Loss=0.9716, Acc=0.6675 | MLP Loss=1.8806, Acc=0.5168\n",
      "[Studygroup][687] CNN Loss=1.0348, Acc=0.6508 | MLP Loss=1.9181, Acc=0.5586\n",
      "[Studygroup][688] CNN Loss=0.9838, Acc=0.6697 | MLP Loss=1.6464, Acc=0.5539\n",
      "[Studygroup][689] CNN Loss=0.9441, Acc=0.6715 | MLP Loss=1.6821, Acc=0.5644\n",
      "[Studygroup][690] CNN Loss=1.0304, Acc=0.6711 | MLP Loss=1.7200, Acc=0.5475\n",
      "[Studygroup][691] CNN Loss=0.8963, Acc=0.6759 | MLP Loss=1.7786, Acc=0.5587\n",
      "[Studygroup][692] CNN Loss=0.8783, Acc=0.6655 | MLP Loss=1.6946, Acc=0.5494\n",
      "[Studygroup][693] CNN Loss=0.9499, Acc=0.6664 | MLP Loss=1.7396, Acc=0.5515\n",
      "[Studygroup][694] CNN Loss=0.9875, Acc=0.6639 | MLP Loss=1.6944, Acc=0.5553\n",
      "[Studygroup][695] CNN Loss=0.9449, Acc=0.6707 | MLP Loss=1.7207, Acc=0.5394\n",
      "[Studygroup][696] CNN Loss=0.8869, Acc=0.6768 | MLP Loss=1.8001, Acc=0.5658\n",
      "[Studygroup][697] CNN Loss=0.9432, Acc=0.6634 | MLP Loss=1.6804, Acc=0.5575\n",
      "[Studygroup][698] CNN Loss=0.9367, Acc=0.6699 | MLP Loss=1.7744, Acc=0.5571\n",
      "[Studygroup][699] CNN Loss=0.9810, Acc=0.6708 | MLP Loss=1.7644, Acc=0.5530\n",
      "[Studygroup][700] CNN Loss=0.9479, Acc=0.6704 | MLP Loss=1.7553, Acc=0.5665\n",
      "[Studygroup][701] CNN Loss=0.9205, Acc=0.6695 | MLP Loss=1.7309, Acc=0.5540\n",
      "[Studygroup][702] CNN Loss=0.9310, Acc=0.6724 | MLP Loss=1.8073, Acc=0.5646\n",
      "[Studygroup][703] CNN Loss=0.9517, Acc=0.6728 | MLP Loss=1.7144, Acc=0.5615\n",
      "[Studygroup][704] CNN Loss=0.9160, Acc=0.6733 | MLP Loss=1.6403, Acc=0.5689\n",
      "[Studygroup][705] CNN Loss=0.9265, Acc=0.6692 | MLP Loss=1.7000, Acc=0.5548\n",
      "[Studygroup][706] CNN Loss=0.9036, Acc=0.6660 | MLP Loss=1.7142, Acc=0.5451\n",
      "[Studygroup][707] CNN Loss=0.9316, Acc=0.6666 | MLP Loss=1.8015, Acc=0.5624\n",
      "[Studygroup][708] CNN Loss=0.9634, Acc=0.6620 | MLP Loss=1.7915, Acc=0.5605\n",
      "[Studygroup][709] CNN Loss=0.9576, Acc=0.6700 | MLP Loss=1.7599, Acc=0.5595\n",
      "[Studygroup][710] CNN Loss=0.9824, Acc=0.6678 | MLP Loss=1.7791, Acc=0.5491\n",
      "[Studygroup][711] CNN Loss=0.8972, Acc=0.6660 | MLP Loss=1.7586, Acc=0.5664\n",
      "[Studygroup][712] CNN Loss=0.9733, Acc=0.6710 | MLP Loss=1.7625, Acc=0.5604\n",
      "[Studygroup][713] CNN Loss=0.8856, Acc=0.6706 | MLP Loss=1.6593, Acc=0.5603\n",
      "[Studygroup][714] CNN Loss=0.9399, Acc=0.6681 | MLP Loss=1.6767, Acc=0.5607\n",
      "[Studygroup][715] CNN Loss=0.9177, Acc=0.6705 | MLP Loss=1.7641, Acc=0.5526\n",
      "[Studygroup][716] CNN Loss=0.9610, Acc=0.6690 | MLP Loss=1.6963, Acc=0.5570\n",
      "[Studygroup][717] CNN Loss=0.9436, Acc=0.6623 | MLP Loss=1.6566, Acc=0.5671\n",
      "[Studygroup][718] CNN Loss=0.9158, Acc=0.6704 | MLP Loss=1.6497, Acc=0.5661\n",
      "[Studygroup][719] CNN Loss=0.9469, Acc=0.6673 | MLP Loss=1.7292, Acc=0.5654\n",
      "[Studygroup][720] CNN Loss=0.9584, Acc=0.6672 | MLP Loss=1.6709, Acc=0.5624\n",
      "[Studygroup][721] CNN Loss=0.9228, Acc=0.6689 | MLP Loss=1.7021, Acc=0.5610\n",
      "[Studygroup][722] CNN Loss=0.8645, Acc=0.6677 | MLP Loss=1.7553, Acc=0.5579\n",
      "[Studygroup][723] CNN Loss=0.9128, Acc=0.6713 | MLP Loss=1.7656, Acc=0.5624\n",
      "[Studygroup][724] CNN Loss=0.9084, Acc=0.6659 | MLP Loss=1.7696, Acc=0.5472\n",
      "[Studygroup][725] CNN Loss=0.9238, Acc=0.6656 | MLP Loss=1.7564, Acc=0.5469\n",
      "[Studygroup][726] CNN Loss=0.9835, Acc=0.6670 | MLP Loss=1.6642, Acc=0.5459\n",
      "[Studygroup][727] CNN Loss=0.9903, Acc=0.6624 | MLP Loss=1.7446, Acc=0.5545\n",
      "[Studygroup][728] CNN Loss=0.9490, Acc=0.6603 | MLP Loss=1.7993, Acc=0.5510\n",
      "[Studygroup][729] CNN Loss=0.9374, Acc=0.6661 | MLP Loss=1.7095, Acc=0.5467\n",
      "[Studygroup][730] CNN Loss=0.9480, Acc=0.6645 | MLP Loss=1.6914, Acc=0.5514\n",
      "[Studygroup][731] CNN Loss=0.9139, Acc=0.6690 | MLP Loss=1.6961, Acc=0.5558\n",
      "[Studygroup][732] CNN Loss=0.9366, Acc=0.6719 | MLP Loss=1.7367, Acc=0.5516\n",
      "[Studygroup][733] CNN Loss=0.9612, Acc=0.6711 | MLP Loss=1.6789, Acc=0.5701\n",
      "[Studygroup][734] CNN Loss=0.9353, Acc=0.6618 | MLP Loss=1.6478, Acc=0.5608\n",
      "[Studygroup][735] CNN Loss=0.9119, Acc=0.6752 | MLP Loss=1.6335, Acc=0.5681\n",
      "[Studygroup][736] CNN Loss=0.9079, Acc=0.6745 | MLP Loss=1.7314, Acc=0.5597\n",
      "[Studygroup][737] CNN Loss=0.9574, Acc=0.6665 | MLP Loss=1.7196, Acc=0.5633\n",
      "[Studygroup][738] CNN Loss=0.9304, Acc=0.6717 | MLP Loss=1.7069, Acc=0.5682\n",
      "[Studygroup][739] CNN Loss=0.9986, Acc=0.6674 | MLP Loss=1.6988, Acc=0.5612\n",
      "[Studygroup][740] CNN Loss=0.9284, Acc=0.6639 | MLP Loss=1.6654, Acc=0.5696\n",
      "[Studygroup][741] CNN Loss=0.9489, Acc=0.6680 | MLP Loss=1.6276, Acc=0.5547\n",
      "[Studygroup][742] CNN Loss=0.9124, Acc=0.6664 | MLP Loss=1.6548, Acc=0.5561\n",
      "[Studygroup][743] CNN Loss=0.9006, Acc=0.6711 | MLP Loss=1.7415, Acc=0.5627\n",
      "[Studygroup][744] CNN Loss=0.8966, Acc=0.6724 | MLP Loss=1.6341, Acc=0.5503\n",
      "[Studygroup][745] CNN Loss=0.9126, Acc=0.6684 | MLP Loss=1.7077, Acc=0.5701\n",
      "[Studygroup][746] CNN Loss=0.9255, Acc=0.6610 | MLP Loss=1.6932, Acc=0.5663\n",
      "[Studygroup][747] CNN Loss=0.9486, Acc=0.6705 | MLP Loss=1.6889, Acc=0.5619\n",
      "[Studygroup][748] CNN Loss=0.9246, Acc=0.6730 | MLP Loss=1.7268, Acc=0.5653\n",
      "[Studygroup][749] CNN Loss=0.9103, Acc=0.6711 | MLP Loss=1.6944, Acc=0.5693\n",
      "[Studygroup][750] CNN Loss=0.9038, Acc=0.6731 | MLP Loss=1.7585, Acc=0.5541\n",
      "[Studygroup][751] CNN Loss=0.8966, Acc=0.6618 | MLP Loss=1.7385, Acc=0.5562\n",
      "[Studygroup][752] CNN Loss=0.9773, Acc=0.6675 | MLP Loss=1.7306, Acc=0.5594\n",
      "[Studygroup][753] CNN Loss=0.9592, Acc=0.6614 | MLP Loss=1.7095, Acc=0.5624\n",
      "[Studygroup][754] CNN Loss=0.9297, Acc=0.6688 | MLP Loss=1.7317, Acc=0.5655\n",
      "[Studygroup][755] CNN Loss=0.9289, Acc=0.6760 | MLP Loss=1.6891, Acc=0.5632\n",
      "[Studygroup][756] CNN Loss=1.0056, Acc=0.6641 | MLP Loss=1.7187, Acc=0.5638\n",
      "[Studygroup][757] CNN Loss=0.8891, Acc=0.6691 | MLP Loss=1.6828, Acc=0.5591\n",
      "[Studygroup][758] CNN Loss=1.0266, Acc=0.6593 | MLP Loss=1.7539, Acc=0.5546\n",
      "[Studygroup][759] CNN Loss=0.9518, Acc=0.6734 | MLP Loss=1.6872, Acc=0.5668\n",
      "[Studygroup][760] CNN Loss=0.9575, Acc=0.6693 | MLP Loss=1.7182, Acc=0.5698\n",
      "[Studygroup][761] CNN Loss=0.9710, Acc=0.6701 | MLP Loss=1.6898, Acc=0.5664\n",
      "[Studygroup][762] CNN Loss=0.9218, Acc=0.6725 | MLP Loss=1.6853, Acc=0.5609\n",
      "[Studygroup][763] CNN Loss=0.9248, Acc=0.6720 | MLP Loss=1.6374, Acc=0.5717\n",
      "[Studygroup][764] CNN Loss=0.8995, Acc=0.6718 | MLP Loss=1.7012, Acc=0.5601\n",
      "[Studygroup][765] CNN Loss=0.9618, Acc=0.6684 | MLP Loss=1.7594, Acc=0.5542\n",
      "[Studygroup][766] CNN Loss=1.0230, Acc=0.6651 | MLP Loss=1.6956, Acc=0.5632\n",
      "[Studygroup][767] CNN Loss=0.8712, Acc=0.6674 | MLP Loss=1.6747, Acc=0.5643\n",
      "[Studygroup][768] CNN Loss=0.8631, Acc=0.6729 | MLP Loss=1.6833, Acc=0.5627\n",
      "[Studygroup][769] CNN Loss=0.9882, Acc=0.6599 | MLP Loss=1.6852, Acc=0.5612\n",
      "[Studygroup][770] CNN Loss=0.8946, Acc=0.6669 | MLP Loss=1.6649, Acc=0.5390\n",
      "[Studygroup][771] CNN Loss=0.8989, Acc=0.6785 | MLP Loss=1.6841, Acc=0.5645\n",
      "[Studygroup][772] CNN Loss=0.8648, Acc=0.6675 | MLP Loss=1.7501, Acc=0.5681\n",
      "[Studygroup][773] CNN Loss=0.9101, Acc=0.6600 | MLP Loss=1.6682, Acc=0.5680\n",
      "[Studygroup][774] CNN Loss=0.9463, Acc=0.6666 | MLP Loss=1.6071, Acc=0.5661\n",
      "[Studygroup][775] CNN Loss=0.9290, Acc=0.6695 | MLP Loss=1.6434, Acc=0.5554\n",
      "[Studygroup][776] CNN Loss=0.8991, Acc=0.6678 | MLP Loss=1.7302, Acc=0.5604\n",
      "[Studygroup][777] CNN Loss=0.9297, Acc=0.6683 | MLP Loss=1.7656, Acc=0.5495\n",
      "[Studygroup][778] CNN Loss=0.9917, Acc=0.6715 | MLP Loss=1.8337, Acc=0.5641\n",
      "[Studygroup][779] CNN Loss=0.9447, Acc=0.6586 | MLP Loss=1.7325, Acc=0.5523\n",
      "[Studygroup][780] CNN Loss=0.9243, Acc=0.6740 | MLP Loss=1.6949, Acc=0.5332\n",
      "[Studygroup][781] CNN Loss=0.9245, Acc=0.6730 | MLP Loss=1.8311, Acc=0.5522\n",
      "[Studygroup][782] CNN Loss=1.0011, Acc=0.6700 | MLP Loss=1.6757, Acc=0.5566\n",
      "[Studygroup][783] CNN Loss=0.9371, Acc=0.6683 | MLP Loss=1.7628, Acc=0.5518\n",
      "[Studygroup][784] CNN Loss=0.9422, Acc=0.6704 | MLP Loss=1.6912, Acc=0.5688\n",
      "[Studygroup][785] CNN Loss=0.9309, Acc=0.6717 | MLP Loss=1.7089, Acc=0.5688\n",
      "[Studygroup][786] CNN Loss=0.9028, Acc=0.6703 | MLP Loss=1.6678, Acc=0.5624\n",
      "[Studygroup][787] CNN Loss=0.9382, Acc=0.6626 | MLP Loss=1.7049, Acc=0.5628\n",
      "[Studygroup][788] CNN Loss=0.9430, Acc=0.6710 | MLP Loss=1.7394, Acc=0.5479\n",
      "[Studygroup][789] CNN Loss=0.8973, Acc=0.6677 | MLP Loss=1.6911, Acc=0.5629\n",
      "[Studygroup][790] CNN Loss=1.0000, Acc=0.6734 | MLP Loss=1.7311, Acc=0.5670\n",
      "[Studygroup][791] CNN Loss=0.9025, Acc=0.6664 | MLP Loss=1.6859, Acc=0.5665\n",
      "[Studygroup][792] CNN Loss=0.9500, Acc=0.6671 | MLP Loss=1.7123, Acc=0.5563\n",
      "[Studygroup][793] CNN Loss=0.9865, Acc=0.6672 | MLP Loss=1.6768, Acc=0.5581\n",
      "[Studygroup][794] CNN Loss=0.9385, Acc=0.6666 | MLP Loss=1.7131, Acc=0.5576\n",
      "[Studygroup][795] CNN Loss=0.8896, Acc=0.6754 | MLP Loss=1.6718, Acc=0.5668\n",
      "[Studygroup][796] CNN Loss=0.9560, Acc=0.6766 | MLP Loss=1.6549, Acc=0.5603\n",
      "[Studygroup][797] CNN Loss=0.9297, Acc=0.6743 | MLP Loss=1.5940, Acc=0.5650\n",
      "[Studygroup][798] CNN Loss=0.8721, Acc=0.6722 | MLP Loss=1.7103, Acc=0.5652\n",
      "[Studygroup][799] CNN Loss=0.8991, Acc=0.6714 | MLP Loss=1.6816, Acc=0.5568\n",
      "[Studygroup][800] CNN Loss=0.8884, Acc=0.6687 | MLP Loss=1.6789, Acc=0.5643\n",
      "[Studygroup][801] CNN Loss=0.9634, Acc=0.6749 | MLP Loss=1.7473, Acc=0.5668\n",
      "[Studygroup][802] CNN Loss=0.9182, Acc=0.6739 | MLP Loss=1.7347, Acc=0.5646\n",
      "[Studygroup][803] CNN Loss=0.8713, Acc=0.6724 | MLP Loss=1.7550, Acc=0.5674\n",
      "[Studygroup][804] CNN Loss=0.9325, Acc=0.6690 | MLP Loss=1.7341, Acc=0.5553\n",
      "[Studygroup][805] CNN Loss=0.9686, Acc=0.6753 | MLP Loss=1.7682, Acc=0.5671\n",
      "[Studygroup][806] CNN Loss=0.9951, Acc=0.6695 | MLP Loss=1.7016, Acc=0.5577\n",
      "[Studygroup][807] CNN Loss=0.9142, Acc=0.6720 | MLP Loss=1.7118, Acc=0.5669\n",
      "[Studygroup][808] CNN Loss=0.9208, Acc=0.6674 | MLP Loss=1.6986, Acc=0.5668\n",
      "[Studygroup][809] CNN Loss=0.9279, Acc=0.6775 | MLP Loss=1.7446, Acc=0.5720\n",
      "[Studygroup][810] CNN Loss=0.9795, Acc=0.6737 | MLP Loss=1.7606, Acc=0.5565\n",
      "[Studygroup][811] CNN Loss=0.8735, Acc=0.6723 | MLP Loss=1.6799, Acc=0.5682\n",
      "[Studygroup][812] CNN Loss=0.8909, Acc=0.6627 | MLP Loss=1.7586, Acc=0.5644\n",
      "[Studygroup][813] CNN Loss=0.9389, Acc=0.6765 | MLP Loss=1.7814, Acc=0.5614\n",
      "[Studygroup][814] CNN Loss=0.9150, Acc=0.6733 | MLP Loss=1.7110, Acc=0.5577\n",
      "[Studygroup][815] CNN Loss=1.0031, Acc=0.6708 | MLP Loss=1.7722, Acc=0.5543\n",
      "[Studygroup][816] CNN Loss=0.9232, Acc=0.6665 | MLP Loss=1.7098, Acc=0.5680\n",
      "[Studygroup][817] CNN Loss=0.8553, Acc=0.6702 | MLP Loss=1.6749, Acc=0.5578\n",
      "[Studygroup][818] CNN Loss=0.8722, Acc=0.6767 | MLP Loss=1.7284, Acc=0.5674\n",
      "[Studygroup][819] CNN Loss=0.9066, Acc=0.6726 | MLP Loss=1.6950, Acc=0.5552\n",
      "[Studygroup][820] CNN Loss=0.9055, Acc=0.6748 | MLP Loss=1.7218, Acc=0.5619\n",
      "[Studygroup][821] CNN Loss=0.8919, Acc=0.6711 | MLP Loss=1.7164, Acc=0.5589\n",
      "[Studygroup][822] CNN Loss=1.0021, Acc=0.6710 | MLP Loss=1.6833, Acc=0.5714\n",
      "[Studygroup][823] CNN Loss=0.8635, Acc=0.6745 | MLP Loss=1.6792, Acc=0.5426\n",
      "[Studygroup][824] CNN Loss=0.9724, Acc=0.6746 | MLP Loss=1.8066, Acc=0.5541\n",
      "[Studygroup][825] CNN Loss=0.9435, Acc=0.6754 | MLP Loss=1.7349, Acc=0.5679\n",
      "[Studygroup][826] CNN Loss=0.9766, Acc=0.6758 | MLP Loss=1.6762, Acc=0.5725\n",
      "[Studygroup][827] CNN Loss=0.9056, Acc=0.6707 | MLP Loss=1.6770, Acc=0.5635\n",
      "[Studygroup][828] CNN Loss=0.8790, Acc=0.6690 | MLP Loss=1.6521, Acc=0.5695\n",
      "[Studygroup][829] CNN Loss=0.8511, Acc=0.6770 | MLP Loss=1.6791, Acc=0.5650\n",
      "[Studygroup][830] CNN Loss=1.0029, Acc=0.6676 | MLP Loss=1.6538, Acc=0.5660\n",
      "[Studygroup][831] CNN Loss=0.9360, Acc=0.6606 | MLP Loss=1.6458, Acc=0.5703\n",
      "[Studygroup][832] CNN Loss=0.9771, Acc=0.6660 | MLP Loss=1.6668, Acc=0.5592\n",
      "[Studygroup][833] CNN Loss=0.9383, Acc=0.6562 | MLP Loss=1.6557, Acc=0.5712\n",
      "[Studygroup][834] CNN Loss=0.9228, Acc=0.6731 | MLP Loss=1.6373, Acc=0.5635\n",
      "[Studygroup][835] CNN Loss=0.9049, Acc=0.6772 | MLP Loss=1.7457, Acc=0.5639\n",
      "[Studygroup][836] CNN Loss=0.9496, Acc=0.6747 | MLP Loss=1.6647, Acc=0.5742\n",
      "[Studygroup][837] CNN Loss=0.8983, Acc=0.6737 | MLP Loss=1.6737, Acc=0.5724\n",
      "[Studygroup][838] CNN Loss=0.8820, Acc=0.6777 | MLP Loss=1.6903, Acc=0.5698\n",
      "[Studygroup][839] CNN Loss=0.8944, Acc=0.6726 | MLP Loss=1.7129, Acc=0.5684\n",
      "[Studygroup][840] CNN Loss=0.9946, Acc=0.6752 | MLP Loss=1.6152, Acc=0.5621\n",
      "[Studygroup][841] CNN Loss=0.9170, Acc=0.6728 | MLP Loss=1.7397, Acc=0.5532\n",
      "[Studygroup][842] CNN Loss=0.9112, Acc=0.6683 | MLP Loss=1.7313, Acc=0.5681\n",
      "[Studygroup][843] CNN Loss=0.9675, Acc=0.6611 | MLP Loss=1.7415, Acc=0.5683\n",
      "[Studygroup][844] CNN Loss=0.9252, Acc=0.6714 | MLP Loss=1.6498, Acc=0.5694\n",
      "[Studygroup][845] CNN Loss=0.8979, Acc=0.6737 | MLP Loss=1.6875, Acc=0.5714\n",
      "[Studygroup][846] CNN Loss=0.9485, Acc=0.6722 | MLP Loss=1.6839, Acc=0.5554\n",
      "[Studygroup][847] CNN Loss=0.9743, Acc=0.6721 | MLP Loss=1.7339, Acc=0.5545\n",
      "[Studygroup][848] CNN Loss=0.8994, Acc=0.6711 | MLP Loss=1.7497, Acc=0.5670\n",
      "[Studygroup][849] CNN Loss=0.8765, Acc=0.6834 | MLP Loss=1.6836, Acc=0.5537\n",
      "[Studygroup][850] CNN Loss=0.9254, Acc=0.6637 | MLP Loss=1.7484, Acc=0.5569\n",
      "[Studygroup][851] CNN Loss=1.0444, Acc=0.6701 | MLP Loss=1.7685, Acc=0.5685\n",
      "[Studygroup][852] CNN Loss=0.8670, Acc=0.6739 | MLP Loss=1.6894, Acc=0.5659\n",
      "[Studygroup][853] CNN Loss=0.9423, Acc=0.6701 | MLP Loss=1.7122, Acc=0.5643\n",
      "[Studygroup][854] CNN Loss=0.9402, Acc=0.6733 | MLP Loss=1.6190, Acc=0.5752\n",
      "[Studygroup][855] CNN Loss=0.8553, Acc=0.6746 | MLP Loss=1.6270, Acc=0.5722\n",
      "[Studygroup][856] CNN Loss=0.8304, Acc=0.6747 | MLP Loss=1.6562, Acc=0.5729\n",
      "[Studygroup][857] CNN Loss=0.9039, Acc=0.6710 | MLP Loss=1.6755, Acc=0.5755\n",
      "[Studygroup][858] CNN Loss=0.9265, Acc=0.6719 | MLP Loss=1.7032, Acc=0.5591\n",
      "[Studygroup][859] CNN Loss=0.9467, Acc=0.6733 | MLP Loss=1.7760, Acc=0.5737\n",
      "[Studygroup][860] CNN Loss=1.0348, Acc=0.6736 | MLP Loss=1.7369, Acc=0.5634\n",
      "[Studygroup][861] CNN Loss=0.9601, Acc=0.6760 | MLP Loss=1.6437, Acc=0.5685\n",
      "[Studygroup][862] CNN Loss=0.9309, Acc=0.6572 | MLP Loss=1.7202, Acc=0.5541\n",
      "[Studygroup][863] CNN Loss=1.0799, Acc=0.6708 | MLP Loss=1.8728, Acc=0.5499\n",
      "[Studygroup][864] CNN Loss=0.9058, Acc=0.6764 | MLP Loss=1.7366, Acc=0.5677\n",
      "[Studygroup][865] CNN Loss=0.9692, Acc=0.6692 | MLP Loss=1.6830, Acc=0.5689\n",
      "[Studygroup][866] CNN Loss=0.9435, Acc=0.6697 | MLP Loss=1.7019, Acc=0.5751\n",
      "[Studygroup][867] CNN Loss=0.9478, Acc=0.6720 | MLP Loss=1.6291, Acc=0.5703\n",
      "[Studygroup][868] CNN Loss=0.9319, Acc=0.6717 | MLP Loss=1.6865, Acc=0.5612\n",
      "[Studygroup][869] CNN Loss=0.8530, Acc=0.6709 | MLP Loss=1.6993, Acc=0.5612\n",
      "[Studygroup][870] CNN Loss=0.9124, Acc=0.6788 | MLP Loss=1.7183, Acc=0.5575\n",
      "[Studygroup][871] CNN Loss=0.9385, Acc=0.6691 | MLP Loss=1.8054, Acc=0.5587\n",
      "[Studygroup][872] CNN Loss=0.9144, Acc=0.6754 | MLP Loss=1.7534, Acc=0.5567\n",
      "[Studygroup][873] CNN Loss=0.9053, Acc=0.6715 | MLP Loss=1.7458, Acc=0.5602\n",
      "[Studygroup][874] CNN Loss=0.8850, Acc=0.6743 | MLP Loss=1.7515, Acc=0.5743\n",
      "[Studygroup][875] CNN Loss=0.8950, Acc=0.6698 | MLP Loss=1.6933, Acc=0.5725\n",
      "[Studygroup][876] CNN Loss=0.9572, Acc=0.6693 | MLP Loss=1.7290, Acc=0.5476\n",
      "[Studygroup][877] CNN Loss=0.8568, Acc=0.6770 | MLP Loss=1.7299, Acc=0.5694\n",
      "[Studygroup][878] CNN Loss=0.8360, Acc=0.6767 | MLP Loss=1.7583, Acc=0.5693\n",
      "[Studygroup][879] CNN Loss=0.8757, Acc=0.6677 | MLP Loss=1.7104, Acc=0.5713\n",
      "[Studygroup][880] CNN Loss=0.8872, Acc=0.6739 | MLP Loss=1.7398, Acc=0.5727\n",
      "[Studygroup][881] CNN Loss=0.8630, Acc=0.6703 | MLP Loss=1.6706, Acc=0.5643\n",
      "[Studygroup][882] CNN Loss=1.0244, Acc=0.6701 | MLP Loss=1.7551, Acc=0.5690\n",
      "[Studygroup][883] CNN Loss=0.9291, Acc=0.6745 | MLP Loss=1.7402, Acc=0.5760\n",
      "[Studygroup][884] CNN Loss=0.8951, Acc=0.6749 | MLP Loss=1.7066, Acc=0.5757\n",
      "[Studygroup][885] CNN Loss=0.9676, Acc=0.6731 | MLP Loss=1.7193, Acc=0.5684\n",
      "[Studygroup][886] CNN Loss=0.8913, Acc=0.6804 | MLP Loss=1.6815, Acc=0.5713\n",
      "[Studygroup][887] CNN Loss=1.0352, Acc=0.6600 | MLP Loss=1.7567, Acc=0.5660\n",
      "[Studygroup][888] CNN Loss=0.9689, Acc=0.6749 | MLP Loss=1.7301, Acc=0.5666\n",
      "[Studygroup][889] CNN Loss=0.9940, Acc=0.6684 | MLP Loss=1.7319, Acc=0.5687\n",
      "[Studygroup][890] CNN Loss=0.9312, Acc=0.6715 | MLP Loss=1.6911, Acc=0.5659\n",
      "[Studygroup][891] CNN Loss=0.9159, Acc=0.6752 | MLP Loss=1.6930, Acc=0.5708\n",
      "[Studygroup][892] CNN Loss=0.9280, Acc=0.6699 | MLP Loss=1.8177, Acc=0.5554\n",
      "[Studygroup][893] CNN Loss=0.9723, Acc=0.6688 | MLP Loss=1.7968, Acc=0.5602\n",
      "[Studygroup][894] CNN Loss=0.9079, Acc=0.6757 | MLP Loss=1.7646, Acc=0.5673\n",
      "[Studygroup][895] CNN Loss=0.8815, Acc=0.6757 | MLP Loss=1.6887, Acc=0.5591\n",
      "[Studygroup][896] CNN Loss=0.9491, Acc=0.6753 | MLP Loss=1.7012, Acc=0.5603\n",
      "[Studygroup][897] CNN Loss=0.9474, Acc=0.6630 | MLP Loss=1.6534, Acc=0.5726\n",
      "[Studygroup][898] CNN Loss=0.9413, Acc=0.6782 | MLP Loss=1.6558, Acc=0.5579\n",
      "[Studygroup][899] CNN Loss=0.8740, Acc=0.6715 | MLP Loss=1.6201, Acc=0.5665\n",
      "[Studygroup][900] CNN Loss=0.9876, Acc=0.6733 | MLP Loss=1.6307, Acc=0.5675\n",
      "[Studygroup][901] CNN Loss=0.9479, Acc=0.6775 | MLP Loss=1.6761, Acc=0.5791\n",
      "[Studygroup][902] CNN Loss=0.8578, Acc=0.6760 | MLP Loss=1.6126, Acc=0.5726\n",
      "[Studygroup][903] CNN Loss=0.9207, Acc=0.6754 | MLP Loss=1.7174, Acc=0.5586\n",
      "[Studygroup][904] CNN Loss=0.9145, Acc=0.6786 | MLP Loss=1.7098, Acc=0.5745\n",
      "[Studygroup][905] CNN Loss=0.8876, Acc=0.6734 | MLP Loss=1.7110, Acc=0.5738\n",
      "[Studygroup][906] CNN Loss=0.9309, Acc=0.6676 | MLP Loss=1.7022, Acc=0.5655\n",
      "[Studygroup][907] CNN Loss=0.9156, Acc=0.6763 | MLP Loss=1.7504, Acc=0.5766\n",
      "[Studygroup][908] CNN Loss=0.8343, Acc=0.6826 | MLP Loss=1.7367, Acc=0.5706\n",
      "[Studygroup][909] CNN Loss=0.9547, Acc=0.6738 | MLP Loss=1.7238, Acc=0.5466\n",
      "[Studygroup][910] CNN Loss=0.9709, Acc=0.6737 | MLP Loss=1.8456, Acc=0.5556\n",
      "[Studygroup][911] CNN Loss=0.9102, Acc=0.6689 | MLP Loss=1.6784, Acc=0.5746\n",
      "[Studygroup][912] CNN Loss=0.8847, Acc=0.6670 | MLP Loss=1.6700, Acc=0.5632\n",
      "[Studygroup][913] CNN Loss=0.8934, Acc=0.6691 | MLP Loss=1.7311, Acc=0.5731\n",
      "[Studygroup][914] CNN Loss=0.9351, Acc=0.6714 | MLP Loss=1.7019, Acc=0.5694\n",
      "[Studygroup][915] CNN Loss=0.9286, Acc=0.6791 | MLP Loss=1.6551, Acc=0.5711\n",
      "[Studygroup][916] CNN Loss=0.8900, Acc=0.6724 | MLP Loss=1.7008, Acc=0.5628\n",
      "[Studygroup][917] CNN Loss=1.0136, Acc=0.6784 | MLP Loss=1.7858, Acc=0.5699\n",
      "[Studygroup][918] CNN Loss=0.9937, Acc=0.6707 | MLP Loss=1.7935, Acc=0.5705\n",
      "[Studygroup][919] CNN Loss=0.9387, Acc=0.6577 | MLP Loss=1.6521, Acc=0.5588\n",
      "[Studygroup][920] CNN Loss=0.9568, Acc=0.6696 | MLP Loss=1.6690, Acc=0.5650\n",
      "[Studygroup][921] CNN Loss=0.8994, Acc=0.6696 | MLP Loss=1.6455, Acc=0.5707\n",
      "[Studygroup][922] CNN Loss=0.9468, Acc=0.6745 | MLP Loss=1.6809, Acc=0.5654\n",
      "[Studygroup][923] CNN Loss=0.9604, Acc=0.6748 | MLP Loss=1.7024, Acc=0.5712\n",
      "[Studygroup][924] CNN Loss=0.8900, Acc=0.6744 | MLP Loss=1.7395, Acc=0.5612\n",
      "[Studygroup][925] CNN Loss=0.9016, Acc=0.6766 | MLP Loss=1.7765, Acc=0.5545\n",
      "[Studygroup][926] CNN Loss=0.8953, Acc=0.6794 | MLP Loss=1.6916, Acc=0.5641\n",
      "[Studygroup][927] CNN Loss=0.9247, Acc=0.6751 | MLP Loss=1.7383, Acc=0.5637\n",
      "[Studygroup][928] CNN Loss=0.9161, Acc=0.6683 | MLP Loss=1.6248, Acc=0.5678\n",
      "[Studygroup][929] CNN Loss=0.8440, Acc=0.6752 | MLP Loss=1.6541, Acc=0.5726\n",
      "[Studygroup][930] CNN Loss=1.0003, Acc=0.6727 | MLP Loss=1.7085, Acc=0.5785\n",
      "[Studygroup][931] CNN Loss=0.8873, Acc=0.6761 | MLP Loss=1.6648, Acc=0.5656\n",
      "[Studygroup][932] CNN Loss=0.9308, Acc=0.6711 | MLP Loss=1.6875, Acc=0.5659\n",
      "[Studygroup][933] CNN Loss=0.8584, Acc=0.6752 | MLP Loss=1.7054, Acc=0.5732\n",
      "[Studygroup][934] CNN Loss=0.8503, Acc=0.6805 | MLP Loss=1.7102, Acc=0.5766\n",
      "[Studygroup][935] CNN Loss=0.8247, Acc=0.6751 | MLP Loss=1.6665, Acc=0.5763\n",
      "[Studygroup][936] CNN Loss=0.8898, Acc=0.6679 | MLP Loss=1.7339, Acc=0.5592\n",
      "[Studygroup][937] CNN Loss=0.9805, Acc=0.6765 | MLP Loss=1.7428, Acc=0.5704\n",
      "[Studygroup][938] CNN Loss=0.8785, Acc=0.6708 | MLP Loss=1.6992, Acc=0.5699\n",
      "[Studygroup][939] CNN Loss=0.9735, Acc=0.6552 | MLP Loss=1.7265, Acc=0.5718\n",
      "[Studygroup][940] CNN Loss=0.9725, Acc=0.6715 | MLP Loss=1.6395, Acc=0.5683\n",
      "[Studygroup][941] CNN Loss=0.9619, Acc=0.6670 | MLP Loss=1.7135, Acc=0.5800\n",
      "[Studygroup][942] CNN Loss=0.9341, Acc=0.6689 | MLP Loss=1.6536, Acc=0.5532\n",
      "[Studygroup][943] CNN Loss=0.9838, Acc=0.6589 | MLP Loss=1.7604, Acc=0.5702\n",
      "[Studygroup][944] CNN Loss=0.9792, Acc=0.6662 | MLP Loss=1.6751, Acc=0.5761\n",
      "[Studygroup][945] CNN Loss=0.8735, Acc=0.6754 | MLP Loss=1.6568, Acc=0.5763\n",
      "[Studygroup][946] CNN Loss=0.9800, Acc=0.6677 | MLP Loss=1.6900, Acc=0.5675\n",
      "[Studygroup][947] CNN Loss=0.9026, Acc=0.6725 | MLP Loss=1.5899, Acc=0.5708\n",
      "[Studygroup][948] CNN Loss=0.9087, Acc=0.6807 | MLP Loss=1.6296, Acc=0.5748\n",
      "[Studygroup][949] CNN Loss=0.8523, Acc=0.6801 | MLP Loss=1.6426, Acc=0.5748\n",
      "[Studygroup][950] CNN Loss=0.9274, Acc=0.6659 | MLP Loss=1.7586, Acc=0.5583\n",
      "[Studygroup][951] CNN Loss=0.9042, Acc=0.6742 | MLP Loss=1.7557, Acc=0.5728\n",
      "[Studygroup][952] CNN Loss=0.8760, Acc=0.6747 | MLP Loss=1.6853, Acc=0.5803\n",
      "[Studygroup][953] CNN Loss=0.9069, Acc=0.6743 | MLP Loss=1.6784, Acc=0.5719\n",
      "[Studygroup][954] CNN Loss=0.9530, Acc=0.6759 | MLP Loss=1.6635, Acc=0.5695\n",
      "[Studygroup][955] CNN Loss=0.9030, Acc=0.6653 | MLP Loss=1.6591, Acc=0.5630\n",
      "[Studygroup][956] CNN Loss=0.9173, Acc=0.6718 | MLP Loss=1.6759, Acc=0.5688\n",
      "[Studygroup][957] CNN Loss=0.9368, Acc=0.6785 | MLP Loss=1.6630, Acc=0.5662\n",
      "[Studygroup][958] CNN Loss=0.9368, Acc=0.6753 | MLP Loss=1.6419, Acc=0.5627\n",
      "[Studygroup][959] CNN Loss=0.8556, Acc=0.6697 | MLP Loss=1.6490, Acc=0.5740\n",
      "[Studygroup][960] CNN Loss=0.8768, Acc=0.6771 | MLP Loss=1.6207, Acc=0.5749\n",
      "[Studygroup][961] CNN Loss=0.9036, Acc=0.6774 | MLP Loss=1.6310, Acc=0.5641\n",
      "[Studygroup][962] CNN Loss=0.8519, Acc=0.6753 | MLP Loss=1.7382, Acc=0.5762\n",
      "[Studygroup][963] CNN Loss=0.8862, Acc=0.6784 | MLP Loss=1.6456, Acc=0.5706\n",
      "[Studygroup][964] CNN Loss=0.8784, Acc=0.6713 | MLP Loss=1.6666, Acc=0.5784\n",
      "[Studygroup][965] CNN Loss=0.8832, Acc=0.6746 | MLP Loss=1.6136, Acc=0.5673\n",
      "[Studygroup][966] CNN Loss=0.8447, Acc=0.6728 | MLP Loss=1.6647, Acc=0.5761\n",
      "[Studygroup][967] CNN Loss=0.9624, Acc=0.6715 | MLP Loss=1.6281, Acc=0.5729\n",
      "[Studygroup][968] CNN Loss=0.8263, Acc=0.6745 | MLP Loss=1.6543, Acc=0.5652\n",
      "[Studygroup][969] CNN Loss=0.8534, Acc=0.6726 | MLP Loss=1.6953, Acc=0.5722\n",
      "[Studygroup][970] CNN Loss=0.8686, Acc=0.6761 | MLP Loss=1.7096, Acc=0.5875\n",
      "[Studygroup][971] CNN Loss=0.8384, Acc=0.6740 | MLP Loss=1.6096, Acc=0.5819\n",
      "[Studygroup][972] CNN Loss=0.8613, Acc=0.6738 | MLP Loss=1.6281, Acc=0.5638\n",
      "[Studygroup][973] CNN Loss=0.8391, Acc=0.6719 | MLP Loss=1.7244, Acc=0.5728\n",
      "[Studygroup][974] CNN Loss=0.9462, Acc=0.6678 | MLP Loss=1.7419, Acc=0.5731\n",
      "[Studygroup][975] CNN Loss=0.9367, Acc=0.6719 | MLP Loss=1.7876, Acc=0.5873\n",
      "[Studygroup][976] CNN Loss=0.9875, Acc=0.6675 | MLP Loss=1.6507, Acc=0.5690\n",
      "[Studygroup][977] CNN Loss=0.8556, Acc=0.6755 | MLP Loss=1.6614, Acc=0.5771\n",
      "[Studygroup][978] CNN Loss=0.8514, Acc=0.6801 | MLP Loss=1.6604, Acc=0.5665\n",
      "[Studygroup][979] CNN Loss=0.8981, Acc=0.6627 | MLP Loss=1.7132, Acc=0.5757\n",
      "[Studygroup][980] CNN Loss=1.0448, Acc=0.6634 | MLP Loss=1.6719, Acc=0.5660\n",
      "[Studygroup][981] CNN Loss=0.9961, Acc=0.6729 | MLP Loss=1.6952, Acc=0.5752\n",
      "[Studygroup][982] CNN Loss=0.9116, Acc=0.6760 | MLP Loss=1.6594, Acc=0.5746\n",
      "[Studygroup][983] CNN Loss=0.8886, Acc=0.6803 | MLP Loss=1.7565, Acc=0.5705\n",
      "[Studygroup][984] CNN Loss=0.8774, Acc=0.6768 | MLP Loss=1.6899, Acc=0.5539\n",
      "[Studygroup][985] CNN Loss=0.9004, Acc=0.6795 | MLP Loss=1.7640, Acc=0.5719\n",
      "[Studygroup][986] CNN Loss=0.9307, Acc=0.6700 | MLP Loss=1.7719, Acc=0.5742\n",
      "[Studygroup][987] CNN Loss=1.0052, Acc=0.6745 | MLP Loss=1.7272, Acc=0.5704\n",
      "[Studygroup][988] CNN Loss=0.9284, Acc=0.6736 | MLP Loss=1.6326, Acc=0.5700\n",
      "[Studygroup][989] CNN Loss=0.8843, Acc=0.6776 | MLP Loss=1.6428, Acc=0.5727\n",
      "[Studygroup][990] CNN Loss=0.8505, Acc=0.6790 | MLP Loss=1.6306, Acc=0.5674\n",
      "[Studygroup][991] CNN Loss=0.8581, Acc=0.6698 | MLP Loss=1.6381, Acc=0.5647\n",
      "[Studygroup][992] CNN Loss=0.9409, Acc=0.6771 | MLP Loss=1.6952, Acc=0.5841\n",
      "[Studygroup][993] CNN Loss=0.9843, Acc=0.6724 | MLP Loss=1.6623, Acc=0.5703\n",
      "[Studygroup][994] CNN Loss=0.9635, Acc=0.6761 | MLP Loss=1.7389, Acc=0.5771\n",
      "[Studygroup][995] CNN Loss=0.8761, Acc=0.6771 | MLP Loss=1.6995, Acc=0.5683\n",
      "[Studygroup][996] CNN Loss=0.8524, Acc=0.6707 | MLP Loss=1.7349, Acc=0.5568\n",
      "[Studygroup][997] CNN Loss=0.9036, Acc=0.6686 | MLP Loss=1.7503, Acc=0.5613\n",
      "[Studygroup][998] CNN Loss=1.0338, Acc=0.6666 | MLP Loss=1.7530, Acc=0.5745\n",
      "[Studygroup][999] CNN Loss=0.9258, Acc=0.6731 | MLP Loss=1.6616, Acc=0.5775\n",
      "[Studygroup][1000] CNN Loss=0.9064, Acc=0.6700 | MLP Loss=1.6858, Acc=0.5723\n",
      "[Studygroup][1001] CNN Loss=0.9192, Acc=0.6784 | MLP Loss=1.6793, Acc=0.5757\n",
      "[Studygroup][1002] CNN Loss=0.9551, Acc=0.6734 | MLP Loss=1.6841, Acc=0.5831\n",
      "[Studygroup][1003] CNN Loss=0.9693, Acc=0.6599 | MLP Loss=1.5977, Acc=0.5779\n",
      "[Studygroup][1004] CNN Loss=0.9171, Acc=0.6746 | MLP Loss=1.5822, Acc=0.5694\n",
      "[Studygroup][1005] CNN Loss=0.8623, Acc=0.6754 | MLP Loss=1.6258, Acc=0.5645\n",
      "[Studygroup][1006] CNN Loss=0.9505, Acc=0.6714 | MLP Loss=1.5908, Acc=0.5808\n",
      "[Studygroup][1007] CNN Loss=0.8187, Acc=0.6803 | MLP Loss=1.6284, Acc=0.5729\n",
      "[Studygroup][1008] CNN Loss=0.9817, Acc=0.6811 | MLP Loss=1.6792, Acc=0.5681\n",
      "[Studygroup][1009] CNN Loss=0.9578, Acc=0.6701 | MLP Loss=1.6435, Acc=0.5695\n",
      "[Studygroup][1010] CNN Loss=0.8405, Acc=0.6726 | MLP Loss=1.6299, Acc=0.5752\n",
      "[Studygroup][1011] CNN Loss=0.9110, Acc=0.6747 | MLP Loss=1.6649, Acc=0.5830\n",
      "[Studygroup][1012] CNN Loss=0.9501, Acc=0.6754 | MLP Loss=1.6377, Acc=0.5627\n",
      "[Studygroup][1013] CNN Loss=0.9332, Acc=0.6673 | MLP Loss=1.6337, Acc=0.5698\n",
      "[Studygroup][1014] CNN Loss=0.9731, Acc=0.6748 | MLP Loss=1.5988, Acc=0.5789\n",
      "[Studygroup][1015] CNN Loss=1.1356, Acc=0.6630 | MLP Loss=1.7164, Acc=0.5685\n",
      "[Studygroup][1016] CNN Loss=0.9457, Acc=0.6787 | MLP Loss=1.5746, Acc=0.5767\n",
      "[Studygroup][1017] CNN Loss=0.8688, Acc=0.6853 | MLP Loss=1.5719, Acc=0.5783\n",
      "[Studygroup][1018] CNN Loss=0.8361, Acc=0.6794 | MLP Loss=1.6462, Acc=0.5816\n",
      "[Studygroup][1019] CNN Loss=0.8190, Acc=0.6737 | MLP Loss=1.6380, Acc=0.5815\n",
      "[Studygroup][1020] CNN Loss=0.9402, Acc=0.6726 | MLP Loss=1.7524, Acc=0.5735\n",
      "[Studygroup][1021] CNN Loss=0.9882, Acc=0.6749 | MLP Loss=1.7917, Acc=0.5694\n",
      "[Studygroup][1022] CNN Loss=0.9335, Acc=0.6807 | MLP Loss=1.7678, Acc=0.5660\n",
      "[Studygroup][1023] CNN Loss=0.9502, Acc=0.6826 | MLP Loss=1.7432, Acc=0.5688\n",
      "[Studygroup][1024] CNN Loss=0.9048, Acc=0.6754 | MLP Loss=1.7006, Acc=0.5826\n",
      "[Studygroup][1025] CNN Loss=0.9436, Acc=0.6748 | MLP Loss=1.6577, Acc=0.5751\n",
      "[Studygroup][1026] CNN Loss=0.9191, Acc=0.6774 | MLP Loss=1.6258, Acc=0.5800\n",
      "[Studygroup][1027] CNN Loss=0.8073, Acc=0.6814 | MLP Loss=1.6774, Acc=0.5714\n",
      "[Studygroup][1028] CNN Loss=0.9065, Acc=0.6778 | MLP Loss=1.6666, Acc=0.5759\n",
      "[Studygroup][1029] CNN Loss=0.8994, Acc=0.6777 | MLP Loss=1.6307, Acc=0.5698\n",
      "[Studygroup][1030] CNN Loss=1.0803, Acc=0.6755 | MLP Loss=1.6677, Acc=0.5731\n",
      "[Studygroup][1031] CNN Loss=0.9770, Acc=0.6749 | MLP Loss=1.6923, Acc=0.5696\n",
      "[Studygroup][1032] CNN Loss=0.9778, Acc=0.6777 | MLP Loss=1.6387, Acc=0.5774\n",
      "[Studygroup][1033] CNN Loss=0.9450, Acc=0.6760 | MLP Loss=1.5861, Acc=0.5732\n",
      "[Studygroup][1034] CNN Loss=0.9086, Acc=0.6764 | MLP Loss=1.6358, Acc=0.5786\n",
      "[Studygroup][1035] CNN Loss=0.8736, Acc=0.6867 | MLP Loss=1.6617, Acc=0.5725\n",
      "[Studygroup][1036] CNN Loss=0.8686, Acc=0.6839 | MLP Loss=1.6519, Acc=0.5776\n",
      "[Studygroup][1037] CNN Loss=0.8451, Acc=0.6838 | MLP Loss=1.6917, Acc=0.5766\n",
      "[Studygroup][1038] CNN Loss=0.8669, Acc=0.6829 | MLP Loss=1.7716, Acc=0.5713\n",
      "[Studygroup][1039] CNN Loss=0.8762, Acc=0.6810 | MLP Loss=1.6178, Acc=0.5784\n",
      "[Studygroup][1040] CNN Loss=0.9209, Acc=0.6747 | MLP Loss=1.7926, Acc=0.5741\n",
      "[Studygroup][1041] CNN Loss=0.9515, Acc=0.6817 | MLP Loss=1.6915, Acc=0.5647\n",
      "[Studygroup][1042] CNN Loss=1.0337, Acc=0.6746 | MLP Loss=1.7524, Acc=0.5669\n",
      "[Studygroup][1043] CNN Loss=0.9520, Acc=0.6785 | MLP Loss=1.6737, Acc=0.5789\n",
      "[Studygroup][1044] CNN Loss=1.0267, Acc=0.6725 | MLP Loss=1.6695, Acc=0.5757\n",
      "[Studygroup][1045] CNN Loss=0.8492, Acc=0.6768 | MLP Loss=1.6349, Acc=0.5783\n",
      "[Studygroup][1046] CNN Loss=0.9087, Acc=0.6828 | MLP Loss=1.6551, Acc=0.5685\n",
      "[Studygroup][1047] CNN Loss=0.8559, Acc=0.6779 | MLP Loss=1.6346, Acc=0.5821\n",
      "[Studygroup][1048] CNN Loss=0.9215, Acc=0.6689 | MLP Loss=1.6772, Acc=0.5597\n",
      "[Studygroup][1049] CNN Loss=0.9479, Acc=0.6797 | MLP Loss=1.8133, Acc=0.5741\n",
      "[Studygroup][1050] CNN Loss=0.9086, Acc=0.6735 | MLP Loss=1.6873, Acc=0.5812\n",
      "[Studygroup][1051] CNN Loss=0.9328, Acc=0.6783 | MLP Loss=1.6605, Acc=0.5745\n",
      "[Studygroup][1052] CNN Loss=0.9012, Acc=0.6766 | MLP Loss=1.6846, Acc=0.5816\n",
      "[Studygroup][1053] CNN Loss=0.8755, Acc=0.6860 | MLP Loss=1.6370, Acc=0.5789\n",
      "[Studygroup][1054] CNN Loss=0.8831, Acc=0.6805 | MLP Loss=1.6360, Acc=0.5725\n",
      "[Studygroup][1055] CNN Loss=0.8220, Acc=0.6845 | MLP Loss=1.7456, Acc=0.5701\n",
      "[Studygroup][1056] CNN Loss=0.9049, Acc=0.6811 | MLP Loss=1.6857, Acc=0.5795\n",
      "[Studygroup][1057] CNN Loss=0.8883, Acc=0.6770 | MLP Loss=1.6662, Acc=0.5798\n",
      "[Studygroup][1058] CNN Loss=0.9156, Acc=0.6753 | MLP Loss=1.6616, Acc=0.5715\n",
      "[Studygroup][1059] CNN Loss=0.9245, Acc=0.6791 | MLP Loss=1.6064, Acc=0.5767\n",
      "[Studygroup][1060] CNN Loss=0.9239, Acc=0.6804 | MLP Loss=1.6316, Acc=0.5715\n",
      "[Studygroup][1061] CNN Loss=0.8863, Acc=0.6833 | MLP Loss=1.6760, Acc=0.5739\n",
      "[Studygroup][1062] CNN Loss=0.9349, Acc=0.6815 | MLP Loss=1.6215, Acc=0.5789\n",
      "[Studygroup][1063] CNN Loss=0.9017, Acc=0.6842 | MLP Loss=1.6536, Acc=0.5723\n",
      "[Studygroup][1064] CNN Loss=0.8772, Acc=0.6808 | MLP Loss=1.7555, Acc=0.5737\n",
      "[Studygroup][1065] CNN Loss=0.9264, Acc=0.6804 | MLP Loss=1.6658, Acc=0.5806\n",
      "[Studygroup][1066] CNN Loss=0.9028, Acc=0.6810 | MLP Loss=1.7148, Acc=0.5813\n",
      "[Studygroup][1067] CNN Loss=0.8996, Acc=0.6754 | MLP Loss=1.6932, Acc=0.5780\n",
      "[Studygroup][1068] CNN Loss=0.9016, Acc=0.6814 | MLP Loss=1.6689, Acc=0.5688\n",
      "[Studygroup][1069] CNN Loss=0.8774, Acc=0.6746 | MLP Loss=1.6680, Acc=0.5763\n",
      "[Studygroup][1070] CNN Loss=0.9437, Acc=0.6731 | MLP Loss=1.6199, Acc=0.5819\n",
      "[Studygroup][1071] CNN Loss=1.0010, Acc=0.6663 | MLP Loss=1.6604, Acc=0.5770\n",
      "[Studygroup][1072] CNN Loss=0.9391, Acc=0.6741 | MLP Loss=1.6039, Acc=0.5821\n",
      "[Studygroup][1073] CNN Loss=0.8880, Acc=0.6782 | MLP Loss=1.6274, Acc=0.5817\n",
      "[Studygroup][1074] CNN Loss=0.9389, Acc=0.6770 | MLP Loss=1.7285, Acc=0.5730\n",
      "[Studygroup][1075] CNN Loss=0.8658, Acc=0.6712 | MLP Loss=1.7228, Acc=0.5700\n",
      "[Studygroup][1076] CNN Loss=0.9165, Acc=0.6784 | MLP Loss=1.6812, Acc=0.5841\n",
      "[Studygroup][1077] CNN Loss=0.8570, Acc=0.6734 | MLP Loss=1.6856, Acc=0.5705\n",
      "[Studygroup][1078] CNN Loss=0.9573, Acc=0.6700 | MLP Loss=1.6639, Acc=0.5866\n",
      "[Studygroup][1079] CNN Loss=0.9040, Acc=0.6780 | MLP Loss=1.6685, Acc=0.5763\n",
      "[Studygroup][1080] CNN Loss=0.8331, Acc=0.6738 | MLP Loss=1.6548, Acc=0.5770\n",
      "[Studygroup][1081] CNN Loss=0.8880, Acc=0.6771 | MLP Loss=1.6781, Acc=0.5785\n",
      "[Studygroup][1082] CNN Loss=1.0073, Acc=0.6795 | MLP Loss=1.6669, Acc=0.5547\n",
      "[Studygroup][1083] CNN Loss=0.9130, Acc=0.6696 | MLP Loss=1.6449, Acc=0.5743\n",
      "[Studygroup][1084] CNN Loss=0.8775, Acc=0.6774 | MLP Loss=1.6210, Acc=0.5742\n",
      "[Studygroup][1085] CNN Loss=0.8978, Acc=0.6676 | MLP Loss=1.6442, Acc=0.5822\n",
      "[Studygroup][1086] CNN Loss=0.9883, Acc=0.6753 | MLP Loss=1.6667, Acc=0.5760\n",
      "[Studygroup][1087] CNN Loss=0.8479, Acc=0.6715 | MLP Loss=1.6255, Acc=0.5782\n",
      "[Studygroup][1088] CNN Loss=0.8718, Acc=0.6730 | MLP Loss=1.6887, Acc=0.5662\n",
      "[Studygroup][1089] CNN Loss=0.8870, Acc=0.6676 | MLP Loss=1.7096, Acc=0.5654\n",
      "[Studygroup][1090] CNN Loss=0.8890, Acc=0.6705 | MLP Loss=1.7186, Acc=0.5699\n",
      "[Studygroup][1091] CNN Loss=0.9264, Acc=0.6793 | MLP Loss=1.6490, Acc=0.5791\n",
      "[Studygroup][1092] CNN Loss=0.9019, Acc=0.6730 | MLP Loss=1.7027, Acc=0.5784\n",
      "[Studygroup][1093] CNN Loss=0.8912, Acc=0.6712 | MLP Loss=1.6548, Acc=0.5598\n",
      "[Studygroup][1094] CNN Loss=0.8595, Acc=0.6747 | MLP Loss=1.6655, Acc=0.5738\n",
      "[Studygroup][1095] CNN Loss=0.8801, Acc=0.6619 | MLP Loss=1.6268, Acc=0.5802\n",
      "[Studygroup][1096] CNN Loss=0.9762, Acc=0.6703 | MLP Loss=1.6047, Acc=0.5725\n",
      "[Studygroup][1097] CNN Loss=1.0404, Acc=0.6716 | MLP Loss=1.6573, Acc=0.5705\n",
      "[Studygroup][1098] CNN Loss=0.9738, Acc=0.6718 | MLP Loss=1.5565, Acc=0.5737\n",
      "[Studygroup][1099] CNN Loss=0.8360, Acc=0.6768 | MLP Loss=1.6713, Acc=0.5740\n",
      "[Studygroup][1100] CNN Loss=0.9441, Acc=0.6711 | MLP Loss=1.7483, Acc=0.5668\n",
      "[Studygroup][1101] CNN Loss=0.8916, Acc=0.6724 | MLP Loss=1.6922, Acc=0.5813\n",
      "[Studygroup][1102] CNN Loss=0.8468, Acc=0.6762 | MLP Loss=1.6428, Acc=0.5854\n",
      "[Studygroup][1103] CNN Loss=0.8811, Acc=0.6736 | MLP Loss=1.6679, Acc=0.5752\n",
      "[Studygroup][1104] CNN Loss=0.9179, Acc=0.6756 | MLP Loss=1.6546, Acc=0.5573\n",
      "[Studygroup][1105] CNN Loss=0.9062, Acc=0.6798 | MLP Loss=1.7170, Acc=0.5673\n",
      "[Studygroup][1106] CNN Loss=0.8917, Acc=0.6718 | MLP Loss=1.7351, Acc=0.5763\n",
      "[Studygroup][1107] CNN Loss=0.8490, Acc=0.6758 | MLP Loss=1.6699, Acc=0.5859\n",
      "[Studygroup][1108] CNN Loss=0.8320, Acc=0.6770 | MLP Loss=1.6076, Acc=0.5938\n",
      "[Studygroup][1109] CNN Loss=0.9572, Acc=0.6799 | MLP Loss=1.7171, Acc=0.5645\n",
      "[Studygroup][1110] CNN Loss=0.9661, Acc=0.6704 | MLP Loss=1.7465, Acc=0.5683\n",
      "[Studygroup][1111] CNN Loss=0.8729, Acc=0.6781 | MLP Loss=1.6049, Acc=0.5615\n",
      "[Studygroup][1112] CNN Loss=1.0065, Acc=0.6639 | MLP Loss=1.7656, Acc=0.5638\n",
      "[Studygroup][1113] CNN Loss=1.0079, Acc=0.6706 | MLP Loss=1.6280, Acc=0.5707\n",
      "[Studygroup][1114] CNN Loss=0.9728, Acc=0.6558 | MLP Loss=1.6277, Acc=0.5830\n",
      "[Studygroup][1115] CNN Loss=0.8610, Acc=0.6739 | MLP Loss=1.6742, Acc=0.5616\n",
      "[Studygroup][1116] CNN Loss=0.9578, Acc=0.6683 | MLP Loss=1.7120, Acc=0.5613\n",
      "[Studygroup][1117] CNN Loss=0.8610, Acc=0.6804 | MLP Loss=1.7370, Acc=0.5725\n",
      "[Studygroup][1118] CNN Loss=0.8580, Acc=0.6825 | MLP Loss=1.6980, Acc=0.5797\n",
      "[Studygroup][1119] CNN Loss=0.9394, Acc=0.6740 | MLP Loss=1.6971, Acc=0.5634\n",
      "[Studygroup][1120] CNN Loss=0.9728, Acc=0.6760 | MLP Loss=1.7503, Acc=0.5695\n",
      "[Studygroup][1121] CNN Loss=1.0212, Acc=0.6789 | MLP Loss=1.7100, Acc=0.5787\n",
      "[Studygroup][1122] CNN Loss=0.9143, Acc=0.6652 | MLP Loss=1.6175, Acc=0.5807\n",
      "[Studygroup][1123] CNN Loss=0.8401, Acc=0.6781 | MLP Loss=1.5753, Acc=0.5713\n",
      "[Studygroup][1124] CNN Loss=0.8589, Acc=0.6738 | MLP Loss=1.6566, Acc=0.5828\n",
      "[Studygroup][1125] CNN Loss=0.9082, Acc=0.6717 | MLP Loss=1.6292, Acc=0.5691\n",
      "[Studygroup][1126] CNN Loss=1.0603, Acc=0.6686 | MLP Loss=1.6715, Acc=0.5805\n",
      "[Studygroup][1127] CNN Loss=0.9340, Acc=0.6719 | MLP Loss=1.6185, Acc=0.5672\n",
      "[Studygroup][1128] CNN Loss=0.9081, Acc=0.6698 | MLP Loss=1.6330, Acc=0.5807\n",
      "[Studygroup][1129] CNN Loss=0.9086, Acc=0.6805 | MLP Loss=1.6876, Acc=0.5849\n",
      "[Studygroup][1130] CNN Loss=0.8282, Acc=0.6752 | MLP Loss=1.6369, Acc=0.5775\n",
      "[Studygroup][1131] CNN Loss=0.9249, Acc=0.6738 | MLP Loss=1.6338, Acc=0.5727\n",
      "[Studygroup][1132] CNN Loss=0.9149, Acc=0.6744 | MLP Loss=1.6215, Acc=0.5778\n",
      "[Studygroup][1133] CNN Loss=0.8196, Acc=0.6790 | MLP Loss=1.6212, Acc=0.5718\n",
      "[Studygroup][1134] CNN Loss=0.8871, Acc=0.6720 | MLP Loss=1.6857, Acc=0.5827\n",
      "[Studygroup][1135] CNN Loss=0.9056, Acc=0.6795 | MLP Loss=1.6853, Acc=0.5783\n",
      "[Studygroup][1136] CNN Loss=0.9233, Acc=0.6810 | MLP Loss=1.6913, Acc=0.5741\n",
      "[Studygroup][1137] CNN Loss=1.0384, Acc=0.6705 | MLP Loss=1.6652, Acc=0.5788\n",
      "[Studygroup][1138] CNN Loss=0.9067, Acc=0.6740 | MLP Loss=1.7166, Acc=0.5583\n",
      "[Studygroup][1139] CNN Loss=0.9339, Acc=0.6733 | MLP Loss=1.6602, Acc=0.5784\n",
      "[Studygroup][1140] CNN Loss=0.9101, Acc=0.6784 | MLP Loss=1.5894, Acc=0.5797\n",
      "[Studygroup][1141] CNN Loss=0.9012, Acc=0.6733 | MLP Loss=1.6142, Acc=0.5815\n",
      "[Studygroup][1142] CNN Loss=0.9291, Acc=0.6780 | MLP Loss=1.6708, Acc=0.5587\n",
      "[Studygroup][1143] CNN Loss=0.9177, Acc=0.6697 | MLP Loss=1.7221, Acc=0.5779\n",
      "[Studygroup][1144] CNN Loss=0.8944, Acc=0.6773 | MLP Loss=1.5889, Acc=0.5689\n",
      "[Studygroup][1145] CNN Loss=0.9229, Acc=0.6712 | MLP Loss=1.6345, Acc=0.5820\n",
      "[Studygroup][1146] CNN Loss=0.9156, Acc=0.6755 | MLP Loss=1.6335, Acc=0.5864\n",
      "[Studygroup][1147] CNN Loss=0.9310, Acc=0.6599 | MLP Loss=1.6100, Acc=0.5781\n",
      "[Studygroup][1148] CNN Loss=0.9241, Acc=0.6776 | MLP Loss=1.5771, Acc=0.5782\n",
      "[Studygroup][1149] CNN Loss=0.8785, Acc=0.6765 | MLP Loss=1.6328, Acc=0.5799\n",
      "[Studygroup][1150] CNN Loss=0.9217, Acc=0.6771 | MLP Loss=1.6576, Acc=0.5748\n",
      "[Studygroup][1151] CNN Loss=0.9255, Acc=0.6748 | MLP Loss=1.6425, Acc=0.5815\n",
      "[Studygroup][1152] CNN Loss=0.9312, Acc=0.6629 | MLP Loss=1.6766, Acc=0.5662\n",
      "[Studygroup][1153] CNN Loss=1.0440, Acc=0.6787 | MLP Loss=1.7375, Acc=0.5763\n",
      "[Studygroup][1154] CNN Loss=0.9249, Acc=0.6756 | MLP Loss=1.6593, Acc=0.5866\n",
      "[Studygroup][1155] CNN Loss=0.9378, Acc=0.6819 | MLP Loss=1.5967, Acc=0.5864\n",
      "[Studygroup][1156] CNN Loss=0.8637, Acc=0.6780 | MLP Loss=1.6538, Acc=0.5770\n",
      "[Studygroup][1157] CNN Loss=0.9207, Acc=0.6680 | MLP Loss=1.7265, Acc=0.5784\n",
      "[Studygroup][1158] CNN Loss=0.8704, Acc=0.6744 | MLP Loss=1.6437, Acc=0.5844\n",
      "[Studygroup][1159] CNN Loss=0.8501, Acc=0.6782 | MLP Loss=1.5838, Acc=0.5678\n",
      "[Studygroup][1160] CNN Loss=0.9504, Acc=0.6736 | MLP Loss=1.6937, Acc=0.5868\n",
      "[Studygroup][1161] CNN Loss=0.9756, Acc=0.6722 | MLP Loss=1.6242, Acc=0.5710\n",
      "[Studygroup][1162] CNN Loss=0.9548, Acc=0.6767 | MLP Loss=1.6517, Acc=0.5763\n",
      "[Studygroup][1163] CNN Loss=0.8635, Acc=0.6801 | MLP Loss=1.6668, Acc=0.5756\n",
      "[Studygroup][1164] CNN Loss=0.8819, Acc=0.6818 | MLP Loss=1.6540, Acc=0.5800\n",
      "[Studygroup][1165] CNN Loss=0.9210, Acc=0.6748 | MLP Loss=1.5691, Acc=0.5723\n",
      "[Studygroup][1166] CNN Loss=0.8584, Acc=0.6776 | MLP Loss=1.6001, Acc=0.5758\n",
      "[Studygroup][1167] CNN Loss=0.9250, Acc=0.6730 | MLP Loss=1.7092, Acc=0.5781\n",
      "[Studygroup][1168] CNN Loss=0.8891, Acc=0.6769 | MLP Loss=1.6181, Acc=0.5863\n",
      "[Studygroup][1169] CNN Loss=0.8573, Acc=0.6801 | MLP Loss=1.6554, Acc=0.5846\n",
      "[Studygroup][1170] CNN Loss=0.8447, Acc=0.6727 | MLP Loss=1.6138, Acc=0.5849\n",
      "[Studygroup][1171] CNN Loss=0.9571, Acc=0.6780 | MLP Loss=1.6144, Acc=0.5856\n",
      "[Studygroup][1172] CNN Loss=0.8902, Acc=0.6692 | MLP Loss=1.6620, Acc=0.5784\n",
      "[Studygroup][1173] CNN Loss=0.8832, Acc=0.6767 | MLP Loss=1.6707, Acc=0.5833\n",
      "[Studygroup][1174] CNN Loss=1.0201, Acc=0.6698 | MLP Loss=1.6427, Acc=0.5809\n",
      "[Studygroup][1175] CNN Loss=0.9598, Acc=0.6678 | MLP Loss=1.6748, Acc=0.5804\n",
      "[Studygroup][1176] CNN Loss=0.9339, Acc=0.6637 | MLP Loss=1.6415, Acc=0.5831\n",
      "[Studygroup][1177] CNN Loss=0.8758, Acc=0.6763 | MLP Loss=1.5981, Acc=0.5738\n",
      "[Studygroup][1178] CNN Loss=0.9093, Acc=0.6716 | MLP Loss=1.6646, Acc=0.5585\n",
      "[Studygroup][1179] CNN Loss=0.9210, Acc=0.6781 | MLP Loss=1.7622, Acc=0.5628\n",
      "[Studygroup][1180] CNN Loss=0.8645, Acc=0.6788 | MLP Loss=1.6633, Acc=0.5862\n",
      "[Studygroup][1181] CNN Loss=0.9564, Acc=0.6782 | MLP Loss=1.6739, Acc=0.5809\n",
      "[Studygroup][1182] CNN Loss=0.9498, Acc=0.6757 | MLP Loss=1.6195, Acc=0.5721\n",
      "[Studygroup][1183] CNN Loss=0.8824, Acc=0.6678 | MLP Loss=1.6499, Acc=0.5787\n",
      "[Studygroup][1184] CNN Loss=0.8448, Acc=0.6785 | MLP Loss=1.6059, Acc=0.5756\n",
      "[Studygroup][1185] CNN Loss=0.9443, Acc=0.6771 | MLP Loss=1.6193, Acc=0.5819\n",
      "[Studygroup][1186] CNN Loss=0.9143, Acc=0.6770 | MLP Loss=1.6327, Acc=0.5675\n",
      "[Studygroup][1187] CNN Loss=0.8728, Acc=0.6765 | MLP Loss=1.6773, Acc=0.5810\n",
      "[Studygroup][1188] CNN Loss=0.8833, Acc=0.6804 | MLP Loss=1.6085, Acc=0.5889\n",
      "[Studygroup][1189] CNN Loss=0.9431, Acc=0.6742 | MLP Loss=1.6819, Acc=0.5812\n",
      "[Studygroup][1190] CNN Loss=0.9370, Acc=0.6787 | MLP Loss=1.6684, Acc=0.5821\n",
      "[Studygroup][1191] CNN Loss=0.8889, Acc=0.6832 | MLP Loss=1.6331, Acc=0.5733\n",
      "[Studygroup][1192] CNN Loss=0.8362, Acc=0.6800 | MLP Loss=1.6673, Acc=0.5726\n",
      "[Studygroup][1193] CNN Loss=0.8648, Acc=0.6786 | MLP Loss=1.7084, Acc=0.5681\n",
      "[Studygroup][1194] CNN Loss=0.9084, Acc=0.6777 | MLP Loss=1.7044, Acc=0.5697\n",
      "[Studygroup][1195] CNN Loss=0.9511, Acc=0.6750 | MLP Loss=1.7433, Acc=0.5667\n",
      "[Studygroup][1196] CNN Loss=0.9011, Acc=0.6790 | MLP Loss=1.6743, Acc=0.5713\n",
      "[Studygroup][1197] CNN Loss=0.8841, Acc=0.6771 | MLP Loss=1.7648, Acc=0.5695\n",
      "[Studygroup][1198] CNN Loss=0.8565, Acc=0.6760 | MLP Loss=1.6721, Acc=0.5774\n",
      "[Studygroup][1199] CNN Loss=0.8324, Acc=0.6811 | MLP Loss=1.6724, Acc=0.5834\n",
      "[Studygroup][1200] CNN Loss=0.9345, Acc=0.6724 | MLP Loss=1.7071, Acc=0.5774\n",
      "[Studygroup][1201] CNN Loss=0.8909, Acc=0.6804 | MLP Loss=1.6576, Acc=0.5826\n",
      "[Studygroup][1202] CNN Loss=0.9035, Acc=0.6792 | MLP Loss=1.5990, Acc=0.5870\n",
      "[Studygroup][1203] CNN Loss=0.8662, Acc=0.6794 | MLP Loss=1.6072, Acc=0.5792\n",
      "[Studygroup][1204] CNN Loss=0.8145, Acc=0.6835 | MLP Loss=1.6694, Acc=0.5780\n",
      "[Studygroup][1205] CNN Loss=0.9408, Acc=0.6840 | MLP Loss=1.6416, Acc=0.5772\n",
      "[Studygroup][1206] CNN Loss=0.9191, Acc=0.6761 | MLP Loss=1.6944, Acc=0.5802\n",
      "[Studygroup][1207] CNN Loss=0.8410, Acc=0.6794 | MLP Loss=1.5842, Acc=0.5766\n",
      "[Studygroup][1208] CNN Loss=0.8590, Acc=0.6827 | MLP Loss=1.5938, Acc=0.5869\n",
      "[Studygroup][1209] CNN Loss=1.0633, Acc=0.6741 | MLP Loss=1.7650, Acc=0.5743\n",
      "[Studygroup][1210] CNN Loss=0.9932, Acc=0.6738 | MLP Loss=1.8487, Acc=0.5571\n",
      "[Studygroup][1211] CNN Loss=0.9295, Acc=0.6739 | MLP Loss=1.8064, Acc=0.5656\n",
      "[Studygroup][1212] CNN Loss=0.9868, Acc=0.6556 | MLP Loss=1.6963, Acc=0.5722\n",
      "[Studygroup][1213] CNN Loss=0.9071, Acc=0.6788 | MLP Loss=1.6541, Acc=0.5609\n",
      "[Studygroup][1214] CNN Loss=0.9736, Acc=0.6745 | MLP Loss=1.6002, Acc=0.5790\n",
      "[Studygroup][1215] CNN Loss=1.0021, Acc=0.6766 | MLP Loss=1.7193, Acc=0.5854\n",
      "[Studygroup][1216] CNN Loss=0.9397, Acc=0.6771 | MLP Loss=1.6335, Acc=0.5783\n",
      "[Studygroup][1217] CNN Loss=0.8835, Acc=0.6833 | MLP Loss=1.6273, Acc=0.5815\n",
      "[Studygroup][1218] CNN Loss=0.9378, Acc=0.6634 | MLP Loss=1.6866, Acc=0.5843\n",
      "[Studygroup][1219] CNN Loss=0.8740, Acc=0.6757 | MLP Loss=1.6281, Acc=0.5752\n",
      "[Studygroup][1220] CNN Loss=0.8801, Acc=0.6749 | MLP Loss=1.5622, Acc=0.5827\n",
      "[Studygroup][1221] CNN Loss=0.8386, Acc=0.6729 | MLP Loss=1.6299, Acc=0.5725\n",
      "[Studygroup][1222] CNN Loss=0.9116, Acc=0.6752 | MLP Loss=1.6331, Acc=0.5874\n",
      "[Studygroup][1223] CNN Loss=0.9154, Acc=0.6737 | MLP Loss=1.6065, Acc=0.5868\n",
      "[Studygroup][1224] CNN Loss=0.8594, Acc=0.6769 | MLP Loss=1.6018, Acc=0.5850\n",
      "[Studygroup][1225] CNN Loss=0.8612, Acc=0.6733 | MLP Loss=1.6580, Acc=0.5861\n",
      "[Studygroup][1226] CNN Loss=1.0275, Acc=0.6587 | MLP Loss=1.8005, Acc=0.5692\n",
      "[Studygroup][1227] CNN Loss=0.9034, Acc=0.6756 | MLP Loss=1.8482, Acc=0.5739\n",
      "[Studygroup][1228] CNN Loss=0.8864, Acc=0.6759 | MLP Loss=1.6529, Acc=0.5760\n",
      "[Studygroup][1229] CNN Loss=0.8865, Acc=0.6794 | MLP Loss=1.7088, Acc=0.5776\n",
      "[Studygroup][1230] CNN Loss=0.9789, Acc=0.6812 | MLP Loss=1.6515, Acc=0.5796\n",
      "[Studygroup][1231] CNN Loss=0.8875, Acc=0.6712 | MLP Loss=1.6670, Acc=0.5770\n",
      "[Studygroup][1232] CNN Loss=0.9604, Acc=0.6670 | MLP Loss=1.7199, Acc=0.5739\n",
      "[Studygroup][1233] CNN Loss=0.8985, Acc=0.6826 | MLP Loss=1.6893, Acc=0.5808\n",
      "[Studygroup][1234] CNN Loss=0.9294, Acc=0.6802 | MLP Loss=1.5762, Acc=0.5867\n",
      "[Studygroup][1235] CNN Loss=0.9198, Acc=0.6778 | MLP Loss=1.6077, Acc=0.5895\n",
      "[Studygroup][1236] CNN Loss=0.9168, Acc=0.6690 | MLP Loss=1.6830, Acc=0.5733\n",
      "[Studygroup][1237] CNN Loss=0.8796, Acc=0.6688 | MLP Loss=1.6711, Acc=0.5790\n",
      "[Studygroup][1238] CNN Loss=0.9090, Acc=0.6825 | MLP Loss=1.7153, Acc=0.5827\n",
      "[Studygroup][1239] CNN Loss=0.9132, Acc=0.6774 | MLP Loss=1.6674, Acc=0.5866\n",
      "[Studygroup][1240] CNN Loss=1.0178, Acc=0.6682 | MLP Loss=1.6460, Acc=0.5770\n",
      "[Studygroup][1241] CNN Loss=0.8461, Acc=0.6758 | MLP Loss=1.6296, Acc=0.5728\n",
      "[Studygroup][1242] CNN Loss=0.8498, Acc=0.6761 | MLP Loss=1.6268, Acc=0.5836\n",
      "[Studygroup][1243] CNN Loss=0.8896, Acc=0.6697 | MLP Loss=1.6192, Acc=0.5775\n",
      "[Studygroup][1244] CNN Loss=0.8482, Acc=0.6800 | MLP Loss=1.6674, Acc=0.5881\n",
      "[Studygroup][1245] CNN Loss=0.9472, Acc=0.6833 | MLP Loss=1.6783, Acc=0.5843\n",
      "[Studygroup][1246] CNN Loss=0.9252, Acc=0.6788 | MLP Loss=1.6659, Acc=0.5945\n",
      "[Studygroup][1247] CNN Loss=1.0482, Acc=0.6746 | MLP Loss=1.7402, Acc=0.5852\n",
      "[Studygroup][1248] CNN Loss=0.8678, Acc=0.6765 | MLP Loss=1.6386, Acc=0.5873\n",
      "[Studygroup][1249] CNN Loss=0.8751, Acc=0.6779 | MLP Loss=1.6793, Acc=0.5792\n",
      "[Studygroup][1250] CNN Loss=0.8538, Acc=0.6721 | MLP Loss=1.6972, Acc=0.5856\n",
      "[Studygroup][1251] CNN Loss=0.8480, Acc=0.6796 | MLP Loss=1.6627, Acc=0.5729\n",
      "[Studygroup][1252] CNN Loss=0.8825, Acc=0.6794 | MLP Loss=1.6142, Acc=0.5918\n",
      "[Studygroup][1253] CNN Loss=0.8500, Acc=0.6783 | MLP Loss=1.6348, Acc=0.5789\n",
      "[Studygroup][1254] CNN Loss=0.8369, Acc=0.6797 | MLP Loss=1.7281, Acc=0.5761\n",
      "[Studygroup][1255] CNN Loss=0.9599, Acc=0.6777 | MLP Loss=1.8312, Acc=0.5717\n",
      "[Studygroup][1256] CNN Loss=0.8931, Acc=0.6781 | MLP Loss=1.6492, Acc=0.5801\n",
      "[Studygroup][1257] CNN Loss=0.9292, Acc=0.6778 | MLP Loss=1.6873, Acc=0.5950\n",
      "[Studygroup][1258] CNN Loss=0.8654, Acc=0.6745 | MLP Loss=1.6058, Acc=0.5709\n",
      "[Studygroup][1259] CNN Loss=0.9013, Acc=0.6723 | MLP Loss=1.6508, Acc=0.5787\n",
      "[Studygroup][1260] CNN Loss=0.8661, Acc=0.6820 | MLP Loss=1.6649, Acc=0.5880\n",
      "[Studygroup][1261] CNN Loss=0.9543, Acc=0.6753 | MLP Loss=1.6033, Acc=0.5696\n",
      "[Studygroup][1262] CNN Loss=0.8680, Acc=0.6733 | MLP Loss=1.7207, Acc=0.5897\n",
      "[Studygroup][1263] CNN Loss=0.9154, Acc=0.6739 | MLP Loss=1.6690, Acc=0.5798\n",
      "[Studygroup][1264] CNN Loss=0.9238, Acc=0.6789 | MLP Loss=1.6890, Acc=0.5833\n",
      "[Studygroup][1265] CNN Loss=0.8837, Acc=0.6768 | MLP Loss=1.6774, Acc=0.5782\n",
      "[Studygroup][1266] CNN Loss=1.0147, Acc=0.6642 | MLP Loss=1.6570, Acc=0.5622\n",
      "[Studygroup][1267] CNN Loss=0.9352, Acc=0.6691 | MLP Loss=1.6226, Acc=0.5855\n",
      "[Studygroup][1268] CNN Loss=0.8706, Acc=0.6820 | MLP Loss=1.7611, Acc=0.5756\n",
      "[Studygroup][1269] CNN Loss=0.8765, Acc=0.6701 | MLP Loss=1.6973, Acc=0.5781\n",
      "[Studygroup][1270] CNN Loss=0.8365, Acc=0.6808 | MLP Loss=1.6151, Acc=0.5817\n",
      "[Studygroup][1271] CNN Loss=0.8457, Acc=0.6805 | MLP Loss=1.6732, Acc=0.5840\n",
      "[Studygroup][1272] CNN Loss=0.9294, Acc=0.6730 | MLP Loss=1.6760, Acc=0.5766\n",
      "[Studygroup][1273] CNN Loss=0.8598, Acc=0.6780 | MLP Loss=1.8465, Acc=0.5672\n",
      "[Studygroup][1274] CNN Loss=0.9048, Acc=0.6769 | MLP Loss=1.7940, Acc=0.5864\n",
      "[Studygroup][1275] CNN Loss=0.9170, Acc=0.6699 | MLP Loss=1.5803, Acc=0.5900\n",
      "[Studygroup][1276] CNN Loss=0.9263, Acc=0.6781 | MLP Loss=1.5571, Acc=0.5817\n",
      "[Studygroup][1277] CNN Loss=0.9174, Acc=0.6742 | MLP Loss=1.6492, Acc=0.5867\n",
      "[Studygroup][1278] CNN Loss=0.8467, Acc=0.6711 | MLP Loss=1.5763, Acc=0.5859\n",
      "[Studygroup][1279] CNN Loss=0.8685, Acc=0.6818 | MLP Loss=1.6674, Acc=0.5844\n",
      "[Studygroup][1280] CNN Loss=0.9209, Acc=0.6746 | MLP Loss=1.6262, Acc=0.5751\n",
      "[Studygroup][1281] CNN Loss=0.9061, Acc=0.6787 | MLP Loss=1.6365, Acc=0.5867\n",
      "[Studygroup][1282] CNN Loss=0.8582, Acc=0.6730 | MLP Loss=1.6466, Acc=0.5780\n",
      "[Studygroup][1283] CNN Loss=0.9972, Acc=0.6757 | MLP Loss=1.5687, Acc=0.5899\n",
      "[Studygroup][1284] CNN Loss=0.8999, Acc=0.6799 | MLP Loss=1.5795, Acc=0.5821\n",
      "[Studygroup][1285] CNN Loss=0.8775, Acc=0.6755 | MLP Loss=1.6329, Acc=0.5785\n",
      "[Studygroup][1286] CNN Loss=0.9479, Acc=0.6715 | MLP Loss=1.6056, Acc=0.5888\n",
      "[Studygroup][1287] CNN Loss=0.8359, Acc=0.6789 | MLP Loss=1.5733, Acc=0.5722\n",
      "[Studygroup][1288] CNN Loss=0.8755, Acc=0.6807 | MLP Loss=1.5990, Acc=0.5761\n",
      "[Studygroup][1289] CNN Loss=0.8496, Acc=0.6751 | MLP Loss=1.5707, Acc=0.5875\n",
      "[Studygroup][1290] CNN Loss=0.8433, Acc=0.6852 | MLP Loss=1.6193, Acc=0.5884\n",
      "[Studygroup][1291] CNN Loss=0.8634, Acc=0.6780 | MLP Loss=1.8003, Acc=0.5811\n",
      "[Studygroup][1292] CNN Loss=0.8510, Acc=0.6799 | MLP Loss=1.6796, Acc=0.5838\n",
      "[Studygroup][1293] CNN Loss=0.8417, Acc=0.6805 | MLP Loss=1.7246, Acc=0.5778\n",
      "[Studygroup][1294] CNN Loss=0.8254, Acc=0.6763 | MLP Loss=1.6070, Acc=0.5938\n",
      "[Studygroup][1295] CNN Loss=0.9232, Acc=0.6571 | MLP Loss=1.6311, Acc=0.5833\n",
      "[Studygroup][1296] CNN Loss=0.9273, Acc=0.6755 | MLP Loss=1.6860, Acc=0.5846\n",
      "[Studygroup][1297] CNN Loss=0.9086, Acc=0.6760 | MLP Loss=1.6308, Acc=0.5799\n",
      "[Studygroup][1298] CNN Loss=0.9068, Acc=0.6804 | MLP Loss=1.6641, Acc=0.5793\n",
      "[Studygroup][1299] CNN Loss=0.8824, Acc=0.6793 | MLP Loss=1.6817, Acc=0.5884\n",
      "[Studygroup][1300] CNN Loss=0.8122, Acc=0.6822 | MLP Loss=1.5981, Acc=0.5890\n",
      "[Studygroup][1301] CNN Loss=0.9722, Acc=0.6751 | MLP Loss=1.6880, Acc=0.5795\n",
      "[Studygroup][1302] CNN Loss=0.8623, Acc=0.6799 | MLP Loss=1.6785, Acc=0.5821\n",
      "[Studygroup][1303] CNN Loss=0.9352, Acc=0.6781 | MLP Loss=1.7064, Acc=0.5850\n",
      "[Studygroup][1304] CNN Loss=0.7844, Acc=0.6815 | MLP Loss=1.5902, Acc=0.5863\n",
      "[Studygroup][1305] CNN Loss=0.8413, Acc=0.6838 | MLP Loss=1.6541, Acc=0.5836\n",
      "[Studygroup][1306] CNN Loss=0.9098, Acc=0.6715 | MLP Loss=1.6321, Acc=0.5810\n",
      "[Studygroup][1307] CNN Loss=0.8744, Acc=0.6779 | MLP Loss=1.6484, Acc=0.5869\n",
      "[Studygroup][1308] CNN Loss=0.9553, Acc=0.6651 | MLP Loss=1.6334, Acc=0.5811\n",
      "[Studygroup][1309] CNN Loss=0.9232, Acc=0.6788 | MLP Loss=1.6518, Acc=0.5706\n",
      "[Studygroup][1310] CNN Loss=0.8495, Acc=0.6802 | MLP Loss=1.7058, Acc=0.5842\n",
      "[Studygroup][1311] CNN Loss=0.9237, Acc=0.6730 | MLP Loss=1.6520, Acc=0.5702\n",
      "[Studygroup][1312] CNN Loss=0.9048, Acc=0.6820 | MLP Loss=1.6424, Acc=0.5708\n",
      "[Studygroup][1313] CNN Loss=0.8940, Acc=0.6744 | MLP Loss=1.6259, Acc=0.5760\n",
      "[Studygroup][1314] CNN Loss=0.8636, Acc=0.6734 | MLP Loss=1.6820, Acc=0.5902\n",
      "[Studygroup][1315] CNN Loss=0.8928, Acc=0.6770 | MLP Loss=1.6700, Acc=0.5830\n",
      "[Studygroup][1316] CNN Loss=0.8803, Acc=0.6828 | MLP Loss=1.7521, Acc=0.5861\n",
      "[Studygroup][1317] CNN Loss=0.8231, Acc=0.6822 | MLP Loss=1.6784, Acc=0.5848\n",
      "[Studygroup][1318] CNN Loss=0.8061, Acc=0.6769 | MLP Loss=1.6658, Acc=0.5769\n",
      "[Studygroup][1319] CNN Loss=0.9250, Acc=0.6757 | MLP Loss=1.6704, Acc=0.5845\n",
      "[Studygroup][1320] CNN Loss=1.0623, Acc=0.6709 | MLP Loss=1.7430, Acc=0.5901\n",
      "[Studygroup][1321] CNN Loss=0.8523, Acc=0.6707 | MLP Loss=1.6511, Acc=0.5779\n",
      "[Studygroup][1322] CNN Loss=0.9428, Acc=0.6738 | MLP Loss=1.6930, Acc=0.5800\n",
      "[Studygroup][1323] CNN Loss=0.9113, Acc=0.6792 | MLP Loss=1.6231, Acc=0.5766\n",
      "[Studygroup][1324] CNN Loss=0.9105, Acc=0.6806 | MLP Loss=1.6637, Acc=0.5828\n",
      "[Studygroup][1325] CNN Loss=0.8598, Acc=0.6744 | MLP Loss=1.6781, Acc=0.5775\n",
      "[Studygroup][1326] CNN Loss=0.8430, Acc=0.6792 | MLP Loss=1.5976, Acc=0.5911\n",
      "[Studygroup][1327] CNN Loss=0.8421, Acc=0.6739 | MLP Loss=1.6106, Acc=0.5888\n",
      "[Studygroup][1328] CNN Loss=0.9032, Acc=0.6834 | MLP Loss=1.6453, Acc=0.5788\n",
      "[Studygroup][1329] CNN Loss=0.9306, Acc=0.6784 | MLP Loss=1.6744, Acc=0.5788\n",
      "[Studygroup][1330] CNN Loss=0.9945, Acc=0.6753 | MLP Loss=1.7207, Acc=0.5730\n",
      "[Studygroup][1331] CNN Loss=0.9030, Acc=0.6778 | MLP Loss=1.6572, Acc=0.5865\n",
      "[Studygroup][1332] CNN Loss=0.8411, Acc=0.6814 | MLP Loss=1.6732, Acc=0.5853\n",
      "[Studygroup][1333] CNN Loss=0.8172, Acc=0.6771 | MLP Loss=1.6584, Acc=0.5742\n",
      "[Studygroup][1334] CNN Loss=0.8352, Acc=0.6784 | MLP Loss=1.6902, Acc=0.5747\n",
      "[Studygroup][1335] CNN Loss=0.9380, Acc=0.6797 | MLP Loss=1.7086, Acc=0.5881\n",
      "[Studygroup][1336] CNN Loss=0.8563, Acc=0.6776 | MLP Loss=1.6958, Acc=0.5908\n",
      "[Studygroup][1337] CNN Loss=0.8552, Acc=0.6729 | MLP Loss=1.7296, Acc=0.5892\n",
      "[Studygroup][1338] CNN Loss=0.9060, Acc=0.6742 | MLP Loss=1.6184, Acc=0.5876\n",
      "[Studygroup][1339] CNN Loss=0.8463, Acc=0.6813 | MLP Loss=1.7375, Acc=0.5859\n",
      "[Studygroup][1340] CNN Loss=0.9765, Acc=0.6856 | MLP Loss=1.7399, Acc=0.5861\n",
      "[Studygroup][1341] CNN Loss=0.7734, Acc=0.6789 | MLP Loss=1.7428, Acc=0.5886\n",
      "[Studygroup][1342] CNN Loss=0.9218, Acc=0.6673 | MLP Loss=1.6861, Acc=0.5864\n",
      "[Studygroup][1343] CNN Loss=0.9546, Acc=0.6813 | MLP Loss=1.6367, Acc=0.5917\n",
      "[Studygroup][1344] CNN Loss=0.9346, Acc=0.6734 | MLP Loss=1.7602, Acc=0.5848\n",
      "[Studygroup][1345] CNN Loss=1.0752, Acc=0.6726 | MLP Loss=1.7211, Acc=0.5705\n",
      "[Studygroup][1346] CNN Loss=0.9018, Acc=0.6817 | MLP Loss=1.6368, Acc=0.5808\n",
      "[Studygroup][1347] CNN Loss=0.8633, Acc=0.6714 | MLP Loss=1.6900, Acc=0.5893\n",
      "[Studygroup][1348] CNN Loss=0.8020, Acc=0.6833 | MLP Loss=1.7286, Acc=0.5817\n",
      "[Studygroup][1349] CNN Loss=0.9015, Acc=0.6786 | MLP Loss=1.7971, Acc=0.5892\n",
      "[Studygroup][1350] CNN Loss=0.8945, Acc=0.6801 | MLP Loss=1.6199, Acc=0.5771\n",
      "[Studygroup][1351] CNN Loss=0.8971, Acc=0.6811 | MLP Loss=1.6439, Acc=0.5920\n",
      "[Studygroup][1352] CNN Loss=0.9037, Acc=0.6793 | MLP Loss=1.6634, Acc=0.5828\n",
      "[Studygroup][1353] CNN Loss=0.9132, Acc=0.6760 | MLP Loss=1.6517, Acc=0.5917\n",
      "[Studygroup][1354] CNN Loss=0.7898, Acc=0.6708 | MLP Loss=1.5550, Acc=0.5928\n",
      "[Studygroup][1355] CNN Loss=0.8833, Acc=0.6787 | MLP Loss=1.6644, Acc=0.5865\n",
      "[Studygroup][1356] CNN Loss=0.9609, Acc=0.6707 | MLP Loss=1.6726, Acc=0.5708\n",
      "[Studygroup][1357] CNN Loss=1.0081, Acc=0.6730 | MLP Loss=1.9176, Acc=0.5684\n",
      "[Studygroup][1358] CNN Loss=1.0394, Acc=0.6722 | MLP Loss=1.6912, Acc=0.5826\n",
      "[Studygroup][1359] CNN Loss=0.9119, Acc=0.6660 | MLP Loss=1.6801, Acc=0.5844\n",
      "[Studygroup][1360] CNN Loss=1.0056, Acc=0.6736 | MLP Loss=1.6843, Acc=0.5668\n",
      "[Studygroup][1361] CNN Loss=0.8933, Acc=0.6763 | MLP Loss=1.6863, Acc=0.5908\n",
      "[Studygroup][1362] CNN Loss=0.9126, Acc=0.6733 | MLP Loss=1.6244, Acc=0.5734\n",
      "[Studygroup][1363] CNN Loss=0.8869, Acc=0.6776 | MLP Loss=1.6830, Acc=0.5707\n",
      "[Studygroup][1364] CNN Loss=0.8810, Acc=0.6768 | MLP Loss=1.6170, Acc=0.5832\n",
      "[Studygroup][1365] CNN Loss=0.8750, Acc=0.6741 | MLP Loss=1.7802, Acc=0.5795\n",
      "[Studygroup][1366] CNN Loss=0.9249, Acc=0.6816 | MLP Loss=1.7048, Acc=0.5773\n",
      "[Studygroup][1367] CNN Loss=0.8762, Acc=0.6734 | MLP Loss=1.5886, Acc=0.5904\n",
      "[Studygroup][1368] CNN Loss=0.8487, Acc=0.6774 | MLP Loss=1.6344, Acc=0.5880\n",
      "[Studygroup][1369] CNN Loss=0.8895, Acc=0.6700 | MLP Loss=1.6678, Acc=0.5845\n",
      "[Studygroup][1370] CNN Loss=0.9020, Acc=0.6771 | MLP Loss=1.6324, Acc=0.5796\n",
      "[Studygroup][1371] CNN Loss=0.8404, Acc=0.6698 | MLP Loss=1.6180, Acc=0.5875\n",
      "[Studygroup][1372] CNN Loss=0.8611, Acc=0.6739 | MLP Loss=1.6120, Acc=0.5908\n",
      "[Studygroup][1373] CNN Loss=0.8461, Acc=0.6792 | MLP Loss=1.6076, Acc=0.5801\n",
      "[Studygroup][1374] CNN Loss=0.8787, Acc=0.6773 | MLP Loss=1.6375, Acc=0.5673\n",
      "[Studygroup][1375] CNN Loss=0.8992, Acc=0.6659 | MLP Loss=1.6650, Acc=0.5888\n",
      "[Studygroup][1376] CNN Loss=0.9257, Acc=0.6755 | MLP Loss=1.6859, Acc=0.5830\n",
      "[Studygroup][1377] CNN Loss=0.9198, Acc=0.6795 | MLP Loss=1.7168, Acc=0.5848\n",
      "[Studygroup][1378] CNN Loss=0.8735, Acc=0.6711 | MLP Loss=1.6677, Acc=0.5839\n",
      "[Studygroup][1379] CNN Loss=0.7824, Acc=0.6786 | MLP Loss=1.6088, Acc=0.5868\n",
      "[Studygroup][1380] CNN Loss=0.9524, Acc=0.6701 | MLP Loss=1.6532, Acc=0.5774\n",
      "[Studygroup][1381] CNN Loss=0.9569, Acc=0.6804 | MLP Loss=1.5663, Acc=0.5867\n",
      "[Studygroup][1382] CNN Loss=0.8951, Acc=0.6760 | MLP Loss=1.6274, Acc=0.5879\n",
      "[Studygroup][1383] CNN Loss=0.8826, Acc=0.6832 | MLP Loss=1.6009, Acc=0.5954\n",
      "[Studygroup][1384] CNN Loss=0.7904, Acc=0.6856 | MLP Loss=1.5352, Acc=0.5832\n",
      "[Studygroup][1385] CNN Loss=0.8495, Acc=0.6774 | MLP Loss=1.5766, Acc=0.5879\n",
      "[Studygroup][1386] CNN Loss=0.8810, Acc=0.6773 | MLP Loss=1.6002, Acc=0.5895\n",
      "[Studygroup][1387] CNN Loss=0.9663, Acc=0.6834 | MLP Loss=1.5878, Acc=0.5874\n",
      "[Studygroup][1388] CNN Loss=0.8880, Acc=0.6748 | MLP Loss=1.6280, Acc=0.5862\n",
      "[Studygroup][1389] CNN Loss=0.8493, Acc=0.6804 | MLP Loss=1.6337, Acc=0.5855\n",
      "[Studygroup][1390] CNN Loss=0.8669, Acc=0.6727 | MLP Loss=1.5987, Acc=0.5882\n",
      "[Studygroup][1391] CNN Loss=0.9242, Acc=0.6795 | MLP Loss=1.5689, Acc=0.5840\n",
      "[Studygroup][1392] CNN Loss=1.0030, Acc=0.6727 | MLP Loss=1.6835, Acc=0.5777\n",
      "[Studygroup][1393] CNN Loss=1.0625, Acc=0.6704 | MLP Loss=1.7295, Acc=0.5887\n",
      "[Studygroup][1394] CNN Loss=0.9345, Acc=0.6773 | MLP Loss=1.6214, Acc=0.5795\n",
      "[Studygroup][1395] CNN Loss=0.9164, Acc=0.6761 | MLP Loss=1.6330, Acc=0.5785\n",
      "[Studygroup][1396] CNN Loss=0.8932, Acc=0.6781 | MLP Loss=1.6147, Acc=0.5801\n",
      "[Studygroup][1397] CNN Loss=0.7961, Acc=0.6806 | MLP Loss=1.6185, Acc=0.5851\n",
      "[Studygroup][1398] CNN Loss=0.8787, Acc=0.6761 | MLP Loss=1.6128, Acc=0.5840\n",
      "[Studygroup][1399] CNN Loss=0.8547, Acc=0.6803 | MLP Loss=1.7420, Acc=0.5824\n",
      "[Studygroup][1400] CNN Loss=0.9246, Acc=0.6749 | MLP Loss=1.5786, Acc=0.5897\n",
      "[Studygroup][1401] CNN Loss=0.9101, Acc=0.6785 | MLP Loss=1.6479, Acc=0.5849\n",
      "[Studygroup][1402] CNN Loss=0.9268, Acc=0.6765 | MLP Loss=1.5837, Acc=0.5873\n",
      "[Studygroup][1403] CNN Loss=0.9003, Acc=0.6724 | MLP Loss=1.5975, Acc=0.5908\n",
      "[Studygroup][1404] CNN Loss=0.8542, Acc=0.6742 | MLP Loss=1.7151, Acc=0.5833\n",
      "[Studygroup][1405] CNN Loss=0.8942, Acc=0.6780 | MLP Loss=1.6106, Acc=0.5823\n",
      "[Studygroup][1406] CNN Loss=0.9596, Acc=0.6723 | MLP Loss=1.7788, Acc=0.5743\n",
      "[Studygroup][1407] CNN Loss=0.9212, Acc=0.6842 | MLP Loss=1.7065, Acc=0.5784\n",
      "[Studygroup][1408] CNN Loss=0.8648, Acc=0.6767 | MLP Loss=1.6717, Acc=0.5861\n",
      "[Studygroup][1409] CNN Loss=0.9158, Acc=0.6739 | MLP Loss=1.6601, Acc=0.5926\n",
      "[Studygroup][1410] CNN Loss=0.9117, Acc=0.6797 | MLP Loss=1.6957, Acc=0.5868\n",
      "[Studygroup][1411] CNN Loss=0.9202, Acc=0.6760 | MLP Loss=1.6946, Acc=0.5801\n",
      "[Studygroup][1412] CNN Loss=0.8764, Acc=0.6590 | MLP Loss=1.6408, Acc=0.5806\n",
      "[Studygroup][1413] CNN Loss=1.0393, Acc=0.6787 | MLP Loss=1.7223, Acc=0.5767\n",
      "[Studygroup][1414] CNN Loss=0.9362, Acc=0.6777 | MLP Loss=1.6055, Acc=0.5855\n",
      "[Studygroup][1415] CNN Loss=0.9704, Acc=0.6795 | MLP Loss=1.6336, Acc=0.5872\n",
      "[Studygroup][1416] CNN Loss=0.8821, Acc=0.6762 | MLP Loss=1.5902, Acc=0.5871\n",
      "[Studygroup][1417] CNN Loss=0.8887, Acc=0.6748 | MLP Loss=1.5731, Acc=0.5846\n",
      "[Studygroup][1418] CNN Loss=1.0044, Acc=0.6742 | MLP Loss=1.6265, Acc=0.5898\n",
      "[Studygroup][1419] CNN Loss=0.8484, Acc=0.6786 | MLP Loss=1.6471, Acc=0.5786\n",
      "[Studygroup][1420] CNN Loss=0.8818, Acc=0.6721 | MLP Loss=1.7256, Acc=0.5863\n",
      "[Studygroup][1421] CNN Loss=0.9639, Acc=0.6739 | MLP Loss=1.6991, Acc=0.5820\n",
      "[Studygroup][1422] CNN Loss=0.9741, Acc=0.6702 | MLP Loss=1.6776, Acc=0.5792\n",
      "[Studygroup][1423] CNN Loss=0.9765, Acc=0.6778 | MLP Loss=1.5811, Acc=0.5886\n",
      "[Studygroup][1424] CNN Loss=0.9465, Acc=0.6802 | MLP Loss=1.5784, Acc=0.5672\n",
      "[Studygroup][1425] CNN Loss=0.9541, Acc=0.6720 | MLP Loss=1.6821, Acc=0.5791\n",
      "[Studygroup][1426] CNN Loss=0.9681, Acc=0.6734 | MLP Loss=1.6201, Acc=0.5742\n",
      "[Studygroup][1427] CNN Loss=0.9488, Acc=0.6830 | MLP Loss=1.6697, Acc=0.5829\n",
      "[Studygroup][1428] CNN Loss=0.9789, Acc=0.6786 | MLP Loss=1.5951, Acc=0.5847\n",
      "[Studygroup][1429] CNN Loss=0.9560, Acc=0.6719 | MLP Loss=1.6453, Acc=0.5776\n",
      "[Studygroup][1430] CNN Loss=0.9501, Acc=0.6759 | MLP Loss=1.5339, Acc=0.5935\n",
      "[Studygroup][1431] CNN Loss=0.8029, Acc=0.6795 | MLP Loss=1.5732, Acc=0.5825\n",
      "[Studygroup][1432] CNN Loss=0.8776, Acc=0.6698 | MLP Loss=1.6499, Acc=0.5720\n",
      "[Studygroup][1433] CNN Loss=0.8894, Acc=0.6688 | MLP Loss=1.9242, Acc=0.5553\n",
      "[Studygroup][1434] CNN Loss=0.8921, Acc=0.6728 | MLP Loss=1.6864, Acc=0.5781\n",
      "[Studygroup][1435] CNN Loss=0.9487, Acc=0.6718 | MLP Loss=1.6784, Acc=0.5636\n",
      "[Studygroup][1436] CNN Loss=0.9410, Acc=0.6776 | MLP Loss=1.6179, Acc=0.5867\n",
      "[Studygroup][1437] CNN Loss=0.8546, Acc=0.6735 | MLP Loss=1.6018, Acc=0.5872\n",
      "[Studygroup][1438] CNN Loss=0.8591, Acc=0.6751 | MLP Loss=1.7110, Acc=0.5841\n",
      "[Studygroup][1439] CNN Loss=0.8930, Acc=0.6747 | MLP Loss=1.6319, Acc=0.5938\n",
      "[Studygroup][1440] CNN Loss=0.9111, Acc=0.6829 | MLP Loss=1.6316, Acc=0.5842\n",
      "[Studygroup][1441] CNN Loss=0.8692, Acc=0.6813 | MLP Loss=1.6610, Acc=0.5826\n",
      "[Studygroup][1442] CNN Loss=0.9150, Acc=0.6795 | MLP Loss=1.6090, Acc=0.5801\n",
      "[Studygroup][1443] CNN Loss=0.8773, Acc=0.6824 | MLP Loss=1.5723, Acc=0.5868\n",
      "[Studygroup][1444] CNN Loss=0.9513, Acc=0.6794 | MLP Loss=1.6625, Acc=0.5922\n",
      "[Studygroup][1445] CNN Loss=0.8637, Acc=0.6836 | MLP Loss=1.6178, Acc=0.5937\n",
      "[Studygroup][1446] CNN Loss=0.8388, Acc=0.6824 | MLP Loss=1.6217, Acc=0.5733\n",
      "[Studygroup][1447] CNN Loss=0.9530, Acc=0.6657 | MLP Loss=1.6243, Acc=0.5756\n",
      "[Studygroup][1448] CNN Loss=0.9465, Acc=0.6767 | MLP Loss=1.6563, Acc=0.5817\n",
      "[Studygroup][1449] CNN Loss=0.8891, Acc=0.6752 | MLP Loss=1.6614, Acc=0.5778\n",
      "[Studygroup][1450] CNN Loss=0.9236, Acc=0.6753 | MLP Loss=1.5948, Acc=0.5882\n",
      "[Studygroup][1451] CNN Loss=1.0082, Acc=0.6752 | MLP Loss=1.6143, Acc=0.5911\n",
      "[Studygroup][1452] CNN Loss=0.9089, Acc=0.6817 | MLP Loss=1.6374, Acc=0.5919\n",
      "[Studygroup][1453] CNN Loss=1.0014, Acc=0.6826 | MLP Loss=1.6317, Acc=0.5857\n",
      "[Studygroup][1454] CNN Loss=0.9466, Acc=0.6889 | MLP Loss=1.6701, Acc=0.5893\n",
      "[Studygroup][1455] CNN Loss=0.7893, Acc=0.6853 | MLP Loss=1.6897, Acc=0.5810\n",
      "[Studygroup][1456] CNN Loss=0.8540, Acc=0.6784 | MLP Loss=1.6972, Acc=0.5797\n",
      "[Studygroup][1457] CNN Loss=0.8876, Acc=0.6841 | MLP Loss=1.7089, Acc=0.5868\n",
      "[Studygroup][1458] CNN Loss=0.9792, Acc=0.6826 | MLP Loss=1.6398, Acc=0.5849\n",
      "[Studygroup][1459] CNN Loss=0.8332, Acc=0.6855 | MLP Loss=1.5743, Acc=0.5882\n",
      "[Studygroup][1460] CNN Loss=0.7725, Acc=0.6786 | MLP Loss=1.5588, Acc=0.5885\n",
      "[Studygroup][1461] CNN Loss=0.8871, Acc=0.6781 | MLP Loss=1.6188, Acc=0.5812\n",
      "[Studygroup][1462] CNN Loss=0.9302, Acc=0.6728 | MLP Loss=1.6372, Acc=0.5932\n",
      "[Studygroup][1463] CNN Loss=0.8945, Acc=0.6788 | MLP Loss=1.6536, Acc=0.5898\n",
      "[Studygroup][1464] CNN Loss=0.8481, Acc=0.6751 | MLP Loss=1.6271, Acc=0.5901\n",
      "[Studygroup][1465] CNN Loss=0.8882, Acc=0.6762 | MLP Loss=1.6619, Acc=0.5885\n",
      "[Studygroup][1466] CNN Loss=0.8980, Acc=0.6795 | MLP Loss=1.5952, Acc=0.5584\n",
      "[Studygroup][1467] CNN Loss=0.7846, Acc=0.6843 | MLP Loss=1.6228, Acc=0.5843\n",
      "[Studygroup][1468] CNN Loss=0.8399, Acc=0.6830 | MLP Loss=1.5781, Acc=0.5837\n",
      "[Studygroup][1469] CNN Loss=0.8291, Acc=0.6822 | MLP Loss=1.8409, Acc=0.5704\n",
      "[Studygroup][1470] CNN Loss=0.8878, Acc=0.6786 | MLP Loss=1.9229, Acc=0.5772\n",
      "[Studygroup][1471] CNN Loss=0.9949, Acc=0.6759 | MLP Loss=1.7988, Acc=0.5744\n",
      "[Studygroup][1472] CNN Loss=0.9156, Acc=0.6835 | MLP Loss=1.6603, Acc=0.5877\n",
      "[Studygroup][1473] CNN Loss=0.8841, Acc=0.6832 | MLP Loss=1.6467, Acc=0.5889\n",
      "[Studygroup][1474] CNN Loss=0.8673, Acc=0.6820 | MLP Loss=1.6203, Acc=0.5865\n",
      "[Studygroup][1475] CNN Loss=0.8386, Acc=0.6857 | MLP Loss=1.6723, Acc=0.5858\n",
      "[Studygroup][1476] CNN Loss=0.9748, Acc=0.6812 | MLP Loss=1.6698, Acc=0.5894\n",
      "[Studygroup][1477] CNN Loss=0.8243, Acc=0.6809 | MLP Loss=1.5601, Acc=0.5828\n",
      "[Studygroup][1478] CNN Loss=0.8924, Acc=0.6825 | MLP Loss=1.6713, Acc=0.5914\n",
      "[Studygroup][1479] CNN Loss=0.9230, Acc=0.6826 | MLP Loss=1.6022, Acc=0.5748\n",
      "[Studygroup][1480] CNN Loss=0.8113, Acc=0.6914 | MLP Loss=1.6064, Acc=0.5855\n",
      "[Studygroup][1481] CNN Loss=0.7777, Acc=0.6858 | MLP Loss=1.7992, Acc=0.5835\n",
      "[Studygroup][1482] CNN Loss=0.7870, Acc=0.6810 | MLP Loss=1.7507, Acc=0.5899\n",
      "[Studygroup][1483] CNN Loss=0.9529, Acc=0.6628 | MLP Loss=1.7335, Acc=0.5804\n",
      "[Studygroup][1484] CNN Loss=1.0059, Acc=0.6802 | MLP Loss=1.5691, Acc=0.5696\n",
      "[Studygroup][1485] CNN Loss=0.8788, Acc=0.6821 | MLP Loss=1.5898, Acc=0.5933\n",
      "[Studygroup][1486] CNN Loss=0.8858, Acc=0.6827 | MLP Loss=1.5981, Acc=0.5909\n",
      "[Studygroup][1487] CNN Loss=0.8691, Acc=0.6837 | MLP Loss=1.7235, Acc=0.5947\n",
      "[Studygroup][1488] CNN Loss=0.9557, Acc=0.6782 | MLP Loss=1.6417, Acc=0.5900\n",
      "[Studygroup][1489] CNN Loss=1.0110, Acc=0.6765 | MLP Loss=1.6259, Acc=0.5809\n",
      "[Studygroup][1490] CNN Loss=0.8201, Acc=0.6847 | MLP Loss=1.5878, Acc=0.5922\n",
      "[Studygroup][1491] CNN Loss=0.8517, Acc=0.6798 | MLP Loss=1.6302, Acc=0.5913\n",
      "[Studygroup][1492] CNN Loss=0.8925, Acc=0.6848 | MLP Loss=1.7125, Acc=0.5742\n",
      "[Studygroup][1493] CNN Loss=0.8244, Acc=0.6835 | MLP Loss=1.7092, Acc=0.5830\n",
      "[Studygroup][1494] CNN Loss=0.8954, Acc=0.6849 | MLP Loss=1.6434, Acc=0.5930\n",
      "[Studygroup][1495] CNN Loss=0.8655, Acc=0.6823 | MLP Loss=1.5932, Acc=0.5915\n",
      "[Studygroup][1496] CNN Loss=0.8421, Acc=0.6843 | MLP Loss=1.6300, Acc=0.5894\n",
      "[Studygroup][1497] CNN Loss=0.8549, Acc=0.6814 | MLP Loss=1.6108, Acc=0.5916\n",
      "[Studygroup][1498] CNN Loss=0.9407, Acc=0.6815 | MLP Loss=1.6186, Acc=0.5864\n",
      "[Studygroup][1499] CNN Loss=0.8940, Acc=0.6662 | MLP Loss=1.7049, Acc=0.5799\n",
      "[Studygroup][1500] CNN Loss=0.8273, Acc=0.6770 | MLP Loss=1.6634, Acc=0.5787\n",
      "[Studygroup][1501] CNN Loss=0.9515, Acc=0.6725 | MLP Loss=1.7077, Acc=0.5929\n",
      "[Studygroup][1502] CNN Loss=0.9044, Acc=0.6705 | MLP Loss=1.6902, Acc=0.5918\n",
      "[Studygroup][1503] CNN Loss=0.9216, Acc=0.6582 | MLP Loss=1.6593, Acc=0.5902\n",
      "[Studygroup][1504] CNN Loss=0.9966, Acc=0.6739 | MLP Loss=1.6491, Acc=0.5807\n",
      "[Studygroup][1505] CNN Loss=0.9675, Acc=0.6804 | MLP Loss=1.5408, Acc=0.5830\n",
      "[Studygroup][1506] CNN Loss=0.9585, Acc=0.6774 | MLP Loss=1.5739, Acc=0.5894\n",
      "[Studygroup][1507] CNN Loss=0.9251, Acc=0.6793 | MLP Loss=1.6054, Acc=0.5850\n",
      "[Studygroup][1508] CNN Loss=0.8331, Acc=0.6838 | MLP Loss=1.5981, Acc=0.5823\n",
      "[Studygroup][1509] CNN Loss=0.8762, Acc=0.6808 | MLP Loss=1.6046, Acc=0.5900\n",
      "[Studygroup][1510] CNN Loss=0.8018, Acc=0.6849 | MLP Loss=1.5938, Acc=0.5909\n",
      "[Studygroup][1511] CNN Loss=0.8396, Acc=0.6794 | MLP Loss=1.5756, Acc=0.5868\n",
      "[Studygroup][1512] CNN Loss=0.8941, Acc=0.6811 | MLP Loss=1.6523, Acc=0.5617\n",
      "[Studygroup][1513] CNN Loss=0.8332, Acc=0.6787 | MLP Loss=1.6372, Acc=0.5885\n",
      "[Studygroup][1514] CNN Loss=0.8803, Acc=0.6780 | MLP Loss=1.6542, Acc=0.5905\n",
      "[Studygroup][1515] CNN Loss=1.0037, Acc=0.6757 | MLP Loss=1.6176, Acc=0.5801\n",
      "[Studygroup][1516] CNN Loss=0.9236, Acc=0.6831 | MLP Loss=1.6102, Acc=0.5870\n",
      "[Studygroup][1517] CNN Loss=0.8882, Acc=0.6807 | MLP Loss=1.6602, Acc=0.5784\n",
      "[Studygroup][1518] CNN Loss=0.9108, Acc=0.6845 | MLP Loss=1.5650, Acc=0.5864\n",
      "[Studygroup][1519] CNN Loss=0.8547, Acc=0.6796 | MLP Loss=1.6233, Acc=0.5846\n",
      "[Studygroup][1520] CNN Loss=0.8515, Acc=0.6826 | MLP Loss=1.6019, Acc=0.5892\n",
      "[Studygroup][1521] CNN Loss=0.8450, Acc=0.6808 | MLP Loss=1.5615, Acc=0.5917\n",
      "[Studygroup][1522] CNN Loss=0.8569, Acc=0.6887 | MLP Loss=1.6551, Acc=0.5814\n",
      "[Studygroup][1523] CNN Loss=0.8040, Acc=0.6887 | MLP Loss=1.6430, Acc=0.5916\n",
      "[Studygroup][1524] CNN Loss=0.9092, Acc=0.6814 | MLP Loss=1.5968, Acc=0.5805\n",
      "[Studygroup][1525] CNN Loss=0.8913, Acc=0.6821 | MLP Loss=1.5996, Acc=0.5894\n",
      "[Studygroup][1526] CNN Loss=0.9217, Acc=0.6781 | MLP Loss=1.5940, Acc=0.5785\n",
      "[Studygroup][1527] CNN Loss=0.8634, Acc=0.6833 | MLP Loss=1.5722, Acc=0.5955\n",
      "[Studygroup][1528] CNN Loss=0.8766, Acc=0.6862 | MLP Loss=1.6245, Acc=0.5830\n",
      "[Studygroup][1529] CNN Loss=0.9219, Acc=0.6772 | MLP Loss=1.7475, Acc=0.5623\n",
      "[Studygroup][1530] CNN Loss=0.9015, Acc=0.6900 | MLP Loss=1.6564, Acc=0.5813\n",
      "[Studygroup][1531] CNN Loss=0.9175, Acc=0.6797 | MLP Loss=1.7062, Acc=0.5818\n",
      "[Studygroup][1532] CNN Loss=0.9197, Acc=0.6819 | MLP Loss=1.7152, Acc=0.5851\n",
      "[Studygroup][1533] CNN Loss=0.8962, Acc=0.6756 | MLP Loss=1.7233, Acc=0.5722\n",
      "[Studygroup][1534] CNN Loss=0.9040, Acc=0.6852 | MLP Loss=1.7580, Acc=0.5823\n",
      "[Studygroup][1535] CNN Loss=0.9380, Acc=0.6813 | MLP Loss=1.7660, Acc=0.5801\n",
      "[Studygroup][1536] CNN Loss=0.9818, Acc=0.6779 | MLP Loss=1.6905, Acc=0.5819\n",
      "[Studygroup][1537] CNN Loss=1.0243, Acc=0.6713 | MLP Loss=1.6431, Acc=0.5750\n",
      "[Studygroup][1538] CNN Loss=1.0242, Acc=0.6722 | MLP Loss=1.6011, Acc=0.5906\n",
      "[Studygroup][1539] CNN Loss=0.9038, Acc=0.6678 | MLP Loss=1.6946, Acc=0.5763\n",
      "[Studygroup][1540] CNN Loss=0.9071, Acc=0.6746 | MLP Loss=1.6875, Acc=0.5922\n",
      "[Studygroup][1541] CNN Loss=0.9810, Acc=0.6798 | MLP Loss=1.7057, Acc=0.5845\n",
      "[Studygroup][1542] CNN Loss=0.9777, Acc=0.6743 | MLP Loss=1.6481, Acc=0.5866\n",
      "[Studygroup][1543] CNN Loss=0.8441, Acc=0.6841 | MLP Loss=1.6520, Acc=0.5810\n",
      "[Studygroup][1544] CNN Loss=0.9212, Acc=0.6760 | MLP Loss=1.5831, Acc=0.5869\n",
      "[Studygroup][1545] CNN Loss=0.8424, Acc=0.6789 | MLP Loss=1.5325, Acc=0.5874\n",
      "[Studygroup][1546] CNN Loss=0.8777, Acc=0.6785 | MLP Loss=1.7140, Acc=0.5802\n",
      "[Studygroup][1547] CNN Loss=0.8939, Acc=0.6857 | MLP Loss=1.6216, Acc=0.5920\n",
      "[Studygroup][1548] CNN Loss=0.9588, Acc=0.6698 | MLP Loss=1.6747, Acc=0.5691\n",
      "[Studygroup][1549] CNN Loss=0.9663, Acc=0.6842 | MLP Loss=1.6960, Acc=0.5954\n",
      "[Studygroup][1550] CNN Loss=0.9461, Acc=0.6806 | MLP Loss=1.7350, Acc=0.5822\n",
      "[Studygroup][1551] CNN Loss=0.9067, Acc=0.6786 | MLP Loss=1.7333, Acc=0.5764\n",
      "[Studygroup][1552] CNN Loss=0.8088, Acc=0.6825 | MLP Loss=1.6636, Acc=0.5849\n",
      "[Studygroup][1553] CNN Loss=0.8451, Acc=0.6887 | MLP Loss=1.7376, Acc=0.5799\n",
      "[Studygroup][1554] CNN Loss=0.8260, Acc=0.6853 | MLP Loss=1.7512, Acc=0.5767\n",
      "[Studygroup][1555] CNN Loss=0.8613, Acc=0.6703 | MLP Loss=1.6910, Acc=0.5752\n",
      "[Studygroup][1556] CNN Loss=1.0031, Acc=0.6760 | MLP Loss=1.6997, Acc=0.5875\n",
      "[Studygroup][1557] CNN Loss=0.8894, Acc=0.6798 | MLP Loss=1.6389, Acc=0.5787\n",
      "[Studygroup][1558] CNN Loss=0.8611, Acc=0.6838 | MLP Loss=1.6140, Acc=0.5874\n",
      "[Studygroup][1559] CNN Loss=0.8984, Acc=0.6813 | MLP Loss=1.6660, Acc=0.5961\n",
      "[Studygroup][1560] CNN Loss=0.8115, Acc=0.6839 | MLP Loss=1.6534, Acc=0.5912\n",
      "[Studygroup][1561] CNN Loss=0.8797, Acc=0.6776 | MLP Loss=1.7205, Acc=0.5814\n",
      "[Studygroup][1562] CNN Loss=0.8611, Acc=0.6811 | MLP Loss=1.6910, Acc=0.5940\n",
      "[Studygroup][1563] CNN Loss=0.9409, Acc=0.6779 | MLP Loss=1.6885, Acc=0.5938\n",
      "[Studygroup][1564] CNN Loss=0.8810, Acc=0.6747 | MLP Loss=1.6930, Acc=0.5785\n",
      "[Studygroup][1565] CNN Loss=0.8962, Acc=0.6766 | MLP Loss=1.7426, Acc=0.5799\n",
      "[Studygroup][1566] CNN Loss=0.9451, Acc=0.6765 | MLP Loss=1.7906, Acc=0.5876\n",
      "[Studygroup][1567] CNN Loss=0.9591, Acc=0.6790 | MLP Loss=1.6234, Acc=0.5848\n",
      "[Studygroup][1568] CNN Loss=0.8822, Acc=0.6801 | MLP Loss=1.6634, Acc=0.5828\n",
      "[Studygroup][1569] CNN Loss=0.8793, Acc=0.6733 | MLP Loss=1.6891, Acc=0.5949\n",
      "[Studygroup][1570] CNN Loss=0.8707, Acc=0.6804 | MLP Loss=1.6671, Acc=0.5851\n",
      "[Studygroup][1571] CNN Loss=0.8167, Acc=0.6773 | MLP Loss=1.6990, Acc=0.5898\n",
      "[Studygroup][1572] CNN Loss=0.8220, Acc=0.6813 | MLP Loss=1.6296, Acc=0.5784\n",
      "[Studygroup][1573] CNN Loss=0.7760, Acc=0.6779 | MLP Loss=1.6511, Acc=0.5824\n",
      "[Studygroup][1574] CNN Loss=0.7660, Acc=0.6842 | MLP Loss=1.7305, Acc=0.5804\n",
      "[Studygroup][1575] CNN Loss=0.9694, Acc=0.6792 | MLP Loss=1.7747, Acc=0.5748\n",
      "[Studygroup][1576] CNN Loss=0.8216, Acc=0.6864 | MLP Loss=1.6438, Acc=0.5818\n",
      "[Studygroup][1577] CNN Loss=0.8592, Acc=0.6889 | MLP Loss=1.6235, Acc=0.5909\n",
      "[Studygroup][1578] CNN Loss=0.7998, Acc=0.6872 | MLP Loss=1.6703, Acc=0.5897\n",
      "[Studygroup][1579] CNN Loss=0.8578, Acc=0.6784 | MLP Loss=1.5972, Acc=0.5821\n",
      "[Studygroup][1580] CNN Loss=0.9069, Acc=0.6835 | MLP Loss=1.6912, Acc=0.5894\n",
      "[Studygroup][1581] CNN Loss=0.8518, Acc=0.6831 | MLP Loss=1.6592, Acc=0.5942\n",
      "[Studygroup][1582] CNN Loss=0.9433, Acc=0.6818 | MLP Loss=1.5806, Acc=0.5934\n",
      "[Studygroup][1583] CNN Loss=0.8806, Acc=0.6860 | MLP Loss=1.6963, Acc=0.5847\n",
      "[Studygroup][1584] CNN Loss=0.9067, Acc=0.6757 | MLP Loss=1.6779, Acc=0.5906\n",
      "[Studygroup][1585] CNN Loss=0.8802, Acc=0.6754 | MLP Loss=1.6918, Acc=0.5926\n",
      "[Studygroup][1586] CNN Loss=0.8894, Acc=0.6776 | MLP Loss=1.6939, Acc=0.5926\n",
      "[Studygroup][1587] CNN Loss=0.8532, Acc=0.6796 | MLP Loss=1.6255, Acc=0.5845\n",
      "[Studygroup][1588] CNN Loss=1.0463, Acc=0.6686 | MLP Loss=1.7131, Acc=0.5818\n",
      "[Studygroup][1589] CNN Loss=1.0114, Acc=0.6819 | MLP Loss=1.6243, Acc=0.5929\n",
      "[Studygroup][1590] CNN Loss=0.8900, Acc=0.6820 | MLP Loss=1.6259, Acc=0.5925\n",
      "[Studygroup][1591] CNN Loss=0.9615, Acc=0.6794 | MLP Loss=1.5790, Acc=0.5932\n",
      "[Studygroup][1592] CNN Loss=0.9698, Acc=0.6734 | MLP Loss=1.5920, Acc=0.5941\n",
      "[Studygroup][1593] CNN Loss=1.0397, Acc=0.6753 | MLP Loss=1.5865, Acc=0.5878\n",
      "[Studygroup][1594] CNN Loss=0.8821, Acc=0.6848 | MLP Loss=1.6455, Acc=0.5802\n",
      "[Studygroup][1595] CNN Loss=0.8972, Acc=0.6829 | MLP Loss=1.6284, Acc=0.5834\n",
      "[Studygroup][1596] CNN Loss=0.8789, Acc=0.6762 | MLP Loss=1.6215, Acc=0.5887\n",
      "[Studygroup][1597] CNN Loss=0.8984, Acc=0.6737 | MLP Loss=1.6492, Acc=0.5880\n",
      "[Studygroup][1598] CNN Loss=0.8422, Acc=0.6832 | MLP Loss=1.5894, Acc=0.5859\n",
      "[Studygroup][1599] CNN Loss=0.9950, Acc=0.6810 | MLP Loss=1.6143, Acc=0.5907\n",
      "[Studygroup][1600] CNN Loss=0.8948, Acc=0.6747 | MLP Loss=1.5824, Acc=0.5954\n",
      "[Studygroup][1601] CNN Loss=0.9176, Acc=0.6744 | MLP Loss=1.6434, Acc=0.5815\n",
      "[Studygroup][1602] CNN Loss=0.8476, Acc=0.6816 | MLP Loss=1.6701, Acc=0.5917\n",
      "[Studygroup][1603] CNN Loss=0.9034, Acc=0.6881 | MLP Loss=1.6683, Acc=0.5864\n",
      "[Studygroup][1604] CNN Loss=0.8807, Acc=0.6792 | MLP Loss=1.6450, Acc=0.5798\n",
      "[Studygroup][1605] CNN Loss=0.9400, Acc=0.6796 | MLP Loss=1.6978, Acc=0.5626\n",
      "[Studygroup][1606] CNN Loss=0.9878, Acc=0.6873 | MLP Loss=1.7299, Acc=0.5880\n",
      "[Studygroup][1607] CNN Loss=0.8195, Acc=0.6816 | MLP Loss=1.6310, Acc=0.5844\n",
      "[Studygroup][1608] CNN Loss=0.9142, Acc=0.6779 | MLP Loss=1.6490, Acc=0.5917\n",
      "[Studygroup][1609] CNN Loss=0.9670, Acc=0.6879 | MLP Loss=1.6365, Acc=0.5890\n",
      "[Studygroup][1610] CNN Loss=0.9313, Acc=0.6794 | MLP Loss=1.6071, Acc=0.5964\n",
      "[Studygroup][1611] CNN Loss=0.8838, Acc=0.6792 | MLP Loss=1.6427, Acc=0.5923\n",
      "[Studygroup][1612] CNN Loss=0.8321, Acc=0.6813 | MLP Loss=1.6004, Acc=0.5938\n",
      "[Studygroup][1613] CNN Loss=0.9371, Acc=0.6796 | MLP Loss=1.6036, Acc=0.5938\n",
      "[Studygroup][1614] CNN Loss=0.9090, Acc=0.6872 | MLP Loss=1.6043, Acc=0.5774\n",
      "[Studygroup][1615] CNN Loss=0.9456, Acc=0.6781 | MLP Loss=1.8691, Acc=0.5807\n",
      "[Studygroup][1616] CNN Loss=0.8857, Acc=0.6819 | MLP Loss=1.7263, Acc=0.5818\n",
      "[Studygroup][1617] CNN Loss=0.8173, Acc=0.6826 | MLP Loss=1.6557, Acc=0.5923\n",
      "[Studygroup][1618] CNN Loss=0.8964, Acc=0.6736 | MLP Loss=1.6417, Acc=0.5868\n",
      "[Studygroup][1619] CNN Loss=0.9224, Acc=0.6800 | MLP Loss=1.5956, Acc=0.5921\n",
      "[Studygroup][1620] CNN Loss=0.8042, Acc=0.6835 | MLP Loss=1.5979, Acc=0.5966\n",
      "[Studygroup][1621] CNN Loss=0.8685, Acc=0.6841 | MLP Loss=1.5916, Acc=0.5869\n",
      "[Studygroup][1622] CNN Loss=0.8711, Acc=0.6686 | MLP Loss=1.5969, Acc=0.5804\n",
      "[Studygroup][1623] CNN Loss=0.8818, Acc=0.6825 | MLP Loss=1.6409, Acc=0.5969\n",
      "[Studygroup][1624] CNN Loss=0.9375, Acc=0.6727 | MLP Loss=1.5674, Acc=0.5860\n",
      "[Studygroup][1625] CNN Loss=0.8974, Acc=0.6766 | MLP Loss=1.5675, Acc=0.5863\n",
      "[Studygroup][1626] CNN Loss=0.8424, Acc=0.6836 | MLP Loss=1.6177, Acc=0.5926\n",
      "[Studygroup][1627] CNN Loss=0.8738, Acc=0.6821 | MLP Loss=1.7062, Acc=0.5813\n",
      "[Studygroup][1628] CNN Loss=0.8997, Acc=0.6718 | MLP Loss=1.6682, Acc=0.5862\n",
      "[Studygroup][1629] CNN Loss=0.9279, Acc=0.6788 | MLP Loss=1.7065, Acc=0.5950\n",
      "[Studygroup][1630] CNN Loss=0.8829, Acc=0.6841 | MLP Loss=1.6397, Acc=0.5947\n",
      "[Studygroup][1631] CNN Loss=0.8686, Acc=0.6755 | MLP Loss=1.6065, Acc=0.5939\n",
      "[Studygroup][1632] CNN Loss=0.9263, Acc=0.6793 | MLP Loss=1.5530, Acc=0.5936\n",
      "[Studygroup][1633] CNN Loss=0.8845, Acc=0.6748 | MLP Loss=1.5657, Acc=0.5870\n",
      "[Studygroup][1634] CNN Loss=0.8765, Acc=0.6765 | MLP Loss=1.6156, Acc=0.5871\n",
      "[Studygroup][1635] CNN Loss=0.9197, Acc=0.6789 | MLP Loss=1.5294, Acc=0.5861\n",
      "[Studygroup][1636] CNN Loss=0.8524, Acc=0.6855 | MLP Loss=1.6739, Acc=0.5921\n",
      "[Studygroup][1637] CNN Loss=0.9171, Acc=0.6783 | MLP Loss=1.6126, Acc=0.5865\n",
      "[Studygroup][1638] CNN Loss=0.9315, Acc=0.6740 | MLP Loss=1.5795, Acc=0.5839\n",
      "[Studygroup][1639] CNN Loss=0.8144, Acc=0.6809 | MLP Loss=1.5976, Acc=0.5839\n",
      "[Studygroup][1640] CNN Loss=0.8533, Acc=0.6822 | MLP Loss=1.6602, Acc=0.5822\n",
      "[Studygroup][1641] CNN Loss=0.8692, Acc=0.6765 | MLP Loss=1.6223, Acc=0.5946\n",
      "[Studygroup][1642] CNN Loss=0.8913, Acc=0.6812 | MLP Loss=1.5888, Acc=0.5877\n",
      "[Studygroup][1643] CNN Loss=0.8415, Acc=0.6801 | MLP Loss=1.5869, Acc=0.5903\n",
      "[Studygroup][1644] CNN Loss=0.9504, Acc=0.6725 | MLP Loss=1.5814, Acc=0.5801\n",
      "[Studygroup][1645] CNN Loss=0.8736, Acc=0.6836 | MLP Loss=1.5776, Acc=0.5912\n",
      "[Studygroup][1646] CNN Loss=1.0269, Acc=0.6727 | MLP Loss=1.6266, Acc=0.5841\n",
      "[Studygroup][1647] CNN Loss=0.9189, Acc=0.6780 | MLP Loss=1.6247, Acc=0.5925\n",
      "[Studygroup][1648] CNN Loss=0.8345, Acc=0.6637 | MLP Loss=1.6435, Acc=0.5623\n",
      "[Studygroup][1649] CNN Loss=1.0785, Acc=0.6742 | MLP Loss=1.9972, Acc=0.5853\n",
      "[Studygroup][1650] CNN Loss=0.9324, Acc=0.6762 | MLP Loss=1.7122, Acc=0.5871\n",
      "[Studygroup][1651] CNN Loss=0.9080, Acc=0.6761 | MLP Loss=1.6487, Acc=0.5898\n",
      "[Studygroup][1652] CNN Loss=0.8294, Acc=0.6797 | MLP Loss=1.6727, Acc=0.5888\n",
      "[Studygroup][1653] CNN Loss=0.8203, Acc=0.6759 | MLP Loss=1.6035, Acc=0.5913\n",
      "[Studygroup][1654] CNN Loss=0.8643, Acc=0.6765 | MLP Loss=1.6455, Acc=0.5959\n",
      "[Studygroup][1655] CNN Loss=0.9509, Acc=0.6828 | MLP Loss=1.6105, Acc=0.5918\n",
      "[Studygroup][1656] CNN Loss=0.8666, Acc=0.6832 | MLP Loss=1.6010, Acc=0.5935\n",
      "[Studygroup][1657] CNN Loss=0.8996, Acc=0.6839 | MLP Loss=1.6735, Acc=0.5963\n",
      "[Studygroup][1658] CNN Loss=0.8712, Acc=0.6848 | MLP Loss=1.6337, Acc=0.5917\n",
      "[Studygroup][1659] CNN Loss=0.8633, Acc=0.6792 | MLP Loss=1.6422, Acc=0.5843\n",
      "[Studygroup][1660] CNN Loss=0.9919, Acc=0.6658 | MLP Loss=1.5978, Acc=0.5701\n",
      "[Studygroup][1661] CNN Loss=0.9350, Acc=0.6770 | MLP Loss=1.5735, Acc=0.5863\n",
      "[Studygroup][1662] CNN Loss=0.9495, Acc=0.6765 | MLP Loss=1.6029, Acc=0.5878\n",
      "[Studygroup][1663] CNN Loss=0.9289, Acc=0.6693 | MLP Loss=1.6910, Acc=0.5878\n",
      "[Studygroup][1664] CNN Loss=1.0055, Acc=0.6813 | MLP Loss=1.6118, Acc=0.5855\n",
      "[Studygroup][1665] CNN Loss=0.9322, Acc=0.6792 | MLP Loss=1.7069, Acc=0.5838\n",
      "[Studygroup][1666] CNN Loss=0.8452, Acc=0.6778 | MLP Loss=1.5771, Acc=0.5930\n",
      "[Studygroup][1667] CNN Loss=0.8447, Acc=0.6828 | MLP Loss=1.6065, Acc=0.5844\n",
      "[Studygroup][1668] CNN Loss=0.8001, Acc=0.6776 | MLP Loss=1.6334, Acc=0.5827\n",
      "[Studygroup][1669] CNN Loss=0.9421, Acc=0.6793 | MLP Loss=1.6721, Acc=0.5856\n",
      "[Studygroup][1670] CNN Loss=0.8335, Acc=0.6820 | MLP Loss=1.5926, Acc=0.5874\n",
      "[Studygroup][1671] CNN Loss=0.8297, Acc=0.6841 | MLP Loss=1.6570, Acc=0.5824\n",
      "[Studygroup][1672] CNN Loss=0.8816, Acc=0.6827 | MLP Loss=1.5892, Acc=0.5903\n",
      "[Studygroup][1673] CNN Loss=0.9400, Acc=0.6823 | MLP Loss=1.5149, Acc=0.5790\n",
      "[Studygroup][1674] CNN Loss=0.9626, Acc=0.6771 | MLP Loss=1.5642, Acc=0.5927\n",
      "[Studygroup][1675] CNN Loss=0.9205, Acc=0.6824 | MLP Loss=1.6385, Acc=0.5845\n",
      "[Studygroup][1676] CNN Loss=0.8175, Acc=0.6816 | MLP Loss=1.6403, Acc=0.5910\n",
      "[Studygroup][1677] CNN Loss=0.8197, Acc=0.6788 | MLP Loss=1.6144, Acc=0.5930\n",
      "[Studygroup][1678] CNN Loss=0.9043, Acc=0.6809 | MLP Loss=1.6792, Acc=0.5881\n",
      "[Studygroup][1679] CNN Loss=0.8829, Acc=0.6812 | MLP Loss=1.6838, Acc=0.5847\n",
      "[Studygroup][1680] CNN Loss=0.9160, Acc=0.6729 | MLP Loss=1.5996, Acc=0.5914\n",
      "[Studygroup][1681] CNN Loss=0.8986, Acc=0.6841 | MLP Loss=1.6641, Acc=0.5824\n",
      "[Studygroup][1682] CNN Loss=0.9065, Acc=0.6772 | MLP Loss=1.6766, Acc=0.5847\n",
      "[Studygroup][1683] CNN Loss=0.8952, Acc=0.6797 | MLP Loss=1.6618, Acc=0.5871\n",
      "[Studygroup][1684] CNN Loss=0.8661, Acc=0.6822 | MLP Loss=1.6162, Acc=0.5872\n",
      "[Studygroup][1685] CNN Loss=0.8133, Acc=0.6872 | MLP Loss=1.6718, Acc=0.5949\n",
      "[Studygroup][1686] CNN Loss=0.8660, Acc=0.6840 | MLP Loss=1.6412, Acc=0.5972\n",
      "[Studygroup][1687] CNN Loss=0.9058, Acc=0.6719 | MLP Loss=1.6405, Acc=0.5796\n",
      "[Studygroup][1688] CNN Loss=1.0252, Acc=0.6686 | MLP Loss=1.6797, Acc=0.5935\n",
      "[Studygroup][1689] CNN Loss=0.8816, Acc=0.6795 | MLP Loss=1.6513, Acc=0.5950\n",
      "[Studygroup][1690] CNN Loss=0.8171, Acc=0.6854 | MLP Loss=1.6178, Acc=0.5911\n",
      "[Studygroup][1691] CNN Loss=0.8730, Acc=0.6797 | MLP Loss=1.6574, Acc=0.5870\n",
      "[Studygroup][1692] CNN Loss=0.9063, Acc=0.6785 | MLP Loss=1.6071, Acc=0.5878\n",
      "[Studygroup][1693] CNN Loss=1.0773, Acc=0.6768 | MLP Loss=1.6258, Acc=0.5932\n",
      "[Studygroup][1694] CNN Loss=0.9089, Acc=0.6814 | MLP Loss=1.6368, Acc=0.5823\n",
      "[Studygroup][1695] CNN Loss=0.9236, Acc=0.6810 | MLP Loss=1.5650, Acc=0.5918\n",
      "[Studygroup][1696] CNN Loss=0.9083, Acc=0.6850 | MLP Loss=1.5781, Acc=0.5961\n",
      "[Studygroup][1697] CNN Loss=0.7955, Acc=0.6824 | MLP Loss=1.5789, Acc=0.5932\n",
      "[Studygroup][1698] CNN Loss=0.8925, Acc=0.6799 | MLP Loss=1.5908, Acc=0.5915\n",
      "[Studygroup][1699] CNN Loss=0.8664, Acc=0.6845 | MLP Loss=1.6770, Acc=0.5960\n",
      "[Studygroup][1700] CNN Loss=0.8626, Acc=0.6810 | MLP Loss=1.7036, Acc=0.5995\n",
      "[Studygroup][1701] CNN Loss=0.8592, Acc=0.6766 | MLP Loss=1.6736, Acc=0.5904\n",
      "[Studygroup][1702] CNN Loss=0.8823, Acc=0.6809 | MLP Loss=1.6895, Acc=0.5955\n",
      "[Studygroup][1703] CNN Loss=0.9421, Acc=0.6777 | MLP Loss=1.6048, Acc=0.5883\n",
      "[Studygroup][1704] CNN Loss=0.9126, Acc=0.6836 | MLP Loss=1.6576, Acc=0.5922\n",
      "[Studygroup][1705] CNN Loss=0.7999, Acc=0.6834 | MLP Loss=1.6388, Acc=0.5933\n",
      "[Studygroup][1706] CNN Loss=0.8868, Acc=0.6825 | MLP Loss=1.7003, Acc=0.5798\n",
      "[Studygroup][1707] CNN Loss=0.8619, Acc=0.6760 | MLP Loss=1.6580, Acc=0.5934\n",
      "[Studygroup][1708] CNN Loss=0.8282, Acc=0.6869 | MLP Loss=1.6151, Acc=0.5976\n",
      "[Studygroup][1709] CNN Loss=0.8319, Acc=0.6757 | MLP Loss=1.5635, Acc=0.5980\n",
      "[Studygroup][1710] CNN Loss=0.8922, Acc=0.6746 | MLP Loss=1.6344, Acc=0.5909\n",
      "[Studygroup][1711] CNN Loss=0.8389, Acc=0.6777 | MLP Loss=1.6315, Acc=0.5782\n",
      "[Studygroup][1712] CNN Loss=0.9027, Acc=0.6798 | MLP Loss=1.6728, Acc=0.5914\n",
      "[Studygroup][1713] CNN Loss=0.8644, Acc=0.6796 | MLP Loss=1.6344, Acc=0.5910\n",
      "[Studygroup][1714] CNN Loss=0.9043, Acc=0.6739 | MLP Loss=1.5966, Acc=0.5900\n",
      "[Studygroup][1715] CNN Loss=0.8145, Acc=0.6725 | MLP Loss=1.6292, Acc=0.5908\n",
      "[Studygroup][1716] CNN Loss=0.8434, Acc=0.6781 | MLP Loss=1.6109, Acc=0.5906\n",
      "[Studygroup][1717] CNN Loss=0.9153, Acc=0.6807 | MLP Loss=1.6446, Acc=0.5946\n",
      "[Studygroup][1718] CNN Loss=0.8693, Acc=0.6760 | MLP Loss=1.5919, Acc=0.5915\n",
      "[Studygroup][1719] CNN Loss=0.8412, Acc=0.6763 | MLP Loss=1.6665, Acc=0.5951\n",
      "[Studygroup][1720] CNN Loss=0.8273, Acc=0.6804 | MLP Loss=1.6627, Acc=0.5879\n",
      "[Studygroup][1721] CNN Loss=0.8230, Acc=0.6785 | MLP Loss=1.5581, Acc=0.5888\n",
      "[Studygroup][1722] CNN Loss=0.9498, Acc=0.6752 | MLP Loss=1.6298, Acc=0.5906\n",
      "[Studygroup][1723] CNN Loss=0.8928, Acc=0.6747 | MLP Loss=1.6721, Acc=0.5829\n",
      "[Studygroup][1724] CNN Loss=0.8751, Acc=0.6794 | MLP Loss=1.6451, Acc=0.5998\n",
      "[Studygroup][1725] CNN Loss=0.8789, Acc=0.6820 | MLP Loss=1.6325, Acc=0.5851\n",
      "[Studygroup][1726] CNN Loss=1.0769, Acc=0.6697 | MLP Loss=1.6754, Acc=0.5873\n",
      "[Studygroup][1727] CNN Loss=0.9512, Acc=0.6780 | MLP Loss=1.5416, Acc=0.5926\n",
      "[Studygroup][1728] CNN Loss=0.8768, Acc=0.6814 | MLP Loss=1.6366, Acc=0.5669\n",
      "[Studygroup][1729] CNN Loss=0.9309, Acc=0.6738 | MLP Loss=1.6133, Acc=0.5939\n",
      "[Studygroup][1730] CNN Loss=0.9405, Acc=0.6774 | MLP Loss=1.8189, Acc=0.5863\n",
      "[Studygroup][1731] CNN Loss=0.9636, Acc=0.6802 | MLP Loss=1.7726, Acc=0.5732\n",
      "[Studygroup][1732] CNN Loss=0.8318, Acc=0.6782 | MLP Loss=1.6485, Acc=0.5886\n",
      "[Studygroup][1733] CNN Loss=0.8394, Acc=0.6815 | MLP Loss=1.5743, Acc=0.5965\n",
      "[Studygroup][1734] CNN Loss=0.9200, Acc=0.6798 | MLP Loss=1.6266, Acc=0.5980\n",
      "[Studygroup][1735] CNN Loss=0.8667, Acc=0.6788 | MLP Loss=1.6167, Acc=0.5893\n",
      "[Studygroup][1736] CNN Loss=0.8439, Acc=0.6805 | MLP Loss=1.5912, Acc=0.5899\n",
      "[Studygroup][1737] CNN Loss=0.8526, Acc=0.6730 | MLP Loss=1.6722, Acc=0.5838\n",
      "[Studygroup][1738] CNN Loss=0.9175, Acc=0.6805 | MLP Loss=1.7284, Acc=0.5965\n",
      "[Studygroup][1739] CNN Loss=0.8880, Acc=0.6772 | MLP Loss=1.6661, Acc=0.5961\n",
      "[Studygroup][1740] CNN Loss=0.9039, Acc=0.6797 | MLP Loss=1.6982, Acc=0.5890\n",
      "[Studygroup][1741] CNN Loss=1.0112, Acc=0.6754 | MLP Loss=1.6072, Acc=0.5890\n",
      "[Studygroup][1742] CNN Loss=0.9100, Acc=0.6737 | MLP Loss=1.6013, Acc=0.5828\n",
      "[Studygroup][1743] CNN Loss=0.9047, Acc=0.6827 | MLP Loss=1.5702, Acc=0.5970\n",
      "[Studygroup][1744] CNN Loss=0.9000, Acc=0.6814 | MLP Loss=1.5850, Acc=0.5880\n",
      "[Studygroup][1745] CNN Loss=0.9340, Acc=0.6787 | MLP Loss=1.6894, Acc=0.5816\n",
      "[Studygroup][1746] CNN Loss=1.0314, Acc=0.6737 | MLP Loss=1.6480, Acc=0.5935\n",
      "[Studygroup][1747] CNN Loss=0.8909, Acc=0.6707 | MLP Loss=1.6146, Acc=0.5956\n",
      "[Studygroup][1748] CNN Loss=0.9407, Acc=0.6786 | MLP Loss=1.6151, Acc=0.5897\n",
      "[Studygroup][1749] CNN Loss=0.9054, Acc=0.6825 | MLP Loss=1.5770, Acc=0.5860\n",
      "[Studygroup][1750] CNN Loss=0.9501, Acc=0.6830 | MLP Loss=1.6610, Acc=0.5956\n",
      "[Studygroup][1751] CNN Loss=0.8753, Acc=0.6799 | MLP Loss=1.6136, Acc=0.5856\n",
      "[Studygroup][1752] CNN Loss=0.8328, Acc=0.6817 | MLP Loss=1.6446, Acc=0.5900\n",
      "[Studygroup][1753] CNN Loss=0.9378, Acc=0.6772 | MLP Loss=1.6114, Acc=0.5908\n",
      "[Studygroup][1754] CNN Loss=0.8875, Acc=0.6769 | MLP Loss=1.5914, Acc=0.5869\n",
      "[Studygroup][1755] CNN Loss=1.0802, Acc=0.6756 | MLP Loss=1.6832, Acc=0.5859\n",
      "[Studygroup][1756] CNN Loss=0.9053, Acc=0.6721 | MLP Loss=1.6227, Acc=0.5883\n",
      "[Studygroup][1757] CNN Loss=0.9153, Acc=0.6752 | MLP Loss=1.5600, Acc=0.5833\n",
      "[Studygroup][1758] CNN Loss=0.8737, Acc=0.6801 | MLP Loss=1.6230, Acc=0.5961\n",
      "[Studygroup][1759] CNN Loss=0.9760, Acc=0.6797 | MLP Loss=1.5928, Acc=0.5891\n",
      "[Studygroup][1760] CNN Loss=0.8722, Acc=0.6846 | MLP Loss=1.5543, Acc=0.5936\n",
      "[Studygroup][1761] CNN Loss=0.8685, Acc=0.6737 | MLP Loss=1.5810, Acc=0.5930\n",
      "[Studygroup][1762] CNN Loss=0.8429, Acc=0.6845 | MLP Loss=1.5940, Acc=0.5838\n",
      "[Studygroup][1763] CNN Loss=0.8436, Acc=0.6782 | MLP Loss=1.5276, Acc=0.5806\n",
      "[Studygroup][1764] CNN Loss=0.8338, Acc=0.6865 | MLP Loss=1.6610, Acc=0.5910\n",
      "[Studygroup][1765] CNN Loss=0.7568, Acc=0.6774 | MLP Loss=1.6411, Acc=0.5928\n",
      "[Studygroup][1766] CNN Loss=0.9101, Acc=0.6784 | MLP Loss=1.6444, Acc=0.5870\n",
      "[Studygroup][1767] CNN Loss=0.9680, Acc=0.6788 | MLP Loss=1.7397, Acc=0.5943\n",
      "[Studygroup][1768] CNN Loss=1.0018, Acc=0.6777 | MLP Loss=1.6157, Acc=0.5883\n",
      "[Studygroup][1769] CNN Loss=0.9174, Acc=0.6816 | MLP Loss=1.5926, Acc=0.5836\n",
      "[Studygroup][1770] CNN Loss=0.8123, Acc=0.6797 | MLP Loss=1.6096, Acc=0.5929\n",
      "[Studygroup][1771] CNN Loss=0.8957, Acc=0.6699 | MLP Loss=1.6554, Acc=0.5932\n",
      "[Studygroup][1772] CNN Loss=0.9444, Acc=0.6762 | MLP Loss=1.5835, Acc=0.5923\n",
      "[Studygroup][1773] CNN Loss=0.8083, Acc=0.6823 | MLP Loss=1.6313, Acc=0.5898\n",
      "[Studygroup][1774] CNN Loss=0.9952, Acc=0.6859 | MLP Loss=1.5773, Acc=0.5773\n",
      "[Studygroup][1775] CNN Loss=0.9489, Acc=0.6812 | MLP Loss=1.5796, Acc=0.5886\n",
      "[Studygroup][1776] CNN Loss=0.9073, Acc=0.6820 | MLP Loss=1.7132, Acc=0.5853\n",
      "[Studygroup][1777] CNN Loss=0.9852, Acc=0.6735 | MLP Loss=1.6273, Acc=0.5964\n",
      "[Studygroup][1778] CNN Loss=0.8887, Acc=0.6809 | MLP Loss=1.5933, Acc=0.5881\n",
      "[Studygroup][1779] CNN Loss=0.9338, Acc=0.6840 | MLP Loss=1.5885, Acc=0.5755\n",
      "[Studygroup][1780] CNN Loss=0.8445, Acc=0.6821 | MLP Loss=1.6677, Acc=0.5977\n",
      "[Studygroup][1781] CNN Loss=0.9246, Acc=0.6868 | MLP Loss=1.5770, Acc=0.5940\n",
      "[Studygroup][1782] CNN Loss=0.8784, Acc=0.6822 | MLP Loss=1.6339, Acc=0.5943\n",
      "[Studygroup][1783] CNN Loss=0.8608, Acc=0.6731 | MLP Loss=1.5448, Acc=0.5955\n",
      "[Studygroup][1784] CNN Loss=0.7939, Acc=0.6813 | MLP Loss=1.6085, Acc=0.5913\n",
      "[Studygroup][1785] CNN Loss=0.8020, Acc=0.6731 | MLP Loss=1.6236, Acc=0.5918\n",
      "[Studygroup][1786] CNN Loss=0.8075, Acc=0.6812 | MLP Loss=1.6484, Acc=0.5863\n",
      "[Studygroup][1787] CNN Loss=0.8329, Acc=0.6796 | MLP Loss=1.6714, Acc=0.5948\n",
      "[Studygroup][1788] CNN Loss=0.8098, Acc=0.6821 | MLP Loss=1.6476, Acc=0.5849\n",
      "[Studygroup][1789] CNN Loss=0.9088, Acc=0.6735 | MLP Loss=1.6249, Acc=0.5941\n",
      "[Studygroup][1790] CNN Loss=0.8550, Acc=0.6809 | MLP Loss=1.6534, Acc=0.5925\n",
      "[Studygroup][1791] CNN Loss=0.9430, Acc=0.6703 | MLP Loss=1.6095, Acc=0.5747\n",
      "[Studygroup][1792] CNN Loss=0.9900, Acc=0.6759 | MLP Loss=1.5706, Acc=0.5917\n",
      "[Studygroup][1793] CNN Loss=0.8887, Acc=0.6772 | MLP Loss=1.4947, Acc=0.5877\n",
      "[Studygroup][1794] CNN Loss=0.8955, Acc=0.6769 | MLP Loss=1.5719, Acc=0.5901\n",
      "[Studygroup][1795] CNN Loss=0.8874, Acc=0.6667 | MLP Loss=1.6287, Acc=0.5933\n",
      "[Studygroup][1796] CNN Loss=0.9058, Acc=0.6787 | MLP Loss=1.5721, Acc=0.5806\n",
      "[Studygroup][1797] CNN Loss=0.8708, Acc=0.6842 | MLP Loss=1.6164, Acc=0.5802\n",
      "[Studygroup][1798] CNN Loss=0.9311, Acc=0.6734 | MLP Loss=1.6491, Acc=0.5854\n",
      "[Studygroup][1799] CNN Loss=0.9297, Acc=0.6805 | MLP Loss=1.6100, Acc=0.5914\n",
      "[Studygroup][1800] CNN Loss=0.8131, Acc=0.6796 | MLP Loss=1.6466, Acc=0.5890\n",
      "[Studygroup][1801] CNN Loss=0.9074, Acc=0.6571 | MLP Loss=1.6211, Acc=0.5872\n",
      "[Studygroup][1802] CNN Loss=0.9926, Acc=0.6621 | MLP Loss=1.6235, Acc=0.5950\n",
      "[Studygroup][1803] CNN Loss=0.8735, Acc=0.6809 | MLP Loss=1.5801, Acc=0.5943\n",
      "[Studygroup][1804] CNN Loss=0.7727, Acc=0.6796 | MLP Loss=1.6270, Acc=0.5905\n",
      "[Studygroup][1805] CNN Loss=0.8812, Acc=0.6829 | MLP Loss=1.6369, Acc=0.5931\n",
      "[Studygroup][1806] CNN Loss=0.8703, Acc=0.6791 | MLP Loss=1.6434, Acc=0.5881\n",
      "[Studygroup][1807] CNN Loss=0.8576, Acc=0.6802 | MLP Loss=1.6057, Acc=0.5887\n",
      "[Studygroup][1808] CNN Loss=0.9710, Acc=0.6612 | MLP Loss=1.6359, Acc=0.5727\n",
      "[Studygroup][1809] CNN Loss=0.9577, Acc=0.6814 | MLP Loss=1.5997, Acc=0.5876\n",
      "[Studygroup][1810] CNN Loss=0.9282, Acc=0.6818 | MLP Loss=1.5491, Acc=0.5750\n",
      "[Studygroup][1811] CNN Loss=0.8525, Acc=0.6819 | MLP Loss=1.6042, Acc=0.5837\n",
      "[Studygroup][1812] CNN Loss=0.8502, Acc=0.6805 | MLP Loss=1.6463, Acc=0.5885\n",
      "[Studygroup][1813] CNN Loss=0.9109, Acc=0.6807 | MLP Loss=1.5839, Acc=0.5798\n",
      "[Studygroup][1814] CNN Loss=0.9634, Acc=0.6749 | MLP Loss=1.7447, Acc=0.5846\n",
      "[Studygroup][1815] CNN Loss=0.8726, Acc=0.6791 | MLP Loss=1.6768, Acc=0.5881\n",
      "[Studygroup][1816] CNN Loss=0.8166, Acc=0.6771 | MLP Loss=1.6340, Acc=0.5918\n",
      "[Studygroup][1817] CNN Loss=0.9064, Acc=0.6800 | MLP Loss=1.6325, Acc=0.5603\n",
      "[Studygroup][1818] CNN Loss=0.7947, Acc=0.6855 | MLP Loss=1.5771, Acc=0.5903\n",
      "[Studygroup][1819] CNN Loss=0.8655, Acc=0.6796 | MLP Loss=1.6226, Acc=0.5907\n",
      "[Studygroup][1820] CNN Loss=0.8786, Acc=0.6802 | MLP Loss=1.6041, Acc=0.5926\n",
      "[Studygroup][1821] CNN Loss=0.9256, Acc=0.6673 | MLP Loss=1.6111, Acc=0.5861\n",
      "[Studygroup][1822] CNN Loss=0.9519, Acc=0.6840 | MLP Loss=1.6436, Acc=0.5880\n",
      "[Studygroup][1823] CNN Loss=0.9780, Acc=0.6792 | MLP Loss=1.6750, Acc=0.5884\n",
      "[Studygroup][1824] CNN Loss=0.9225, Acc=0.6775 | MLP Loss=1.6541, Acc=0.5909\n",
      "[Studygroup][1825] CNN Loss=0.8198, Acc=0.6833 | MLP Loss=1.6505, Acc=0.5919\n",
      "[Studygroup][1826] CNN Loss=0.8329, Acc=0.6863 | MLP Loss=1.6717, Acc=0.5917\n",
      "[Studygroup][1827] CNN Loss=0.8184, Acc=0.6824 | MLP Loss=1.6533, Acc=0.5877\n",
      "[Studygroup][1828] CNN Loss=0.8163, Acc=0.6804 | MLP Loss=1.6466, Acc=0.5943\n",
      "[Studygroup][1829] CNN Loss=0.8845, Acc=0.6895 | MLP Loss=1.5708, Acc=0.5946\n",
      "[Studygroup][1830] CNN Loss=0.8557, Acc=0.6807 | MLP Loss=1.6207, Acc=0.5947\n",
      "[Studygroup][1831] CNN Loss=0.9358, Acc=0.6828 | MLP Loss=1.6052, Acc=0.5906\n",
      "[Studygroup][1832] CNN Loss=0.8520, Acc=0.6865 | MLP Loss=1.6094, Acc=0.5882\n",
      "[Studygroup][1833] CNN Loss=1.1357, Acc=0.6832 | MLP Loss=1.5950, Acc=0.5966\n",
      "[Studygroup][1834] CNN Loss=0.8864, Acc=0.6813 | MLP Loss=1.6468, Acc=0.5982\n",
      "[Studygroup][1835] CNN Loss=0.8779, Acc=0.6843 | MLP Loss=1.6329, Acc=0.5853\n",
      "[Studygroup][1836] CNN Loss=0.9699, Acc=0.6730 | MLP Loss=1.6756, Acc=0.5956\n",
      "[Studygroup][1837] CNN Loss=0.8564, Acc=0.6839 | MLP Loss=1.6241, Acc=0.5851\n",
      "[Studygroup][1838] CNN Loss=0.9270, Acc=0.6838 | MLP Loss=1.8817, Acc=0.5801\n",
      "[Studygroup][1839] CNN Loss=0.8865, Acc=0.6781 | MLP Loss=1.6492, Acc=0.5884\n",
      "[Studygroup][1840] CNN Loss=0.8941, Acc=0.6823 | MLP Loss=1.5698, Acc=0.5954\n",
      "[Studygroup][1841] CNN Loss=0.9165, Acc=0.6794 | MLP Loss=1.5896, Acc=0.6016\n",
      "[Studygroup][1842] CNN Loss=0.8991, Acc=0.6848 | MLP Loss=1.6031, Acc=0.5898\n",
      "[Studygroup][1843] CNN Loss=0.9208, Acc=0.6851 | MLP Loss=1.5023, Acc=0.5968\n",
      "[Studygroup][1844] CNN Loss=0.8822, Acc=0.6757 | MLP Loss=1.6010, Acc=0.5917\n",
      "[Studygroup][1845] CNN Loss=0.8201, Acc=0.6869 | MLP Loss=1.5571, Acc=0.5933\n",
      "[Studygroup][1846] CNN Loss=0.8326, Acc=0.6786 | MLP Loss=1.5934, Acc=0.5896\n",
      "[Studygroup][1847] CNN Loss=0.9166, Acc=0.6740 | MLP Loss=1.6323, Acc=0.5962\n",
      "[Studygroup][1848] CNN Loss=0.8518, Acc=0.6783 | MLP Loss=1.5652, Acc=0.5967\n",
      "[Studygroup][1849] CNN Loss=0.8918, Acc=0.6820 | MLP Loss=1.6114, Acc=0.5840\n",
      "[Studygroup][1850] CNN Loss=0.8557, Acc=0.6784 | MLP Loss=1.5697, Acc=0.5944\n",
      "[Studygroup][1851] CNN Loss=0.8793, Acc=0.6823 | MLP Loss=1.5809, Acc=0.6001\n",
      "[Studygroup][1852] CNN Loss=0.8897, Acc=0.6771 | MLP Loss=1.6698, Acc=0.5946\n",
      "[Studygroup][1853] CNN Loss=0.8501, Acc=0.6740 | MLP Loss=1.6011, Acc=0.5878\n",
      "[Studygroup][1854] CNN Loss=0.8238, Acc=0.6851 | MLP Loss=1.6802, Acc=0.5896\n",
      "[Studygroup][1855] CNN Loss=0.8044, Acc=0.6859 | MLP Loss=1.7159, Acc=0.5751\n",
      "[Studygroup][1856] CNN Loss=0.8588, Acc=0.6823 | MLP Loss=1.7043, Acc=0.5932\n",
      "[Studygroup][1857] CNN Loss=0.8515, Acc=0.6796 | MLP Loss=1.6495, Acc=0.5849\n",
      "[Studygroup][1858] CNN Loss=0.8996, Acc=0.6753 | MLP Loss=1.8202, Acc=0.5771\n",
      "[Studygroup][1859] CNN Loss=0.8677, Acc=0.6766 | MLP Loss=1.6929, Acc=0.5850\n",
      "[Studygroup][1860] CNN Loss=0.9105, Acc=0.6716 | MLP Loss=1.6314, Acc=0.5934\n",
      "[Studygroup][1861] CNN Loss=0.8779, Acc=0.6743 | MLP Loss=1.5907, Acc=0.5723\n",
      "[Studygroup][1862] CNN Loss=0.9312, Acc=0.6822 | MLP Loss=1.7566, Acc=0.5936\n",
      "[Studygroup][1863] CNN Loss=0.8873, Acc=0.6776 | MLP Loss=1.6842, Acc=0.5975\n",
      "[Studygroup][1864] CNN Loss=0.8229, Acc=0.6839 | MLP Loss=1.6793, Acc=0.5969\n",
      "[Studygroup][1865] CNN Loss=0.8637, Acc=0.6826 | MLP Loss=1.6073, Acc=0.5926\n",
      "[Studygroup][1866] CNN Loss=0.9792, Acc=0.6644 | MLP Loss=1.5318, Acc=0.5974\n",
      "[Studygroup][1867] CNN Loss=0.9204, Acc=0.6825 | MLP Loss=1.5484, Acc=0.5993\n",
      "[Studygroup][1868] CNN Loss=0.8196, Acc=0.6781 | MLP Loss=1.5991, Acc=0.5982\n",
      "[Studygroup][1869] CNN Loss=0.8138, Acc=0.6819 | MLP Loss=1.5526, Acc=0.5948\n",
      "[Studygroup][1870] CNN Loss=0.8986, Acc=0.6807 | MLP Loss=1.6170, Acc=0.5881\n",
      "[Studygroup][1871] CNN Loss=0.8543, Acc=0.6788 | MLP Loss=1.6780, Acc=0.5858\n",
      "[Studygroup][1872] CNN Loss=0.7975, Acc=0.6745 | MLP Loss=1.5629, Acc=0.5850\n",
      "[Studygroup][1873] CNN Loss=0.8441, Acc=0.6820 | MLP Loss=1.6691, Acc=0.5936\n",
      "[Studygroup][1874] CNN Loss=0.9187, Acc=0.6835 | MLP Loss=1.5804, Acc=0.5911\n",
      "[Studygroup][1875] CNN Loss=0.8783, Acc=0.6753 | MLP Loss=1.5935, Acc=0.5831\n",
      "[Studygroup][1876] CNN Loss=0.8993, Acc=0.6724 | MLP Loss=1.6393, Acc=0.5865\n",
      "[Studygroup][1877] CNN Loss=0.9304, Acc=0.6794 | MLP Loss=1.5474, Acc=0.5996\n",
      "[Studygroup][1878] CNN Loss=0.9320, Acc=0.6767 | MLP Loss=1.5859, Acc=0.5925\n",
      "[Studygroup][1879] CNN Loss=0.8740, Acc=0.6759 | MLP Loss=1.6190, Acc=0.5836\n",
      "[Studygroup][1880] CNN Loss=0.9628, Acc=0.6790 | MLP Loss=1.6321, Acc=0.5960\n",
      "[Studygroup][1881] CNN Loss=0.9343, Acc=0.6769 | MLP Loss=1.6764, Acc=0.5855\n",
      "[Studygroup][1882] CNN Loss=0.9106, Acc=0.6803 | MLP Loss=1.6742, Acc=0.5944\n",
      "[Studygroup][1883] CNN Loss=0.9276, Acc=0.6816 | MLP Loss=1.6454, Acc=0.5831\n",
      "[Studygroup][1884] CNN Loss=0.8295, Acc=0.6768 | MLP Loss=1.6288, Acc=0.5880\n",
      "[Studygroup][1885] CNN Loss=0.9690, Acc=0.6824 | MLP Loss=1.6238, Acc=0.5871\n",
      "[Studygroup][1886] CNN Loss=0.9734, Acc=0.6822 | MLP Loss=1.5360, Acc=0.5953\n",
      "[Studygroup][1887] CNN Loss=0.9084, Acc=0.6865 | MLP Loss=1.5550, Acc=0.5950\n",
      "[Studygroup][1888] CNN Loss=0.8120, Acc=0.6749 | MLP Loss=1.6304, Acc=0.5927\n",
      "[Studygroup][1889] CNN Loss=0.8590, Acc=0.6815 | MLP Loss=1.6226, Acc=0.5951\n",
      "[Studygroup][1890] CNN Loss=0.8787, Acc=0.6781 | MLP Loss=1.5538, Acc=0.5983\n",
      "[Studygroup][1891] CNN Loss=0.8787, Acc=0.6714 | MLP Loss=1.6796, Acc=0.5879\n",
      "[Studygroup][1892] CNN Loss=0.9764, Acc=0.6772 | MLP Loss=1.8201, Acc=0.5782\n",
      "[Studygroup][1893] CNN Loss=0.9549, Acc=0.6764 | MLP Loss=1.7946, Acc=0.5844\n",
      "[Studygroup][1894] CNN Loss=0.9339, Acc=0.6747 | MLP Loss=1.6406, Acc=0.5899\n",
      "[Studygroup][1895] CNN Loss=1.0400, Acc=0.6675 | MLP Loss=1.7035, Acc=0.5879\n",
      "[Studygroup][1896] CNN Loss=0.9595, Acc=0.6748 | MLP Loss=1.6359, Acc=0.5962\n",
      "[Studygroup][1897] CNN Loss=0.8422, Acc=0.6753 | MLP Loss=1.5647, Acc=0.5965\n",
      "[Studygroup][1898] CNN Loss=0.8768, Acc=0.6745 | MLP Loss=1.6317, Acc=0.5950\n",
      "[Studygroup][1899] CNN Loss=0.8879, Acc=0.6782 | MLP Loss=1.5669, Acc=0.5884\n",
      "[Studygroup][1900] CNN Loss=0.8723, Acc=0.6795 | MLP Loss=1.6267, Acc=0.5936\n",
      "[Studygroup][1901] CNN Loss=0.8118, Acc=0.6831 | MLP Loss=1.7159, Acc=0.5967\n",
      "[Studygroup][1902] CNN Loss=0.8606, Acc=0.6803 | MLP Loss=1.6320, Acc=0.5907\n",
      "[Studygroup][1903] CNN Loss=0.9027, Acc=0.6709 | MLP Loss=1.6888, Acc=0.5909\n",
      "[Studygroup][1904] CNN Loss=1.0940, Acc=0.6667 | MLP Loss=1.6266, Acc=0.5849\n",
      "[Studygroup][1905] CNN Loss=0.9051, Acc=0.6823 | MLP Loss=1.6207, Acc=0.5950\n",
      "[Studygroup][1906] CNN Loss=0.8893, Acc=0.6811 | MLP Loss=1.6654, Acc=0.5939\n",
      "[Studygroup][1907] CNN Loss=0.8695, Acc=0.6802 | MLP Loss=1.7929, Acc=0.5829\n",
      "[Studygroup][1908] CNN Loss=1.1133, Acc=0.6738 | MLP Loss=1.7943, Acc=0.5854\n",
      "[Studygroup][1909] CNN Loss=0.9279, Acc=0.6703 | MLP Loss=1.6459, Acc=0.5918\n",
      "[Studygroup][1910] CNN Loss=0.8746, Acc=0.6810 | MLP Loss=1.6367, Acc=0.5856\n",
      "[Studygroup][1911] CNN Loss=0.9974, Acc=0.6782 | MLP Loss=1.5933, Acc=0.5964\n",
      "[Studygroup][1912] CNN Loss=0.8329, Acc=0.6813 | MLP Loss=1.6498, Acc=0.5879\n",
      "[Studygroup][1913] CNN Loss=0.9129, Acc=0.6752 | MLP Loss=1.6586, Acc=0.5977\n",
      "[Studygroup][1914] CNN Loss=0.9157, Acc=0.6788 | MLP Loss=1.6705, Acc=0.5895\n",
      "[Studygroup][1915] CNN Loss=0.8636, Acc=0.6728 | MLP Loss=1.6833, Acc=0.5903\n",
      "[Studygroup][1916] CNN Loss=0.8971, Acc=0.6747 | MLP Loss=1.6489, Acc=0.5971\n",
      "[Studygroup][1917] CNN Loss=0.8928, Acc=0.6783 | MLP Loss=1.6059, Acc=0.5862\n",
      "[Studygroup][1918] CNN Loss=0.8373, Acc=0.6798 | MLP Loss=1.6210, Acc=0.5843\n",
      "[Studygroup][1919] CNN Loss=0.8937, Acc=0.6859 | MLP Loss=1.6654, Acc=0.5909\n",
      "[Studygroup][1920] CNN Loss=0.8645, Acc=0.6776 | MLP Loss=1.5716, Acc=0.5903\n",
      "[Studygroup][1921] CNN Loss=0.8699, Acc=0.6791 | MLP Loss=1.6023, Acc=0.5845\n",
      "[Studygroup][1922] CNN Loss=0.8742, Acc=0.6775 | MLP Loss=1.7248, Acc=0.5960\n",
      "[Studygroup][1923] CNN Loss=0.8630, Acc=0.6760 | MLP Loss=1.6259, Acc=0.5936\n",
      "[Studygroup][1924] CNN Loss=0.8397, Acc=0.6840 | MLP Loss=1.6561, Acc=0.5963\n",
      "[Studygroup][1925] CNN Loss=0.9268, Acc=0.6827 | MLP Loss=1.7020, Acc=0.5829\n",
      "[Studygroup][1926] CNN Loss=0.9161, Acc=0.6756 | MLP Loss=1.6417, Acc=0.5978\n",
      "[Studygroup][1927] CNN Loss=0.8991, Acc=0.6788 | MLP Loss=1.6175, Acc=0.5860\n",
      "[Studygroup][1928] CNN Loss=0.9514, Acc=0.6777 | MLP Loss=1.6295, Acc=0.5793\n",
      "[Studygroup][1929] CNN Loss=0.8070, Acc=0.6840 | MLP Loss=1.6053, Acc=0.5920\n",
      "[Studygroup][1930] CNN Loss=0.9061, Acc=0.6789 | MLP Loss=1.6227, Acc=0.5918\n",
      "[Studygroup][1931] CNN Loss=0.8710, Acc=0.6770 | MLP Loss=1.5895, Acc=0.5879\n",
      "[Studygroup][1932] CNN Loss=0.8699, Acc=0.6698 | MLP Loss=1.6492, Acc=0.5968\n",
      "[Studygroup][1933] CNN Loss=1.0796, Acc=0.6670 | MLP Loss=1.7048, Acc=0.5883\n",
      "[Studygroup][1934] CNN Loss=0.8589, Acc=0.6734 | MLP Loss=1.6446, Acc=0.5881\n",
      "[Studygroup][1935] CNN Loss=0.9515, Acc=0.6802 | MLP Loss=1.6509, Acc=0.5944\n",
      "[Studygroup][1936] CNN Loss=0.8221, Acc=0.6773 | MLP Loss=1.6225, Acc=0.5931\n",
      "[Studygroup][1937] CNN Loss=0.8451, Acc=0.6784 | MLP Loss=1.7898, Acc=0.5775\n",
      "[Studygroup][1938] CNN Loss=1.0150, Acc=0.6771 | MLP Loss=1.7794, Acc=0.5860\n",
      "[Studygroup][1939] CNN Loss=0.8349, Acc=0.6800 | MLP Loss=1.6064, Acc=0.5990\n",
      "[Studygroup][1940] CNN Loss=0.8167, Acc=0.6784 | MLP Loss=1.6855, Acc=0.5940\n",
      "[Studygroup][1941] CNN Loss=0.8608, Acc=0.6752 | MLP Loss=1.6546, Acc=0.5967\n",
      "[Studygroup][1942] CNN Loss=0.8011, Acc=0.6721 | MLP Loss=1.6351, Acc=0.5918\n",
      "[Studygroup][1943] CNN Loss=0.9776, Acc=0.6834 | MLP Loss=1.8074, Acc=0.5888\n",
      "[Studygroup][1944] CNN Loss=0.9752, Acc=0.6769 | MLP Loss=1.6635, Acc=0.5963\n",
      "[Studygroup][1945] CNN Loss=0.8963, Acc=0.6787 | MLP Loss=1.6615, Acc=0.5942\n",
      "[Studygroup][1946] CNN Loss=0.8041, Acc=0.6822 | MLP Loss=1.6214, Acc=0.5966\n",
      "[Studygroup][1947] CNN Loss=0.9753, Acc=0.6759 | MLP Loss=1.6722, Acc=0.5909\n",
      "[Studygroup][1948] CNN Loss=1.1343, Acc=0.6748 | MLP Loss=1.7495, Acc=0.5835\n",
      "[Studygroup][1949] CNN Loss=0.9155, Acc=0.6824 | MLP Loss=1.7326, Acc=0.5958\n",
      "[Studygroup][1950] CNN Loss=0.9429, Acc=0.6766 | MLP Loss=1.6524, Acc=0.5907\n",
      "[Studygroup][1951] CNN Loss=0.8339, Acc=0.6759 | MLP Loss=1.6196, Acc=0.5914\n",
      "[Studygroup][1952] CNN Loss=0.9061, Acc=0.6783 | MLP Loss=1.7124, Acc=0.5806\n",
      "[Studygroup][1953] CNN Loss=0.9573, Acc=0.6735 | MLP Loss=1.7454, Acc=0.5819\n",
      "[Studygroup][1954] CNN Loss=0.8739, Acc=0.6775 | MLP Loss=1.6284, Acc=0.5936\n",
      "[Studygroup][1955] CNN Loss=0.8482, Acc=0.6808 | MLP Loss=1.5487, Acc=0.5993\n",
      "[Studygroup][1956] CNN Loss=0.9185, Acc=0.6731 | MLP Loss=1.5638, Acc=0.5964\n",
      "[Studygroup][1957] CNN Loss=1.0250, Acc=0.6744 | MLP Loss=1.6002, Acc=0.5933\n",
      "[Studygroup][1958] CNN Loss=0.8611, Acc=0.6827 | MLP Loss=1.6526, Acc=0.5906\n",
      "[Studygroup][1959] CNN Loss=1.0015, Acc=0.6745 | MLP Loss=1.6355, Acc=0.5908\n",
      "[Studygroup][1960] CNN Loss=0.8212, Acc=0.6854 | MLP Loss=1.6609, Acc=0.5952\n",
      "[Studygroup][1961] CNN Loss=0.8108, Acc=0.6779 | MLP Loss=1.6304, Acc=0.5906\n",
      "[Studygroup][1962] CNN Loss=0.8452, Acc=0.6739 | MLP Loss=1.5983, Acc=0.5930\n",
      "[Studygroup][1963] CNN Loss=0.8314, Acc=0.6823 | MLP Loss=1.6394, Acc=0.5978\n",
      "[Studygroup][1964] CNN Loss=0.9015, Acc=0.6745 | MLP Loss=1.6651, Acc=0.5961\n",
      "[Studygroup][1965] CNN Loss=0.8699, Acc=0.6769 | MLP Loss=1.5225, Acc=0.6020\n",
      "[Studygroup][1966] CNN Loss=0.8900, Acc=0.6737 | MLP Loss=1.5631, Acc=0.6023\n",
      "[Studygroup][1967] CNN Loss=0.7776, Acc=0.6799 | MLP Loss=1.6194, Acc=0.5932\n",
      "[Studygroup][1968] CNN Loss=0.8521, Acc=0.6777 | MLP Loss=1.6155, Acc=0.5886\n",
      "[Studygroup][1969] CNN Loss=0.7738, Acc=0.6870 | MLP Loss=1.7434, Acc=0.5801\n",
      "[Studygroup][1970] CNN Loss=0.9160, Acc=0.6788 | MLP Loss=1.6245, Acc=0.5889\n",
      "[Studygroup][1971] CNN Loss=0.9332, Acc=0.6763 | MLP Loss=1.5729, Acc=0.6001\n",
      "[Studygroup][1972] CNN Loss=0.8850, Acc=0.6667 | MLP Loss=1.5604, Acc=0.5925\n",
      "[Studygroup][1973] CNN Loss=0.9492, Acc=0.6774 | MLP Loss=1.6087, Acc=0.5805\n",
      "[Studygroup][1974] CNN Loss=0.8487, Acc=0.6653 | MLP Loss=1.5942, Acc=0.5868\n",
      "[Studygroup][1975] CNN Loss=0.9100, Acc=0.6828 | MLP Loss=1.5909, Acc=0.6041\n",
      "[Studygroup][1976] CNN Loss=0.9217, Acc=0.6728 | MLP Loss=1.6210, Acc=0.5823\n",
      "[Studygroup][1977] CNN Loss=0.8185, Acc=0.6746 | MLP Loss=1.7581, Acc=0.5990\n",
      "[Studygroup][1978] CNN Loss=0.9001, Acc=0.6798 | MLP Loss=1.6538, Acc=0.5968\n",
      "[Studygroup][1979] CNN Loss=0.8981, Acc=0.6782 | MLP Loss=1.5426, Acc=0.5991\n",
      "[Studygroup][1980] CNN Loss=0.8900, Acc=0.6758 | MLP Loss=1.6613, Acc=0.5999\n",
      "[Studygroup][1981] CNN Loss=0.9095, Acc=0.6746 | MLP Loss=1.6441, Acc=0.5916\n",
      "[Studygroup][1982] CNN Loss=0.9274, Acc=0.6773 | MLP Loss=1.5768, Acc=0.5949\n",
      "[Studygroup][1983] CNN Loss=0.9008, Acc=0.6838 | MLP Loss=1.6924, Acc=0.5901\n",
      "[Studygroup][1984] CNN Loss=0.9077, Acc=0.6724 | MLP Loss=1.5807, Acc=0.5931\n",
      "[Studygroup][1985] CNN Loss=0.8438, Acc=0.6805 | MLP Loss=1.5615, Acc=0.5930\n",
      "[Studygroup][1986] CNN Loss=0.8359, Acc=0.6774 | MLP Loss=1.5595, Acc=0.5836\n",
      "[Studygroup][1987] CNN Loss=0.8708, Acc=0.6749 | MLP Loss=1.6743, Acc=0.5799\n",
      "[Studygroup][1988] CNN Loss=0.8315, Acc=0.6725 | MLP Loss=1.5491, Acc=0.5878\n",
      "[Studygroup][1989] CNN Loss=0.9115, Acc=0.6788 | MLP Loss=1.5847, Acc=0.5893\n",
      "[Studygroup][1990] CNN Loss=0.8822, Acc=0.6800 | MLP Loss=1.5447, Acc=0.5935\n",
      "[Studygroup][1991] CNN Loss=0.7548, Acc=0.6869 | MLP Loss=1.5665, Acc=0.5960\n",
      "[Studygroup][1992] CNN Loss=0.8896, Acc=0.6815 | MLP Loss=1.6667, Acc=0.5969\n",
      "[Studygroup][1993] CNN Loss=0.7558, Acc=0.6821 | MLP Loss=1.6579, Acc=0.5862\n",
      "[Studygroup][1994] CNN Loss=0.8297, Acc=0.6807 | MLP Loss=1.6996, Acc=0.5925\n",
      "[Studygroup][1995] CNN Loss=0.8074, Acc=0.6702 | MLP Loss=1.5914, Acc=0.5880\n",
      "[Studygroup][1996] CNN Loss=0.9173, Acc=0.6698 | MLP Loss=1.6084, Acc=0.6010\n",
      "[Studygroup][1997] CNN Loss=1.0161, Acc=0.6706 | MLP Loss=1.6433, Acc=0.5956\n",
      "[Studygroup][1998] CNN Loss=0.8744, Acc=0.6743 | MLP Loss=1.6241, Acc=0.5808\n",
      "[Studygroup][1999] CNN Loss=0.8699, Acc=0.6777 | MLP Loss=1.6950, Acc=0.6007\n"
     ]
    }
   ],
   "source": [
    "cnn_id1 = CNN_CIFAR().to(device)\n",
    "cnn_id1.load_state_dict(cnn_init_state)\n",
    "cnn_id2 = CNN_CIFAR().to(device)\n",
    "cnn_id2.load_state_dict(cnn_init_state)\n",
    "\n",
    "opt_cnn_id1 = torch.optim.Adam(cnn_id1.parameters(), lr=1e-3)\n",
    "opt_cnn_id2 = torch.optim.Adam(cnn_id2.parameters(), lr=1e-3)\n",
    "\n",
    "train_studygroup(\n",
    "    cnn_id1,\n",
    "    cnn_id2,\n",
    "    opt_cnn_id1,\n",
    "    opt_cnn_id2,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    epochs,\n",
    "    logs[\"individual_cnn1\"],\n",
    "    logs[\"individual_cnn2\"],\n",
    "    T=2.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b923855-9b88-4e3e-bb28-7c9a34c5e68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44bd7002-2d37-47f3-a09c-4e9fd9f6b81c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa7e7029dcf41f89dfc5b08e7ff3d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Studygroup][00] CNN Loss=2.2355, Acc=0.3047 | MLP Loss=2.3225, Acc=0.1517\n",
      "[Studygroup][01] CNN Loss=2.1588, Acc=0.3265 | MLP Loss=2.3237, Acc=0.1737\n",
      "[Studygroup][02] CNN Loss=2.0872, Acc=0.3771 | MLP Loss=2.3209, Acc=0.1813\n",
      "[Studygroup][03] CNN Loss=2.0331, Acc=0.4177 | MLP Loss=2.2904, Acc=0.2197\n",
      "[Studygroup][04] CNN Loss=2.0037, Acc=0.4272 | MLP Loss=2.2989, Acc=0.2402\n",
      "[Studygroup][05] CNN Loss=1.9726, Acc=0.4460 | MLP Loss=2.2842, Acc=0.2358\n",
      "[Studygroup][06] CNN Loss=1.9538, Acc=0.4307 | MLP Loss=2.2853, Acc=0.2357\n",
      "[Studygroup][07] CNN Loss=1.9539, Acc=0.4573 | MLP Loss=2.2411, Acc=0.2738\n",
      "[Studygroup][08] CNN Loss=1.8953, Acc=0.4784 | MLP Loss=2.2271, Acc=0.2687\n",
      "[Studygroup][09] CNN Loss=1.9072, Acc=0.4771 | MLP Loss=2.2585, Acc=0.2656\n",
      "[Studygroup][10] CNN Loss=1.8909, Acc=0.4932 | MLP Loss=2.2296, Acc=0.2464\n",
      "[Studygroup][11] CNN Loss=1.8503, Acc=0.4679 | MLP Loss=2.1946, Acc=0.2421\n",
      "[Studygroup][12] CNN Loss=1.8781, Acc=0.4757 | MLP Loss=2.2229, Acc=0.2639\n",
      "[Studygroup][13] CNN Loss=1.8610, Acc=0.5217 | MLP Loss=2.2012, Acc=0.2545\n",
      "[Studygroup][14] CNN Loss=1.8455, Acc=0.4940 | MLP Loss=2.1551, Acc=0.2464\n",
      "[Studygroup][15] CNN Loss=1.7701, Acc=0.5241 | MLP Loss=2.1710, Acc=0.3004\n",
      "[Studygroup][16] CNN Loss=1.7985, Acc=0.4974 | MLP Loss=2.1611, Acc=0.2957\n",
      "[Studygroup][17] CNN Loss=1.7703, Acc=0.5289 | MLP Loss=2.1684, Acc=0.2916\n",
      "[Studygroup][18] CNN Loss=1.7370, Acc=0.5342 | MLP Loss=2.1847, Acc=0.3042\n",
      "[Studygroup][19] CNN Loss=1.7731, Acc=0.5446 | MLP Loss=2.1628, Acc=0.2993\n",
      "[Studygroup][20] CNN Loss=1.7365, Acc=0.5544 | MLP Loss=2.1304, Acc=0.3129\n",
      "[Studygroup][21] CNN Loss=1.7467, Acc=0.5307 | MLP Loss=2.1614, Acc=0.3035\n",
      "[Studygroup][22] CNN Loss=1.7338, Acc=0.5517 | MLP Loss=2.1476, Acc=0.3224\n",
      "[Studygroup][23] CNN Loss=1.6996, Acc=0.5456 | MLP Loss=2.1730, Acc=0.3058\n",
      "[Studygroup][24] CNN Loss=1.7224, Acc=0.5310 | MLP Loss=2.1883, Acc=0.2893\n",
      "[Studygroup][25] CNN Loss=1.7046, Acc=0.5373 | MLP Loss=2.1591, Acc=0.3187\n",
      "[Studygroup][26] CNN Loss=1.6783, Acc=0.5653 | MLP Loss=2.1219, Acc=0.3221\n",
      "[Studygroup][27] CNN Loss=1.6800, Acc=0.5349 | MLP Loss=2.0958, Acc=0.3193\n",
      "[Studygroup][28] CNN Loss=1.6369, Acc=0.5684 | MLP Loss=2.0890, Acc=0.3320\n",
      "[Studygroup][29] CNN Loss=1.6096, Acc=0.5518 | MLP Loss=2.0934, Acc=0.3144\n",
      "[Studygroup][30] CNN Loss=1.5677, Acc=0.5518 | MLP Loss=2.0871, Acc=0.3065\n",
      "[Studygroup][31] CNN Loss=1.6129, Acc=0.5759 | MLP Loss=2.1145, Acc=0.3252\n",
      "[Studygroup][32] CNN Loss=1.5855, Acc=0.5815 | MLP Loss=2.1041, Acc=0.3349\n",
      "[Studygroup][33] CNN Loss=1.5573, Acc=0.5541 | MLP Loss=2.0966, Acc=0.3293\n",
      "[Studygroup][34] CNN Loss=1.5650, Acc=0.5702 | MLP Loss=2.0645, Acc=0.3244\n",
      "[Studygroup][35] CNN Loss=1.5654, Acc=0.5868 | MLP Loss=2.0777, Acc=0.3117\n",
      "[Studygroup][36] CNN Loss=1.5373, Acc=0.5502 | MLP Loss=2.0637, Acc=0.3154\n",
      "[Studygroup][37] CNN Loss=1.6108, Acc=0.5878 | MLP Loss=2.1598, Acc=0.3570\n",
      "[Studygroup][38] CNN Loss=1.5318, Acc=0.5605 | MLP Loss=2.0491, Acc=0.3337\n",
      "[Studygroup][39] CNN Loss=1.5375, Acc=0.5667 | MLP Loss=2.0913, Acc=0.3481\n",
      "[Studygroup][40] CNN Loss=1.5249, Acc=0.5697 | MLP Loss=2.0755, Acc=0.3507\n",
      "[Studygroup][41] CNN Loss=1.4904, Acc=0.5910 | MLP Loss=2.0666, Acc=0.3454\n",
      "[Studygroup][42] CNN Loss=1.5093, Acc=0.5856 | MLP Loss=2.0668, Acc=0.3256\n",
      "[Studygroup][43] CNN Loss=1.5128, Acc=0.5858 | MLP Loss=2.0743, Acc=0.3352\n",
      "[Studygroup][44] CNN Loss=1.5019, Acc=0.5892 | MLP Loss=2.0869, Acc=0.3340\n",
      "[Studygroup][45] CNN Loss=1.5414, Acc=0.5912 | MLP Loss=2.0993, Acc=0.3415\n",
      "[Studygroup][46] CNN Loss=1.4392, Acc=0.5974 | MLP Loss=2.0346, Acc=0.3516\n",
      "[Studygroup][47] CNN Loss=1.5095, Acc=0.5873 | MLP Loss=2.0754, Acc=0.3508\n",
      "[Studygroup][48] CNN Loss=1.4889, Acc=0.5966 | MLP Loss=2.0323, Acc=0.3777\n",
      "[Studygroup][49] CNN Loss=1.4581, Acc=0.5706 | MLP Loss=2.0320, Acc=0.3565\n",
      "[Studygroup][50] CNN Loss=1.4846, Acc=0.5886 | MLP Loss=2.0485, Acc=0.3248\n",
      "[Studygroup][51] CNN Loss=1.4606, Acc=0.6039 | MLP Loss=2.0530, Acc=0.3561\n",
      "[Studygroup][52] CNN Loss=1.4407, Acc=0.5986 | MLP Loss=2.0493, Acc=0.3373\n",
      "[Studygroup][53] CNN Loss=1.4418, Acc=0.6116 | MLP Loss=2.0329, Acc=0.3713\n",
      "[Studygroup][54] CNN Loss=1.4021, Acc=0.6106 | MLP Loss=2.0113, Acc=0.3613\n",
      "[Studygroup][55] CNN Loss=1.4410, Acc=0.6173 | MLP Loss=2.0549, Acc=0.3571\n",
      "[Studygroup][56] CNN Loss=1.4331, Acc=0.5964 | MLP Loss=2.0362, Acc=0.3797\n",
      "[Studygroup][57] CNN Loss=1.4384, Acc=0.6132 | MLP Loss=1.9963, Acc=0.3697\n",
      "[Studygroup][58] CNN Loss=1.4181, Acc=0.6073 | MLP Loss=2.0278, Acc=0.3479\n",
      "[Studygroup][59] CNN Loss=1.4135, Acc=0.6138 | MLP Loss=2.0415, Acc=0.3969\n",
      "[Studygroup][60] CNN Loss=1.4164, Acc=0.6126 | MLP Loss=2.0447, Acc=0.3880\n",
      "[Studygroup][61] CNN Loss=1.3986, Acc=0.6111 | MLP Loss=2.0412, Acc=0.3784\n",
      "[Studygroup][62] CNN Loss=1.3884, Acc=0.6112 | MLP Loss=2.0040, Acc=0.4121\n",
      "[Studygroup][63] CNN Loss=1.3926, Acc=0.6187 | MLP Loss=1.9756, Acc=0.3985\n",
      "[Studygroup][64] CNN Loss=1.3960, Acc=0.6080 | MLP Loss=1.9982, Acc=0.3585\n",
      "[Studygroup][65] CNN Loss=1.4072, Acc=0.6155 | MLP Loss=2.0194, Acc=0.3656\n",
      "[Studygroup][66] CNN Loss=1.4092, Acc=0.6143 | MLP Loss=2.0521, Acc=0.3811\n",
      "[Studygroup][67] CNN Loss=1.3938, Acc=0.6102 | MLP Loss=2.0068, Acc=0.4051\n",
      "[Studygroup][68] CNN Loss=1.3644, Acc=0.6188 | MLP Loss=1.9636, Acc=0.4131\n",
      "[Studygroup][69] CNN Loss=1.3226, Acc=0.6074 | MLP Loss=2.0095, Acc=0.3978\n",
      "[Studygroup][70] CNN Loss=1.3613, Acc=0.6061 | MLP Loss=1.9991, Acc=0.4074\n",
      "[Studygroup][71] CNN Loss=1.3889, Acc=0.5977 | MLP Loss=2.0063, Acc=0.4089\n",
      "[Studygroup][72] CNN Loss=1.3944, Acc=0.6170 | MLP Loss=2.0111, Acc=0.4069\n",
      "[Studygroup][73] CNN Loss=1.3730, Acc=0.6241 | MLP Loss=2.0140, Acc=0.3965\n",
      "[Studygroup][74] CNN Loss=1.3953, Acc=0.6160 | MLP Loss=1.9924, Acc=0.4014\n",
      "[Studygroup][75] CNN Loss=1.3887, Acc=0.6020 | MLP Loss=1.9713, Acc=0.3791\n",
      "[Studygroup][76] CNN Loss=1.3614, Acc=0.6202 | MLP Loss=2.0219, Acc=0.3940\n",
      "[Studygroup][77] CNN Loss=1.3528, Acc=0.6250 | MLP Loss=2.0324, Acc=0.4035\n",
      "[Studygroup][78] CNN Loss=1.3956, Acc=0.6129 | MLP Loss=1.9925, Acc=0.3980\n",
      "[Studygroup][79] CNN Loss=1.3240, Acc=0.6297 | MLP Loss=1.9665, Acc=0.4066\n",
      "[Studygroup][80] CNN Loss=1.3317, Acc=0.6138 | MLP Loss=1.9301, Acc=0.4232\n",
      "[Studygroup][81] CNN Loss=1.3350, Acc=0.6250 | MLP Loss=1.9490, Acc=0.4219\n",
      "[Studygroup][82] CNN Loss=1.3335, Acc=0.6044 | MLP Loss=1.9621, Acc=0.4075\n",
      "[Studygroup][83] CNN Loss=1.2946, Acc=0.6049 | MLP Loss=1.9782, Acc=0.4053\n",
      "[Studygroup][84] CNN Loss=1.3393, Acc=0.6295 | MLP Loss=1.9962, Acc=0.4138\n",
      "[Studygroup][85] CNN Loss=1.3314, Acc=0.6127 | MLP Loss=2.0121, Acc=0.4018\n",
      "[Studygroup][86] CNN Loss=1.3444, Acc=0.6228 | MLP Loss=1.9398, Acc=0.4280\n",
      "[Studygroup][87] CNN Loss=1.3013, Acc=0.6299 | MLP Loss=1.9829, Acc=0.4164\n",
      "[Studygroup][88] CNN Loss=1.2979, Acc=0.6331 | MLP Loss=1.9706, Acc=0.4253\n",
      "[Studygroup][89] CNN Loss=1.3198, Acc=0.6206 | MLP Loss=1.9517, Acc=0.4123\n",
      "[Studygroup][90] CNN Loss=1.3424, Acc=0.6294 | MLP Loss=1.9371, Acc=0.4176\n",
      "[Studygroup][91] CNN Loss=1.2840, Acc=0.6270 | MLP Loss=1.9535, Acc=0.4127\n",
      "[Studygroup][92] CNN Loss=1.3075, Acc=0.6164 | MLP Loss=1.9345, Acc=0.4311\n",
      "[Studygroup][93] CNN Loss=1.2667, Acc=0.6341 | MLP Loss=1.9774, Acc=0.4349\n",
      "[Studygroup][94] CNN Loss=1.2728, Acc=0.6229 | MLP Loss=1.9727, Acc=0.4268\n",
      "[Studygroup][95] CNN Loss=1.3062, Acc=0.6274 | MLP Loss=1.9829, Acc=0.4223\n",
      "[Studygroup][96] CNN Loss=1.3012, Acc=0.6152 | MLP Loss=1.9274, Acc=0.4199\n",
      "[Studygroup][97] CNN Loss=1.2690, Acc=0.6304 | MLP Loss=1.9556, Acc=0.3977\n",
      "[Studygroup][98] CNN Loss=1.2970, Acc=0.6273 | MLP Loss=1.9927, Acc=0.4079\n",
      "[Studygroup][99] CNN Loss=1.2615, Acc=0.6291 | MLP Loss=1.9703, Acc=0.4000\n",
      "[Studygroup][100] CNN Loss=1.3184, Acc=0.6295 | MLP Loss=1.9906, Acc=0.4139\n",
      "[Studygroup][101] CNN Loss=1.3074, Acc=0.6230 | MLP Loss=1.9884, Acc=0.4135\n",
      "[Studygroup][102] CNN Loss=1.2444, Acc=0.6199 | MLP Loss=1.9562, Acc=0.4241\n",
      "[Studygroup][103] CNN Loss=1.2688, Acc=0.6330 | MLP Loss=1.8931, Acc=0.4332\n",
      "[Studygroup][104] CNN Loss=1.2653, Acc=0.6317 | MLP Loss=1.9417, Acc=0.4335\n",
      "[Studygroup][105] CNN Loss=1.2966, Acc=0.6270 | MLP Loss=1.9134, Acc=0.4236\n",
      "[Studygroup][106] CNN Loss=1.2552, Acc=0.6150 | MLP Loss=1.9381, Acc=0.4316\n",
      "[Studygroup][107] CNN Loss=1.2543, Acc=0.6351 | MLP Loss=1.9820, Acc=0.4391\n",
      "[Studygroup][108] CNN Loss=1.2586, Acc=0.6316 | MLP Loss=1.9945, Acc=0.4263\n",
      "[Studygroup][109] CNN Loss=1.2539, Acc=0.6283 | MLP Loss=1.9374, Acc=0.4414\n",
      "[Studygroup][110] CNN Loss=1.2314, Acc=0.6393 | MLP Loss=1.9184, Acc=0.4351\n",
      "[Studygroup][111] CNN Loss=1.2400, Acc=0.6469 | MLP Loss=1.9585, Acc=0.4373\n",
      "[Studygroup][112] CNN Loss=1.2297, Acc=0.6246 | MLP Loss=1.9606, Acc=0.4529\n",
      "[Studygroup][113] CNN Loss=1.2293, Acc=0.6297 | MLP Loss=1.9459, Acc=0.4412\n",
      "[Studygroup][114] CNN Loss=1.2577, Acc=0.6214 | MLP Loss=1.9704, Acc=0.4464\n",
      "[Studygroup][115] CNN Loss=1.2214, Acc=0.6448 | MLP Loss=1.9215, Acc=0.4415\n",
      "[Studygroup][116] CNN Loss=1.2449, Acc=0.6338 | MLP Loss=1.9499, Acc=0.4490\n",
      "[Studygroup][117] CNN Loss=1.1943, Acc=0.6297 | MLP Loss=1.8791, Acc=0.4102\n",
      "[Studygroup][118] CNN Loss=1.1982, Acc=0.6330 | MLP Loss=1.9406, Acc=0.4191\n",
      "[Studygroup][119] CNN Loss=1.2625, Acc=0.6404 | MLP Loss=1.9669, Acc=0.4360\n",
      "[Studygroup][120] CNN Loss=1.2143, Acc=0.6288 | MLP Loss=1.9116, Acc=0.4268\n",
      "[Studygroup][121] CNN Loss=1.2014, Acc=0.6270 | MLP Loss=1.9514, Acc=0.4362\n",
      "[Studygroup][122] CNN Loss=1.2463, Acc=0.6335 | MLP Loss=2.0215, Acc=0.4330\n",
      "[Studygroup][123] CNN Loss=1.2604, Acc=0.6278 | MLP Loss=1.9311, Acc=0.4487\n",
      "[Studygroup][124] CNN Loss=1.2686, Acc=0.6391 | MLP Loss=1.9408, Acc=0.4424\n",
      "[Studygroup][125] CNN Loss=1.2455, Acc=0.6324 | MLP Loss=1.9481, Acc=0.4400\n",
      "[Studygroup][126] CNN Loss=1.1775, Acc=0.6434 | MLP Loss=1.9508, Acc=0.4518\n",
      "[Studygroup][127] CNN Loss=1.2569, Acc=0.6416 | MLP Loss=1.9290, Acc=0.4551\n",
      "[Studygroup][128] CNN Loss=1.1812, Acc=0.6368 | MLP Loss=1.9220, Acc=0.4554\n",
      "[Studygroup][129] CNN Loss=1.2564, Acc=0.6419 | MLP Loss=1.9857, Acc=0.4599\n",
      "[Studygroup][130] CNN Loss=1.1907, Acc=0.6472 | MLP Loss=1.9329, Acc=0.4411\n",
      "[Studygroup][131] CNN Loss=1.2053, Acc=0.6381 | MLP Loss=1.9324, Acc=0.4542\n",
      "[Studygroup][132] CNN Loss=1.2003, Acc=0.6186 | MLP Loss=1.9753, Acc=0.4250\n",
      "[Studygroup][133] CNN Loss=1.2130, Acc=0.6444 | MLP Loss=1.9181, Acc=0.4577\n",
      "[Studygroup][134] CNN Loss=1.2635, Acc=0.6493 | MLP Loss=1.9776, Acc=0.4481\n",
      "[Studygroup][135] CNN Loss=1.1820, Acc=0.6334 | MLP Loss=1.9139, Acc=0.4364\n",
      "[Studygroup][136] CNN Loss=1.2501, Acc=0.6451 | MLP Loss=1.9241, Acc=0.4473\n",
      "[Studygroup][137] CNN Loss=1.2174, Acc=0.6470 | MLP Loss=1.9281, Acc=0.4170\n",
      "[Studygroup][138] CNN Loss=1.2839, Acc=0.6356 | MLP Loss=1.9526, Acc=0.4446\n",
      "[Studygroup][139] CNN Loss=1.1918, Acc=0.6382 | MLP Loss=1.9054, Acc=0.4571\n",
      "[Studygroup][140] CNN Loss=1.1965, Acc=0.6416 | MLP Loss=1.9127, Acc=0.4593\n",
      "[Studygroup][141] CNN Loss=1.2209, Acc=0.6393 | MLP Loss=1.9409, Acc=0.4545\n",
      "[Studygroup][142] CNN Loss=1.2142, Acc=0.6449 | MLP Loss=1.9420, Acc=0.4444\n",
      "[Studygroup][143] CNN Loss=1.1828, Acc=0.6416 | MLP Loss=1.9279, Acc=0.4643\n",
      "[Studygroup][144] CNN Loss=1.1938, Acc=0.6502 | MLP Loss=1.9418, Acc=0.4411\n",
      "[Studygroup][145] CNN Loss=1.1757, Acc=0.6412 | MLP Loss=1.9311, Acc=0.4531\n",
      "[Studygroup][146] CNN Loss=1.2162, Acc=0.6407 | MLP Loss=1.9459, Acc=0.4241\n",
      "[Studygroup][147] CNN Loss=1.1668, Acc=0.6380 | MLP Loss=1.9018, Acc=0.4611\n",
      "[Studygroup][148] CNN Loss=1.1568, Acc=0.6465 | MLP Loss=1.9073, Acc=0.4656\n",
      "[Studygroup][149] CNN Loss=1.1882, Acc=0.6389 | MLP Loss=1.9326, Acc=0.4652\n",
      "[Studygroup][150] CNN Loss=1.1805, Acc=0.6515 | MLP Loss=1.9557, Acc=0.4408\n",
      "[Studygroup][151] CNN Loss=1.1890, Acc=0.6479 | MLP Loss=1.9456, Acc=0.4349\n",
      "[Studygroup][152] CNN Loss=1.1460, Acc=0.6520 | MLP Loss=1.9504, Acc=0.4510\n",
      "[Studygroup][153] CNN Loss=1.1927, Acc=0.6408 | MLP Loss=1.9303, Acc=0.4642\n",
      "[Studygroup][154] CNN Loss=1.1661, Acc=0.6460 | MLP Loss=1.9057, Acc=0.4592\n",
      "[Studygroup][155] CNN Loss=1.1783, Acc=0.6380 | MLP Loss=1.9422, Acc=0.4538\n",
      "[Studygroup][156] CNN Loss=1.1367, Acc=0.6513 | MLP Loss=1.9392, Acc=0.4694\n",
      "[Studygroup][157] CNN Loss=1.1967, Acc=0.6453 | MLP Loss=2.0141, Acc=0.4692\n",
      "[Studygroup][158] CNN Loss=1.1590, Acc=0.6416 | MLP Loss=2.0170, Acc=0.4698\n",
      "[Studygroup][159] CNN Loss=1.2042, Acc=0.6363 | MLP Loss=1.9412, Acc=0.4468\n",
      "[Studygroup][160] CNN Loss=1.1746, Acc=0.6395 | MLP Loss=1.9372, Acc=0.4594\n",
      "[Studygroup][161] CNN Loss=1.1731, Acc=0.6430 | MLP Loss=1.9801, Acc=0.4577\n",
      "[Studygroup][162] CNN Loss=1.1718, Acc=0.6405 | MLP Loss=1.9230, Acc=0.4656\n",
      "[Studygroup][163] CNN Loss=1.1376, Acc=0.6463 | MLP Loss=1.9275, Acc=0.4717\n",
      "[Studygroup][164] CNN Loss=1.2471, Acc=0.6386 | MLP Loss=1.9590, Acc=0.4770\n",
      "[Studygroup][165] CNN Loss=1.1938, Acc=0.6476 | MLP Loss=1.9384, Acc=0.4550\n",
      "[Studygroup][166] CNN Loss=1.1774, Acc=0.6498 | MLP Loss=1.9847, Acc=0.4669\n",
      "[Studygroup][167] CNN Loss=1.1371, Acc=0.6431 | MLP Loss=1.9364, Acc=0.4436\n",
      "[Studygroup][168] CNN Loss=1.2324, Acc=0.6352 | MLP Loss=1.9041, Acc=0.4575\n",
      "[Studygroup][169] CNN Loss=1.2316, Acc=0.6387 | MLP Loss=1.8507, Acc=0.4797\n",
      "[Studygroup][170] CNN Loss=1.1554, Acc=0.6539 | MLP Loss=1.8856, Acc=0.4516\n",
      "[Studygroup][171] CNN Loss=1.1916, Acc=0.6470 | MLP Loss=1.8696, Acc=0.4587\n",
      "[Studygroup][172] CNN Loss=1.1465, Acc=0.6409 | MLP Loss=1.8880, Acc=0.4747\n",
      "[Studygroup][173] CNN Loss=1.1522, Acc=0.6512 | MLP Loss=1.8583, Acc=0.4637\n",
      "[Studygroup][174] CNN Loss=1.1323, Acc=0.6405 | MLP Loss=1.9025, Acc=0.4781\n",
      "[Studygroup][175] CNN Loss=1.1526, Acc=0.6358 | MLP Loss=1.9220, Acc=0.4687\n",
      "[Studygroup][176] CNN Loss=1.1674, Acc=0.6528 | MLP Loss=1.8890, Acc=0.4592\n",
      "[Studygroup][177] CNN Loss=1.1317, Acc=0.6538 | MLP Loss=1.8981, Acc=0.4776\n",
      "[Studygroup][178] CNN Loss=1.0813, Acc=0.6350 | MLP Loss=1.9111, Acc=0.4636\n",
      "[Studygroup][179] CNN Loss=1.1211, Acc=0.6430 | MLP Loss=1.8818, Acc=0.4670\n",
      "[Studygroup][180] CNN Loss=1.1432, Acc=0.6455 | MLP Loss=1.8864, Acc=0.4628\n",
      "[Studygroup][181] CNN Loss=1.0922, Acc=0.6504 | MLP Loss=1.8875, Acc=0.4818\n",
      "[Studygroup][182] CNN Loss=1.1486, Acc=0.6461 | MLP Loss=1.9405, Acc=0.4639\n",
      "[Studygroup][183] CNN Loss=1.1424, Acc=0.6408 | MLP Loss=2.0066, Acc=0.4449\n",
      "[Studygroup][184] CNN Loss=1.3028, Acc=0.6386 | MLP Loss=2.0762, Acc=0.4681\n",
      "[Studygroup][185] CNN Loss=1.1064, Acc=0.6452 | MLP Loss=1.8982, Acc=0.4805\n",
      "[Studygroup][186] CNN Loss=1.1427, Acc=0.6509 | MLP Loss=1.8858, Acc=0.4724\n",
      "[Studygroup][187] CNN Loss=1.0932, Acc=0.6511 | MLP Loss=1.8923, Acc=0.4832\n",
      "[Studygroup][188] CNN Loss=1.1259, Acc=0.6516 | MLP Loss=1.9160, Acc=0.4484\n",
      "[Studygroup][189] CNN Loss=1.1613, Acc=0.6443 | MLP Loss=1.8762, Acc=0.4691\n",
      "[Studygroup][190] CNN Loss=1.1655, Acc=0.6389 | MLP Loss=1.9260, Acc=0.4836\n",
      "[Studygroup][191] CNN Loss=1.1444, Acc=0.6488 | MLP Loss=1.8660, Acc=0.4882\n",
      "[Studygroup][192] CNN Loss=1.1173, Acc=0.6512 | MLP Loss=1.8918, Acc=0.4765\n",
      "[Studygroup][193] CNN Loss=1.0983, Acc=0.6467 | MLP Loss=1.9362, Acc=0.4547\n",
      "[Studygroup][194] CNN Loss=1.2374, Acc=0.6542 | MLP Loss=2.0853, Acc=0.4671\n",
      "[Studygroup][195] CNN Loss=1.1251, Acc=0.6411 | MLP Loss=1.8658, Acc=0.4846\n",
      "[Studygroup][196] CNN Loss=1.1102, Acc=0.6387 | MLP Loss=1.8810, Acc=0.4770\n",
      "[Studygroup][197] CNN Loss=1.1015, Acc=0.6488 | MLP Loss=1.8711, Acc=0.4700\n",
      "[Studygroup][198] CNN Loss=1.1389, Acc=0.6503 | MLP Loss=1.8850, Acc=0.4795\n",
      "[Studygroup][199] CNN Loss=1.1109, Acc=0.6479 | MLP Loss=1.8749, Acc=0.4730\n",
      "[Studygroup][200] CNN Loss=1.0913, Acc=0.6512 | MLP Loss=1.8995, Acc=0.4809\n",
      "[Studygroup][201] CNN Loss=1.1254, Acc=0.6500 | MLP Loss=1.8856, Acc=0.4667\n",
      "[Studygroup][202] CNN Loss=1.0968, Acc=0.6555 | MLP Loss=1.8734, Acc=0.4838\n",
      "[Studygroup][203] CNN Loss=1.1858, Acc=0.6323 | MLP Loss=2.0087, Acc=0.4709\n",
      "[Studygroup][204] CNN Loss=1.1394, Acc=0.6542 | MLP Loss=1.8577, Acc=0.4888\n",
      "[Studygroup][205] CNN Loss=1.1227, Acc=0.6515 | MLP Loss=1.9324, Acc=0.4833\n",
      "[Studygroup][206] CNN Loss=1.1414, Acc=0.6400 | MLP Loss=1.9426, Acc=0.4706\n",
      "[Studygroup][207] CNN Loss=1.1008, Acc=0.6522 | MLP Loss=1.8416, Acc=0.4645\n",
      "[Studygroup][208] CNN Loss=1.1523, Acc=0.6506 | MLP Loss=1.8680, Acc=0.4692\n",
      "[Studygroup][209] CNN Loss=1.1440, Acc=0.6461 | MLP Loss=1.8111, Acc=0.4845\n",
      "[Studygroup][210] CNN Loss=1.0996, Acc=0.6579 | MLP Loss=1.8882, Acc=0.4865\n",
      "[Studygroup][211] CNN Loss=1.1144, Acc=0.6555 | MLP Loss=1.9326, Acc=0.4756\n",
      "[Studygroup][212] CNN Loss=1.1422, Acc=0.6529 | MLP Loss=1.9610, Acc=0.4614\n",
      "[Studygroup][213] CNN Loss=1.0984, Acc=0.6546 | MLP Loss=1.8958, Acc=0.4803\n",
      "[Studygroup][214] CNN Loss=1.1123, Acc=0.6440 | MLP Loss=1.8369, Acc=0.4922\n",
      "[Studygroup][215] CNN Loss=1.1134, Acc=0.6529 | MLP Loss=1.9018, Acc=0.4968\n",
      "[Studygroup][216] CNN Loss=1.0964, Acc=0.6452 | MLP Loss=1.9012, Acc=0.4776\n",
      "[Studygroup][217] CNN Loss=1.1265, Acc=0.6596 | MLP Loss=1.8443, Acc=0.4918\n",
      "[Studygroup][218] CNN Loss=1.1318, Acc=0.6544 | MLP Loss=1.8562, Acc=0.4963\n",
      "[Studygroup][219] CNN Loss=1.0988, Acc=0.6501 | MLP Loss=1.8285, Acc=0.4772\n",
      "[Studygroup][220] CNN Loss=1.0736, Acc=0.6523 | MLP Loss=1.8379, Acc=0.4694\n",
      "[Studygroup][221] CNN Loss=1.0901, Acc=0.6551 | MLP Loss=1.8898, Acc=0.4877\n",
      "[Studygroup][222] CNN Loss=1.1401, Acc=0.6490 | MLP Loss=1.8532, Acc=0.4895\n",
      "[Studygroup][223] CNN Loss=1.1014, Acc=0.6561 | MLP Loss=1.8721, Acc=0.4966\n",
      "[Studygroup][224] CNN Loss=1.1433, Acc=0.6516 | MLP Loss=1.9086, Acc=0.4806\n",
      "[Studygroup][225] CNN Loss=1.1512, Acc=0.6487 | MLP Loss=1.8867, Acc=0.4951\n",
      "[Studygroup][226] CNN Loss=1.0987, Acc=0.6567 | MLP Loss=1.8789, Acc=0.4849\n",
      "[Studygroup][227] CNN Loss=1.1064, Acc=0.6538 | MLP Loss=1.8791, Acc=0.4837\n",
      "[Studygroup][228] CNN Loss=1.0948, Acc=0.6522 | MLP Loss=1.8860, Acc=0.4686\n",
      "[Studygroup][229] CNN Loss=1.1517, Acc=0.6544 | MLP Loss=1.9569, Acc=0.4905\n",
      "[Studygroup][230] CNN Loss=1.1104, Acc=0.6470 | MLP Loss=1.8205, Acc=0.4916\n",
      "[Studygroup][231] CNN Loss=1.1148, Acc=0.6523 | MLP Loss=1.8685, Acc=0.4961\n",
      "[Studygroup][232] CNN Loss=1.0753, Acc=0.6526 | MLP Loss=1.9359, Acc=0.4699\n",
      "[Studygroup][233] CNN Loss=1.1637, Acc=0.6447 | MLP Loss=1.9444, Acc=0.4868\n",
      "[Studygroup][234] CNN Loss=1.1156, Acc=0.6564 | MLP Loss=1.8552, Acc=0.5011\n",
      "[Studygroup][235] CNN Loss=1.0864, Acc=0.6522 | MLP Loss=1.8600, Acc=0.4929\n",
      "[Studygroup][236] CNN Loss=1.1283, Acc=0.6525 | MLP Loss=1.8407, Acc=0.4987\n",
      "[Studygroup][237] CNN Loss=1.0856, Acc=0.6520 | MLP Loss=1.8298, Acc=0.4906\n",
      "[Studygroup][238] CNN Loss=1.1056, Acc=0.6582 | MLP Loss=1.9161, Acc=0.4909\n",
      "[Studygroup][239] CNN Loss=1.1053, Acc=0.6582 | MLP Loss=1.8668, Acc=0.4940\n",
      "[Studygroup][240] CNN Loss=1.0766, Acc=0.6513 | MLP Loss=1.8016, Acc=0.4901\n",
      "[Studygroup][241] CNN Loss=1.1033, Acc=0.6471 | MLP Loss=1.8966, Acc=0.4887\n",
      "[Studygroup][242] CNN Loss=1.1227, Acc=0.6482 | MLP Loss=1.8548, Acc=0.5078\n",
      "[Studygroup][243] CNN Loss=1.1013, Acc=0.6568 | MLP Loss=1.8696, Acc=0.4919\n",
      "[Studygroup][244] CNN Loss=1.0557, Acc=0.6573 | MLP Loss=1.8640, Acc=0.5046\n",
      "[Studygroup][245] CNN Loss=1.0847, Acc=0.6603 | MLP Loss=1.8392, Acc=0.5023\n",
      "[Studygroup][246] CNN Loss=1.0189, Acc=0.6492 | MLP Loss=1.8828, Acc=0.4811\n",
      "[Studygroup][247] CNN Loss=1.0653, Acc=0.6576 | MLP Loss=1.8796, Acc=0.4986\n",
      "[Studygroup][248] CNN Loss=1.0945, Acc=0.6530 | MLP Loss=1.8446, Acc=0.4985\n",
      "[Studygroup][249] CNN Loss=1.0856, Acc=0.6447 | MLP Loss=1.8950, Acc=0.4611\n",
      "[Studygroup][250] CNN Loss=1.1018, Acc=0.6540 | MLP Loss=1.8761, Acc=0.5092\n",
      "[Studygroup][251] CNN Loss=1.0519, Acc=0.6435 | MLP Loss=1.8007, Acc=0.4821\n",
      "[Studygroup][252] CNN Loss=1.1017, Acc=0.6532 | MLP Loss=1.8918, Acc=0.4987\n",
      "[Studygroup][253] CNN Loss=1.0201, Acc=0.6583 | MLP Loss=1.8799, Acc=0.4866\n",
      "[Studygroup][254] CNN Loss=1.0051, Acc=0.6424 | MLP Loss=1.8594, Acc=0.4921\n",
      "[Studygroup][255] CNN Loss=1.0212, Acc=0.6412 | MLP Loss=1.8649, Acc=0.5147\n",
      "[Studygroup][256] CNN Loss=1.0821, Acc=0.6537 | MLP Loss=1.8641, Acc=0.5039\n",
      "[Studygroup][257] CNN Loss=1.0639, Acc=0.6555 | MLP Loss=1.8831, Acc=0.4978\n",
      "[Studygroup][258] CNN Loss=1.0968, Acc=0.6526 | MLP Loss=1.8727, Acc=0.5088\n",
      "[Studygroup][259] CNN Loss=1.0720, Acc=0.6459 | MLP Loss=1.9204, Acc=0.5055\n",
      "[Studygroup][260] CNN Loss=1.1238, Acc=0.6506 | MLP Loss=1.9251, Acc=0.5070\n",
      "[Studygroup][261] CNN Loss=1.1445, Acc=0.6508 | MLP Loss=1.8552, Acc=0.5071\n",
      "[Studygroup][262] CNN Loss=1.1156, Acc=0.6520 | MLP Loss=1.8261, Acc=0.5051\n",
      "[Studygroup][263] CNN Loss=1.0819, Acc=0.6487 | MLP Loss=1.8666, Acc=0.5011\n",
      "[Studygroup][264] CNN Loss=1.1533, Acc=0.6463 | MLP Loss=1.8294, Acc=0.5027\n",
      "[Studygroup][265] CNN Loss=1.0668, Acc=0.6601 | MLP Loss=1.8448, Acc=0.4987\n",
      "[Studygroup][266] CNN Loss=1.0190, Acc=0.6477 | MLP Loss=1.8383, Acc=0.5101\n",
      "[Studygroup][267] CNN Loss=1.0943, Acc=0.6452 | MLP Loss=1.8191, Acc=0.5043\n",
      "[Studygroup][268] CNN Loss=1.0969, Acc=0.6568 | MLP Loss=1.8632, Acc=0.4991\n",
      "[Studygroup][269] CNN Loss=1.0655, Acc=0.6500 | MLP Loss=1.8601, Acc=0.4752\n",
      "[Studygroup][270] CNN Loss=1.1200, Acc=0.6521 | MLP Loss=1.8823, Acc=0.4903\n",
      "[Studygroup][271] CNN Loss=1.0610, Acc=0.6581 | MLP Loss=1.8029, Acc=0.5118\n",
      "[Studygroup][272] CNN Loss=1.0610, Acc=0.6556 | MLP Loss=1.8075, Acc=0.5014\n",
      "[Studygroup][273] CNN Loss=1.1097, Acc=0.6533 | MLP Loss=1.8485, Acc=0.4930\n",
      "[Studygroup][274] CNN Loss=1.0622, Acc=0.6579 | MLP Loss=1.7835, Acc=0.5120\n",
      "[Studygroup][275] CNN Loss=1.0601, Acc=0.6482 | MLP Loss=1.8390, Acc=0.4950\n",
      "[Studygroup][276] CNN Loss=1.0256, Acc=0.6581 | MLP Loss=1.9032, Acc=0.5013\n",
      "[Studygroup][277] CNN Loss=1.1452, Acc=0.6472 | MLP Loss=1.9568, Acc=0.4927\n",
      "[Studygroup][278] CNN Loss=1.0669, Acc=0.6551 | MLP Loss=1.7765, Acc=0.5066\n",
      "[Studygroup][279] CNN Loss=1.0705, Acc=0.6598 | MLP Loss=1.8526, Acc=0.5113\n",
      "[Studygroup][280] CNN Loss=1.0424, Acc=0.6444 | MLP Loss=1.7969, Acc=0.5140\n",
      "[Studygroup][281] CNN Loss=1.0537, Acc=0.6574 | MLP Loss=1.8233, Acc=0.5069\n",
      "[Studygroup][282] CNN Loss=1.0585, Acc=0.6531 | MLP Loss=1.8747, Acc=0.4976\n",
      "[Studygroup][283] CNN Loss=1.0398, Acc=0.6552 | MLP Loss=1.8345, Acc=0.5137\n",
      "[Studygroup][284] CNN Loss=1.0913, Acc=0.6555 | MLP Loss=1.9001, Acc=0.4930\n",
      "[Studygroup][285] CNN Loss=1.0345, Acc=0.6568 | MLP Loss=1.8664, Acc=0.5016\n",
      "[Studygroup][286] CNN Loss=1.1118, Acc=0.6444 | MLP Loss=1.8622, Acc=0.5067\n",
      "[Studygroup][287] CNN Loss=1.0768, Acc=0.6523 | MLP Loss=1.8138, Acc=0.4957\n",
      "[Studygroup][288] CNN Loss=1.1484, Acc=0.6526 | MLP Loss=1.8373, Acc=0.5040\n",
      "[Studygroup][289] CNN Loss=1.0986, Acc=0.6583 | MLP Loss=1.8874, Acc=0.5164\n",
      "[Studygroup][290] CNN Loss=1.1579, Acc=0.6557 | MLP Loss=1.9389, Acc=0.4870\n",
      "[Studygroup][291] CNN Loss=1.1441, Acc=0.6505 | MLP Loss=1.8970, Acc=0.5136\n",
      "[Studygroup][292] CNN Loss=1.0677, Acc=0.6579 | MLP Loss=1.8252, Acc=0.5186\n",
      "[Studygroup][293] CNN Loss=1.0217, Acc=0.6564 | MLP Loss=1.8445, Acc=0.5057\n",
      "[Studygroup][294] CNN Loss=1.0619, Acc=0.6546 | MLP Loss=1.8243, Acc=0.5079\n",
      "[Studygroup][295] CNN Loss=1.0718, Acc=0.6512 | MLP Loss=1.8407, Acc=0.4862\n",
      "[Studygroup][296] CNN Loss=1.0603, Acc=0.6569 | MLP Loss=1.8729, Acc=0.5099\n",
      "[Studygroup][297] CNN Loss=1.0303, Acc=0.6603 | MLP Loss=1.8335, Acc=0.5151\n",
      "[Studygroup][298] CNN Loss=1.1335, Acc=0.6587 | MLP Loss=1.8740, Acc=0.5021\n",
      "[Studygroup][299] CNN Loss=1.1206, Acc=0.6532 | MLP Loss=1.8566, Acc=0.5180\n",
      "[Studygroup][300] CNN Loss=1.0820, Acc=0.6568 | MLP Loss=1.7718, Acc=0.5070\n",
      "[Studygroup][301] CNN Loss=1.0117, Acc=0.6550 | MLP Loss=1.8001, Acc=0.4852\n",
      "[Studygroup][302] CNN Loss=1.0345, Acc=0.6539 | MLP Loss=1.8428, Acc=0.5090\n",
      "[Studygroup][303] CNN Loss=1.0453, Acc=0.6565 | MLP Loss=1.8373, Acc=0.4831\n",
      "[Studygroup][304] CNN Loss=1.0770, Acc=0.6526 | MLP Loss=1.8433, Acc=0.5037\n",
      "[Studygroup][305] CNN Loss=1.1009, Acc=0.6533 | MLP Loss=1.8381, Acc=0.4944\n",
      "[Studygroup][306] CNN Loss=1.0393, Acc=0.6593 | MLP Loss=1.8243, Acc=0.5223\n",
      "[Studygroup][307] CNN Loss=1.0389, Acc=0.6531 | MLP Loss=1.8372, Acc=0.5081\n",
      "[Studygroup][308] CNN Loss=1.0162, Acc=0.6512 | MLP Loss=1.8088, Acc=0.5090\n",
      "[Studygroup][309] CNN Loss=1.0556, Acc=0.6543 | MLP Loss=1.8796, Acc=0.5163\n",
      "[Studygroup][310] CNN Loss=1.0600, Acc=0.6623 | MLP Loss=1.8884, Acc=0.5138\n",
      "[Studygroup][311] CNN Loss=1.0754, Acc=0.6495 | MLP Loss=1.7882, Acc=0.5154\n",
      "[Studygroup][312] CNN Loss=1.1124, Acc=0.6559 | MLP Loss=1.8279, Acc=0.5111\n",
      "[Studygroup][313] CNN Loss=1.0895, Acc=0.6528 | MLP Loss=1.8319, Acc=0.5128\n",
      "[Studygroup][314] CNN Loss=1.0586, Acc=0.6613 | MLP Loss=1.8090, Acc=0.5140\n",
      "[Studygroup][315] CNN Loss=1.0352, Acc=0.6601 | MLP Loss=1.7934, Acc=0.5063\n",
      "[Studygroup][316] CNN Loss=1.0553, Acc=0.6585 | MLP Loss=1.8076, Acc=0.5176\n",
      "[Studygroup][317] CNN Loss=0.9825, Acc=0.6517 | MLP Loss=1.8240, Acc=0.4985\n",
      "[Studygroup][318] CNN Loss=1.0609, Acc=0.6575 | MLP Loss=1.8573, Acc=0.5149\n",
      "[Studygroup][319] CNN Loss=1.0247, Acc=0.6628 | MLP Loss=1.8654, Acc=0.5180\n",
      "[Studygroup][320] CNN Loss=1.0781, Acc=0.6486 | MLP Loss=1.8396, Acc=0.5085\n",
      "[Studygroup][321] CNN Loss=1.0124, Acc=0.6530 | MLP Loss=1.8258, Acc=0.5124\n",
      "[Studygroup][322] CNN Loss=1.0007, Acc=0.6593 | MLP Loss=1.7702, Acc=0.5222\n",
      "[Studygroup][323] CNN Loss=1.0170, Acc=0.6609 | MLP Loss=1.8067, Acc=0.4949\n",
      "[Studygroup][324] CNN Loss=1.1087, Acc=0.6599 | MLP Loss=1.9112, Acc=0.5084\n",
      "[Studygroup][325] CNN Loss=1.0809, Acc=0.6513 | MLP Loss=1.7963, Acc=0.5181\n",
      "[Studygroup][326] CNN Loss=1.0143, Acc=0.6666 | MLP Loss=1.8102, Acc=0.5196\n",
      "[Studygroup][327] CNN Loss=1.0368, Acc=0.6608 | MLP Loss=1.8569, Acc=0.5123\n",
      "[Studygroup][328] CNN Loss=1.0383, Acc=0.6545 | MLP Loss=1.8065, Acc=0.5079\n",
      "[Studygroup][329] CNN Loss=1.0319, Acc=0.6570 | MLP Loss=1.8419, Acc=0.5215\n",
      "[Studygroup][330] CNN Loss=1.0237, Acc=0.6591 | MLP Loss=1.8093, Acc=0.5083\n",
      "[Studygroup][331] CNN Loss=1.0056, Acc=0.6627 | MLP Loss=1.8292, Acc=0.5252\n",
      "[Studygroup][332] CNN Loss=1.0494, Acc=0.6606 | MLP Loss=1.8772, Acc=0.5111\n",
      "[Studygroup][333] CNN Loss=1.0685, Acc=0.6607 | MLP Loss=1.8833, Acc=0.5213\n",
      "[Studygroup][334] CNN Loss=1.0555, Acc=0.6529 | MLP Loss=1.8157, Acc=0.5027\n",
      "[Studygroup][335] CNN Loss=1.0534, Acc=0.6601 | MLP Loss=1.8007, Acc=0.5166\n",
      "[Studygroup][336] CNN Loss=1.0679, Acc=0.6588 | MLP Loss=1.8343, Acc=0.5202\n",
      "[Studygroup][337] CNN Loss=1.0164, Acc=0.6534 | MLP Loss=1.8087, Acc=0.5191\n",
      "[Studygroup][338] CNN Loss=1.0778, Acc=0.6554 | MLP Loss=1.7926, Acc=0.5188\n",
      "[Studygroup][339] CNN Loss=1.0858, Acc=0.6532 | MLP Loss=1.8350, Acc=0.5152\n",
      "[Studygroup][340] CNN Loss=1.0487, Acc=0.6624 | MLP Loss=1.7657, Acc=0.5053\n",
      "[Studygroup][341] CNN Loss=1.0386, Acc=0.6572 | MLP Loss=1.8402, Acc=0.5164\n",
      "[Studygroup][342] CNN Loss=1.0238, Acc=0.6485 | MLP Loss=1.7968, Acc=0.4870\n",
      "[Studygroup][343] CNN Loss=1.0967, Acc=0.6613 | MLP Loss=1.8717, Acc=0.5197\n",
      "[Studygroup][344] CNN Loss=1.0699, Acc=0.6539 | MLP Loss=1.8114, Acc=0.5184\n",
      "[Studygroup][345] CNN Loss=1.0393, Acc=0.6674 | MLP Loss=1.8139, Acc=0.5217\n",
      "[Studygroup][346] CNN Loss=1.0687, Acc=0.6619 | MLP Loss=1.8582, Acc=0.5027\n",
      "[Studygroup][347] CNN Loss=1.0703, Acc=0.6633 | MLP Loss=1.7770, Acc=0.5327\n",
      "[Studygroup][348] CNN Loss=1.0287, Acc=0.6550 | MLP Loss=1.7832, Acc=0.5296\n",
      "[Studygroup][349] CNN Loss=1.0410, Acc=0.6569 | MLP Loss=1.7920, Acc=0.5201\n",
      "[Studygroup][350] CNN Loss=1.0034, Acc=0.6580 | MLP Loss=1.7678, Acc=0.5280\n",
      "[Studygroup][351] CNN Loss=1.0642, Acc=0.6473 | MLP Loss=1.8572, Acc=0.5188\n",
      "[Studygroup][352] CNN Loss=1.0846, Acc=0.6527 | MLP Loss=1.7624, Acc=0.5146\n",
      "[Studygroup][353] CNN Loss=1.0350, Acc=0.6558 | MLP Loss=1.8132, Acc=0.5101\n",
      "[Studygroup][354] CNN Loss=1.0299, Acc=0.6575 | MLP Loss=1.8314, Acc=0.5166\n",
      "[Studygroup][355] CNN Loss=1.0499, Acc=0.6483 | MLP Loss=1.8349, Acc=0.5169\n",
      "[Studygroup][356] CNN Loss=1.0717, Acc=0.6602 | MLP Loss=1.7823, Acc=0.5062\n",
      "[Studygroup][357] CNN Loss=1.0216, Acc=0.6561 | MLP Loss=1.7819, Acc=0.5259\n",
      "[Studygroup][358] CNN Loss=1.0068, Acc=0.6597 | MLP Loss=1.7440, Acc=0.5275\n",
      "[Studygroup][359] CNN Loss=1.0082, Acc=0.6611 | MLP Loss=1.8416, Acc=0.5102\n",
      "[Studygroup][360] CNN Loss=1.0138, Acc=0.6577 | MLP Loss=1.7987, Acc=0.5295\n",
      "[Studygroup][361] CNN Loss=1.0406, Acc=0.6567 | MLP Loss=1.9031, Acc=0.5223\n",
      "[Studygroup][362] CNN Loss=1.1502, Acc=0.6557 | MLP Loss=1.9293, Acc=0.5275\n",
      "[Studygroup][363] CNN Loss=0.9605, Acc=0.6571 | MLP Loss=1.7842, Acc=0.5299\n",
      "[Studygroup][364] CNN Loss=1.0179, Acc=0.6514 | MLP Loss=1.7838, Acc=0.5126\n",
      "[Studygroup][365] CNN Loss=0.9549, Acc=0.6552 | MLP Loss=1.8417, Acc=0.5289\n",
      "[Studygroup][366] CNN Loss=0.9684, Acc=0.6573 | MLP Loss=1.7764, Acc=0.5330\n",
      "[Studygroup][367] CNN Loss=1.0116, Acc=0.6563 | MLP Loss=1.8811, Acc=0.5341\n",
      "[Studygroup][368] CNN Loss=1.0589, Acc=0.6634 | MLP Loss=1.8123, Acc=0.5263\n",
      "[Studygroup][369] CNN Loss=1.0214, Acc=0.6616 | MLP Loss=1.8254, Acc=0.5112\n",
      "[Studygroup][370] CNN Loss=0.9919, Acc=0.6623 | MLP Loss=1.8196, Acc=0.5185\n",
      "[Studygroup][371] CNN Loss=1.0085, Acc=0.6518 | MLP Loss=1.7781, Acc=0.5146\n",
      "[Studygroup][372] CNN Loss=1.0130, Acc=0.6530 | MLP Loss=1.7709, Acc=0.5244\n",
      "[Studygroup][373] CNN Loss=0.9815, Acc=0.6643 | MLP Loss=1.8253, Acc=0.5156\n",
      "[Studygroup][374] CNN Loss=1.0637, Acc=0.6576 | MLP Loss=1.8453, Acc=0.5138\n",
      "[Studygroup][375] CNN Loss=1.0279, Acc=0.6595 | MLP Loss=1.7433, Acc=0.5325\n",
      "[Studygroup][376] CNN Loss=0.9737, Acc=0.6598 | MLP Loss=1.8113, Acc=0.5345\n",
      "[Studygroup][377] CNN Loss=1.0078, Acc=0.6517 | MLP Loss=1.8042, Acc=0.5241\n",
      "[Studygroup][378] CNN Loss=1.0172, Acc=0.6536 | MLP Loss=1.8609, Acc=0.5327\n",
      "[Studygroup][379] CNN Loss=1.0045, Acc=0.6615 | MLP Loss=1.8300, Acc=0.5162\n",
      "[Studygroup][380] CNN Loss=1.0048, Acc=0.6535 | MLP Loss=1.8222, Acc=0.5105\n",
      "[Studygroup][381] CNN Loss=0.9835, Acc=0.6680 | MLP Loss=1.8066, Acc=0.5222\n",
      "[Studygroup][382] CNN Loss=1.0070, Acc=0.6630 | MLP Loss=1.8527, Acc=0.5258\n",
      "[Studygroup][383] CNN Loss=1.0366, Acc=0.6584 | MLP Loss=1.8641, Acc=0.5176\n",
      "[Studygroup][384] CNN Loss=0.9272, Acc=0.6673 | MLP Loss=1.8503, Acc=0.5253\n",
      "[Studygroup][385] CNN Loss=1.0139, Acc=0.6599 | MLP Loss=1.8291, Acc=0.5310\n",
      "[Studygroup][386] CNN Loss=0.9851, Acc=0.6603 | MLP Loss=1.7836, Acc=0.5116\n",
      "[Studygroup][387] CNN Loss=0.9948, Acc=0.6562 | MLP Loss=1.8408, Acc=0.5116\n",
      "[Studygroup][388] CNN Loss=1.0314, Acc=0.6587 | MLP Loss=1.7995, Acc=0.5324\n",
      "[Studygroup][389] CNN Loss=1.0658, Acc=0.6557 | MLP Loss=1.8526, Acc=0.5034\n",
      "[Studygroup][390] CNN Loss=1.0109, Acc=0.6566 | MLP Loss=1.8428, Acc=0.5130\n",
      "[Studygroup][391] CNN Loss=1.0151, Acc=0.6609 | MLP Loss=1.8090, Acc=0.5224\n",
      "[Studygroup][392] CNN Loss=1.0151, Acc=0.6626 | MLP Loss=1.8321, Acc=0.5205\n",
      "[Studygroup][393] CNN Loss=0.9973, Acc=0.6528 | MLP Loss=1.8429, Acc=0.5142\n",
      "[Studygroup][394] CNN Loss=0.9901, Acc=0.6600 | MLP Loss=1.7874, Acc=0.5248\n",
      "[Studygroup][395] CNN Loss=0.9702, Acc=0.6638 | MLP Loss=1.8104, Acc=0.5312\n",
      "[Studygroup][396] CNN Loss=1.0116, Acc=0.6600 | MLP Loss=1.8627, Acc=0.5261\n",
      "[Studygroup][397] CNN Loss=0.9920, Acc=0.6562 | MLP Loss=1.7802, Acc=0.5401\n",
      "[Studygroup][398] CNN Loss=0.9816, Acc=0.6599 | MLP Loss=1.7915, Acc=0.5241\n",
      "[Studygroup][399] CNN Loss=1.0019, Acc=0.6603 | MLP Loss=1.7720, Acc=0.5339\n",
      "[Studygroup][400] CNN Loss=1.0374, Acc=0.6616 | MLP Loss=1.7245, Acc=0.5228\n",
      "[Studygroup][401] CNN Loss=1.0050, Acc=0.6597 | MLP Loss=1.7958, Acc=0.5306\n",
      "[Studygroup][402] CNN Loss=0.9734, Acc=0.6624 | MLP Loss=1.8169, Acc=0.5258\n",
      "[Studygroup][403] CNN Loss=0.9568, Acc=0.6619 | MLP Loss=1.7614, Acc=0.5217\n",
      "[Studygroup][404] CNN Loss=1.0248, Acc=0.6575 | MLP Loss=1.8201, Acc=0.5223\n",
      "[Studygroup][405] CNN Loss=1.0120, Acc=0.6579 | MLP Loss=1.7774, Acc=0.5369\n",
      "[Studygroup][406] CNN Loss=0.9517, Acc=0.6641 | MLP Loss=1.7778, Acc=0.5350\n",
      "[Studygroup][407] CNN Loss=0.9332, Acc=0.6578 | MLP Loss=1.8368, Acc=0.5239\n",
      "[Studygroup][408] CNN Loss=0.9801, Acc=0.6668 | MLP Loss=1.7927, Acc=0.5195\n",
      "[Studygroup][409] CNN Loss=1.0107, Acc=0.6532 | MLP Loss=1.8505, Acc=0.5115\n",
      "[Studygroup][410] CNN Loss=1.1464, Acc=0.6476 | MLP Loss=1.8941, Acc=0.5286\n",
      "[Studygroup][411] CNN Loss=0.9846, Acc=0.6675 | MLP Loss=1.7959, Acc=0.5382\n",
      "[Studygroup][412] CNN Loss=0.9311, Acc=0.6652 | MLP Loss=1.7949, Acc=0.5210\n",
      "[Studygroup][413] CNN Loss=1.0401, Acc=0.6469 | MLP Loss=1.8391, Acc=0.5204\n",
      "[Studygroup][414] CNN Loss=1.0324, Acc=0.6518 | MLP Loss=1.7314, Acc=0.5226\n",
      "[Studygroup][415] CNN Loss=1.1098, Acc=0.6576 | MLP Loss=1.7977, Acc=0.5203\n",
      "[Studygroup][416] CNN Loss=1.0246, Acc=0.6601 | MLP Loss=1.7836, Acc=0.5407\n",
      "[Studygroup][417] CNN Loss=0.9790, Acc=0.6655 | MLP Loss=1.7314, Acc=0.5364\n",
      "[Studygroup][418] CNN Loss=0.9373, Acc=0.6637 | MLP Loss=1.7468, Acc=0.5255\n",
      "[Studygroup][419] CNN Loss=0.9760, Acc=0.6635 | MLP Loss=1.7872, Acc=0.5280\n",
      "[Studygroup][420] CNN Loss=0.9679, Acc=0.6587 | MLP Loss=1.7832, Acc=0.5337\n",
      "[Studygroup][421] CNN Loss=0.9938, Acc=0.6668 | MLP Loss=1.7627, Acc=0.5248\n",
      "[Studygroup][422] CNN Loss=0.9837, Acc=0.6556 | MLP Loss=1.8088, Acc=0.5354\n",
      "[Studygroup][423] CNN Loss=0.9655, Acc=0.6665 | MLP Loss=1.7851, Acc=0.5215\n",
      "[Studygroup][424] CNN Loss=0.9683, Acc=0.6543 | MLP Loss=1.7747, Acc=0.5338\n",
      "[Studygroup][425] CNN Loss=0.9637, Acc=0.6642 | MLP Loss=1.8217, Acc=0.5250\n",
      "[Studygroup][426] CNN Loss=0.9310, Acc=0.6567 | MLP Loss=1.7781, Acc=0.5325\n",
      "[Studygroup][427] CNN Loss=0.9560, Acc=0.6557 | MLP Loss=1.8303, Acc=0.5228\n",
      "[Studygroup][428] CNN Loss=0.9438, Acc=0.6619 | MLP Loss=1.8169, Acc=0.5182\n",
      "[Studygroup][429] CNN Loss=1.0070, Acc=0.6596 | MLP Loss=1.8263, Acc=0.5139\n",
      "[Studygroup][430] CNN Loss=0.9997, Acc=0.6638 | MLP Loss=1.8520, Acc=0.5401\n",
      "[Studygroup][431] CNN Loss=1.0681, Acc=0.6606 | MLP Loss=1.8380, Acc=0.5393\n",
      "[Studygroup][432] CNN Loss=0.9911, Acc=0.6626 | MLP Loss=1.7797, Acc=0.5352\n",
      "[Studygroup][433] CNN Loss=1.0106, Acc=0.6618 | MLP Loss=1.8105, Acc=0.5138\n",
      "[Studygroup][434] CNN Loss=1.0739, Acc=0.6589 | MLP Loss=1.9381, Acc=0.5204\n",
      "[Studygroup][435] CNN Loss=0.9809, Acc=0.6618 | MLP Loss=1.8410, Acc=0.5271\n",
      "[Studygroup][436] CNN Loss=0.9607, Acc=0.6608 | MLP Loss=1.8281, Acc=0.5131\n",
      "[Studygroup][437] CNN Loss=0.9735, Acc=0.6660 | MLP Loss=1.9516, Acc=0.5109\n",
      "[Studygroup][438] CNN Loss=1.0290, Acc=0.6567 | MLP Loss=1.8078, Acc=0.5090\n",
      "[Studygroup][439] CNN Loss=0.9986, Acc=0.6697 | MLP Loss=1.7762, Acc=0.5350\n",
      "[Studygroup][440] CNN Loss=1.1087, Acc=0.6549 | MLP Loss=1.7452, Acc=0.5356\n",
      "[Studygroup][441] CNN Loss=0.9835, Acc=0.6594 | MLP Loss=1.7694, Acc=0.5276\n",
      "[Studygroup][442] CNN Loss=1.0139, Acc=0.6613 | MLP Loss=1.7960, Acc=0.5238\n",
      "[Studygroup][443] CNN Loss=1.0644, Acc=0.6613 | MLP Loss=1.8529, Acc=0.5213\n",
      "[Studygroup][444] CNN Loss=1.0081, Acc=0.6535 | MLP Loss=1.7133, Acc=0.5177\n",
      "[Studygroup][445] CNN Loss=0.9856, Acc=0.6658 | MLP Loss=1.7794, Acc=0.5309\n",
      "[Studygroup][446] CNN Loss=0.9564, Acc=0.6639 | MLP Loss=1.7532, Acc=0.5393\n",
      "[Studygroup][447] CNN Loss=0.9893, Acc=0.6648 | MLP Loss=1.7736, Acc=0.5414\n",
      "[Studygroup][448] CNN Loss=0.9832, Acc=0.6560 | MLP Loss=1.7386, Acc=0.5401\n",
      "[Studygroup][449] CNN Loss=0.9881, Acc=0.6609 | MLP Loss=1.7841, Acc=0.5425\n",
      "[Studygroup][450] CNN Loss=1.0054, Acc=0.6524 | MLP Loss=1.7499, Acc=0.5331\n",
      "[Studygroup][451] CNN Loss=0.9904, Acc=0.6636 | MLP Loss=1.7850, Acc=0.5279\n",
      "[Studygroup][452] CNN Loss=0.9987, Acc=0.6597 | MLP Loss=1.8183, Acc=0.5361\n",
      "[Studygroup][453] CNN Loss=0.9755, Acc=0.6503 | MLP Loss=1.7712, Acc=0.5225\n",
      "[Studygroup][454] CNN Loss=1.0101, Acc=0.6627 | MLP Loss=1.7170, Acc=0.5386\n",
      "[Studygroup][455] CNN Loss=1.0035, Acc=0.6636 | MLP Loss=1.7874, Acc=0.5381\n",
      "[Studygroup][456] CNN Loss=1.0506, Acc=0.6561 | MLP Loss=1.8187, Acc=0.5424\n",
      "[Studygroup][457] CNN Loss=0.9775, Acc=0.6586 | MLP Loss=1.7830, Acc=0.5382\n",
      "[Studygroup][458] CNN Loss=0.9677, Acc=0.6680 | MLP Loss=1.8444, Acc=0.5321\n",
      "[Studygroup][459] CNN Loss=1.0427, Acc=0.6654 | MLP Loss=1.8579, Acc=0.5325\n",
      "[Studygroup][460] CNN Loss=0.9833, Acc=0.6660 | MLP Loss=1.7993, Acc=0.5145\n",
      "[Studygroup][461] CNN Loss=0.9842, Acc=0.6613 | MLP Loss=1.7654, Acc=0.5274\n",
      "[Studygroup][462] CNN Loss=1.0084, Acc=0.6708 | MLP Loss=1.8220, Acc=0.5350\n",
      "[Studygroup][463] CNN Loss=0.9679, Acc=0.6603 | MLP Loss=1.8126, Acc=0.5385\n",
      "[Studygroup][464] CNN Loss=1.0096, Acc=0.6518 | MLP Loss=1.7878, Acc=0.5208\n",
      "[Studygroup][465] CNN Loss=0.9729, Acc=0.6682 | MLP Loss=1.7941, Acc=0.5349\n",
      "[Studygroup][466] CNN Loss=1.0107, Acc=0.6605 | MLP Loss=1.7999, Acc=0.5395\n",
      "[Studygroup][467] CNN Loss=0.9675, Acc=0.6634 | MLP Loss=1.7104, Acc=0.5388\n",
      "[Studygroup][468] CNN Loss=0.9988, Acc=0.6605 | MLP Loss=1.7987, Acc=0.5409\n",
      "[Studygroup][469] CNN Loss=1.0058, Acc=0.6660 | MLP Loss=1.8024, Acc=0.5349\n",
      "[Studygroup][470] CNN Loss=0.9280, Acc=0.6618 | MLP Loss=1.7696, Acc=0.5398\n",
      "[Studygroup][471] CNN Loss=1.0332, Acc=0.6600 | MLP Loss=1.8104, Acc=0.5312\n",
      "[Studygroup][472] CNN Loss=1.0019, Acc=0.6680 | MLP Loss=1.8073, Acc=0.5400\n",
      "[Studygroup][473] CNN Loss=1.1244, Acc=0.6597 | MLP Loss=1.7872, Acc=0.5331\n",
      "[Studygroup][474] CNN Loss=1.0140, Acc=0.6652 | MLP Loss=1.7511, Acc=0.5401\n",
      "[Studygroup][475] CNN Loss=0.9790, Acc=0.6626 | MLP Loss=1.7565, Acc=0.5401\n",
      "[Studygroup][476] CNN Loss=1.0303, Acc=0.6648 | MLP Loss=1.8078, Acc=0.5403\n",
      "[Studygroup][477] CNN Loss=0.9887, Acc=0.6565 | MLP Loss=1.6869, Acc=0.5392\n",
      "[Studygroup][478] CNN Loss=0.9763, Acc=0.6576 | MLP Loss=1.7452, Acc=0.5409\n",
      "[Studygroup][479] CNN Loss=1.0097, Acc=0.6653 | MLP Loss=1.7387, Acc=0.5327\n",
      "[Studygroup][480] CNN Loss=0.9311, Acc=0.6659 | MLP Loss=1.7501, Acc=0.5473\n",
      "[Studygroup][481] CNN Loss=0.9769, Acc=0.6653 | MLP Loss=1.7113, Acc=0.5491\n",
      "[Studygroup][482] CNN Loss=0.9836, Acc=0.6687 | MLP Loss=1.8915, Acc=0.5305\n",
      "[Studygroup][483] CNN Loss=0.9408, Acc=0.6617 | MLP Loss=1.8969, Acc=0.5437\n",
      "[Studygroup][484] CNN Loss=0.9751, Acc=0.6693 | MLP Loss=1.8965, Acc=0.5437\n",
      "[Studygroup][485] CNN Loss=0.9727, Acc=0.6627 | MLP Loss=1.8188, Acc=0.5355\n",
      "[Studygroup][486] CNN Loss=0.9579, Acc=0.6611 | MLP Loss=1.7500, Acc=0.5398\n",
      "[Studygroup][487] CNN Loss=0.9559, Acc=0.6633 | MLP Loss=1.7528, Acc=0.5312\n",
      "[Studygroup][488] CNN Loss=1.0187, Acc=0.6503 | MLP Loss=1.8977, Acc=0.5478\n",
      "[Studygroup][489] CNN Loss=1.0079, Acc=0.6604 | MLP Loss=1.7684, Acc=0.5435\n",
      "[Studygroup][490] CNN Loss=0.9763, Acc=0.6672 | MLP Loss=1.7561, Acc=0.5379\n",
      "[Studygroup][491] CNN Loss=1.0777, Acc=0.6511 | MLP Loss=1.7021, Acc=0.5366\n",
      "[Studygroup][492] CNN Loss=0.9980, Acc=0.6650 | MLP Loss=1.7340, Acc=0.5395\n",
      "[Studygroup][493] CNN Loss=0.8972, Acc=0.6677 | MLP Loss=1.7196, Acc=0.5280\n",
      "[Studygroup][494] CNN Loss=0.9570, Acc=0.6667 | MLP Loss=1.7462, Acc=0.5263\n",
      "[Studygroup][495] CNN Loss=0.9315, Acc=0.6660 | MLP Loss=1.7374, Acc=0.5388\n",
      "[Studygroup][496] CNN Loss=0.9784, Acc=0.6650 | MLP Loss=1.7956, Acc=0.5312\n",
      "[Studygroup][497] CNN Loss=1.0652, Acc=0.6564 | MLP Loss=1.7939, Acc=0.5431\n",
      "[Studygroup][498] CNN Loss=1.0139, Acc=0.6625 | MLP Loss=1.7336, Acc=0.5408\n",
      "[Studygroup][499] CNN Loss=1.0319, Acc=0.6565 | MLP Loss=1.8022, Acc=0.5478\n",
      "[Studygroup][500] CNN Loss=0.9533, Acc=0.6538 | MLP Loss=1.7769, Acc=0.5216\n",
      "[Studygroup][501] CNN Loss=1.0181, Acc=0.6532 | MLP Loss=1.7451, Acc=0.5316\n",
      "[Studygroup][502] CNN Loss=1.0013, Acc=0.6634 | MLP Loss=1.7634, Acc=0.5452\n",
      "[Studygroup][503] CNN Loss=0.9500, Acc=0.6651 | MLP Loss=1.7064, Acc=0.5365\n",
      "[Studygroup][504] CNN Loss=0.9936, Acc=0.6628 | MLP Loss=1.7402, Acc=0.5474\n",
      "[Studygroup][505] CNN Loss=0.9607, Acc=0.6660 | MLP Loss=1.7974, Acc=0.5493\n",
      "[Studygroup][506] CNN Loss=0.9587, Acc=0.6624 | MLP Loss=1.8010, Acc=0.5177\n",
      "[Studygroup][507] CNN Loss=1.0887, Acc=0.6624 | MLP Loss=1.7890, Acc=0.5410\n",
      "[Studygroup][508] CNN Loss=0.9956, Acc=0.6633 | MLP Loss=1.7191, Acc=0.5462\n",
      "[Studygroup][509] CNN Loss=0.9635, Acc=0.6678 | MLP Loss=1.7432, Acc=0.5437\n",
      "[Studygroup][510] CNN Loss=0.9624, Acc=0.6687 | MLP Loss=1.7313, Acc=0.5431\n",
      "[Studygroup][511] CNN Loss=0.9671, Acc=0.6652 | MLP Loss=1.7394, Acc=0.5372\n",
      "[Studygroup][512] CNN Loss=0.9214, Acc=0.6656 | MLP Loss=1.7549, Acc=0.5166\n",
      "[Studygroup][513] CNN Loss=0.9609, Acc=0.6681 | MLP Loss=1.8111, Acc=0.5321\n",
      "[Studygroup][514] CNN Loss=0.9745, Acc=0.6624 | MLP Loss=1.7622, Acc=0.5555\n",
      "[Studygroup][515] CNN Loss=0.9983, Acc=0.6739 | MLP Loss=1.8080, Acc=0.5338\n",
      "[Studygroup][516] CNN Loss=1.0777, Acc=0.6704 | MLP Loss=1.7655, Acc=0.5347\n",
      "[Studygroup][517] CNN Loss=1.0333, Acc=0.6682 | MLP Loss=1.7650, Acc=0.5413\n",
      "[Studygroup][518] CNN Loss=0.9713, Acc=0.6692 | MLP Loss=1.7805, Acc=0.5461\n",
      "[Studygroup][519] CNN Loss=0.9328, Acc=0.6677 | MLP Loss=1.7285, Acc=0.5390\n",
      "[Studygroup][520] CNN Loss=0.9859, Acc=0.6683 | MLP Loss=1.7778, Acc=0.5273\n",
      "[Studygroup][521] CNN Loss=1.0020, Acc=0.6547 | MLP Loss=1.8171, Acc=0.5448\n",
      "[Studygroup][522] CNN Loss=1.0398, Acc=0.6729 | MLP Loss=1.7043, Acc=0.5457\n",
      "[Studygroup][523] CNN Loss=0.9348, Acc=0.6721 | MLP Loss=1.7249, Acc=0.5415\n",
      "[Studygroup][524] CNN Loss=1.0268, Acc=0.6644 | MLP Loss=1.7221, Acc=0.5483\n",
      "[Studygroup][525] CNN Loss=0.9847, Acc=0.6634 | MLP Loss=1.7473, Acc=0.5498\n",
      "[Studygroup][526] CNN Loss=0.9580, Acc=0.6636 | MLP Loss=1.7405, Acc=0.5507\n",
      "[Studygroup][527] CNN Loss=0.9908, Acc=0.6658 | MLP Loss=1.7574, Acc=0.5406\n",
      "[Studygroup][528] CNN Loss=0.9993, Acc=0.6668 | MLP Loss=1.7008, Acc=0.5543\n",
      "[Studygroup][529] CNN Loss=0.9089, Acc=0.6637 | MLP Loss=1.7178, Acc=0.5466\n",
      "[Studygroup][530] CNN Loss=0.9691, Acc=0.6672 | MLP Loss=1.7178, Acc=0.5294\n",
      "[Studygroup][531] CNN Loss=0.9655, Acc=0.6723 | MLP Loss=1.7796, Acc=0.5499\n",
      "[Studygroup][532] CNN Loss=0.9619, Acc=0.6692 | MLP Loss=1.8045, Acc=0.5344\n",
      "[Studygroup][533] CNN Loss=1.0470, Acc=0.6581 | MLP Loss=1.7401, Acc=0.5504\n",
      "[Studygroup][534] CNN Loss=1.0508, Acc=0.6683 | MLP Loss=1.6830, Acc=0.5490\n",
      "[Studygroup][535] CNN Loss=0.9790, Acc=0.6696 | MLP Loss=1.6680, Acc=0.5459\n",
      "[Studygroup][536] CNN Loss=0.9972, Acc=0.6651 | MLP Loss=1.7773, Acc=0.5274\n",
      "[Studygroup][537] CNN Loss=1.0037, Acc=0.6764 | MLP Loss=1.7940, Acc=0.5509\n",
      "[Studygroup][538] CNN Loss=0.9745, Acc=0.6679 | MLP Loss=1.7927, Acc=0.5457\n",
      "[Studygroup][539] CNN Loss=1.0103, Acc=0.6670 | MLP Loss=1.7350, Acc=0.5314\n",
      "[Studygroup][540] CNN Loss=0.9537, Acc=0.6645 | MLP Loss=1.6588, Acc=0.5418\n",
      "[Studygroup][541] CNN Loss=1.0332, Acc=0.6594 | MLP Loss=1.6974, Acc=0.5470\n",
      "[Studygroup][542] CNN Loss=0.9570, Acc=0.6675 | MLP Loss=1.7407, Acc=0.5486\n",
      "[Studygroup][543] CNN Loss=0.9374, Acc=0.6629 | MLP Loss=1.7781, Acc=0.5528\n",
      "[Studygroup][544] CNN Loss=0.9111, Acc=0.6675 | MLP Loss=1.7293, Acc=0.5508\n",
      "[Studygroup][545] CNN Loss=0.9366, Acc=0.6625 | MLP Loss=1.7401, Acc=0.5539\n",
      "[Studygroup][546] CNN Loss=0.9755, Acc=0.6625 | MLP Loss=1.7316, Acc=0.5368\n",
      "[Studygroup][547] CNN Loss=0.9933, Acc=0.6739 | MLP Loss=1.8009, Acc=0.5496\n",
      "[Studygroup][548] CNN Loss=0.9770, Acc=0.6708 | MLP Loss=1.7495, Acc=0.5424\n",
      "[Studygroup][549] CNN Loss=0.9412, Acc=0.6698 | MLP Loss=1.7418, Acc=0.5287\n",
      "[Studygroup][550] CNN Loss=0.9427, Acc=0.6684 | MLP Loss=1.7761, Acc=0.5443\n",
      "[Studygroup][551] CNN Loss=0.9329, Acc=0.6629 | MLP Loss=1.7139, Acc=0.5464\n",
      "[Studygroup][552] CNN Loss=0.9612, Acc=0.6559 | MLP Loss=1.7207, Acc=0.5431\n",
      "[Studygroup][553] CNN Loss=0.9998, Acc=0.6709 | MLP Loss=1.8385, Acc=0.5511\n",
      "[Studygroup][554] CNN Loss=0.9693, Acc=0.6678 | MLP Loss=1.7284, Acc=0.5474\n",
      "[Studygroup][555] CNN Loss=0.9221, Acc=0.6603 | MLP Loss=1.8207, Acc=0.5352\n",
      "[Studygroup][556] CNN Loss=0.9973, Acc=0.6721 | MLP Loss=1.7793, Acc=0.5483\n",
      "[Studygroup][557] CNN Loss=0.9471, Acc=0.6693 | MLP Loss=1.7071, Acc=0.5513\n",
      "[Studygroup][558] CNN Loss=1.0053, Acc=0.6688 | MLP Loss=1.7956, Acc=0.5386\n",
      "[Studygroup][559] CNN Loss=0.9434, Acc=0.6640 | MLP Loss=1.7483, Acc=0.5385\n",
      "[Studygroup][560] CNN Loss=1.0055, Acc=0.6708 | MLP Loss=1.8146, Acc=0.5464\n",
      "[Studygroup][561] CNN Loss=1.0275, Acc=0.6689 | MLP Loss=1.7470, Acc=0.5520\n",
      "[Studygroup][562] CNN Loss=0.9372, Acc=0.6671 | MLP Loss=1.7477, Acc=0.5511\n",
      "[Studygroup][563] CNN Loss=0.9568, Acc=0.6679 | MLP Loss=1.7998, Acc=0.5303\n",
      "[Studygroup][564] CNN Loss=0.9129, Acc=0.6694 | MLP Loss=1.7712, Acc=0.5516\n",
      "[Studygroup][565] CNN Loss=0.9629, Acc=0.6658 | MLP Loss=1.7996, Acc=0.5486\n",
      "[Studygroup][566] CNN Loss=0.9252, Acc=0.6627 | MLP Loss=1.6851, Acc=0.5454\n",
      "[Studygroup][567] CNN Loss=0.9127, Acc=0.6707 | MLP Loss=1.7682, Acc=0.5527\n",
      "[Studygroup][568] CNN Loss=0.9309, Acc=0.6605 | MLP Loss=1.7742, Acc=0.5335\n",
      "[Studygroup][569] CNN Loss=0.9772, Acc=0.6641 | MLP Loss=1.7850, Acc=0.5486\n",
      "[Studygroup][570] CNN Loss=0.8827, Acc=0.6738 | MLP Loss=1.7990, Acc=0.5585\n",
      "[Studygroup][571] CNN Loss=0.9136, Acc=0.6703 | MLP Loss=1.7966, Acc=0.5442\n",
      "[Studygroup][572] CNN Loss=0.9622, Acc=0.6610 | MLP Loss=1.7960, Acc=0.5457\n",
      "[Studygroup][573] CNN Loss=1.0189, Acc=0.6656 | MLP Loss=1.7485, Acc=0.5518\n",
      "[Studygroup][574] CNN Loss=0.9643, Acc=0.6676 | MLP Loss=1.7373, Acc=0.5497\n",
      "[Studygroup][575] CNN Loss=0.9879, Acc=0.6579 | MLP Loss=1.6759, Acc=0.5479\n",
      "[Studygroup][576] CNN Loss=0.9637, Acc=0.6656 | MLP Loss=1.7293, Acc=0.5440\n",
      "[Studygroup][577] CNN Loss=0.9719, Acc=0.6697 | MLP Loss=1.7928, Acc=0.5298\n",
      "[Studygroup][578] CNN Loss=1.0005, Acc=0.6608 | MLP Loss=1.8389, Acc=0.5275\n",
      "[Studygroup][579] CNN Loss=0.9143, Acc=0.6613 | MLP Loss=1.7958, Acc=0.5533\n",
      "[Studygroup][580] CNN Loss=0.9569, Acc=0.6697 | MLP Loss=1.7741, Acc=0.5270\n",
      "[Studygroup][581] CNN Loss=0.9269, Acc=0.6585 | MLP Loss=1.7052, Acc=0.5437\n",
      "[Studygroup][582] CNN Loss=1.0400, Acc=0.6650 | MLP Loss=1.7284, Acc=0.5530\n",
      "[Studygroup][583] CNN Loss=0.9551, Acc=0.6672 | MLP Loss=1.7455, Acc=0.5354\n",
      "[Studygroup][584] CNN Loss=0.8927, Acc=0.6711 | MLP Loss=1.7502, Acc=0.5413\n",
      "[Studygroup][585] CNN Loss=0.9586, Acc=0.6734 | MLP Loss=1.7870, Acc=0.5546\n",
      "[Studygroup][586] CNN Loss=0.9118, Acc=0.6747 | MLP Loss=1.7462, Acc=0.5469\n",
      "[Studygroup][587] CNN Loss=0.9433, Acc=0.6710 | MLP Loss=1.6889, Acc=0.5484\n",
      "[Studygroup][588] CNN Loss=0.9400, Acc=0.6633 | MLP Loss=1.7634, Acc=0.5522\n",
      "[Studygroup][589] CNN Loss=1.0343, Acc=0.6607 | MLP Loss=1.7064, Acc=0.5375\n",
      "[Studygroup][590] CNN Loss=0.9849, Acc=0.6626 | MLP Loss=1.7100, Acc=0.5474\n",
      "[Studygroup][591] CNN Loss=0.9387, Acc=0.6701 | MLP Loss=1.7263, Acc=0.5508\n",
      "[Studygroup][592] CNN Loss=0.9713, Acc=0.6594 | MLP Loss=1.7335, Acc=0.5572\n",
      "[Studygroup][593] CNN Loss=0.9589, Acc=0.6719 | MLP Loss=1.7223, Acc=0.5448\n",
      "[Studygroup][594] CNN Loss=1.0004, Acc=0.6635 | MLP Loss=1.8161, Acc=0.5270\n",
      "[Studygroup][595] CNN Loss=0.9329, Acc=0.6574 | MLP Loss=1.7012, Acc=0.5555\n",
      "[Studygroup][596] CNN Loss=1.0263, Acc=0.6607 | MLP Loss=1.7154, Acc=0.5477\n",
      "[Studygroup][597] CNN Loss=1.0008, Acc=0.6630 | MLP Loss=1.7137, Acc=0.5394\n",
      "[Studygroup][598] CNN Loss=0.9694, Acc=0.6705 | MLP Loss=1.7493, Acc=0.5464\n",
      "[Studygroup][599] CNN Loss=0.9479, Acc=0.6725 | MLP Loss=1.7576, Acc=0.5497\n",
      "[Studygroup][600] CNN Loss=0.9766, Acc=0.6665 | MLP Loss=1.7212, Acc=0.5515\n",
      "[Studygroup][601] CNN Loss=0.9645, Acc=0.6747 | MLP Loss=1.6887, Acc=0.5509\n",
      "[Studygroup][602] CNN Loss=0.9570, Acc=0.6623 | MLP Loss=1.7373, Acc=0.5512\n",
      "[Studygroup][603] CNN Loss=0.9763, Acc=0.6658 | MLP Loss=1.8192, Acc=0.5490\n",
      "[Studygroup][604] CNN Loss=0.9242, Acc=0.6658 | MLP Loss=1.7963, Acc=0.5444\n",
      "[Studygroup][605] CNN Loss=0.9511, Acc=0.6713 | MLP Loss=1.7889, Acc=0.5542\n",
      "[Studygroup][606] CNN Loss=1.0567, Acc=0.6567 | MLP Loss=1.7579, Acc=0.5394\n",
      "[Studygroup][607] CNN Loss=0.9746, Acc=0.6642 | MLP Loss=1.7134, Acc=0.5544\n",
      "[Studygroup][608] CNN Loss=0.9427, Acc=0.6728 | MLP Loss=1.7715, Acc=0.5612\n",
      "[Studygroup][609] CNN Loss=0.9516, Acc=0.6615 | MLP Loss=1.7497, Acc=0.5346\n",
      "[Studygroup][610] CNN Loss=0.9797, Acc=0.6677 | MLP Loss=1.7615, Acc=0.5573\n",
      "[Studygroup][611] CNN Loss=0.9401, Acc=0.6713 | MLP Loss=1.7138, Acc=0.5422\n",
      "[Studygroup][612] CNN Loss=0.9681, Acc=0.6680 | MLP Loss=1.7766, Acc=0.5583\n",
      "[Studygroup][613] CNN Loss=0.9144, Acc=0.6675 | MLP Loss=1.7130, Acc=0.5315\n",
      "[Studygroup][614] CNN Loss=0.9809, Acc=0.6667 | MLP Loss=1.8825, Acc=0.5467\n",
      "[Studygroup][615] CNN Loss=1.0013, Acc=0.6704 | MLP Loss=1.7611, Acc=0.5414\n",
      "[Studygroup][616] CNN Loss=0.9743, Acc=0.6683 | MLP Loss=1.7351, Acc=0.5526\n",
      "[Studygroup][617] CNN Loss=0.8827, Acc=0.6745 | MLP Loss=1.6946, Acc=0.5488\n",
      "[Studygroup][618] CNN Loss=0.9558, Acc=0.6669 | MLP Loss=1.7086, Acc=0.5465\n",
      "[Studygroup][619] CNN Loss=0.9976, Acc=0.6618 | MLP Loss=1.7263, Acc=0.5550\n",
      "[Studygroup][620] CNN Loss=0.9857, Acc=0.6700 | MLP Loss=1.7191, Acc=0.5527\n",
      "[Studygroup][621] CNN Loss=0.9512, Acc=0.6661 | MLP Loss=1.6630, Acc=0.5491\n",
      "[Studygroup][622] CNN Loss=0.8860, Acc=0.6748 | MLP Loss=1.7445, Acc=0.5603\n",
      "[Studygroup][623] CNN Loss=0.9162, Acc=0.6767 | MLP Loss=1.7570, Acc=0.5475\n",
      "[Studygroup][624] CNN Loss=0.9336, Acc=0.6664 | MLP Loss=1.7783, Acc=0.5516\n",
      "[Studygroup][625] CNN Loss=0.9780, Acc=0.6620 | MLP Loss=1.7781, Acc=0.5623\n",
      "[Studygroup][626] CNN Loss=0.9587, Acc=0.6624 | MLP Loss=1.6657, Acc=0.5515\n",
      "[Studygroup][627] CNN Loss=0.9628, Acc=0.6548 | MLP Loss=1.7501, Acc=0.5597\n",
      "[Studygroup][628] CNN Loss=0.9586, Acc=0.6710 | MLP Loss=1.7114, Acc=0.5543\n",
      "[Studygroup][629] CNN Loss=0.9134, Acc=0.6652 | MLP Loss=1.7128, Acc=0.5613\n",
      "[Studygroup][630] CNN Loss=0.8964, Acc=0.6713 | MLP Loss=1.7102, Acc=0.5511\n",
      "[Studygroup][631] CNN Loss=0.9527, Acc=0.6662 | MLP Loss=1.7379, Acc=0.5424\n",
      "[Studygroup][632] CNN Loss=0.9538, Acc=0.6646 | MLP Loss=1.6846, Acc=0.5493\n",
      "[Studygroup][633] CNN Loss=1.0021, Acc=0.6659 | MLP Loss=1.7361, Acc=0.5608\n",
      "[Studygroup][634] CNN Loss=0.9363, Acc=0.6653 | MLP Loss=1.7468, Acc=0.5467\n",
      "[Studygroup][635] CNN Loss=0.9615, Acc=0.6698 | MLP Loss=1.7547, Acc=0.5563\n",
      "[Studygroup][636] CNN Loss=0.9807, Acc=0.6669 | MLP Loss=1.7294, Acc=0.5603\n",
      "[Studygroup][637] CNN Loss=0.9499, Acc=0.6660 | MLP Loss=1.7937, Acc=0.5373\n",
      "[Studygroup][638] CNN Loss=0.9133, Acc=0.6713 | MLP Loss=1.7257, Acc=0.5498\n",
      "[Studygroup][639] CNN Loss=1.0142, Acc=0.6584 | MLP Loss=1.7320, Acc=0.5526\n",
      "[Studygroup][640] CNN Loss=0.9545, Acc=0.6636 | MLP Loss=1.7516, Acc=0.5492\n",
      "[Studygroup][641] CNN Loss=0.9747, Acc=0.6725 | MLP Loss=1.7069, Acc=0.5564\n",
      "[Studygroup][642] CNN Loss=0.9022, Acc=0.6655 | MLP Loss=1.6975, Acc=0.5513\n",
      "[Studygroup][643] CNN Loss=1.0012, Acc=0.6695 | MLP Loss=1.7968, Acc=0.5540\n",
      "[Studygroup][644] CNN Loss=0.9667, Acc=0.6613 | MLP Loss=1.7306, Acc=0.5433\n",
      "[Studygroup][645] CNN Loss=0.9557, Acc=0.6689 | MLP Loss=1.7304, Acc=0.5571\n",
      "[Studygroup][646] CNN Loss=0.9355, Acc=0.6620 | MLP Loss=1.7324, Acc=0.5583\n",
      "[Studygroup][647] CNN Loss=0.9116, Acc=0.6729 | MLP Loss=1.6672, Acc=0.5528\n",
      "[Studygroup][648] CNN Loss=0.9663, Acc=0.6584 | MLP Loss=1.6749, Acc=0.5387\n",
      "[Studygroup][649] CNN Loss=0.9350, Acc=0.6694 | MLP Loss=1.7059, Acc=0.5413\n",
      "[Studygroup][650] CNN Loss=0.9554, Acc=0.6652 | MLP Loss=1.7230, Acc=0.5533\n",
      "[Studygroup][651] CNN Loss=0.8716, Acc=0.6743 | MLP Loss=1.6725, Acc=0.5540\n",
      "[Studygroup][652] CNN Loss=0.9715, Acc=0.6609 | MLP Loss=1.7709, Acc=0.5530\n",
      "[Studygroup][653] CNN Loss=0.9205, Acc=0.6748 | MLP Loss=1.7660, Acc=0.5565\n",
      "[Studygroup][654] CNN Loss=0.9725, Acc=0.6547 | MLP Loss=1.7122, Acc=0.5573\n",
      "[Studygroup][655] CNN Loss=1.0043, Acc=0.6667 | MLP Loss=1.7240, Acc=0.5606\n",
      "[Studygroup][656] CNN Loss=0.9072, Acc=0.6728 | MLP Loss=1.7065, Acc=0.5507\n",
      "[Studygroup][657] CNN Loss=0.8728, Acc=0.6723 | MLP Loss=1.7110, Acc=0.5606\n",
      "[Studygroup][658] CNN Loss=0.9601, Acc=0.6598 | MLP Loss=1.7062, Acc=0.5662\n",
      "[Studygroup][659] CNN Loss=0.9348, Acc=0.6732 | MLP Loss=1.7543, Acc=0.5613\n",
      "[Studygroup][660] CNN Loss=0.8956, Acc=0.6679 | MLP Loss=1.7584, Acc=0.5382\n",
      "[Studygroup][661] CNN Loss=1.0140, Acc=0.6676 | MLP Loss=1.8162, Acc=0.5582\n",
      "[Studygroup][662] CNN Loss=0.9893, Acc=0.6698 | MLP Loss=1.7178, Acc=0.5631\n",
      "[Studygroup][663] CNN Loss=0.9129, Acc=0.6689 | MLP Loss=1.7072, Acc=0.5538\n",
      "[Studygroup][664] CNN Loss=0.9429, Acc=0.6703 | MLP Loss=1.6614, Acc=0.5557\n",
      "[Studygroup][665] CNN Loss=1.0044, Acc=0.6497 | MLP Loss=1.7247, Acc=0.5350\n",
      "[Studygroup][666] CNN Loss=0.9850, Acc=0.6661 | MLP Loss=1.7787, Acc=0.5453\n",
      "[Studygroup][667] CNN Loss=0.9286, Acc=0.6672 | MLP Loss=1.7205, Acc=0.5510\n",
      "[Studygroup][668] CNN Loss=0.9334, Acc=0.6715 | MLP Loss=1.7066, Acc=0.5577\n",
      "[Studygroup][669] CNN Loss=0.9816, Acc=0.6537 | MLP Loss=1.6528, Acc=0.5505\n",
      "[Studygroup][670] CNN Loss=0.9648, Acc=0.6678 | MLP Loss=1.6714, Acc=0.5516\n",
      "[Studygroup][671] CNN Loss=1.0653, Acc=0.6671 | MLP Loss=1.8107, Acc=0.5598\n",
      "[Studygroup][672] CNN Loss=0.9556, Acc=0.6666 | MLP Loss=1.6961, Acc=0.5640\n",
      "[Studygroup][673] CNN Loss=0.9399, Acc=0.6663 | MLP Loss=1.7002, Acc=0.5582\n",
      "[Studygroup][674] CNN Loss=0.9726, Acc=0.6547 | MLP Loss=1.7162, Acc=0.5489\n",
      "[Studygroup][675] CNN Loss=0.9760, Acc=0.6679 | MLP Loss=1.7653, Acc=0.5434\n",
      "[Studygroup][676] CNN Loss=0.9605, Acc=0.6613 | MLP Loss=1.6896, Acc=0.5606\n",
      "[Studygroup][677] CNN Loss=0.9244, Acc=0.6644 | MLP Loss=1.7341, Acc=0.5627\n",
      "[Studygroup][678] CNN Loss=0.9427, Acc=0.6696 | MLP Loss=1.7489, Acc=0.5568\n",
      "[Studygroup][679] CNN Loss=0.8929, Acc=0.6576 | MLP Loss=1.7353, Acc=0.5509\n",
      "[Studygroup][680] CNN Loss=1.0072, Acc=0.6716 | MLP Loss=1.7104, Acc=0.5561\n",
      "[Studygroup][681] CNN Loss=0.9187, Acc=0.6734 | MLP Loss=1.7378, Acc=0.5597\n",
      "[Studygroup][682] CNN Loss=0.8256, Acc=0.6728 | MLP Loss=1.6770, Acc=0.5589\n",
      "[Studygroup][683] CNN Loss=0.8802, Acc=0.6703 | MLP Loss=1.7282, Acc=0.5552\n",
      "[Studygroup][684] CNN Loss=0.8555, Acc=0.6714 | MLP Loss=1.7762, Acc=0.5598\n",
      "[Studygroup][685] CNN Loss=0.9298, Acc=0.6630 | MLP Loss=1.7382, Acc=0.5479\n",
      "[Studygroup][686] CNN Loss=0.9716, Acc=0.6675 | MLP Loss=1.8806, Acc=0.5168\n",
      "[Studygroup][687] CNN Loss=1.0348, Acc=0.6508 | MLP Loss=1.9181, Acc=0.5586\n",
      "[Studygroup][688] CNN Loss=0.9838, Acc=0.6697 | MLP Loss=1.6464, Acc=0.5539\n",
      "[Studygroup][689] CNN Loss=0.9441, Acc=0.6715 | MLP Loss=1.6821, Acc=0.5644\n",
      "[Studygroup][690] CNN Loss=1.0304, Acc=0.6711 | MLP Loss=1.7200, Acc=0.5475\n",
      "[Studygroup][691] CNN Loss=0.8963, Acc=0.6759 | MLP Loss=1.7786, Acc=0.5587\n",
      "[Studygroup][692] CNN Loss=0.8783, Acc=0.6655 | MLP Loss=1.6946, Acc=0.5494\n",
      "[Studygroup][693] CNN Loss=0.9499, Acc=0.6664 | MLP Loss=1.7396, Acc=0.5515\n",
      "[Studygroup][694] CNN Loss=0.9875, Acc=0.6639 | MLP Loss=1.6944, Acc=0.5553\n",
      "[Studygroup][695] CNN Loss=0.9449, Acc=0.6707 | MLP Loss=1.7207, Acc=0.5394\n",
      "[Studygroup][696] CNN Loss=0.8869, Acc=0.6768 | MLP Loss=1.8001, Acc=0.5658\n",
      "[Studygroup][697] CNN Loss=0.9432, Acc=0.6634 | MLP Loss=1.6804, Acc=0.5575\n",
      "[Studygroup][698] CNN Loss=0.9367, Acc=0.6699 | MLP Loss=1.7744, Acc=0.5571\n",
      "[Studygroup][699] CNN Loss=0.9810, Acc=0.6708 | MLP Loss=1.7644, Acc=0.5530\n",
      "[Studygroup][700] CNN Loss=0.9479, Acc=0.6704 | MLP Loss=1.7553, Acc=0.5665\n",
      "[Studygroup][701] CNN Loss=0.9205, Acc=0.6695 | MLP Loss=1.7309, Acc=0.5540\n",
      "[Studygroup][702] CNN Loss=0.9310, Acc=0.6724 | MLP Loss=1.8073, Acc=0.5646\n",
      "[Studygroup][703] CNN Loss=0.9517, Acc=0.6728 | MLP Loss=1.7144, Acc=0.5615\n",
      "[Studygroup][704] CNN Loss=0.9160, Acc=0.6733 | MLP Loss=1.6403, Acc=0.5689\n",
      "[Studygroup][705] CNN Loss=0.9265, Acc=0.6692 | MLP Loss=1.7000, Acc=0.5548\n",
      "[Studygroup][706] CNN Loss=0.9036, Acc=0.6660 | MLP Loss=1.7142, Acc=0.5451\n",
      "[Studygroup][707] CNN Loss=0.9316, Acc=0.6666 | MLP Loss=1.8015, Acc=0.5624\n",
      "[Studygroup][708] CNN Loss=0.9634, Acc=0.6620 | MLP Loss=1.7915, Acc=0.5605\n",
      "[Studygroup][709] CNN Loss=0.9576, Acc=0.6700 | MLP Loss=1.7599, Acc=0.5595\n",
      "[Studygroup][710] CNN Loss=0.9824, Acc=0.6678 | MLP Loss=1.7791, Acc=0.5491\n",
      "[Studygroup][711] CNN Loss=0.8972, Acc=0.6660 | MLP Loss=1.7586, Acc=0.5664\n",
      "[Studygroup][712] CNN Loss=0.9733, Acc=0.6710 | MLP Loss=1.7625, Acc=0.5604\n",
      "[Studygroup][713] CNN Loss=0.8856, Acc=0.6706 | MLP Loss=1.6593, Acc=0.5603\n",
      "[Studygroup][714] CNN Loss=0.9399, Acc=0.6681 | MLP Loss=1.6767, Acc=0.5607\n",
      "[Studygroup][715] CNN Loss=0.9177, Acc=0.6705 | MLP Loss=1.7641, Acc=0.5526\n",
      "[Studygroup][716] CNN Loss=0.9610, Acc=0.6690 | MLP Loss=1.6963, Acc=0.5570\n",
      "[Studygroup][717] CNN Loss=0.9436, Acc=0.6623 | MLP Loss=1.6566, Acc=0.5671\n",
      "[Studygroup][718] CNN Loss=0.9158, Acc=0.6704 | MLP Loss=1.6497, Acc=0.5661\n",
      "[Studygroup][719] CNN Loss=0.9469, Acc=0.6673 | MLP Loss=1.7292, Acc=0.5654\n",
      "[Studygroup][720] CNN Loss=0.9584, Acc=0.6672 | MLP Loss=1.6709, Acc=0.5624\n",
      "[Studygroup][721] CNN Loss=0.9228, Acc=0.6689 | MLP Loss=1.7021, Acc=0.5610\n",
      "[Studygroup][722] CNN Loss=0.8645, Acc=0.6677 | MLP Loss=1.7553, Acc=0.5579\n",
      "[Studygroup][723] CNN Loss=0.9128, Acc=0.6713 | MLP Loss=1.7656, Acc=0.5624\n",
      "[Studygroup][724] CNN Loss=0.9084, Acc=0.6659 | MLP Loss=1.7696, Acc=0.5472\n",
      "[Studygroup][725] CNN Loss=0.9238, Acc=0.6656 | MLP Loss=1.7564, Acc=0.5469\n",
      "[Studygroup][726] CNN Loss=0.9835, Acc=0.6670 | MLP Loss=1.6642, Acc=0.5459\n",
      "[Studygroup][727] CNN Loss=0.9903, Acc=0.6624 | MLP Loss=1.7446, Acc=0.5545\n",
      "[Studygroup][728] CNN Loss=0.9490, Acc=0.6603 | MLP Loss=1.7993, Acc=0.5510\n",
      "[Studygroup][729] CNN Loss=0.9374, Acc=0.6661 | MLP Loss=1.7095, Acc=0.5467\n",
      "[Studygroup][730] CNN Loss=0.9480, Acc=0.6645 | MLP Loss=1.6914, Acc=0.5514\n",
      "[Studygroup][731] CNN Loss=0.9139, Acc=0.6690 | MLP Loss=1.6961, Acc=0.5558\n",
      "[Studygroup][732] CNN Loss=0.9366, Acc=0.6719 | MLP Loss=1.7367, Acc=0.5516\n",
      "[Studygroup][733] CNN Loss=0.9612, Acc=0.6711 | MLP Loss=1.6789, Acc=0.5701\n",
      "[Studygroup][734] CNN Loss=0.9353, Acc=0.6618 | MLP Loss=1.6478, Acc=0.5608\n",
      "[Studygroup][735] CNN Loss=0.9119, Acc=0.6752 | MLP Loss=1.6335, Acc=0.5681\n",
      "[Studygroup][736] CNN Loss=0.9079, Acc=0.6745 | MLP Loss=1.7314, Acc=0.5597\n",
      "[Studygroup][737] CNN Loss=0.9574, Acc=0.6665 | MLP Loss=1.7196, Acc=0.5633\n",
      "[Studygroup][738] CNN Loss=0.9304, Acc=0.6717 | MLP Loss=1.7069, Acc=0.5682\n",
      "[Studygroup][739] CNN Loss=0.9986, Acc=0.6674 | MLP Loss=1.6988, Acc=0.5612\n",
      "[Studygroup][740] CNN Loss=0.9284, Acc=0.6639 | MLP Loss=1.6654, Acc=0.5696\n",
      "[Studygroup][741] CNN Loss=0.9489, Acc=0.6680 | MLP Loss=1.6276, Acc=0.5547\n",
      "[Studygroup][742] CNN Loss=0.9124, Acc=0.6664 | MLP Loss=1.6548, Acc=0.5561\n",
      "[Studygroup][743] CNN Loss=0.9006, Acc=0.6711 | MLP Loss=1.7415, Acc=0.5627\n",
      "[Studygroup][744] CNN Loss=0.8966, Acc=0.6724 | MLP Loss=1.6341, Acc=0.5503\n",
      "[Studygroup][745] CNN Loss=0.9126, Acc=0.6684 | MLP Loss=1.7077, Acc=0.5701\n",
      "[Studygroup][746] CNN Loss=0.9255, Acc=0.6610 | MLP Loss=1.6932, Acc=0.5663\n",
      "[Studygroup][747] CNN Loss=0.9486, Acc=0.6705 | MLP Loss=1.6889, Acc=0.5619\n",
      "[Studygroup][748] CNN Loss=0.9246, Acc=0.6730 | MLP Loss=1.7268, Acc=0.5653\n",
      "[Studygroup][749] CNN Loss=0.9103, Acc=0.6711 | MLP Loss=1.6944, Acc=0.5693\n",
      "[Studygroup][750] CNN Loss=0.9038, Acc=0.6731 | MLP Loss=1.7585, Acc=0.5541\n",
      "[Studygroup][751] CNN Loss=0.8966, Acc=0.6618 | MLP Loss=1.7385, Acc=0.5562\n",
      "[Studygroup][752] CNN Loss=0.9773, Acc=0.6675 | MLP Loss=1.7306, Acc=0.5594\n",
      "[Studygroup][753] CNN Loss=0.9592, Acc=0.6614 | MLP Loss=1.7095, Acc=0.5624\n",
      "[Studygroup][754] CNN Loss=0.9297, Acc=0.6688 | MLP Loss=1.7317, Acc=0.5655\n",
      "[Studygroup][755] CNN Loss=0.9289, Acc=0.6760 | MLP Loss=1.6891, Acc=0.5632\n",
      "[Studygroup][756] CNN Loss=1.0056, Acc=0.6641 | MLP Loss=1.7187, Acc=0.5638\n",
      "[Studygroup][757] CNN Loss=0.8891, Acc=0.6691 | MLP Loss=1.6828, Acc=0.5591\n",
      "[Studygroup][758] CNN Loss=1.0266, Acc=0.6593 | MLP Loss=1.7539, Acc=0.5546\n",
      "[Studygroup][759] CNN Loss=0.9518, Acc=0.6734 | MLP Loss=1.6872, Acc=0.5668\n",
      "[Studygroup][760] CNN Loss=0.9575, Acc=0.6693 | MLP Loss=1.7182, Acc=0.5698\n",
      "[Studygroup][761] CNN Loss=0.9710, Acc=0.6701 | MLP Loss=1.6898, Acc=0.5664\n",
      "[Studygroup][762] CNN Loss=0.9218, Acc=0.6725 | MLP Loss=1.6853, Acc=0.5609\n",
      "[Studygroup][763] CNN Loss=0.9248, Acc=0.6720 | MLP Loss=1.6374, Acc=0.5717\n",
      "[Studygroup][764] CNN Loss=0.8995, Acc=0.6718 | MLP Loss=1.7012, Acc=0.5601\n",
      "[Studygroup][765] CNN Loss=0.9618, Acc=0.6684 | MLP Loss=1.7594, Acc=0.5542\n",
      "[Studygroup][766] CNN Loss=1.0230, Acc=0.6651 | MLP Loss=1.6956, Acc=0.5632\n",
      "[Studygroup][767] CNN Loss=0.8712, Acc=0.6674 | MLP Loss=1.6747, Acc=0.5643\n",
      "[Studygroup][768] CNN Loss=0.8631, Acc=0.6729 | MLP Loss=1.6833, Acc=0.5627\n",
      "[Studygroup][769] CNN Loss=0.9882, Acc=0.6599 | MLP Loss=1.6852, Acc=0.5612\n",
      "[Studygroup][770] CNN Loss=0.8946, Acc=0.6669 | MLP Loss=1.6649, Acc=0.5390\n",
      "[Studygroup][771] CNN Loss=0.8989, Acc=0.6785 | MLP Loss=1.6841, Acc=0.5645\n",
      "[Studygroup][772] CNN Loss=0.8648, Acc=0.6675 | MLP Loss=1.7501, Acc=0.5681\n",
      "[Studygroup][773] CNN Loss=0.9101, Acc=0.6600 | MLP Loss=1.6682, Acc=0.5680\n",
      "[Studygroup][774] CNN Loss=0.9463, Acc=0.6666 | MLP Loss=1.6071, Acc=0.5661\n",
      "[Studygroup][775] CNN Loss=0.9290, Acc=0.6695 | MLP Loss=1.6434, Acc=0.5554\n",
      "[Studygroup][776] CNN Loss=0.8991, Acc=0.6678 | MLP Loss=1.7302, Acc=0.5604\n",
      "[Studygroup][777] CNN Loss=0.9297, Acc=0.6683 | MLP Loss=1.7656, Acc=0.5495\n",
      "[Studygroup][778] CNN Loss=0.9917, Acc=0.6715 | MLP Loss=1.8337, Acc=0.5641\n",
      "[Studygroup][779] CNN Loss=0.9447, Acc=0.6586 | MLP Loss=1.7325, Acc=0.5523\n",
      "[Studygroup][780] CNN Loss=0.9243, Acc=0.6740 | MLP Loss=1.6949, Acc=0.5332\n",
      "[Studygroup][781] CNN Loss=0.9245, Acc=0.6730 | MLP Loss=1.8311, Acc=0.5522\n",
      "[Studygroup][782] CNN Loss=1.0011, Acc=0.6700 | MLP Loss=1.6757, Acc=0.5566\n",
      "[Studygroup][783] CNN Loss=0.9371, Acc=0.6683 | MLP Loss=1.7628, Acc=0.5518\n",
      "[Studygroup][784] CNN Loss=0.9422, Acc=0.6704 | MLP Loss=1.6912, Acc=0.5688\n",
      "[Studygroup][785] CNN Loss=0.9309, Acc=0.6717 | MLP Loss=1.7089, Acc=0.5688\n",
      "[Studygroup][786] CNN Loss=0.9028, Acc=0.6703 | MLP Loss=1.6678, Acc=0.5624\n",
      "[Studygroup][787] CNN Loss=0.9382, Acc=0.6626 | MLP Loss=1.7049, Acc=0.5628\n",
      "[Studygroup][788] CNN Loss=0.9430, Acc=0.6710 | MLP Loss=1.7394, Acc=0.5479\n",
      "[Studygroup][789] CNN Loss=0.8973, Acc=0.6677 | MLP Loss=1.6911, Acc=0.5629\n",
      "[Studygroup][790] CNN Loss=1.0000, Acc=0.6734 | MLP Loss=1.7311, Acc=0.5670\n",
      "[Studygroup][791] CNN Loss=0.9025, Acc=0.6664 | MLP Loss=1.6859, Acc=0.5665\n",
      "[Studygroup][792] CNN Loss=0.9500, Acc=0.6671 | MLP Loss=1.7123, Acc=0.5563\n",
      "[Studygroup][793] CNN Loss=0.9865, Acc=0.6672 | MLP Loss=1.6768, Acc=0.5581\n",
      "[Studygroup][794] CNN Loss=0.9385, Acc=0.6666 | MLP Loss=1.7131, Acc=0.5576\n",
      "[Studygroup][795] CNN Loss=0.8896, Acc=0.6754 | MLP Loss=1.6718, Acc=0.5668\n",
      "[Studygroup][796] CNN Loss=0.9560, Acc=0.6766 | MLP Loss=1.6549, Acc=0.5603\n",
      "[Studygroup][797] CNN Loss=0.9297, Acc=0.6743 | MLP Loss=1.5940, Acc=0.5650\n",
      "[Studygroup][798] CNN Loss=0.8721, Acc=0.6722 | MLP Loss=1.7103, Acc=0.5652\n",
      "[Studygroup][799] CNN Loss=0.8991, Acc=0.6714 | MLP Loss=1.6816, Acc=0.5568\n",
      "[Studygroup][800] CNN Loss=0.8884, Acc=0.6687 | MLP Loss=1.6789, Acc=0.5643\n",
      "[Studygroup][801] CNN Loss=0.9634, Acc=0.6749 | MLP Loss=1.7473, Acc=0.5668\n",
      "[Studygroup][802] CNN Loss=0.9182, Acc=0.6739 | MLP Loss=1.7347, Acc=0.5646\n",
      "[Studygroup][803] CNN Loss=0.8713, Acc=0.6724 | MLP Loss=1.7550, Acc=0.5674\n",
      "[Studygroup][804] CNN Loss=0.9325, Acc=0.6690 | MLP Loss=1.7341, Acc=0.5553\n",
      "[Studygroup][805] CNN Loss=0.9686, Acc=0.6753 | MLP Loss=1.7682, Acc=0.5671\n",
      "[Studygroup][806] CNN Loss=0.9951, Acc=0.6695 | MLP Loss=1.7016, Acc=0.5577\n",
      "[Studygroup][807] CNN Loss=0.9142, Acc=0.6720 | MLP Loss=1.7118, Acc=0.5669\n",
      "[Studygroup][808] CNN Loss=0.9208, Acc=0.6674 | MLP Loss=1.6986, Acc=0.5668\n",
      "[Studygroup][809] CNN Loss=0.9279, Acc=0.6775 | MLP Loss=1.7446, Acc=0.5720\n",
      "[Studygroup][810] CNN Loss=0.9795, Acc=0.6737 | MLP Loss=1.7606, Acc=0.5565\n",
      "[Studygroup][811] CNN Loss=0.8735, Acc=0.6723 | MLP Loss=1.6799, Acc=0.5682\n",
      "[Studygroup][812] CNN Loss=0.8909, Acc=0.6627 | MLP Loss=1.7586, Acc=0.5644\n",
      "[Studygroup][813] CNN Loss=0.9389, Acc=0.6765 | MLP Loss=1.7814, Acc=0.5614\n",
      "[Studygroup][814] CNN Loss=0.9150, Acc=0.6733 | MLP Loss=1.7110, Acc=0.5577\n",
      "[Studygroup][815] CNN Loss=1.0031, Acc=0.6708 | MLP Loss=1.7722, Acc=0.5543\n",
      "[Studygroup][816] CNN Loss=0.9232, Acc=0.6665 | MLP Loss=1.7098, Acc=0.5680\n",
      "[Studygroup][817] CNN Loss=0.8553, Acc=0.6702 | MLP Loss=1.6749, Acc=0.5578\n",
      "[Studygroup][818] CNN Loss=0.8722, Acc=0.6767 | MLP Loss=1.7284, Acc=0.5674\n",
      "[Studygroup][819] CNN Loss=0.9066, Acc=0.6726 | MLP Loss=1.6950, Acc=0.5552\n",
      "[Studygroup][820] CNN Loss=0.9055, Acc=0.6748 | MLP Loss=1.7218, Acc=0.5619\n",
      "[Studygroup][821] CNN Loss=0.8919, Acc=0.6711 | MLP Loss=1.7164, Acc=0.5589\n",
      "[Studygroup][822] CNN Loss=1.0021, Acc=0.6710 | MLP Loss=1.6833, Acc=0.5714\n",
      "[Studygroup][823] CNN Loss=0.8635, Acc=0.6745 | MLP Loss=1.6792, Acc=0.5426\n",
      "[Studygroup][824] CNN Loss=0.9724, Acc=0.6746 | MLP Loss=1.8066, Acc=0.5541\n",
      "[Studygroup][825] CNN Loss=0.9435, Acc=0.6754 | MLP Loss=1.7349, Acc=0.5679\n",
      "[Studygroup][826] CNN Loss=0.9766, Acc=0.6758 | MLP Loss=1.6762, Acc=0.5725\n",
      "[Studygroup][827] CNN Loss=0.9056, Acc=0.6707 | MLP Loss=1.6770, Acc=0.5635\n",
      "[Studygroup][828] CNN Loss=0.8790, Acc=0.6690 | MLP Loss=1.6521, Acc=0.5695\n",
      "[Studygroup][829] CNN Loss=0.8511, Acc=0.6770 | MLP Loss=1.6791, Acc=0.5650\n",
      "[Studygroup][830] CNN Loss=1.0029, Acc=0.6676 | MLP Loss=1.6538, Acc=0.5660\n",
      "[Studygroup][831] CNN Loss=0.9360, Acc=0.6606 | MLP Loss=1.6458, Acc=0.5703\n",
      "[Studygroup][832] CNN Loss=0.9771, Acc=0.6660 | MLP Loss=1.6668, Acc=0.5592\n",
      "[Studygroup][833] CNN Loss=0.9383, Acc=0.6562 | MLP Loss=1.6557, Acc=0.5712\n",
      "[Studygroup][834] CNN Loss=0.9228, Acc=0.6731 | MLP Loss=1.6373, Acc=0.5635\n",
      "[Studygroup][835] CNN Loss=0.9049, Acc=0.6772 | MLP Loss=1.7457, Acc=0.5639\n",
      "[Studygroup][836] CNN Loss=0.9496, Acc=0.6747 | MLP Loss=1.6647, Acc=0.5742\n",
      "[Studygroup][837] CNN Loss=0.8983, Acc=0.6737 | MLP Loss=1.6737, Acc=0.5724\n",
      "[Studygroup][838] CNN Loss=0.8820, Acc=0.6777 | MLP Loss=1.6903, Acc=0.5698\n",
      "[Studygroup][839] CNN Loss=0.8944, Acc=0.6726 | MLP Loss=1.7129, Acc=0.5684\n",
      "[Studygroup][840] CNN Loss=0.9946, Acc=0.6752 | MLP Loss=1.6152, Acc=0.5621\n",
      "[Studygroup][841] CNN Loss=0.9170, Acc=0.6728 | MLP Loss=1.7397, Acc=0.5532\n",
      "[Studygroup][842] CNN Loss=0.9112, Acc=0.6683 | MLP Loss=1.7313, Acc=0.5681\n",
      "[Studygroup][843] CNN Loss=0.9675, Acc=0.6611 | MLP Loss=1.7415, Acc=0.5683\n",
      "[Studygroup][844] CNN Loss=0.9252, Acc=0.6714 | MLP Loss=1.6498, Acc=0.5694\n",
      "[Studygroup][845] CNN Loss=0.8979, Acc=0.6737 | MLP Loss=1.6875, Acc=0.5714\n",
      "[Studygroup][846] CNN Loss=0.9485, Acc=0.6722 | MLP Loss=1.6839, Acc=0.5554\n",
      "[Studygroup][847] CNN Loss=0.9743, Acc=0.6721 | MLP Loss=1.7339, Acc=0.5545\n",
      "[Studygroup][848] CNN Loss=0.8994, Acc=0.6711 | MLP Loss=1.7497, Acc=0.5670\n",
      "[Studygroup][849] CNN Loss=0.8765, Acc=0.6834 | MLP Loss=1.6836, Acc=0.5537\n",
      "[Studygroup][850] CNN Loss=0.9254, Acc=0.6637 | MLP Loss=1.7484, Acc=0.5569\n",
      "[Studygroup][851] CNN Loss=1.0444, Acc=0.6701 | MLP Loss=1.7685, Acc=0.5685\n",
      "[Studygroup][852] CNN Loss=0.8670, Acc=0.6739 | MLP Loss=1.6894, Acc=0.5659\n",
      "[Studygroup][853] CNN Loss=0.9423, Acc=0.6701 | MLP Loss=1.7122, Acc=0.5643\n",
      "[Studygroup][854] CNN Loss=0.9402, Acc=0.6733 | MLP Loss=1.6190, Acc=0.5752\n",
      "[Studygroup][855] CNN Loss=0.8553, Acc=0.6746 | MLP Loss=1.6270, Acc=0.5722\n",
      "[Studygroup][856] CNN Loss=0.8304, Acc=0.6747 | MLP Loss=1.6562, Acc=0.5729\n",
      "[Studygroup][857] CNN Loss=0.9039, Acc=0.6710 | MLP Loss=1.6755, Acc=0.5755\n",
      "[Studygroup][858] CNN Loss=0.9265, Acc=0.6719 | MLP Loss=1.7032, Acc=0.5591\n",
      "[Studygroup][859] CNN Loss=0.9467, Acc=0.6733 | MLP Loss=1.7760, Acc=0.5737\n",
      "[Studygroup][860] CNN Loss=1.0348, Acc=0.6736 | MLP Loss=1.7369, Acc=0.5634\n",
      "[Studygroup][861] CNN Loss=0.9601, Acc=0.6760 | MLP Loss=1.6437, Acc=0.5685\n",
      "[Studygroup][862] CNN Loss=0.9309, Acc=0.6572 | MLP Loss=1.7202, Acc=0.5541\n",
      "[Studygroup][863] CNN Loss=1.0799, Acc=0.6708 | MLP Loss=1.8728, Acc=0.5499\n",
      "[Studygroup][864] CNN Loss=0.9058, Acc=0.6764 | MLP Loss=1.7366, Acc=0.5677\n",
      "[Studygroup][865] CNN Loss=0.9692, Acc=0.6692 | MLP Loss=1.6830, Acc=0.5689\n",
      "[Studygroup][866] CNN Loss=0.9435, Acc=0.6697 | MLP Loss=1.7019, Acc=0.5751\n",
      "[Studygroup][867] CNN Loss=0.9478, Acc=0.6720 | MLP Loss=1.6291, Acc=0.5703\n",
      "[Studygroup][868] CNN Loss=0.9319, Acc=0.6717 | MLP Loss=1.6865, Acc=0.5612\n",
      "[Studygroup][869] CNN Loss=0.8530, Acc=0.6709 | MLP Loss=1.6993, Acc=0.5612\n",
      "[Studygroup][870] CNN Loss=0.9124, Acc=0.6788 | MLP Loss=1.7183, Acc=0.5575\n",
      "[Studygroup][871] CNN Loss=0.9385, Acc=0.6691 | MLP Loss=1.8054, Acc=0.5587\n",
      "[Studygroup][872] CNN Loss=0.9144, Acc=0.6754 | MLP Loss=1.7534, Acc=0.5567\n",
      "[Studygroup][873] CNN Loss=0.9053, Acc=0.6715 | MLP Loss=1.7458, Acc=0.5602\n",
      "[Studygroup][874] CNN Loss=0.8850, Acc=0.6743 | MLP Loss=1.7515, Acc=0.5743\n",
      "[Studygroup][875] CNN Loss=0.8950, Acc=0.6698 | MLP Loss=1.6933, Acc=0.5725\n",
      "[Studygroup][876] CNN Loss=0.9572, Acc=0.6693 | MLP Loss=1.7290, Acc=0.5476\n",
      "[Studygroup][877] CNN Loss=0.8568, Acc=0.6770 | MLP Loss=1.7299, Acc=0.5694\n",
      "[Studygroup][878] CNN Loss=0.8360, Acc=0.6767 | MLP Loss=1.7583, Acc=0.5693\n",
      "[Studygroup][879] CNN Loss=0.8757, Acc=0.6677 | MLP Loss=1.7104, Acc=0.5713\n",
      "[Studygroup][880] CNN Loss=0.8872, Acc=0.6739 | MLP Loss=1.7398, Acc=0.5727\n",
      "[Studygroup][881] CNN Loss=0.8630, Acc=0.6703 | MLP Loss=1.6706, Acc=0.5643\n",
      "[Studygroup][882] CNN Loss=1.0244, Acc=0.6701 | MLP Loss=1.7551, Acc=0.5690\n",
      "[Studygroup][883] CNN Loss=0.9291, Acc=0.6745 | MLP Loss=1.7402, Acc=0.5760\n",
      "[Studygroup][884] CNN Loss=0.8951, Acc=0.6749 | MLP Loss=1.7066, Acc=0.5757\n",
      "[Studygroup][885] CNN Loss=0.9676, Acc=0.6731 | MLP Loss=1.7193, Acc=0.5684\n",
      "[Studygroup][886] CNN Loss=0.8913, Acc=0.6804 | MLP Loss=1.6815, Acc=0.5713\n",
      "[Studygroup][887] CNN Loss=1.0352, Acc=0.6600 | MLP Loss=1.7567, Acc=0.5660\n",
      "[Studygroup][888] CNN Loss=0.9689, Acc=0.6749 | MLP Loss=1.7301, Acc=0.5666\n",
      "[Studygroup][889] CNN Loss=0.9940, Acc=0.6684 | MLP Loss=1.7319, Acc=0.5687\n",
      "[Studygroup][890] CNN Loss=0.9312, Acc=0.6715 | MLP Loss=1.6911, Acc=0.5659\n",
      "[Studygroup][891] CNN Loss=0.9159, Acc=0.6752 | MLP Loss=1.6930, Acc=0.5708\n",
      "[Studygroup][892] CNN Loss=0.9280, Acc=0.6699 | MLP Loss=1.8177, Acc=0.5554\n",
      "[Studygroup][893] CNN Loss=0.9723, Acc=0.6688 | MLP Loss=1.7968, Acc=0.5602\n",
      "[Studygroup][894] CNN Loss=0.9079, Acc=0.6757 | MLP Loss=1.7646, Acc=0.5673\n",
      "[Studygroup][895] CNN Loss=0.8815, Acc=0.6757 | MLP Loss=1.6887, Acc=0.5591\n",
      "[Studygroup][896] CNN Loss=0.9491, Acc=0.6753 | MLP Loss=1.7012, Acc=0.5603\n",
      "[Studygroup][897] CNN Loss=0.9474, Acc=0.6630 | MLP Loss=1.6534, Acc=0.5726\n",
      "[Studygroup][898] CNN Loss=0.9413, Acc=0.6782 | MLP Loss=1.6558, Acc=0.5579\n",
      "[Studygroup][899] CNN Loss=0.8740, Acc=0.6715 | MLP Loss=1.6201, Acc=0.5665\n",
      "[Studygroup][900] CNN Loss=0.9876, Acc=0.6733 | MLP Loss=1.6307, Acc=0.5675\n",
      "[Studygroup][901] CNN Loss=0.9479, Acc=0.6775 | MLP Loss=1.6761, Acc=0.5791\n",
      "[Studygroup][902] CNN Loss=0.8578, Acc=0.6760 | MLP Loss=1.6126, Acc=0.5726\n",
      "[Studygroup][903] CNN Loss=0.9207, Acc=0.6754 | MLP Loss=1.7174, Acc=0.5586\n",
      "[Studygroup][904] CNN Loss=0.9145, Acc=0.6786 | MLP Loss=1.7098, Acc=0.5745\n",
      "[Studygroup][905] CNN Loss=0.8876, Acc=0.6734 | MLP Loss=1.7110, Acc=0.5738\n",
      "[Studygroup][906] CNN Loss=0.9309, Acc=0.6676 | MLP Loss=1.7022, Acc=0.5655\n",
      "[Studygroup][907] CNN Loss=0.9156, Acc=0.6763 | MLP Loss=1.7504, Acc=0.5766\n",
      "[Studygroup][908] CNN Loss=0.8343, Acc=0.6826 | MLP Loss=1.7367, Acc=0.5706\n",
      "[Studygroup][909] CNN Loss=0.9547, Acc=0.6738 | MLP Loss=1.7238, Acc=0.5466\n",
      "[Studygroup][910] CNN Loss=0.9709, Acc=0.6737 | MLP Loss=1.8456, Acc=0.5556\n",
      "[Studygroup][911] CNN Loss=0.9102, Acc=0.6689 | MLP Loss=1.6784, Acc=0.5746\n",
      "[Studygroup][912] CNN Loss=0.8847, Acc=0.6670 | MLP Loss=1.6700, Acc=0.5632\n",
      "[Studygroup][913] CNN Loss=0.8934, Acc=0.6691 | MLP Loss=1.7311, Acc=0.5731\n",
      "[Studygroup][914] CNN Loss=0.9351, Acc=0.6714 | MLP Loss=1.7019, Acc=0.5694\n",
      "[Studygroup][915] CNN Loss=0.9286, Acc=0.6791 | MLP Loss=1.6551, Acc=0.5711\n",
      "[Studygroup][916] CNN Loss=0.8900, Acc=0.6724 | MLP Loss=1.7008, Acc=0.5628\n",
      "[Studygroup][917] CNN Loss=1.0136, Acc=0.6784 | MLP Loss=1.7858, Acc=0.5699\n",
      "[Studygroup][918] CNN Loss=0.9937, Acc=0.6707 | MLP Loss=1.7935, Acc=0.5705\n",
      "[Studygroup][919] CNN Loss=0.9387, Acc=0.6577 | MLP Loss=1.6521, Acc=0.5588\n",
      "[Studygroup][920] CNN Loss=0.9568, Acc=0.6696 | MLP Loss=1.6690, Acc=0.5650\n",
      "[Studygroup][921] CNN Loss=0.8994, Acc=0.6696 | MLP Loss=1.6455, Acc=0.5707\n",
      "[Studygroup][922] CNN Loss=0.9468, Acc=0.6745 | MLP Loss=1.6809, Acc=0.5654\n",
      "[Studygroup][923] CNN Loss=0.9604, Acc=0.6748 | MLP Loss=1.7024, Acc=0.5712\n",
      "[Studygroup][924] CNN Loss=0.8900, Acc=0.6744 | MLP Loss=1.7395, Acc=0.5612\n",
      "[Studygroup][925] CNN Loss=0.9016, Acc=0.6766 | MLP Loss=1.7765, Acc=0.5545\n",
      "[Studygroup][926] CNN Loss=0.8953, Acc=0.6794 | MLP Loss=1.6916, Acc=0.5641\n",
      "[Studygroup][927] CNN Loss=0.9247, Acc=0.6751 | MLP Loss=1.7383, Acc=0.5637\n",
      "[Studygroup][928] CNN Loss=0.9161, Acc=0.6683 | MLP Loss=1.6248, Acc=0.5678\n",
      "[Studygroup][929] CNN Loss=0.8440, Acc=0.6752 | MLP Loss=1.6541, Acc=0.5726\n",
      "[Studygroup][930] CNN Loss=1.0003, Acc=0.6727 | MLP Loss=1.7085, Acc=0.5785\n",
      "[Studygroup][931] CNN Loss=0.8873, Acc=0.6761 | MLP Loss=1.6648, Acc=0.5656\n",
      "[Studygroup][932] CNN Loss=0.9308, Acc=0.6711 | MLP Loss=1.6875, Acc=0.5659\n",
      "[Studygroup][933] CNN Loss=0.8584, Acc=0.6752 | MLP Loss=1.7054, Acc=0.5732\n",
      "[Studygroup][934] CNN Loss=0.8503, Acc=0.6805 | MLP Loss=1.7102, Acc=0.5766\n",
      "[Studygroup][935] CNN Loss=0.8247, Acc=0.6751 | MLP Loss=1.6665, Acc=0.5763\n",
      "[Studygroup][936] CNN Loss=0.8898, Acc=0.6679 | MLP Loss=1.7339, Acc=0.5592\n",
      "[Studygroup][937] CNN Loss=0.9805, Acc=0.6765 | MLP Loss=1.7428, Acc=0.5704\n",
      "[Studygroup][938] CNN Loss=0.8785, Acc=0.6708 | MLP Loss=1.6992, Acc=0.5699\n",
      "[Studygroup][939] CNN Loss=0.9735, Acc=0.6552 | MLP Loss=1.7265, Acc=0.5718\n",
      "[Studygroup][940] CNN Loss=0.9725, Acc=0.6715 | MLP Loss=1.6395, Acc=0.5683\n",
      "[Studygroup][941] CNN Loss=0.9619, Acc=0.6670 | MLP Loss=1.7135, Acc=0.5800\n",
      "[Studygroup][942] CNN Loss=0.9341, Acc=0.6689 | MLP Loss=1.6536, Acc=0.5532\n",
      "[Studygroup][943] CNN Loss=0.9838, Acc=0.6589 | MLP Loss=1.7604, Acc=0.5702\n",
      "[Studygroup][944] CNN Loss=0.9792, Acc=0.6662 | MLP Loss=1.6751, Acc=0.5761\n",
      "[Studygroup][945] CNN Loss=0.8735, Acc=0.6754 | MLP Loss=1.6568, Acc=0.5763\n",
      "[Studygroup][946] CNN Loss=0.9800, Acc=0.6677 | MLP Loss=1.6900, Acc=0.5675\n",
      "[Studygroup][947] CNN Loss=0.9026, Acc=0.6725 | MLP Loss=1.5899, Acc=0.5708\n",
      "[Studygroup][948] CNN Loss=0.9087, Acc=0.6807 | MLP Loss=1.6296, Acc=0.5748\n",
      "[Studygroup][949] CNN Loss=0.8523, Acc=0.6801 | MLP Loss=1.6426, Acc=0.5748\n",
      "[Studygroup][950] CNN Loss=0.9274, Acc=0.6659 | MLP Loss=1.7586, Acc=0.5583\n",
      "[Studygroup][951] CNN Loss=0.9042, Acc=0.6742 | MLP Loss=1.7557, Acc=0.5728\n",
      "[Studygroup][952] CNN Loss=0.8760, Acc=0.6747 | MLP Loss=1.6853, Acc=0.5803\n",
      "[Studygroup][953] CNN Loss=0.9069, Acc=0.6743 | MLP Loss=1.6784, Acc=0.5719\n",
      "[Studygroup][954] CNN Loss=0.9530, Acc=0.6759 | MLP Loss=1.6635, Acc=0.5695\n",
      "[Studygroup][955] CNN Loss=0.9030, Acc=0.6653 | MLP Loss=1.6591, Acc=0.5630\n",
      "[Studygroup][956] CNN Loss=0.9173, Acc=0.6718 | MLP Loss=1.6759, Acc=0.5688\n",
      "[Studygroup][957] CNN Loss=0.9368, Acc=0.6785 | MLP Loss=1.6630, Acc=0.5662\n",
      "[Studygroup][958] CNN Loss=0.9368, Acc=0.6753 | MLP Loss=1.6419, Acc=0.5627\n",
      "[Studygroup][959] CNN Loss=0.8556, Acc=0.6697 | MLP Loss=1.6490, Acc=0.5740\n",
      "[Studygroup][960] CNN Loss=0.8768, Acc=0.6771 | MLP Loss=1.6207, Acc=0.5749\n",
      "[Studygroup][961] CNN Loss=0.9036, Acc=0.6774 | MLP Loss=1.6310, Acc=0.5641\n",
      "[Studygroup][962] CNN Loss=0.8519, Acc=0.6753 | MLP Loss=1.7382, Acc=0.5762\n",
      "[Studygroup][963] CNN Loss=0.8862, Acc=0.6784 | MLP Loss=1.6456, Acc=0.5706\n",
      "[Studygroup][964] CNN Loss=0.8784, Acc=0.6713 | MLP Loss=1.6666, Acc=0.5784\n",
      "[Studygroup][965] CNN Loss=0.8832, Acc=0.6746 | MLP Loss=1.6136, Acc=0.5673\n",
      "[Studygroup][966] CNN Loss=0.8447, Acc=0.6728 | MLP Loss=1.6647, Acc=0.5761\n",
      "[Studygroup][967] CNN Loss=0.9624, Acc=0.6715 | MLP Loss=1.6281, Acc=0.5729\n",
      "[Studygroup][968] CNN Loss=0.8263, Acc=0.6745 | MLP Loss=1.6543, Acc=0.5652\n",
      "[Studygroup][969] CNN Loss=0.8534, Acc=0.6726 | MLP Loss=1.6953, Acc=0.5722\n",
      "[Studygroup][970] CNN Loss=0.8686, Acc=0.6761 | MLP Loss=1.7096, Acc=0.5875\n",
      "[Studygroup][971] CNN Loss=0.8384, Acc=0.6740 | MLP Loss=1.6096, Acc=0.5819\n",
      "[Studygroup][972] CNN Loss=0.8613, Acc=0.6738 | MLP Loss=1.6281, Acc=0.5638\n",
      "[Studygroup][973] CNN Loss=0.8391, Acc=0.6719 | MLP Loss=1.7244, Acc=0.5728\n",
      "[Studygroup][974] CNN Loss=0.9462, Acc=0.6678 | MLP Loss=1.7419, Acc=0.5731\n",
      "[Studygroup][975] CNN Loss=0.9367, Acc=0.6719 | MLP Loss=1.7876, Acc=0.5873\n",
      "[Studygroup][976] CNN Loss=0.9875, Acc=0.6675 | MLP Loss=1.6507, Acc=0.5690\n",
      "[Studygroup][977] CNN Loss=0.8556, Acc=0.6755 | MLP Loss=1.6614, Acc=0.5771\n",
      "[Studygroup][978] CNN Loss=0.8514, Acc=0.6801 | MLP Loss=1.6604, Acc=0.5665\n",
      "[Studygroup][979] CNN Loss=0.8981, Acc=0.6627 | MLP Loss=1.7132, Acc=0.5757\n",
      "[Studygroup][980] CNN Loss=1.0448, Acc=0.6634 | MLP Loss=1.6719, Acc=0.5660\n",
      "[Studygroup][981] CNN Loss=0.9961, Acc=0.6729 | MLP Loss=1.6952, Acc=0.5752\n",
      "[Studygroup][982] CNN Loss=0.9116, Acc=0.6760 | MLP Loss=1.6594, Acc=0.5746\n",
      "[Studygroup][983] CNN Loss=0.8886, Acc=0.6803 | MLP Loss=1.7565, Acc=0.5705\n",
      "[Studygroup][984] CNN Loss=0.8774, Acc=0.6768 | MLP Loss=1.6899, Acc=0.5539\n",
      "[Studygroup][985] CNN Loss=0.9004, Acc=0.6795 | MLP Loss=1.7640, Acc=0.5719\n",
      "[Studygroup][986] CNN Loss=0.9307, Acc=0.6700 | MLP Loss=1.7719, Acc=0.5742\n",
      "[Studygroup][987] CNN Loss=1.0052, Acc=0.6745 | MLP Loss=1.7272, Acc=0.5704\n",
      "[Studygroup][988] CNN Loss=0.9284, Acc=0.6736 | MLP Loss=1.6326, Acc=0.5700\n",
      "[Studygroup][989] CNN Loss=0.8843, Acc=0.6776 | MLP Loss=1.6428, Acc=0.5727\n",
      "[Studygroup][990] CNN Loss=0.8505, Acc=0.6790 | MLP Loss=1.6306, Acc=0.5674\n",
      "[Studygroup][991] CNN Loss=0.8581, Acc=0.6698 | MLP Loss=1.6381, Acc=0.5647\n",
      "[Studygroup][992] CNN Loss=0.9409, Acc=0.6771 | MLP Loss=1.6952, Acc=0.5841\n",
      "[Studygroup][993] CNN Loss=0.9843, Acc=0.6724 | MLP Loss=1.6623, Acc=0.5703\n",
      "[Studygroup][994] CNN Loss=0.9635, Acc=0.6761 | MLP Loss=1.7389, Acc=0.5771\n",
      "[Studygroup][995] CNN Loss=0.8761, Acc=0.6771 | MLP Loss=1.6995, Acc=0.5683\n",
      "[Studygroup][996] CNN Loss=0.8524, Acc=0.6707 | MLP Loss=1.7349, Acc=0.5568\n",
      "[Studygroup][997] CNN Loss=0.9036, Acc=0.6686 | MLP Loss=1.7503, Acc=0.5613\n",
      "[Studygroup][998] CNN Loss=1.0338, Acc=0.6666 | MLP Loss=1.7530, Acc=0.5745\n",
      "[Studygroup][999] CNN Loss=0.9258, Acc=0.6731 | MLP Loss=1.6616, Acc=0.5775\n",
      "[Studygroup][1000] CNN Loss=0.9064, Acc=0.6700 | MLP Loss=1.6858, Acc=0.5723\n",
      "[Studygroup][1001] CNN Loss=0.9192, Acc=0.6784 | MLP Loss=1.6793, Acc=0.5757\n",
      "[Studygroup][1002] CNN Loss=0.9551, Acc=0.6734 | MLP Loss=1.6841, Acc=0.5831\n",
      "[Studygroup][1003] CNN Loss=0.9693, Acc=0.6599 | MLP Loss=1.5977, Acc=0.5779\n",
      "[Studygroup][1004] CNN Loss=0.9171, Acc=0.6746 | MLP Loss=1.5822, Acc=0.5694\n",
      "[Studygroup][1005] CNN Loss=0.8623, Acc=0.6754 | MLP Loss=1.6258, Acc=0.5645\n",
      "[Studygroup][1006] CNN Loss=0.9505, Acc=0.6714 | MLP Loss=1.5908, Acc=0.5808\n",
      "[Studygroup][1007] CNN Loss=0.8187, Acc=0.6803 | MLP Loss=1.6284, Acc=0.5729\n",
      "[Studygroup][1008] CNN Loss=0.9817, Acc=0.6811 | MLP Loss=1.6792, Acc=0.5681\n",
      "[Studygroup][1009] CNN Loss=0.9578, Acc=0.6701 | MLP Loss=1.6435, Acc=0.5695\n",
      "[Studygroup][1010] CNN Loss=0.8405, Acc=0.6726 | MLP Loss=1.6299, Acc=0.5752\n",
      "[Studygroup][1011] CNN Loss=0.9110, Acc=0.6747 | MLP Loss=1.6649, Acc=0.5830\n",
      "[Studygroup][1012] CNN Loss=0.9501, Acc=0.6754 | MLP Loss=1.6377, Acc=0.5627\n",
      "[Studygroup][1013] CNN Loss=0.9332, Acc=0.6673 | MLP Loss=1.6337, Acc=0.5698\n",
      "[Studygroup][1014] CNN Loss=0.9731, Acc=0.6748 | MLP Loss=1.5988, Acc=0.5789\n",
      "[Studygroup][1015] CNN Loss=1.1356, Acc=0.6630 | MLP Loss=1.7164, Acc=0.5685\n",
      "[Studygroup][1016] CNN Loss=0.9457, Acc=0.6787 | MLP Loss=1.5746, Acc=0.5767\n",
      "[Studygroup][1017] CNN Loss=0.8688, Acc=0.6853 | MLP Loss=1.5719, Acc=0.5783\n",
      "[Studygroup][1018] CNN Loss=0.8361, Acc=0.6794 | MLP Loss=1.6462, Acc=0.5816\n",
      "[Studygroup][1019] CNN Loss=0.8190, Acc=0.6737 | MLP Loss=1.6380, Acc=0.5815\n",
      "[Studygroup][1020] CNN Loss=0.9402, Acc=0.6726 | MLP Loss=1.7524, Acc=0.5735\n",
      "[Studygroup][1021] CNN Loss=0.9882, Acc=0.6749 | MLP Loss=1.7917, Acc=0.5694\n",
      "[Studygroup][1022] CNN Loss=0.9335, Acc=0.6807 | MLP Loss=1.7678, Acc=0.5660\n",
      "[Studygroup][1023] CNN Loss=0.9502, Acc=0.6826 | MLP Loss=1.7432, Acc=0.5688\n",
      "[Studygroup][1024] CNN Loss=0.9048, Acc=0.6754 | MLP Loss=1.7006, Acc=0.5826\n",
      "[Studygroup][1025] CNN Loss=0.9436, Acc=0.6748 | MLP Loss=1.6577, Acc=0.5751\n",
      "[Studygroup][1026] CNN Loss=0.9191, Acc=0.6774 | MLP Loss=1.6258, Acc=0.5800\n",
      "[Studygroup][1027] CNN Loss=0.8073, Acc=0.6814 | MLP Loss=1.6774, Acc=0.5714\n",
      "[Studygroup][1028] CNN Loss=0.9065, Acc=0.6778 | MLP Loss=1.6666, Acc=0.5759\n",
      "[Studygroup][1029] CNN Loss=0.8994, Acc=0.6777 | MLP Loss=1.6307, Acc=0.5698\n",
      "[Studygroup][1030] CNN Loss=1.0803, Acc=0.6755 | MLP Loss=1.6677, Acc=0.5731\n",
      "[Studygroup][1031] CNN Loss=0.9770, Acc=0.6749 | MLP Loss=1.6923, Acc=0.5696\n",
      "[Studygroup][1032] CNN Loss=0.9778, Acc=0.6777 | MLP Loss=1.6387, Acc=0.5774\n",
      "[Studygroup][1033] CNN Loss=0.9450, Acc=0.6760 | MLP Loss=1.5861, Acc=0.5732\n",
      "[Studygroup][1034] CNN Loss=0.9086, Acc=0.6764 | MLP Loss=1.6358, Acc=0.5786\n",
      "[Studygroup][1035] CNN Loss=0.8736, Acc=0.6867 | MLP Loss=1.6617, Acc=0.5725\n",
      "[Studygroup][1036] CNN Loss=0.8686, Acc=0.6839 | MLP Loss=1.6519, Acc=0.5776\n",
      "[Studygroup][1037] CNN Loss=0.8451, Acc=0.6838 | MLP Loss=1.6917, Acc=0.5766\n",
      "[Studygroup][1038] CNN Loss=0.8669, Acc=0.6829 | MLP Loss=1.7716, Acc=0.5713\n",
      "[Studygroup][1039] CNN Loss=0.8762, Acc=0.6810 | MLP Loss=1.6178, Acc=0.5784\n",
      "[Studygroup][1040] CNN Loss=0.9209, Acc=0.6747 | MLP Loss=1.7926, Acc=0.5741\n",
      "[Studygroup][1041] CNN Loss=0.9515, Acc=0.6817 | MLP Loss=1.6915, Acc=0.5647\n",
      "[Studygroup][1042] CNN Loss=1.0337, Acc=0.6746 | MLP Loss=1.7524, Acc=0.5669\n",
      "[Studygroup][1043] CNN Loss=0.9520, Acc=0.6785 | MLP Loss=1.6737, Acc=0.5789\n",
      "[Studygroup][1044] CNN Loss=1.0267, Acc=0.6725 | MLP Loss=1.6695, Acc=0.5757\n",
      "[Studygroup][1045] CNN Loss=0.8492, Acc=0.6768 | MLP Loss=1.6349, Acc=0.5783\n",
      "[Studygroup][1046] CNN Loss=0.9087, Acc=0.6828 | MLP Loss=1.6551, Acc=0.5685\n",
      "[Studygroup][1047] CNN Loss=0.8559, Acc=0.6779 | MLP Loss=1.6346, Acc=0.5821\n",
      "[Studygroup][1048] CNN Loss=0.9215, Acc=0.6689 | MLP Loss=1.6772, Acc=0.5597\n",
      "[Studygroup][1049] CNN Loss=0.9479, Acc=0.6797 | MLP Loss=1.8133, Acc=0.5741\n",
      "[Studygroup][1050] CNN Loss=0.9086, Acc=0.6735 | MLP Loss=1.6873, Acc=0.5812\n",
      "[Studygroup][1051] CNN Loss=0.9328, Acc=0.6783 | MLP Loss=1.6605, Acc=0.5745\n",
      "[Studygroup][1052] CNN Loss=0.9012, Acc=0.6766 | MLP Loss=1.6846, Acc=0.5816\n",
      "[Studygroup][1053] CNN Loss=0.8755, Acc=0.6860 | MLP Loss=1.6370, Acc=0.5789\n",
      "[Studygroup][1054] CNN Loss=0.8831, Acc=0.6805 | MLP Loss=1.6360, Acc=0.5725\n",
      "[Studygroup][1055] CNN Loss=0.8220, Acc=0.6845 | MLP Loss=1.7456, Acc=0.5701\n",
      "[Studygroup][1056] CNN Loss=0.9049, Acc=0.6811 | MLP Loss=1.6857, Acc=0.5795\n",
      "[Studygroup][1057] CNN Loss=0.8883, Acc=0.6770 | MLP Loss=1.6662, Acc=0.5798\n",
      "[Studygroup][1058] CNN Loss=0.9156, Acc=0.6753 | MLP Loss=1.6616, Acc=0.5715\n",
      "[Studygroup][1059] CNN Loss=0.9245, Acc=0.6791 | MLP Loss=1.6064, Acc=0.5767\n",
      "[Studygroup][1060] CNN Loss=0.9239, Acc=0.6804 | MLP Loss=1.6316, Acc=0.5715\n",
      "[Studygroup][1061] CNN Loss=0.8863, Acc=0.6833 | MLP Loss=1.6760, Acc=0.5739\n",
      "[Studygroup][1062] CNN Loss=0.9349, Acc=0.6815 | MLP Loss=1.6215, Acc=0.5789\n",
      "[Studygroup][1063] CNN Loss=0.9017, Acc=0.6842 | MLP Loss=1.6536, Acc=0.5723\n",
      "[Studygroup][1064] CNN Loss=0.8772, Acc=0.6808 | MLP Loss=1.7555, Acc=0.5737\n",
      "[Studygroup][1065] CNN Loss=0.9264, Acc=0.6804 | MLP Loss=1.6658, Acc=0.5806\n",
      "[Studygroup][1066] CNN Loss=0.9028, Acc=0.6810 | MLP Loss=1.7148, Acc=0.5813\n",
      "[Studygroup][1067] CNN Loss=0.8996, Acc=0.6754 | MLP Loss=1.6932, Acc=0.5780\n",
      "[Studygroup][1068] CNN Loss=0.9016, Acc=0.6814 | MLP Loss=1.6689, Acc=0.5688\n",
      "[Studygroup][1069] CNN Loss=0.8774, Acc=0.6746 | MLP Loss=1.6680, Acc=0.5763\n",
      "[Studygroup][1070] CNN Loss=0.9437, Acc=0.6731 | MLP Loss=1.6199, Acc=0.5819\n",
      "[Studygroup][1071] CNN Loss=1.0010, Acc=0.6663 | MLP Loss=1.6604, Acc=0.5770\n",
      "[Studygroup][1072] CNN Loss=0.9391, Acc=0.6741 | MLP Loss=1.6039, Acc=0.5821\n",
      "[Studygroup][1073] CNN Loss=0.8880, Acc=0.6782 | MLP Loss=1.6274, Acc=0.5817\n",
      "[Studygroup][1074] CNN Loss=0.9389, Acc=0.6770 | MLP Loss=1.7285, Acc=0.5730\n",
      "[Studygroup][1075] CNN Loss=0.8658, Acc=0.6712 | MLP Loss=1.7228, Acc=0.5700\n",
      "[Studygroup][1076] CNN Loss=0.9165, Acc=0.6784 | MLP Loss=1.6812, Acc=0.5841\n",
      "[Studygroup][1077] CNN Loss=0.8570, Acc=0.6734 | MLP Loss=1.6856, Acc=0.5705\n",
      "[Studygroup][1078] CNN Loss=0.9573, Acc=0.6700 | MLP Loss=1.6639, Acc=0.5866\n",
      "[Studygroup][1079] CNN Loss=0.9040, Acc=0.6780 | MLP Loss=1.6685, Acc=0.5763\n",
      "[Studygroup][1080] CNN Loss=0.8331, Acc=0.6738 | MLP Loss=1.6548, Acc=0.5770\n",
      "[Studygroup][1081] CNN Loss=0.8880, Acc=0.6771 | MLP Loss=1.6781, Acc=0.5785\n",
      "[Studygroup][1082] CNN Loss=1.0073, Acc=0.6795 | MLP Loss=1.6669, Acc=0.5547\n",
      "[Studygroup][1083] CNN Loss=0.9130, Acc=0.6696 | MLP Loss=1.6449, Acc=0.5743\n",
      "[Studygroup][1084] CNN Loss=0.8775, Acc=0.6774 | MLP Loss=1.6210, Acc=0.5742\n",
      "[Studygroup][1085] CNN Loss=0.8978, Acc=0.6676 | MLP Loss=1.6442, Acc=0.5822\n",
      "[Studygroup][1086] CNN Loss=0.9883, Acc=0.6753 | MLP Loss=1.6667, Acc=0.5760\n",
      "[Studygroup][1087] CNN Loss=0.8479, Acc=0.6715 | MLP Loss=1.6255, Acc=0.5782\n",
      "[Studygroup][1088] CNN Loss=0.8718, Acc=0.6730 | MLP Loss=1.6887, Acc=0.5662\n",
      "[Studygroup][1089] CNN Loss=0.8870, Acc=0.6676 | MLP Loss=1.7096, Acc=0.5654\n",
      "[Studygroup][1090] CNN Loss=0.8890, Acc=0.6705 | MLP Loss=1.7186, Acc=0.5699\n",
      "[Studygroup][1091] CNN Loss=0.9264, Acc=0.6793 | MLP Loss=1.6490, Acc=0.5791\n",
      "[Studygroup][1092] CNN Loss=0.9019, Acc=0.6730 | MLP Loss=1.7027, Acc=0.5784\n",
      "[Studygroup][1093] CNN Loss=0.8912, Acc=0.6712 | MLP Loss=1.6548, Acc=0.5598\n",
      "[Studygroup][1094] CNN Loss=0.8595, Acc=0.6747 | MLP Loss=1.6655, Acc=0.5738\n",
      "[Studygroup][1095] CNN Loss=0.8801, Acc=0.6619 | MLP Loss=1.6268, Acc=0.5802\n",
      "[Studygroup][1096] CNN Loss=0.9762, Acc=0.6703 | MLP Loss=1.6047, Acc=0.5725\n",
      "[Studygroup][1097] CNN Loss=1.0404, Acc=0.6716 | MLP Loss=1.6573, Acc=0.5705\n",
      "[Studygroup][1098] CNN Loss=0.9738, Acc=0.6718 | MLP Loss=1.5565, Acc=0.5737\n",
      "[Studygroup][1099] CNN Loss=0.8360, Acc=0.6768 | MLP Loss=1.6713, Acc=0.5740\n",
      "[Studygroup][1100] CNN Loss=0.9441, Acc=0.6711 | MLP Loss=1.7483, Acc=0.5668\n",
      "[Studygroup][1101] CNN Loss=0.8916, Acc=0.6724 | MLP Loss=1.6922, Acc=0.5813\n",
      "[Studygroup][1102] CNN Loss=0.8468, Acc=0.6762 | MLP Loss=1.6428, Acc=0.5854\n",
      "[Studygroup][1103] CNN Loss=0.8811, Acc=0.6736 | MLP Loss=1.6679, Acc=0.5752\n",
      "[Studygroup][1104] CNN Loss=0.9179, Acc=0.6756 | MLP Loss=1.6546, Acc=0.5573\n",
      "[Studygroup][1105] CNN Loss=0.9062, Acc=0.6798 | MLP Loss=1.7170, Acc=0.5673\n",
      "[Studygroup][1106] CNN Loss=0.8917, Acc=0.6718 | MLP Loss=1.7351, Acc=0.5763\n",
      "[Studygroup][1107] CNN Loss=0.8490, Acc=0.6758 | MLP Loss=1.6699, Acc=0.5859\n",
      "[Studygroup][1108] CNN Loss=0.8320, Acc=0.6770 | MLP Loss=1.6076, Acc=0.5938\n",
      "[Studygroup][1109] CNN Loss=0.9572, Acc=0.6799 | MLP Loss=1.7171, Acc=0.5645\n",
      "[Studygroup][1110] CNN Loss=0.9661, Acc=0.6704 | MLP Loss=1.7465, Acc=0.5683\n",
      "[Studygroup][1111] CNN Loss=0.8729, Acc=0.6781 | MLP Loss=1.6049, Acc=0.5615\n",
      "[Studygroup][1112] CNN Loss=1.0065, Acc=0.6639 | MLP Loss=1.7656, Acc=0.5638\n",
      "[Studygroup][1113] CNN Loss=1.0079, Acc=0.6706 | MLP Loss=1.6280, Acc=0.5707\n",
      "[Studygroup][1114] CNN Loss=0.9728, Acc=0.6558 | MLP Loss=1.6277, Acc=0.5830\n",
      "[Studygroup][1115] CNN Loss=0.8610, Acc=0.6739 | MLP Loss=1.6742, Acc=0.5616\n",
      "[Studygroup][1116] CNN Loss=0.9578, Acc=0.6683 | MLP Loss=1.7120, Acc=0.5613\n",
      "[Studygroup][1117] CNN Loss=0.8610, Acc=0.6804 | MLP Loss=1.7370, Acc=0.5725\n",
      "[Studygroup][1118] CNN Loss=0.8580, Acc=0.6825 | MLP Loss=1.6980, Acc=0.5797\n",
      "[Studygroup][1119] CNN Loss=0.9394, Acc=0.6740 | MLP Loss=1.6971, Acc=0.5634\n",
      "[Studygroup][1120] CNN Loss=0.9728, Acc=0.6760 | MLP Loss=1.7503, Acc=0.5695\n",
      "[Studygroup][1121] CNN Loss=1.0212, Acc=0.6789 | MLP Loss=1.7100, Acc=0.5787\n",
      "[Studygroup][1122] CNN Loss=0.9143, Acc=0.6652 | MLP Loss=1.6175, Acc=0.5807\n",
      "[Studygroup][1123] CNN Loss=0.8401, Acc=0.6781 | MLP Loss=1.5753, Acc=0.5713\n",
      "[Studygroup][1124] CNN Loss=0.8589, Acc=0.6738 | MLP Loss=1.6566, Acc=0.5828\n",
      "[Studygroup][1125] CNN Loss=0.9082, Acc=0.6717 | MLP Loss=1.6292, Acc=0.5691\n",
      "[Studygroup][1126] CNN Loss=1.0603, Acc=0.6686 | MLP Loss=1.6715, Acc=0.5805\n",
      "[Studygroup][1127] CNN Loss=0.9340, Acc=0.6719 | MLP Loss=1.6185, Acc=0.5672\n",
      "[Studygroup][1128] CNN Loss=0.9081, Acc=0.6698 | MLP Loss=1.6330, Acc=0.5807\n",
      "[Studygroup][1129] CNN Loss=0.9086, Acc=0.6805 | MLP Loss=1.6876, Acc=0.5849\n",
      "[Studygroup][1130] CNN Loss=0.8282, Acc=0.6752 | MLP Loss=1.6369, Acc=0.5775\n",
      "[Studygroup][1131] CNN Loss=0.9249, Acc=0.6738 | MLP Loss=1.6338, Acc=0.5727\n",
      "[Studygroup][1132] CNN Loss=0.9149, Acc=0.6744 | MLP Loss=1.6215, Acc=0.5778\n",
      "[Studygroup][1133] CNN Loss=0.8196, Acc=0.6790 | MLP Loss=1.6212, Acc=0.5718\n",
      "[Studygroup][1134] CNN Loss=0.8871, Acc=0.6720 | MLP Loss=1.6857, Acc=0.5827\n",
      "[Studygroup][1135] CNN Loss=0.9056, Acc=0.6795 | MLP Loss=1.6853, Acc=0.5783\n",
      "[Studygroup][1136] CNN Loss=0.9233, Acc=0.6810 | MLP Loss=1.6913, Acc=0.5741\n",
      "[Studygroup][1137] CNN Loss=1.0384, Acc=0.6705 | MLP Loss=1.6652, Acc=0.5788\n",
      "[Studygroup][1138] CNN Loss=0.9067, Acc=0.6740 | MLP Loss=1.7166, Acc=0.5583\n",
      "[Studygroup][1139] CNN Loss=0.9339, Acc=0.6733 | MLP Loss=1.6602, Acc=0.5784\n",
      "[Studygroup][1140] CNN Loss=0.9101, Acc=0.6784 | MLP Loss=1.5894, Acc=0.5797\n",
      "[Studygroup][1141] CNN Loss=0.9012, Acc=0.6733 | MLP Loss=1.6142, Acc=0.5815\n",
      "[Studygroup][1142] CNN Loss=0.9291, Acc=0.6780 | MLP Loss=1.6708, Acc=0.5587\n",
      "[Studygroup][1143] CNN Loss=0.9177, Acc=0.6697 | MLP Loss=1.7221, Acc=0.5779\n",
      "[Studygroup][1144] CNN Loss=0.8944, Acc=0.6773 | MLP Loss=1.5889, Acc=0.5689\n",
      "[Studygroup][1145] CNN Loss=0.9229, Acc=0.6712 | MLP Loss=1.6345, Acc=0.5820\n",
      "[Studygroup][1146] CNN Loss=0.9156, Acc=0.6755 | MLP Loss=1.6335, Acc=0.5864\n",
      "[Studygroup][1147] CNN Loss=0.9310, Acc=0.6599 | MLP Loss=1.6100, Acc=0.5781\n",
      "[Studygroup][1148] CNN Loss=0.9241, Acc=0.6776 | MLP Loss=1.5771, Acc=0.5782\n",
      "[Studygroup][1149] CNN Loss=0.8785, Acc=0.6765 | MLP Loss=1.6328, Acc=0.5799\n",
      "[Studygroup][1150] CNN Loss=0.9217, Acc=0.6771 | MLP Loss=1.6576, Acc=0.5748\n",
      "[Studygroup][1151] CNN Loss=0.9255, Acc=0.6748 | MLP Loss=1.6425, Acc=0.5815\n",
      "[Studygroup][1152] CNN Loss=0.9312, Acc=0.6629 | MLP Loss=1.6766, Acc=0.5662\n",
      "[Studygroup][1153] CNN Loss=1.0440, Acc=0.6787 | MLP Loss=1.7375, Acc=0.5763\n",
      "[Studygroup][1154] CNN Loss=0.9249, Acc=0.6756 | MLP Loss=1.6593, Acc=0.5866\n",
      "[Studygroup][1155] CNN Loss=0.9378, Acc=0.6819 | MLP Loss=1.5967, Acc=0.5864\n",
      "[Studygroup][1156] CNN Loss=0.8637, Acc=0.6780 | MLP Loss=1.6538, Acc=0.5770\n",
      "[Studygroup][1157] CNN Loss=0.9207, Acc=0.6680 | MLP Loss=1.7265, Acc=0.5784\n",
      "[Studygroup][1158] CNN Loss=0.8704, Acc=0.6744 | MLP Loss=1.6437, Acc=0.5844\n",
      "[Studygroup][1159] CNN Loss=0.8501, Acc=0.6782 | MLP Loss=1.5838, Acc=0.5678\n",
      "[Studygroup][1160] CNN Loss=0.9504, Acc=0.6736 | MLP Loss=1.6937, Acc=0.5868\n",
      "[Studygroup][1161] CNN Loss=0.9756, Acc=0.6722 | MLP Loss=1.6242, Acc=0.5710\n",
      "[Studygroup][1162] CNN Loss=0.9548, Acc=0.6767 | MLP Loss=1.6517, Acc=0.5763\n",
      "[Studygroup][1163] CNN Loss=0.8635, Acc=0.6801 | MLP Loss=1.6668, Acc=0.5756\n",
      "[Studygroup][1164] CNN Loss=0.8819, Acc=0.6818 | MLP Loss=1.6540, Acc=0.5800\n",
      "[Studygroup][1165] CNN Loss=0.9210, Acc=0.6748 | MLP Loss=1.5691, Acc=0.5723\n",
      "[Studygroup][1166] CNN Loss=0.8584, Acc=0.6776 | MLP Loss=1.6001, Acc=0.5758\n",
      "[Studygroup][1167] CNN Loss=0.9250, Acc=0.6730 | MLP Loss=1.7092, Acc=0.5781\n",
      "[Studygroup][1168] CNN Loss=0.8891, Acc=0.6769 | MLP Loss=1.6181, Acc=0.5863\n",
      "[Studygroup][1169] CNN Loss=0.8573, Acc=0.6801 | MLP Loss=1.6554, Acc=0.5846\n",
      "[Studygroup][1170] CNN Loss=0.8447, Acc=0.6727 | MLP Loss=1.6138, Acc=0.5849\n",
      "[Studygroup][1171] CNN Loss=0.9571, Acc=0.6780 | MLP Loss=1.6144, Acc=0.5856\n",
      "[Studygroup][1172] CNN Loss=0.8902, Acc=0.6692 | MLP Loss=1.6620, Acc=0.5784\n",
      "[Studygroup][1173] CNN Loss=0.8832, Acc=0.6767 | MLP Loss=1.6707, Acc=0.5833\n",
      "[Studygroup][1174] CNN Loss=1.0201, Acc=0.6698 | MLP Loss=1.6427, Acc=0.5809\n",
      "[Studygroup][1175] CNN Loss=0.9598, Acc=0.6678 | MLP Loss=1.6748, Acc=0.5804\n",
      "[Studygroup][1176] CNN Loss=0.9339, Acc=0.6637 | MLP Loss=1.6415, Acc=0.5831\n",
      "[Studygroup][1177] CNN Loss=0.8758, Acc=0.6763 | MLP Loss=1.5981, Acc=0.5738\n",
      "[Studygroup][1178] CNN Loss=0.9093, Acc=0.6716 | MLP Loss=1.6646, Acc=0.5585\n",
      "[Studygroup][1179] CNN Loss=0.9210, Acc=0.6781 | MLP Loss=1.7622, Acc=0.5628\n",
      "[Studygroup][1180] CNN Loss=0.8645, Acc=0.6788 | MLP Loss=1.6633, Acc=0.5862\n",
      "[Studygroup][1181] CNN Loss=0.9564, Acc=0.6782 | MLP Loss=1.6739, Acc=0.5809\n",
      "[Studygroup][1182] CNN Loss=0.9498, Acc=0.6757 | MLP Loss=1.6195, Acc=0.5721\n",
      "[Studygroup][1183] CNN Loss=0.8824, Acc=0.6678 | MLP Loss=1.6499, Acc=0.5787\n",
      "[Studygroup][1184] CNN Loss=0.8448, Acc=0.6785 | MLP Loss=1.6059, Acc=0.5756\n",
      "[Studygroup][1185] CNN Loss=0.9443, Acc=0.6771 | MLP Loss=1.6193, Acc=0.5819\n",
      "[Studygroup][1186] CNN Loss=0.9143, Acc=0.6770 | MLP Loss=1.6327, Acc=0.5675\n",
      "[Studygroup][1187] CNN Loss=0.8728, Acc=0.6765 | MLP Loss=1.6773, Acc=0.5810\n",
      "[Studygroup][1188] CNN Loss=0.8833, Acc=0.6804 | MLP Loss=1.6085, Acc=0.5889\n",
      "[Studygroup][1189] CNN Loss=0.9431, Acc=0.6742 | MLP Loss=1.6819, Acc=0.5812\n",
      "[Studygroup][1190] CNN Loss=0.9370, Acc=0.6787 | MLP Loss=1.6684, Acc=0.5821\n",
      "[Studygroup][1191] CNN Loss=0.8889, Acc=0.6832 | MLP Loss=1.6331, Acc=0.5733\n",
      "[Studygroup][1192] CNN Loss=0.8362, Acc=0.6800 | MLP Loss=1.6673, Acc=0.5726\n",
      "[Studygroup][1193] CNN Loss=0.8648, Acc=0.6786 | MLP Loss=1.7084, Acc=0.5681\n",
      "[Studygroup][1194] CNN Loss=0.9084, Acc=0.6777 | MLP Loss=1.7044, Acc=0.5697\n",
      "[Studygroup][1195] CNN Loss=0.9511, Acc=0.6750 | MLP Loss=1.7433, Acc=0.5667\n",
      "[Studygroup][1196] CNN Loss=0.9011, Acc=0.6790 | MLP Loss=1.6743, Acc=0.5713\n",
      "[Studygroup][1197] CNN Loss=0.8841, Acc=0.6771 | MLP Loss=1.7648, Acc=0.5695\n",
      "[Studygroup][1198] CNN Loss=0.8565, Acc=0.6760 | MLP Loss=1.6721, Acc=0.5774\n",
      "[Studygroup][1199] CNN Loss=0.8324, Acc=0.6811 | MLP Loss=1.6724, Acc=0.5834\n",
      "[Studygroup][1200] CNN Loss=0.9345, Acc=0.6724 | MLP Loss=1.7071, Acc=0.5774\n",
      "[Studygroup][1201] CNN Loss=0.8909, Acc=0.6804 | MLP Loss=1.6576, Acc=0.5826\n",
      "[Studygroup][1202] CNN Loss=0.9035, Acc=0.6792 | MLP Loss=1.5990, Acc=0.5870\n",
      "[Studygroup][1203] CNN Loss=0.8662, Acc=0.6794 | MLP Loss=1.6072, Acc=0.5792\n",
      "[Studygroup][1204] CNN Loss=0.8145, Acc=0.6835 | MLP Loss=1.6694, Acc=0.5780\n",
      "[Studygroup][1205] CNN Loss=0.9408, Acc=0.6840 | MLP Loss=1.6416, Acc=0.5772\n",
      "[Studygroup][1206] CNN Loss=0.9191, Acc=0.6761 | MLP Loss=1.6944, Acc=0.5802\n",
      "[Studygroup][1207] CNN Loss=0.8410, Acc=0.6794 | MLP Loss=1.5842, Acc=0.5766\n",
      "[Studygroup][1208] CNN Loss=0.8590, Acc=0.6827 | MLP Loss=1.5938, Acc=0.5869\n",
      "[Studygroup][1209] CNN Loss=1.0633, Acc=0.6741 | MLP Loss=1.7650, Acc=0.5743\n",
      "[Studygroup][1210] CNN Loss=0.9932, Acc=0.6738 | MLP Loss=1.8487, Acc=0.5571\n",
      "[Studygroup][1211] CNN Loss=0.9295, Acc=0.6739 | MLP Loss=1.8064, Acc=0.5656\n",
      "[Studygroup][1212] CNN Loss=0.9868, Acc=0.6556 | MLP Loss=1.6963, Acc=0.5722\n",
      "[Studygroup][1213] CNN Loss=0.9071, Acc=0.6788 | MLP Loss=1.6541, Acc=0.5609\n",
      "[Studygroup][1214] CNN Loss=0.9736, Acc=0.6745 | MLP Loss=1.6002, Acc=0.5790\n",
      "[Studygroup][1215] CNN Loss=1.0021, Acc=0.6766 | MLP Loss=1.7193, Acc=0.5854\n",
      "[Studygroup][1216] CNN Loss=0.9397, Acc=0.6771 | MLP Loss=1.6335, Acc=0.5783\n",
      "[Studygroup][1217] CNN Loss=0.8835, Acc=0.6833 | MLP Loss=1.6273, Acc=0.5815\n",
      "[Studygroup][1218] CNN Loss=0.9378, Acc=0.6634 | MLP Loss=1.6866, Acc=0.5843\n",
      "[Studygroup][1219] CNN Loss=0.8740, Acc=0.6757 | MLP Loss=1.6281, Acc=0.5752\n",
      "[Studygroup][1220] CNN Loss=0.8801, Acc=0.6749 | MLP Loss=1.5622, Acc=0.5827\n",
      "[Studygroup][1221] CNN Loss=0.8386, Acc=0.6729 | MLP Loss=1.6299, Acc=0.5725\n",
      "[Studygroup][1222] CNN Loss=0.9116, Acc=0.6752 | MLP Loss=1.6331, Acc=0.5874\n",
      "[Studygroup][1223] CNN Loss=0.9154, Acc=0.6737 | MLP Loss=1.6065, Acc=0.5868\n",
      "[Studygroup][1224] CNN Loss=0.8594, Acc=0.6769 | MLP Loss=1.6018, Acc=0.5850\n",
      "[Studygroup][1225] CNN Loss=0.8612, Acc=0.6733 | MLP Loss=1.6580, Acc=0.5861\n",
      "[Studygroup][1226] CNN Loss=1.0275, Acc=0.6587 | MLP Loss=1.8005, Acc=0.5692\n",
      "[Studygroup][1227] CNN Loss=0.9034, Acc=0.6756 | MLP Loss=1.8482, Acc=0.5739\n",
      "[Studygroup][1228] CNN Loss=0.8864, Acc=0.6759 | MLP Loss=1.6529, Acc=0.5760\n",
      "[Studygroup][1229] CNN Loss=0.8865, Acc=0.6794 | MLP Loss=1.7088, Acc=0.5776\n",
      "[Studygroup][1230] CNN Loss=0.9789, Acc=0.6812 | MLP Loss=1.6515, Acc=0.5796\n",
      "[Studygroup][1231] CNN Loss=0.8875, Acc=0.6712 | MLP Loss=1.6670, Acc=0.5770\n",
      "[Studygroup][1232] CNN Loss=0.9604, Acc=0.6670 | MLP Loss=1.7199, Acc=0.5739\n",
      "[Studygroup][1233] CNN Loss=0.8985, Acc=0.6826 | MLP Loss=1.6893, Acc=0.5808\n",
      "[Studygroup][1234] CNN Loss=0.9294, Acc=0.6802 | MLP Loss=1.5762, Acc=0.5867\n",
      "[Studygroup][1235] CNN Loss=0.9198, Acc=0.6778 | MLP Loss=1.6077, Acc=0.5895\n",
      "[Studygroup][1236] CNN Loss=0.9168, Acc=0.6690 | MLP Loss=1.6830, Acc=0.5733\n",
      "[Studygroup][1237] CNN Loss=0.8796, Acc=0.6688 | MLP Loss=1.6711, Acc=0.5790\n",
      "[Studygroup][1238] CNN Loss=0.9090, Acc=0.6825 | MLP Loss=1.7153, Acc=0.5827\n",
      "[Studygroup][1239] CNN Loss=0.9132, Acc=0.6774 | MLP Loss=1.6674, Acc=0.5866\n",
      "[Studygroup][1240] CNN Loss=1.0178, Acc=0.6682 | MLP Loss=1.6460, Acc=0.5770\n",
      "[Studygroup][1241] CNN Loss=0.8461, Acc=0.6758 | MLP Loss=1.6296, Acc=0.5728\n",
      "[Studygroup][1242] CNN Loss=0.8498, Acc=0.6761 | MLP Loss=1.6268, Acc=0.5836\n",
      "[Studygroup][1243] CNN Loss=0.8896, Acc=0.6697 | MLP Loss=1.6192, Acc=0.5775\n",
      "[Studygroup][1244] CNN Loss=0.8482, Acc=0.6800 | MLP Loss=1.6674, Acc=0.5881\n",
      "[Studygroup][1245] CNN Loss=0.9472, Acc=0.6833 | MLP Loss=1.6783, Acc=0.5843\n",
      "[Studygroup][1246] CNN Loss=0.9252, Acc=0.6788 | MLP Loss=1.6659, Acc=0.5945\n",
      "[Studygroup][1247] CNN Loss=1.0482, Acc=0.6746 | MLP Loss=1.7402, Acc=0.5852\n",
      "[Studygroup][1248] CNN Loss=0.8678, Acc=0.6765 | MLP Loss=1.6386, Acc=0.5873\n",
      "[Studygroup][1249] CNN Loss=0.8751, Acc=0.6779 | MLP Loss=1.6793, Acc=0.5792\n",
      "[Studygroup][1250] CNN Loss=0.8538, Acc=0.6721 | MLP Loss=1.6972, Acc=0.5856\n",
      "[Studygroup][1251] CNN Loss=0.8480, Acc=0.6796 | MLP Loss=1.6627, Acc=0.5729\n",
      "[Studygroup][1252] CNN Loss=0.8825, Acc=0.6794 | MLP Loss=1.6142, Acc=0.5918\n",
      "[Studygroup][1253] CNN Loss=0.8500, Acc=0.6783 | MLP Loss=1.6348, Acc=0.5789\n",
      "[Studygroup][1254] CNN Loss=0.8369, Acc=0.6797 | MLP Loss=1.7281, Acc=0.5761\n",
      "[Studygroup][1255] CNN Loss=0.9599, Acc=0.6777 | MLP Loss=1.8312, Acc=0.5717\n",
      "[Studygroup][1256] CNN Loss=0.8931, Acc=0.6781 | MLP Loss=1.6492, Acc=0.5801\n",
      "[Studygroup][1257] CNN Loss=0.9292, Acc=0.6778 | MLP Loss=1.6873, Acc=0.5950\n",
      "[Studygroup][1258] CNN Loss=0.8654, Acc=0.6745 | MLP Loss=1.6058, Acc=0.5709\n",
      "[Studygroup][1259] CNN Loss=0.9013, Acc=0.6723 | MLP Loss=1.6508, Acc=0.5787\n",
      "[Studygroup][1260] CNN Loss=0.8661, Acc=0.6820 | MLP Loss=1.6649, Acc=0.5880\n",
      "[Studygroup][1261] CNN Loss=0.9543, Acc=0.6753 | MLP Loss=1.6033, Acc=0.5696\n",
      "[Studygroup][1262] CNN Loss=0.8680, Acc=0.6733 | MLP Loss=1.7207, Acc=0.5897\n",
      "[Studygroup][1263] CNN Loss=0.9154, Acc=0.6739 | MLP Loss=1.6690, Acc=0.5798\n",
      "[Studygroup][1264] CNN Loss=0.9238, Acc=0.6789 | MLP Loss=1.6890, Acc=0.5833\n",
      "[Studygroup][1265] CNN Loss=0.8837, Acc=0.6768 | MLP Loss=1.6774, Acc=0.5782\n",
      "[Studygroup][1266] CNN Loss=1.0147, Acc=0.6642 | MLP Loss=1.6570, Acc=0.5622\n",
      "[Studygroup][1267] CNN Loss=0.9352, Acc=0.6691 | MLP Loss=1.6226, Acc=0.5855\n",
      "[Studygroup][1268] CNN Loss=0.8706, Acc=0.6820 | MLP Loss=1.7611, Acc=0.5756\n",
      "[Studygroup][1269] CNN Loss=0.8765, Acc=0.6701 | MLP Loss=1.6973, Acc=0.5781\n",
      "[Studygroup][1270] CNN Loss=0.8365, Acc=0.6808 | MLP Loss=1.6151, Acc=0.5817\n",
      "[Studygroup][1271] CNN Loss=0.8457, Acc=0.6805 | MLP Loss=1.6732, Acc=0.5840\n",
      "[Studygroup][1272] CNN Loss=0.9294, Acc=0.6730 | MLP Loss=1.6760, Acc=0.5766\n",
      "[Studygroup][1273] CNN Loss=0.8598, Acc=0.6780 | MLP Loss=1.8465, Acc=0.5672\n",
      "[Studygroup][1274] CNN Loss=0.9048, Acc=0.6769 | MLP Loss=1.7940, Acc=0.5864\n",
      "[Studygroup][1275] CNN Loss=0.9170, Acc=0.6699 | MLP Loss=1.5803, Acc=0.5900\n",
      "[Studygroup][1276] CNN Loss=0.9263, Acc=0.6781 | MLP Loss=1.5571, Acc=0.5817\n",
      "[Studygroup][1277] CNN Loss=0.9174, Acc=0.6742 | MLP Loss=1.6492, Acc=0.5867\n",
      "[Studygroup][1278] CNN Loss=0.8467, Acc=0.6711 | MLP Loss=1.5763, Acc=0.5859\n",
      "[Studygroup][1279] CNN Loss=0.8685, Acc=0.6818 | MLP Loss=1.6674, Acc=0.5844\n",
      "[Studygroup][1280] CNN Loss=0.9209, Acc=0.6746 | MLP Loss=1.6262, Acc=0.5751\n",
      "[Studygroup][1281] CNN Loss=0.9061, Acc=0.6787 | MLP Loss=1.6365, Acc=0.5867\n",
      "[Studygroup][1282] CNN Loss=0.8582, Acc=0.6730 | MLP Loss=1.6466, Acc=0.5780\n",
      "[Studygroup][1283] CNN Loss=0.9972, Acc=0.6757 | MLP Loss=1.5687, Acc=0.5899\n",
      "[Studygroup][1284] CNN Loss=0.8999, Acc=0.6799 | MLP Loss=1.5795, Acc=0.5821\n",
      "[Studygroup][1285] CNN Loss=0.8775, Acc=0.6755 | MLP Loss=1.6329, Acc=0.5785\n",
      "[Studygroup][1286] CNN Loss=0.9479, Acc=0.6715 | MLP Loss=1.6056, Acc=0.5888\n",
      "[Studygroup][1287] CNN Loss=0.8359, Acc=0.6789 | MLP Loss=1.5733, Acc=0.5722\n",
      "[Studygroup][1288] CNN Loss=0.8755, Acc=0.6807 | MLP Loss=1.5990, Acc=0.5761\n",
      "[Studygroup][1289] CNN Loss=0.8496, Acc=0.6751 | MLP Loss=1.5707, Acc=0.5875\n",
      "[Studygroup][1290] CNN Loss=0.8433, Acc=0.6852 | MLP Loss=1.6193, Acc=0.5884\n",
      "[Studygroup][1291] CNN Loss=0.8634, Acc=0.6780 | MLP Loss=1.8003, Acc=0.5811\n",
      "[Studygroup][1292] CNN Loss=0.8510, Acc=0.6799 | MLP Loss=1.6796, Acc=0.5838\n",
      "[Studygroup][1293] CNN Loss=0.8417, Acc=0.6805 | MLP Loss=1.7246, Acc=0.5778\n",
      "[Studygroup][1294] CNN Loss=0.8254, Acc=0.6763 | MLP Loss=1.6070, Acc=0.5938\n",
      "[Studygroup][1295] CNN Loss=0.9232, Acc=0.6571 | MLP Loss=1.6311, Acc=0.5833\n",
      "[Studygroup][1296] CNN Loss=0.9273, Acc=0.6755 | MLP Loss=1.6860, Acc=0.5846\n",
      "[Studygroup][1297] CNN Loss=0.9086, Acc=0.6760 | MLP Loss=1.6308, Acc=0.5799\n",
      "[Studygroup][1298] CNN Loss=0.9068, Acc=0.6804 | MLP Loss=1.6641, Acc=0.5793\n",
      "[Studygroup][1299] CNN Loss=0.8824, Acc=0.6793 | MLP Loss=1.6817, Acc=0.5884\n",
      "[Studygroup][1300] CNN Loss=0.8122, Acc=0.6822 | MLP Loss=1.5981, Acc=0.5890\n",
      "[Studygroup][1301] CNN Loss=0.9722, Acc=0.6751 | MLP Loss=1.6880, Acc=0.5795\n",
      "[Studygroup][1302] CNN Loss=0.8623, Acc=0.6799 | MLP Loss=1.6785, Acc=0.5821\n",
      "[Studygroup][1303] CNN Loss=0.9352, Acc=0.6781 | MLP Loss=1.7064, Acc=0.5850\n",
      "[Studygroup][1304] CNN Loss=0.7844, Acc=0.6815 | MLP Loss=1.5902, Acc=0.5863\n",
      "[Studygroup][1305] CNN Loss=0.8413, Acc=0.6838 | MLP Loss=1.6541, Acc=0.5836\n",
      "[Studygroup][1306] CNN Loss=0.9098, Acc=0.6715 | MLP Loss=1.6321, Acc=0.5810\n",
      "[Studygroup][1307] CNN Loss=0.8744, Acc=0.6779 | MLP Loss=1.6484, Acc=0.5869\n",
      "[Studygroup][1308] CNN Loss=0.9553, Acc=0.6651 | MLP Loss=1.6334, Acc=0.5811\n",
      "[Studygroup][1309] CNN Loss=0.9232, Acc=0.6788 | MLP Loss=1.6518, Acc=0.5706\n",
      "[Studygroup][1310] CNN Loss=0.8495, Acc=0.6802 | MLP Loss=1.7058, Acc=0.5842\n",
      "[Studygroup][1311] CNN Loss=0.9237, Acc=0.6730 | MLP Loss=1.6520, Acc=0.5702\n",
      "[Studygroup][1312] CNN Loss=0.9048, Acc=0.6820 | MLP Loss=1.6424, Acc=0.5708\n",
      "[Studygroup][1313] CNN Loss=0.8940, Acc=0.6744 | MLP Loss=1.6259, Acc=0.5760\n",
      "[Studygroup][1314] CNN Loss=0.8636, Acc=0.6734 | MLP Loss=1.6820, Acc=0.5902\n",
      "[Studygroup][1315] CNN Loss=0.8928, Acc=0.6770 | MLP Loss=1.6700, Acc=0.5830\n",
      "[Studygroup][1316] CNN Loss=0.8803, Acc=0.6828 | MLP Loss=1.7521, Acc=0.5861\n",
      "[Studygroup][1317] CNN Loss=0.8231, Acc=0.6822 | MLP Loss=1.6784, Acc=0.5848\n",
      "[Studygroup][1318] CNN Loss=0.8061, Acc=0.6769 | MLP Loss=1.6658, Acc=0.5769\n",
      "[Studygroup][1319] CNN Loss=0.9250, Acc=0.6757 | MLP Loss=1.6704, Acc=0.5845\n",
      "[Studygroup][1320] CNN Loss=1.0623, Acc=0.6709 | MLP Loss=1.7430, Acc=0.5901\n",
      "[Studygroup][1321] CNN Loss=0.8523, Acc=0.6707 | MLP Loss=1.6511, Acc=0.5779\n",
      "[Studygroup][1322] CNN Loss=0.9428, Acc=0.6738 | MLP Loss=1.6930, Acc=0.5800\n",
      "[Studygroup][1323] CNN Loss=0.9113, Acc=0.6792 | MLP Loss=1.6231, Acc=0.5766\n",
      "[Studygroup][1324] CNN Loss=0.9105, Acc=0.6806 | MLP Loss=1.6637, Acc=0.5828\n",
      "[Studygroup][1325] CNN Loss=0.8598, Acc=0.6744 | MLP Loss=1.6781, Acc=0.5775\n",
      "[Studygroup][1326] CNN Loss=0.8430, Acc=0.6792 | MLP Loss=1.5976, Acc=0.5911\n",
      "[Studygroup][1327] CNN Loss=0.8421, Acc=0.6739 | MLP Loss=1.6106, Acc=0.5888\n",
      "[Studygroup][1328] CNN Loss=0.9032, Acc=0.6834 | MLP Loss=1.6453, Acc=0.5788\n",
      "[Studygroup][1329] CNN Loss=0.9306, Acc=0.6784 | MLP Loss=1.6744, Acc=0.5788\n",
      "[Studygroup][1330] CNN Loss=0.9945, Acc=0.6753 | MLP Loss=1.7207, Acc=0.5730\n",
      "[Studygroup][1331] CNN Loss=0.9030, Acc=0.6778 | MLP Loss=1.6572, Acc=0.5865\n",
      "[Studygroup][1332] CNN Loss=0.8411, Acc=0.6814 | MLP Loss=1.6732, Acc=0.5853\n",
      "[Studygroup][1333] CNN Loss=0.8172, Acc=0.6771 | MLP Loss=1.6584, Acc=0.5742\n",
      "[Studygroup][1334] CNN Loss=0.8352, Acc=0.6784 | MLP Loss=1.6902, Acc=0.5747\n",
      "[Studygroup][1335] CNN Loss=0.9380, Acc=0.6797 | MLP Loss=1.7086, Acc=0.5881\n",
      "[Studygroup][1336] CNN Loss=0.8563, Acc=0.6776 | MLP Loss=1.6958, Acc=0.5908\n",
      "[Studygroup][1337] CNN Loss=0.8552, Acc=0.6729 | MLP Loss=1.7296, Acc=0.5892\n",
      "[Studygroup][1338] CNN Loss=0.9060, Acc=0.6742 | MLP Loss=1.6184, Acc=0.5876\n",
      "[Studygroup][1339] CNN Loss=0.8463, Acc=0.6813 | MLP Loss=1.7375, Acc=0.5859\n",
      "[Studygroup][1340] CNN Loss=0.9765, Acc=0.6856 | MLP Loss=1.7399, Acc=0.5861\n",
      "[Studygroup][1341] CNN Loss=0.7734, Acc=0.6789 | MLP Loss=1.7428, Acc=0.5886\n",
      "[Studygroup][1342] CNN Loss=0.9218, Acc=0.6673 | MLP Loss=1.6861, Acc=0.5864\n",
      "[Studygroup][1343] CNN Loss=0.9546, Acc=0.6813 | MLP Loss=1.6367, Acc=0.5917\n",
      "[Studygroup][1344] CNN Loss=0.9346, Acc=0.6734 | MLP Loss=1.7602, Acc=0.5848\n",
      "[Studygroup][1345] CNN Loss=1.0752, Acc=0.6726 | MLP Loss=1.7211, Acc=0.5705\n",
      "[Studygroup][1346] CNN Loss=0.9018, Acc=0.6817 | MLP Loss=1.6368, Acc=0.5808\n",
      "[Studygroup][1347] CNN Loss=0.8633, Acc=0.6714 | MLP Loss=1.6900, Acc=0.5893\n",
      "[Studygroup][1348] CNN Loss=0.8020, Acc=0.6833 | MLP Loss=1.7286, Acc=0.5817\n",
      "[Studygroup][1349] CNN Loss=0.9015, Acc=0.6786 | MLP Loss=1.7971, Acc=0.5892\n",
      "[Studygroup][1350] CNN Loss=0.8945, Acc=0.6801 | MLP Loss=1.6199, Acc=0.5771\n",
      "[Studygroup][1351] CNN Loss=0.8971, Acc=0.6811 | MLP Loss=1.6439, Acc=0.5920\n",
      "[Studygroup][1352] CNN Loss=0.9037, Acc=0.6793 | MLP Loss=1.6634, Acc=0.5828\n",
      "[Studygroup][1353] CNN Loss=0.9132, Acc=0.6760 | MLP Loss=1.6517, Acc=0.5917\n",
      "[Studygroup][1354] CNN Loss=0.7898, Acc=0.6708 | MLP Loss=1.5550, Acc=0.5928\n",
      "[Studygroup][1355] CNN Loss=0.8833, Acc=0.6787 | MLP Loss=1.6644, Acc=0.5865\n",
      "[Studygroup][1356] CNN Loss=0.9609, Acc=0.6707 | MLP Loss=1.6726, Acc=0.5708\n",
      "[Studygroup][1357] CNN Loss=1.0081, Acc=0.6730 | MLP Loss=1.9176, Acc=0.5684\n",
      "[Studygroup][1358] CNN Loss=1.0394, Acc=0.6722 | MLP Loss=1.6912, Acc=0.5826\n",
      "[Studygroup][1359] CNN Loss=0.9119, Acc=0.6660 | MLP Loss=1.6801, Acc=0.5844\n",
      "[Studygroup][1360] CNN Loss=1.0056, Acc=0.6736 | MLP Loss=1.6843, Acc=0.5668\n",
      "[Studygroup][1361] CNN Loss=0.8933, Acc=0.6763 | MLP Loss=1.6863, Acc=0.5908\n",
      "[Studygroup][1362] CNN Loss=0.9126, Acc=0.6733 | MLP Loss=1.6244, Acc=0.5734\n",
      "[Studygroup][1363] CNN Loss=0.8869, Acc=0.6776 | MLP Loss=1.6830, Acc=0.5707\n",
      "[Studygroup][1364] CNN Loss=0.8810, Acc=0.6768 | MLP Loss=1.6170, Acc=0.5832\n",
      "[Studygroup][1365] CNN Loss=0.8750, Acc=0.6741 | MLP Loss=1.7802, Acc=0.5795\n",
      "[Studygroup][1366] CNN Loss=0.9249, Acc=0.6816 | MLP Loss=1.7048, Acc=0.5773\n",
      "[Studygroup][1367] CNN Loss=0.8762, Acc=0.6734 | MLP Loss=1.5886, Acc=0.5904\n",
      "[Studygroup][1368] CNN Loss=0.8487, Acc=0.6774 | MLP Loss=1.6344, Acc=0.5880\n",
      "[Studygroup][1369] CNN Loss=0.8895, Acc=0.6700 | MLP Loss=1.6678, Acc=0.5845\n",
      "[Studygroup][1370] CNN Loss=0.9020, Acc=0.6771 | MLP Loss=1.6324, Acc=0.5796\n",
      "[Studygroup][1371] CNN Loss=0.8404, Acc=0.6698 | MLP Loss=1.6180, Acc=0.5875\n",
      "[Studygroup][1372] CNN Loss=0.8611, Acc=0.6739 | MLP Loss=1.6120, Acc=0.5908\n",
      "[Studygroup][1373] CNN Loss=0.8461, Acc=0.6792 | MLP Loss=1.6076, Acc=0.5801\n",
      "[Studygroup][1374] CNN Loss=0.8787, Acc=0.6773 | MLP Loss=1.6375, Acc=0.5673\n",
      "[Studygroup][1375] CNN Loss=0.8992, Acc=0.6659 | MLP Loss=1.6650, Acc=0.5888\n",
      "[Studygroup][1376] CNN Loss=0.9257, Acc=0.6755 | MLP Loss=1.6859, Acc=0.5830\n",
      "[Studygroup][1377] CNN Loss=0.9198, Acc=0.6795 | MLP Loss=1.7168, Acc=0.5848\n",
      "[Studygroup][1378] CNN Loss=0.8735, Acc=0.6711 | MLP Loss=1.6677, Acc=0.5839\n",
      "[Studygroup][1379] CNN Loss=0.7824, Acc=0.6786 | MLP Loss=1.6088, Acc=0.5868\n",
      "[Studygroup][1380] CNN Loss=0.9524, Acc=0.6701 | MLP Loss=1.6532, Acc=0.5774\n",
      "[Studygroup][1381] CNN Loss=0.9569, Acc=0.6804 | MLP Loss=1.5663, Acc=0.5867\n",
      "[Studygroup][1382] CNN Loss=0.8951, Acc=0.6760 | MLP Loss=1.6274, Acc=0.5879\n",
      "[Studygroup][1383] CNN Loss=0.8826, Acc=0.6832 | MLP Loss=1.6009, Acc=0.5954\n",
      "[Studygroup][1384] CNN Loss=0.7904, Acc=0.6856 | MLP Loss=1.5352, Acc=0.5832\n",
      "[Studygroup][1385] CNN Loss=0.8495, Acc=0.6774 | MLP Loss=1.5766, Acc=0.5879\n",
      "[Studygroup][1386] CNN Loss=0.8810, Acc=0.6773 | MLP Loss=1.6002, Acc=0.5895\n",
      "[Studygroup][1387] CNN Loss=0.9663, Acc=0.6834 | MLP Loss=1.5878, Acc=0.5874\n",
      "[Studygroup][1388] CNN Loss=0.8880, Acc=0.6748 | MLP Loss=1.6280, Acc=0.5862\n",
      "[Studygroup][1389] CNN Loss=0.8493, Acc=0.6804 | MLP Loss=1.6337, Acc=0.5855\n",
      "[Studygroup][1390] CNN Loss=0.8669, Acc=0.6727 | MLP Loss=1.5987, Acc=0.5882\n",
      "[Studygroup][1391] CNN Loss=0.9242, Acc=0.6795 | MLP Loss=1.5689, Acc=0.5840\n",
      "[Studygroup][1392] CNN Loss=1.0030, Acc=0.6727 | MLP Loss=1.6835, Acc=0.5777\n",
      "[Studygroup][1393] CNN Loss=1.0625, Acc=0.6704 | MLP Loss=1.7295, Acc=0.5887\n",
      "[Studygroup][1394] CNN Loss=0.9345, Acc=0.6773 | MLP Loss=1.6214, Acc=0.5795\n",
      "[Studygroup][1395] CNN Loss=0.9164, Acc=0.6761 | MLP Loss=1.6330, Acc=0.5785\n",
      "[Studygroup][1396] CNN Loss=0.8932, Acc=0.6781 | MLP Loss=1.6147, Acc=0.5801\n",
      "[Studygroup][1397] CNN Loss=0.7961, Acc=0.6806 | MLP Loss=1.6185, Acc=0.5851\n",
      "[Studygroup][1398] CNN Loss=0.8787, Acc=0.6761 | MLP Loss=1.6128, Acc=0.5840\n",
      "[Studygroup][1399] CNN Loss=0.8547, Acc=0.6803 | MLP Loss=1.7420, Acc=0.5824\n",
      "[Studygroup][1400] CNN Loss=0.9246, Acc=0.6749 | MLP Loss=1.5786, Acc=0.5897\n",
      "[Studygroup][1401] CNN Loss=0.9101, Acc=0.6785 | MLP Loss=1.6479, Acc=0.5849\n",
      "[Studygroup][1402] CNN Loss=0.9268, Acc=0.6765 | MLP Loss=1.5837, Acc=0.5873\n",
      "[Studygroup][1403] CNN Loss=0.9003, Acc=0.6724 | MLP Loss=1.5975, Acc=0.5908\n",
      "[Studygroup][1404] CNN Loss=0.8542, Acc=0.6742 | MLP Loss=1.7151, Acc=0.5833\n",
      "[Studygroup][1405] CNN Loss=0.8942, Acc=0.6780 | MLP Loss=1.6106, Acc=0.5823\n",
      "[Studygroup][1406] CNN Loss=0.9596, Acc=0.6723 | MLP Loss=1.7788, Acc=0.5743\n",
      "[Studygroup][1407] CNN Loss=0.9212, Acc=0.6842 | MLP Loss=1.7065, Acc=0.5784\n",
      "[Studygroup][1408] CNN Loss=0.8648, Acc=0.6767 | MLP Loss=1.6717, Acc=0.5861\n",
      "[Studygroup][1409] CNN Loss=0.9158, Acc=0.6739 | MLP Loss=1.6601, Acc=0.5926\n",
      "[Studygroup][1410] CNN Loss=0.9117, Acc=0.6797 | MLP Loss=1.6957, Acc=0.5868\n",
      "[Studygroup][1411] CNN Loss=0.9202, Acc=0.6760 | MLP Loss=1.6946, Acc=0.5801\n",
      "[Studygroup][1412] CNN Loss=0.8764, Acc=0.6590 | MLP Loss=1.6408, Acc=0.5806\n",
      "[Studygroup][1413] CNN Loss=1.0393, Acc=0.6787 | MLP Loss=1.7223, Acc=0.5767\n",
      "[Studygroup][1414] CNN Loss=0.9362, Acc=0.6777 | MLP Loss=1.6055, Acc=0.5855\n",
      "[Studygroup][1415] CNN Loss=0.9704, Acc=0.6795 | MLP Loss=1.6336, Acc=0.5872\n",
      "[Studygroup][1416] CNN Loss=0.8821, Acc=0.6762 | MLP Loss=1.5902, Acc=0.5871\n",
      "[Studygroup][1417] CNN Loss=0.8887, Acc=0.6748 | MLP Loss=1.5731, Acc=0.5846\n",
      "[Studygroup][1418] CNN Loss=1.0044, Acc=0.6742 | MLP Loss=1.6265, Acc=0.5898\n",
      "[Studygroup][1419] CNN Loss=0.8484, Acc=0.6786 | MLP Loss=1.6471, Acc=0.5786\n",
      "[Studygroup][1420] CNN Loss=0.8818, Acc=0.6721 | MLP Loss=1.7256, Acc=0.5863\n",
      "[Studygroup][1421] CNN Loss=0.9639, Acc=0.6739 | MLP Loss=1.6991, Acc=0.5820\n",
      "[Studygroup][1422] CNN Loss=0.9741, Acc=0.6702 | MLP Loss=1.6776, Acc=0.5792\n",
      "[Studygroup][1423] CNN Loss=0.9765, Acc=0.6778 | MLP Loss=1.5811, Acc=0.5886\n",
      "[Studygroup][1424] CNN Loss=0.9465, Acc=0.6802 | MLP Loss=1.5784, Acc=0.5672\n",
      "[Studygroup][1425] CNN Loss=0.9541, Acc=0.6720 | MLP Loss=1.6821, Acc=0.5791\n",
      "[Studygroup][1426] CNN Loss=0.9681, Acc=0.6734 | MLP Loss=1.6201, Acc=0.5742\n",
      "[Studygroup][1427] CNN Loss=0.9488, Acc=0.6830 | MLP Loss=1.6697, Acc=0.5829\n",
      "[Studygroup][1428] CNN Loss=0.9789, Acc=0.6786 | MLP Loss=1.5951, Acc=0.5847\n",
      "[Studygroup][1429] CNN Loss=0.9560, Acc=0.6719 | MLP Loss=1.6453, Acc=0.5776\n",
      "[Studygroup][1430] CNN Loss=0.9501, Acc=0.6759 | MLP Loss=1.5339, Acc=0.5935\n",
      "[Studygroup][1431] CNN Loss=0.8029, Acc=0.6795 | MLP Loss=1.5732, Acc=0.5825\n",
      "[Studygroup][1432] CNN Loss=0.8776, Acc=0.6698 | MLP Loss=1.6499, Acc=0.5720\n",
      "[Studygroup][1433] CNN Loss=0.8894, Acc=0.6688 | MLP Loss=1.9242, Acc=0.5553\n",
      "[Studygroup][1434] CNN Loss=0.8921, Acc=0.6728 | MLP Loss=1.6864, Acc=0.5781\n",
      "[Studygroup][1435] CNN Loss=0.9487, Acc=0.6718 | MLP Loss=1.6784, Acc=0.5636\n",
      "[Studygroup][1436] CNN Loss=0.9410, Acc=0.6776 | MLP Loss=1.6179, Acc=0.5867\n",
      "[Studygroup][1437] CNN Loss=0.8546, Acc=0.6735 | MLP Loss=1.6018, Acc=0.5872\n",
      "[Studygroup][1438] CNN Loss=0.8591, Acc=0.6751 | MLP Loss=1.7110, Acc=0.5841\n",
      "[Studygroup][1439] CNN Loss=0.8930, Acc=0.6747 | MLP Loss=1.6319, Acc=0.5938\n",
      "[Studygroup][1440] CNN Loss=0.9111, Acc=0.6829 | MLP Loss=1.6316, Acc=0.5842\n",
      "[Studygroup][1441] CNN Loss=0.8692, Acc=0.6813 | MLP Loss=1.6610, Acc=0.5826\n",
      "[Studygroup][1442] CNN Loss=0.9150, Acc=0.6795 | MLP Loss=1.6090, Acc=0.5801\n",
      "[Studygroup][1443] CNN Loss=0.8773, Acc=0.6824 | MLP Loss=1.5723, Acc=0.5868\n",
      "[Studygroup][1444] CNN Loss=0.9513, Acc=0.6794 | MLP Loss=1.6625, Acc=0.5922\n",
      "[Studygroup][1445] CNN Loss=0.8637, Acc=0.6836 | MLP Loss=1.6178, Acc=0.5937\n",
      "[Studygroup][1446] CNN Loss=0.8388, Acc=0.6824 | MLP Loss=1.6217, Acc=0.5733\n",
      "[Studygroup][1447] CNN Loss=0.9530, Acc=0.6657 | MLP Loss=1.6243, Acc=0.5756\n",
      "[Studygroup][1448] CNN Loss=0.9465, Acc=0.6767 | MLP Loss=1.6563, Acc=0.5817\n",
      "[Studygroup][1449] CNN Loss=0.8891, Acc=0.6752 | MLP Loss=1.6614, Acc=0.5778\n",
      "[Studygroup][1450] CNN Loss=0.9236, Acc=0.6753 | MLP Loss=1.5948, Acc=0.5882\n",
      "[Studygroup][1451] CNN Loss=1.0082, Acc=0.6752 | MLP Loss=1.6143, Acc=0.5911\n",
      "[Studygroup][1452] CNN Loss=0.9089, Acc=0.6817 | MLP Loss=1.6374, Acc=0.5919\n",
      "[Studygroup][1453] CNN Loss=1.0014, Acc=0.6826 | MLP Loss=1.6317, Acc=0.5857\n",
      "[Studygroup][1454] CNN Loss=0.9466, Acc=0.6889 | MLP Loss=1.6701, Acc=0.5893\n",
      "[Studygroup][1455] CNN Loss=0.7893, Acc=0.6853 | MLP Loss=1.6897, Acc=0.5810\n",
      "[Studygroup][1456] CNN Loss=0.8540, Acc=0.6784 | MLP Loss=1.6972, Acc=0.5797\n",
      "[Studygroup][1457] CNN Loss=0.8876, Acc=0.6841 | MLP Loss=1.7089, Acc=0.5868\n",
      "[Studygroup][1458] CNN Loss=0.9792, Acc=0.6826 | MLP Loss=1.6398, Acc=0.5849\n",
      "[Studygroup][1459] CNN Loss=0.8332, Acc=0.6855 | MLP Loss=1.5743, Acc=0.5882\n",
      "[Studygroup][1460] CNN Loss=0.7725, Acc=0.6786 | MLP Loss=1.5588, Acc=0.5885\n",
      "[Studygroup][1461] CNN Loss=0.8871, Acc=0.6781 | MLP Loss=1.6188, Acc=0.5812\n",
      "[Studygroup][1462] CNN Loss=0.9302, Acc=0.6728 | MLP Loss=1.6372, Acc=0.5932\n",
      "[Studygroup][1463] CNN Loss=0.8945, Acc=0.6788 | MLP Loss=1.6536, Acc=0.5898\n",
      "[Studygroup][1464] CNN Loss=0.8481, Acc=0.6751 | MLP Loss=1.6271, Acc=0.5901\n",
      "[Studygroup][1465] CNN Loss=0.8882, Acc=0.6762 | MLP Loss=1.6619, Acc=0.5885\n",
      "[Studygroup][1466] CNN Loss=0.8980, Acc=0.6795 | MLP Loss=1.5952, Acc=0.5584\n",
      "[Studygroup][1467] CNN Loss=0.7846, Acc=0.6843 | MLP Loss=1.6228, Acc=0.5843\n",
      "[Studygroup][1468] CNN Loss=0.8399, Acc=0.6830 | MLP Loss=1.5781, Acc=0.5837\n",
      "[Studygroup][1469] CNN Loss=0.8291, Acc=0.6822 | MLP Loss=1.8409, Acc=0.5704\n",
      "[Studygroup][1470] CNN Loss=0.8878, Acc=0.6786 | MLP Loss=1.9229, Acc=0.5772\n",
      "[Studygroup][1471] CNN Loss=0.9949, Acc=0.6759 | MLP Loss=1.7988, Acc=0.5744\n",
      "[Studygroup][1472] CNN Loss=0.9156, Acc=0.6835 | MLP Loss=1.6603, Acc=0.5877\n",
      "[Studygroup][1473] CNN Loss=0.8841, Acc=0.6832 | MLP Loss=1.6467, Acc=0.5889\n",
      "[Studygroup][1474] CNN Loss=0.8673, Acc=0.6820 | MLP Loss=1.6203, Acc=0.5865\n",
      "[Studygroup][1475] CNN Loss=0.8386, Acc=0.6857 | MLP Loss=1.6723, Acc=0.5858\n",
      "[Studygroup][1476] CNN Loss=0.9748, Acc=0.6812 | MLP Loss=1.6698, Acc=0.5894\n",
      "[Studygroup][1477] CNN Loss=0.8243, Acc=0.6809 | MLP Loss=1.5601, Acc=0.5828\n",
      "[Studygroup][1478] CNN Loss=0.8924, Acc=0.6825 | MLP Loss=1.6713, Acc=0.5914\n",
      "[Studygroup][1479] CNN Loss=0.9230, Acc=0.6826 | MLP Loss=1.6022, Acc=0.5748\n",
      "[Studygroup][1480] CNN Loss=0.8113, Acc=0.6914 | MLP Loss=1.6064, Acc=0.5855\n",
      "[Studygroup][1481] CNN Loss=0.7777, Acc=0.6858 | MLP Loss=1.7992, Acc=0.5835\n",
      "[Studygroup][1482] CNN Loss=0.7870, Acc=0.6810 | MLP Loss=1.7507, Acc=0.5899\n",
      "[Studygroup][1483] CNN Loss=0.9529, Acc=0.6628 | MLP Loss=1.7335, Acc=0.5804\n",
      "[Studygroup][1484] CNN Loss=1.0059, Acc=0.6802 | MLP Loss=1.5691, Acc=0.5696\n",
      "[Studygroup][1485] CNN Loss=0.8788, Acc=0.6821 | MLP Loss=1.5898, Acc=0.5933\n",
      "[Studygroup][1486] CNN Loss=0.8858, Acc=0.6827 | MLP Loss=1.5981, Acc=0.5909\n",
      "[Studygroup][1487] CNN Loss=0.8691, Acc=0.6837 | MLP Loss=1.7235, Acc=0.5947\n",
      "[Studygroup][1488] CNN Loss=0.9557, Acc=0.6782 | MLP Loss=1.6417, Acc=0.5900\n",
      "[Studygroup][1489] CNN Loss=1.0110, Acc=0.6765 | MLP Loss=1.6259, Acc=0.5809\n",
      "[Studygroup][1490] CNN Loss=0.8201, Acc=0.6847 | MLP Loss=1.5878, Acc=0.5922\n",
      "[Studygroup][1491] CNN Loss=0.8517, Acc=0.6798 | MLP Loss=1.6302, Acc=0.5913\n",
      "[Studygroup][1492] CNN Loss=0.8925, Acc=0.6848 | MLP Loss=1.7125, Acc=0.5742\n",
      "[Studygroup][1493] CNN Loss=0.8244, Acc=0.6835 | MLP Loss=1.7092, Acc=0.5830\n",
      "[Studygroup][1494] CNN Loss=0.8954, Acc=0.6849 | MLP Loss=1.6434, Acc=0.5930\n",
      "[Studygroup][1495] CNN Loss=0.8655, Acc=0.6823 | MLP Loss=1.5932, Acc=0.5915\n",
      "[Studygroup][1496] CNN Loss=0.8421, Acc=0.6843 | MLP Loss=1.6300, Acc=0.5894\n",
      "[Studygroup][1497] CNN Loss=0.8549, Acc=0.6814 | MLP Loss=1.6108, Acc=0.5916\n",
      "[Studygroup][1498] CNN Loss=0.9407, Acc=0.6815 | MLP Loss=1.6186, Acc=0.5864\n",
      "[Studygroup][1499] CNN Loss=0.8940, Acc=0.6662 | MLP Loss=1.7049, Acc=0.5799\n",
      "[Studygroup][1500] CNN Loss=0.8273, Acc=0.6770 | MLP Loss=1.6634, Acc=0.5787\n",
      "[Studygroup][1501] CNN Loss=0.9515, Acc=0.6725 | MLP Loss=1.7077, Acc=0.5929\n",
      "[Studygroup][1502] CNN Loss=0.9044, Acc=0.6705 | MLP Loss=1.6902, Acc=0.5918\n",
      "[Studygroup][1503] CNN Loss=0.9216, Acc=0.6582 | MLP Loss=1.6593, Acc=0.5902\n",
      "[Studygroup][1504] CNN Loss=0.9966, Acc=0.6739 | MLP Loss=1.6491, Acc=0.5807\n",
      "[Studygroup][1505] CNN Loss=0.9675, Acc=0.6804 | MLP Loss=1.5408, Acc=0.5830\n",
      "[Studygroup][1506] CNN Loss=0.9585, Acc=0.6774 | MLP Loss=1.5739, Acc=0.5894\n",
      "[Studygroup][1507] CNN Loss=0.9251, Acc=0.6793 | MLP Loss=1.6054, Acc=0.5850\n",
      "[Studygroup][1508] CNN Loss=0.8331, Acc=0.6838 | MLP Loss=1.5981, Acc=0.5823\n",
      "[Studygroup][1509] CNN Loss=0.8762, Acc=0.6808 | MLP Loss=1.6046, Acc=0.5900\n",
      "[Studygroup][1510] CNN Loss=0.8018, Acc=0.6849 | MLP Loss=1.5938, Acc=0.5909\n",
      "[Studygroup][1511] CNN Loss=0.8396, Acc=0.6794 | MLP Loss=1.5756, Acc=0.5868\n",
      "[Studygroup][1512] CNN Loss=0.8941, Acc=0.6811 | MLP Loss=1.6523, Acc=0.5617\n",
      "[Studygroup][1513] CNN Loss=0.8332, Acc=0.6787 | MLP Loss=1.6372, Acc=0.5885\n",
      "[Studygroup][1514] CNN Loss=0.8803, Acc=0.6780 | MLP Loss=1.6542, Acc=0.5905\n",
      "[Studygroup][1515] CNN Loss=1.0037, Acc=0.6757 | MLP Loss=1.6176, Acc=0.5801\n",
      "[Studygroup][1516] CNN Loss=0.9236, Acc=0.6831 | MLP Loss=1.6102, Acc=0.5870\n",
      "[Studygroup][1517] CNN Loss=0.8882, Acc=0.6807 | MLP Loss=1.6602, Acc=0.5784\n",
      "[Studygroup][1518] CNN Loss=0.9108, Acc=0.6845 | MLP Loss=1.5650, Acc=0.5864\n",
      "[Studygroup][1519] CNN Loss=0.8547, Acc=0.6796 | MLP Loss=1.6233, Acc=0.5846\n",
      "[Studygroup][1520] CNN Loss=0.8515, Acc=0.6826 | MLP Loss=1.6019, Acc=0.5892\n",
      "[Studygroup][1521] CNN Loss=0.8450, Acc=0.6808 | MLP Loss=1.5615, Acc=0.5917\n",
      "[Studygroup][1522] CNN Loss=0.8569, Acc=0.6887 | MLP Loss=1.6551, Acc=0.5814\n",
      "[Studygroup][1523] CNN Loss=0.8040, Acc=0.6887 | MLP Loss=1.6430, Acc=0.5916\n",
      "[Studygroup][1524] CNN Loss=0.9092, Acc=0.6814 | MLP Loss=1.5968, Acc=0.5805\n",
      "[Studygroup][1525] CNN Loss=0.8913, Acc=0.6821 | MLP Loss=1.5996, Acc=0.5894\n",
      "[Studygroup][1526] CNN Loss=0.9217, Acc=0.6781 | MLP Loss=1.5940, Acc=0.5785\n",
      "[Studygroup][1527] CNN Loss=0.8634, Acc=0.6833 | MLP Loss=1.5722, Acc=0.5955\n",
      "[Studygroup][1528] CNN Loss=0.8766, Acc=0.6862 | MLP Loss=1.6245, Acc=0.5830\n",
      "[Studygroup][1529] CNN Loss=0.9219, Acc=0.6772 | MLP Loss=1.7475, Acc=0.5623\n",
      "[Studygroup][1530] CNN Loss=0.9015, Acc=0.6900 | MLP Loss=1.6564, Acc=0.5813\n",
      "[Studygroup][1531] CNN Loss=0.9175, Acc=0.6797 | MLP Loss=1.7062, Acc=0.5818\n",
      "[Studygroup][1532] CNN Loss=0.9197, Acc=0.6819 | MLP Loss=1.7152, Acc=0.5851\n",
      "[Studygroup][1533] CNN Loss=0.8962, Acc=0.6756 | MLP Loss=1.7233, Acc=0.5722\n",
      "[Studygroup][1534] CNN Loss=0.9040, Acc=0.6852 | MLP Loss=1.7580, Acc=0.5823\n",
      "[Studygroup][1535] CNN Loss=0.9380, Acc=0.6813 | MLP Loss=1.7660, Acc=0.5801\n",
      "[Studygroup][1536] CNN Loss=0.9818, Acc=0.6779 | MLP Loss=1.6905, Acc=0.5819\n",
      "[Studygroup][1537] CNN Loss=1.0243, Acc=0.6713 | MLP Loss=1.6431, Acc=0.5750\n",
      "[Studygroup][1538] CNN Loss=1.0242, Acc=0.6722 | MLP Loss=1.6011, Acc=0.5906\n",
      "[Studygroup][1539] CNN Loss=0.9038, Acc=0.6678 | MLP Loss=1.6946, Acc=0.5763\n",
      "[Studygroup][1540] CNN Loss=0.9071, Acc=0.6746 | MLP Loss=1.6875, Acc=0.5922\n",
      "[Studygroup][1541] CNN Loss=0.9810, Acc=0.6798 | MLP Loss=1.7057, Acc=0.5845\n",
      "[Studygroup][1542] CNN Loss=0.9777, Acc=0.6743 | MLP Loss=1.6481, Acc=0.5866\n",
      "[Studygroup][1543] CNN Loss=0.8441, Acc=0.6841 | MLP Loss=1.6520, Acc=0.5810\n",
      "[Studygroup][1544] CNN Loss=0.9212, Acc=0.6760 | MLP Loss=1.5831, Acc=0.5869\n",
      "[Studygroup][1545] CNN Loss=0.8424, Acc=0.6789 | MLP Loss=1.5325, Acc=0.5874\n",
      "[Studygroup][1546] CNN Loss=0.8777, Acc=0.6785 | MLP Loss=1.7140, Acc=0.5802\n",
      "[Studygroup][1547] CNN Loss=0.8939, Acc=0.6857 | MLP Loss=1.6216, Acc=0.5920\n",
      "[Studygroup][1548] CNN Loss=0.9588, Acc=0.6698 | MLP Loss=1.6747, Acc=0.5691\n",
      "[Studygroup][1549] CNN Loss=0.9663, Acc=0.6842 | MLP Loss=1.6960, Acc=0.5954\n",
      "[Studygroup][1550] CNN Loss=0.9461, Acc=0.6806 | MLP Loss=1.7350, Acc=0.5822\n",
      "[Studygroup][1551] CNN Loss=0.9067, Acc=0.6786 | MLP Loss=1.7333, Acc=0.5764\n",
      "[Studygroup][1552] CNN Loss=0.8088, Acc=0.6825 | MLP Loss=1.6636, Acc=0.5849\n",
      "[Studygroup][1553] CNN Loss=0.8451, Acc=0.6887 | MLP Loss=1.7376, Acc=0.5799\n",
      "[Studygroup][1554] CNN Loss=0.8260, Acc=0.6853 | MLP Loss=1.7512, Acc=0.5767\n",
      "[Studygroup][1555] CNN Loss=0.8613, Acc=0.6703 | MLP Loss=1.6910, Acc=0.5752\n",
      "[Studygroup][1556] CNN Loss=1.0031, Acc=0.6760 | MLP Loss=1.6997, Acc=0.5875\n",
      "[Studygroup][1557] CNN Loss=0.8894, Acc=0.6798 | MLP Loss=1.6389, Acc=0.5787\n",
      "[Studygroup][1558] CNN Loss=0.8611, Acc=0.6838 | MLP Loss=1.6140, Acc=0.5874\n",
      "[Studygroup][1559] CNN Loss=0.8984, Acc=0.6813 | MLP Loss=1.6660, Acc=0.5961\n",
      "[Studygroup][1560] CNN Loss=0.8115, Acc=0.6839 | MLP Loss=1.6534, Acc=0.5912\n",
      "[Studygroup][1561] CNN Loss=0.8797, Acc=0.6776 | MLP Loss=1.7205, Acc=0.5814\n",
      "[Studygroup][1562] CNN Loss=0.8611, Acc=0.6811 | MLP Loss=1.6910, Acc=0.5940\n",
      "[Studygroup][1563] CNN Loss=0.9409, Acc=0.6779 | MLP Loss=1.6885, Acc=0.5938\n",
      "[Studygroup][1564] CNN Loss=0.8810, Acc=0.6747 | MLP Loss=1.6930, Acc=0.5785\n",
      "[Studygroup][1565] CNN Loss=0.8962, Acc=0.6766 | MLP Loss=1.7426, Acc=0.5799\n",
      "[Studygroup][1566] CNN Loss=0.9451, Acc=0.6765 | MLP Loss=1.7906, Acc=0.5876\n",
      "[Studygroup][1567] CNN Loss=0.9591, Acc=0.6790 | MLP Loss=1.6234, Acc=0.5848\n",
      "[Studygroup][1568] CNN Loss=0.8822, Acc=0.6801 | MLP Loss=1.6634, Acc=0.5828\n",
      "[Studygroup][1569] CNN Loss=0.8793, Acc=0.6733 | MLP Loss=1.6891, Acc=0.5949\n",
      "[Studygroup][1570] CNN Loss=0.8707, Acc=0.6804 | MLP Loss=1.6671, Acc=0.5851\n",
      "[Studygroup][1571] CNN Loss=0.8167, Acc=0.6773 | MLP Loss=1.6990, Acc=0.5898\n",
      "[Studygroup][1572] CNN Loss=0.8220, Acc=0.6813 | MLP Loss=1.6296, Acc=0.5784\n",
      "[Studygroup][1573] CNN Loss=0.7760, Acc=0.6779 | MLP Loss=1.6511, Acc=0.5824\n",
      "[Studygroup][1574] CNN Loss=0.7660, Acc=0.6842 | MLP Loss=1.7305, Acc=0.5804\n",
      "[Studygroup][1575] CNN Loss=0.9694, Acc=0.6792 | MLP Loss=1.7747, Acc=0.5748\n",
      "[Studygroup][1576] CNN Loss=0.8216, Acc=0.6864 | MLP Loss=1.6438, Acc=0.5818\n",
      "[Studygroup][1577] CNN Loss=0.8592, Acc=0.6889 | MLP Loss=1.6235, Acc=0.5909\n",
      "[Studygroup][1578] CNN Loss=0.7998, Acc=0.6872 | MLP Loss=1.6703, Acc=0.5897\n",
      "[Studygroup][1579] CNN Loss=0.8578, Acc=0.6784 | MLP Loss=1.5972, Acc=0.5821\n",
      "[Studygroup][1580] CNN Loss=0.9069, Acc=0.6835 | MLP Loss=1.6912, Acc=0.5894\n",
      "[Studygroup][1581] CNN Loss=0.8518, Acc=0.6831 | MLP Loss=1.6592, Acc=0.5942\n",
      "[Studygroup][1582] CNN Loss=0.9433, Acc=0.6818 | MLP Loss=1.5806, Acc=0.5934\n",
      "[Studygroup][1583] CNN Loss=0.8806, Acc=0.6860 | MLP Loss=1.6963, Acc=0.5847\n",
      "[Studygroup][1584] CNN Loss=0.9067, Acc=0.6757 | MLP Loss=1.6779, Acc=0.5906\n",
      "[Studygroup][1585] CNN Loss=0.8802, Acc=0.6754 | MLP Loss=1.6918, Acc=0.5926\n",
      "[Studygroup][1586] CNN Loss=0.8894, Acc=0.6776 | MLP Loss=1.6939, Acc=0.5926\n",
      "[Studygroup][1587] CNN Loss=0.8532, Acc=0.6796 | MLP Loss=1.6255, Acc=0.5845\n",
      "[Studygroup][1588] CNN Loss=1.0463, Acc=0.6686 | MLP Loss=1.7131, Acc=0.5818\n",
      "[Studygroup][1589] CNN Loss=1.0114, Acc=0.6819 | MLP Loss=1.6243, Acc=0.5929\n",
      "[Studygroup][1590] CNN Loss=0.8900, Acc=0.6820 | MLP Loss=1.6259, Acc=0.5925\n",
      "[Studygroup][1591] CNN Loss=0.9615, Acc=0.6794 | MLP Loss=1.5790, Acc=0.5932\n",
      "[Studygroup][1592] CNN Loss=0.9698, Acc=0.6734 | MLP Loss=1.5920, Acc=0.5941\n",
      "[Studygroup][1593] CNN Loss=1.0397, Acc=0.6753 | MLP Loss=1.5865, Acc=0.5878\n",
      "[Studygroup][1594] CNN Loss=0.8821, Acc=0.6848 | MLP Loss=1.6455, Acc=0.5802\n",
      "[Studygroup][1595] CNN Loss=0.8972, Acc=0.6829 | MLP Loss=1.6284, Acc=0.5834\n",
      "[Studygroup][1596] CNN Loss=0.8789, Acc=0.6762 | MLP Loss=1.6215, Acc=0.5887\n",
      "[Studygroup][1597] CNN Loss=0.8984, Acc=0.6737 | MLP Loss=1.6492, Acc=0.5880\n",
      "[Studygroup][1598] CNN Loss=0.8422, Acc=0.6832 | MLP Loss=1.5894, Acc=0.5859\n",
      "[Studygroup][1599] CNN Loss=0.9950, Acc=0.6810 | MLP Loss=1.6143, Acc=0.5907\n",
      "[Studygroup][1600] CNN Loss=0.8948, Acc=0.6747 | MLP Loss=1.5824, Acc=0.5954\n",
      "[Studygroup][1601] CNN Loss=0.9176, Acc=0.6744 | MLP Loss=1.6434, Acc=0.5815\n",
      "[Studygroup][1602] CNN Loss=0.8476, Acc=0.6816 | MLP Loss=1.6701, Acc=0.5917\n",
      "[Studygroup][1603] CNN Loss=0.9034, Acc=0.6881 | MLP Loss=1.6683, Acc=0.5864\n",
      "[Studygroup][1604] CNN Loss=0.8807, Acc=0.6792 | MLP Loss=1.6450, Acc=0.5798\n",
      "[Studygroup][1605] CNN Loss=0.9400, Acc=0.6796 | MLP Loss=1.6978, Acc=0.5626\n",
      "[Studygroup][1606] CNN Loss=0.9878, Acc=0.6873 | MLP Loss=1.7299, Acc=0.5880\n",
      "[Studygroup][1607] CNN Loss=0.8195, Acc=0.6816 | MLP Loss=1.6310, Acc=0.5844\n",
      "[Studygroup][1608] CNN Loss=0.9142, Acc=0.6779 | MLP Loss=1.6490, Acc=0.5917\n",
      "[Studygroup][1609] CNN Loss=0.9670, Acc=0.6879 | MLP Loss=1.6365, Acc=0.5890\n",
      "[Studygroup][1610] CNN Loss=0.9313, Acc=0.6794 | MLP Loss=1.6071, Acc=0.5964\n",
      "[Studygroup][1611] CNN Loss=0.8838, Acc=0.6792 | MLP Loss=1.6427, Acc=0.5923\n",
      "[Studygroup][1612] CNN Loss=0.8321, Acc=0.6813 | MLP Loss=1.6004, Acc=0.5938\n",
      "[Studygroup][1613] CNN Loss=0.9371, Acc=0.6796 | MLP Loss=1.6036, Acc=0.5938\n",
      "[Studygroup][1614] CNN Loss=0.9090, Acc=0.6872 | MLP Loss=1.6043, Acc=0.5774\n",
      "[Studygroup][1615] CNN Loss=0.9456, Acc=0.6781 | MLP Loss=1.8691, Acc=0.5807\n",
      "[Studygroup][1616] CNN Loss=0.8857, Acc=0.6819 | MLP Loss=1.7263, Acc=0.5818\n",
      "[Studygroup][1617] CNN Loss=0.8173, Acc=0.6826 | MLP Loss=1.6557, Acc=0.5923\n",
      "[Studygroup][1618] CNN Loss=0.8964, Acc=0.6736 | MLP Loss=1.6417, Acc=0.5868\n",
      "[Studygroup][1619] CNN Loss=0.9224, Acc=0.6800 | MLP Loss=1.5956, Acc=0.5921\n",
      "[Studygroup][1620] CNN Loss=0.8042, Acc=0.6835 | MLP Loss=1.5979, Acc=0.5966\n",
      "[Studygroup][1621] CNN Loss=0.8685, Acc=0.6841 | MLP Loss=1.5916, Acc=0.5869\n",
      "[Studygroup][1622] CNN Loss=0.8711, Acc=0.6686 | MLP Loss=1.5969, Acc=0.5804\n",
      "[Studygroup][1623] CNN Loss=0.8818, Acc=0.6825 | MLP Loss=1.6409, Acc=0.5969\n",
      "[Studygroup][1624] CNN Loss=0.9375, Acc=0.6727 | MLP Loss=1.5674, Acc=0.5860\n",
      "[Studygroup][1625] CNN Loss=0.8974, Acc=0.6766 | MLP Loss=1.5675, Acc=0.5863\n",
      "[Studygroup][1626] CNN Loss=0.8424, Acc=0.6836 | MLP Loss=1.6177, Acc=0.5926\n",
      "[Studygroup][1627] CNN Loss=0.8738, Acc=0.6821 | MLP Loss=1.7062, Acc=0.5813\n",
      "[Studygroup][1628] CNN Loss=0.8997, Acc=0.6718 | MLP Loss=1.6682, Acc=0.5862\n",
      "[Studygroup][1629] CNN Loss=0.9279, Acc=0.6788 | MLP Loss=1.7065, Acc=0.5950\n",
      "[Studygroup][1630] CNN Loss=0.8829, Acc=0.6841 | MLP Loss=1.6397, Acc=0.5947\n",
      "[Studygroup][1631] CNN Loss=0.8686, Acc=0.6755 | MLP Loss=1.6065, Acc=0.5939\n",
      "[Studygroup][1632] CNN Loss=0.9263, Acc=0.6793 | MLP Loss=1.5530, Acc=0.5936\n",
      "[Studygroup][1633] CNN Loss=0.8845, Acc=0.6748 | MLP Loss=1.5657, Acc=0.5870\n",
      "[Studygroup][1634] CNN Loss=0.8765, Acc=0.6765 | MLP Loss=1.6156, Acc=0.5871\n",
      "[Studygroup][1635] CNN Loss=0.9197, Acc=0.6789 | MLP Loss=1.5294, Acc=0.5861\n",
      "[Studygroup][1636] CNN Loss=0.8524, Acc=0.6855 | MLP Loss=1.6739, Acc=0.5921\n",
      "[Studygroup][1637] CNN Loss=0.9171, Acc=0.6783 | MLP Loss=1.6126, Acc=0.5865\n",
      "[Studygroup][1638] CNN Loss=0.9315, Acc=0.6740 | MLP Loss=1.5795, Acc=0.5839\n",
      "[Studygroup][1639] CNN Loss=0.8144, Acc=0.6809 | MLP Loss=1.5976, Acc=0.5839\n",
      "[Studygroup][1640] CNN Loss=0.8533, Acc=0.6822 | MLP Loss=1.6602, Acc=0.5822\n",
      "[Studygroup][1641] CNN Loss=0.8692, Acc=0.6765 | MLP Loss=1.6223, Acc=0.5946\n",
      "[Studygroup][1642] CNN Loss=0.8913, Acc=0.6812 | MLP Loss=1.5888, Acc=0.5877\n",
      "[Studygroup][1643] CNN Loss=0.8415, Acc=0.6801 | MLP Loss=1.5869, Acc=0.5903\n",
      "[Studygroup][1644] CNN Loss=0.9504, Acc=0.6725 | MLP Loss=1.5814, Acc=0.5801\n",
      "[Studygroup][1645] CNN Loss=0.8736, Acc=0.6836 | MLP Loss=1.5776, Acc=0.5912\n",
      "[Studygroup][1646] CNN Loss=1.0269, Acc=0.6727 | MLP Loss=1.6266, Acc=0.5841\n",
      "[Studygroup][1647] CNN Loss=0.9189, Acc=0.6780 | MLP Loss=1.6247, Acc=0.5925\n",
      "[Studygroup][1648] CNN Loss=0.8345, Acc=0.6637 | MLP Loss=1.6435, Acc=0.5623\n",
      "[Studygroup][1649] CNN Loss=1.0785, Acc=0.6742 | MLP Loss=1.9972, Acc=0.5853\n",
      "[Studygroup][1650] CNN Loss=0.9324, Acc=0.6762 | MLP Loss=1.7122, Acc=0.5871\n",
      "[Studygroup][1651] CNN Loss=0.9080, Acc=0.6761 | MLP Loss=1.6487, Acc=0.5898\n",
      "[Studygroup][1652] CNN Loss=0.8294, Acc=0.6797 | MLP Loss=1.6727, Acc=0.5888\n",
      "[Studygroup][1653] CNN Loss=0.8203, Acc=0.6759 | MLP Loss=1.6035, Acc=0.5913\n",
      "[Studygroup][1654] CNN Loss=0.8643, Acc=0.6765 | MLP Loss=1.6455, Acc=0.5959\n",
      "[Studygroup][1655] CNN Loss=0.9509, Acc=0.6828 | MLP Loss=1.6105, Acc=0.5918\n",
      "[Studygroup][1656] CNN Loss=0.8666, Acc=0.6832 | MLP Loss=1.6010, Acc=0.5935\n",
      "[Studygroup][1657] CNN Loss=0.8996, Acc=0.6839 | MLP Loss=1.6735, Acc=0.5963\n",
      "[Studygroup][1658] CNN Loss=0.8712, Acc=0.6848 | MLP Loss=1.6337, Acc=0.5917\n",
      "[Studygroup][1659] CNN Loss=0.8633, Acc=0.6792 | MLP Loss=1.6422, Acc=0.5843\n",
      "[Studygroup][1660] CNN Loss=0.9919, Acc=0.6658 | MLP Loss=1.5978, Acc=0.5701\n",
      "[Studygroup][1661] CNN Loss=0.9350, Acc=0.6770 | MLP Loss=1.5735, Acc=0.5863\n",
      "[Studygroup][1662] CNN Loss=0.9495, Acc=0.6765 | MLP Loss=1.6029, Acc=0.5878\n",
      "[Studygroup][1663] CNN Loss=0.9289, Acc=0.6693 | MLP Loss=1.6910, Acc=0.5878\n",
      "[Studygroup][1664] CNN Loss=1.0055, Acc=0.6813 | MLP Loss=1.6118, Acc=0.5855\n",
      "[Studygroup][1665] CNN Loss=0.9322, Acc=0.6792 | MLP Loss=1.7069, Acc=0.5838\n",
      "[Studygroup][1666] CNN Loss=0.8452, Acc=0.6778 | MLP Loss=1.5771, Acc=0.5930\n",
      "[Studygroup][1667] CNN Loss=0.8447, Acc=0.6828 | MLP Loss=1.6065, Acc=0.5844\n",
      "[Studygroup][1668] CNN Loss=0.8001, Acc=0.6776 | MLP Loss=1.6334, Acc=0.5827\n",
      "[Studygroup][1669] CNN Loss=0.9421, Acc=0.6793 | MLP Loss=1.6721, Acc=0.5856\n",
      "[Studygroup][1670] CNN Loss=0.8335, Acc=0.6820 | MLP Loss=1.5926, Acc=0.5874\n",
      "[Studygroup][1671] CNN Loss=0.8297, Acc=0.6841 | MLP Loss=1.6570, Acc=0.5824\n",
      "[Studygroup][1672] CNN Loss=0.8816, Acc=0.6827 | MLP Loss=1.5892, Acc=0.5903\n",
      "[Studygroup][1673] CNN Loss=0.9400, Acc=0.6823 | MLP Loss=1.5149, Acc=0.5790\n",
      "[Studygroup][1674] CNN Loss=0.9626, Acc=0.6771 | MLP Loss=1.5642, Acc=0.5927\n",
      "[Studygroup][1675] CNN Loss=0.9205, Acc=0.6824 | MLP Loss=1.6385, Acc=0.5845\n",
      "[Studygroup][1676] CNN Loss=0.8175, Acc=0.6816 | MLP Loss=1.6403, Acc=0.5910\n",
      "[Studygroup][1677] CNN Loss=0.8197, Acc=0.6788 | MLP Loss=1.6144, Acc=0.5930\n",
      "[Studygroup][1678] CNN Loss=0.9043, Acc=0.6809 | MLP Loss=1.6792, Acc=0.5881\n",
      "[Studygroup][1679] CNN Loss=0.8829, Acc=0.6812 | MLP Loss=1.6838, Acc=0.5847\n",
      "[Studygroup][1680] CNN Loss=0.9160, Acc=0.6729 | MLP Loss=1.5996, Acc=0.5914\n",
      "[Studygroup][1681] CNN Loss=0.8986, Acc=0.6841 | MLP Loss=1.6641, Acc=0.5824\n",
      "[Studygroup][1682] CNN Loss=0.9065, Acc=0.6772 | MLP Loss=1.6766, Acc=0.5847\n",
      "[Studygroup][1683] CNN Loss=0.8952, Acc=0.6797 | MLP Loss=1.6618, Acc=0.5871\n",
      "[Studygroup][1684] CNN Loss=0.8661, Acc=0.6822 | MLP Loss=1.6162, Acc=0.5872\n",
      "[Studygroup][1685] CNN Loss=0.8133, Acc=0.6872 | MLP Loss=1.6718, Acc=0.5949\n",
      "[Studygroup][1686] CNN Loss=0.8660, Acc=0.6840 | MLP Loss=1.6412, Acc=0.5972\n",
      "[Studygroup][1687] CNN Loss=0.9058, Acc=0.6719 | MLP Loss=1.6405, Acc=0.5796\n",
      "[Studygroup][1688] CNN Loss=1.0252, Acc=0.6686 | MLP Loss=1.6797, Acc=0.5935\n",
      "[Studygroup][1689] CNN Loss=0.8816, Acc=0.6795 | MLP Loss=1.6513, Acc=0.5950\n",
      "[Studygroup][1690] CNN Loss=0.8171, Acc=0.6854 | MLP Loss=1.6178, Acc=0.5911\n",
      "[Studygroup][1691] CNN Loss=0.8730, Acc=0.6797 | MLP Loss=1.6574, Acc=0.5870\n",
      "[Studygroup][1692] CNN Loss=0.9063, Acc=0.6785 | MLP Loss=1.6071, Acc=0.5878\n",
      "[Studygroup][1693] CNN Loss=1.0773, Acc=0.6768 | MLP Loss=1.6258, Acc=0.5932\n",
      "[Studygroup][1694] CNN Loss=0.9089, Acc=0.6814 | MLP Loss=1.6368, Acc=0.5823\n",
      "[Studygroup][1695] CNN Loss=0.9236, Acc=0.6810 | MLP Loss=1.5650, Acc=0.5918\n",
      "[Studygroup][1696] CNN Loss=0.9083, Acc=0.6850 | MLP Loss=1.5781, Acc=0.5961\n",
      "[Studygroup][1697] CNN Loss=0.7955, Acc=0.6824 | MLP Loss=1.5789, Acc=0.5932\n",
      "[Studygroup][1698] CNN Loss=0.8925, Acc=0.6799 | MLP Loss=1.5908, Acc=0.5915\n",
      "[Studygroup][1699] CNN Loss=0.8664, Acc=0.6845 | MLP Loss=1.6770, Acc=0.5960\n",
      "[Studygroup][1700] CNN Loss=0.8626, Acc=0.6810 | MLP Loss=1.7036, Acc=0.5995\n",
      "[Studygroup][1701] CNN Loss=0.8592, Acc=0.6766 | MLP Loss=1.6736, Acc=0.5904\n",
      "[Studygroup][1702] CNN Loss=0.8823, Acc=0.6809 | MLP Loss=1.6895, Acc=0.5955\n",
      "[Studygroup][1703] CNN Loss=0.9421, Acc=0.6777 | MLP Loss=1.6048, Acc=0.5883\n",
      "[Studygroup][1704] CNN Loss=0.9126, Acc=0.6836 | MLP Loss=1.6576, Acc=0.5922\n",
      "[Studygroup][1705] CNN Loss=0.7999, Acc=0.6834 | MLP Loss=1.6388, Acc=0.5933\n",
      "[Studygroup][1706] CNN Loss=0.8868, Acc=0.6825 | MLP Loss=1.7003, Acc=0.5798\n",
      "[Studygroup][1707] CNN Loss=0.8619, Acc=0.6760 | MLP Loss=1.6580, Acc=0.5934\n",
      "[Studygroup][1708] CNN Loss=0.8282, Acc=0.6869 | MLP Loss=1.6151, Acc=0.5976\n",
      "[Studygroup][1709] CNN Loss=0.8319, Acc=0.6757 | MLP Loss=1.5635, Acc=0.5980\n",
      "[Studygroup][1710] CNN Loss=0.8922, Acc=0.6746 | MLP Loss=1.6344, Acc=0.5909\n",
      "[Studygroup][1711] CNN Loss=0.8389, Acc=0.6777 | MLP Loss=1.6315, Acc=0.5782\n",
      "[Studygroup][1712] CNN Loss=0.9027, Acc=0.6798 | MLP Loss=1.6728, Acc=0.5914\n",
      "[Studygroup][1713] CNN Loss=0.8644, Acc=0.6796 | MLP Loss=1.6344, Acc=0.5910\n",
      "[Studygroup][1714] CNN Loss=0.9043, Acc=0.6739 | MLP Loss=1.5966, Acc=0.5900\n",
      "[Studygroup][1715] CNN Loss=0.8145, Acc=0.6725 | MLP Loss=1.6292, Acc=0.5908\n",
      "[Studygroup][1716] CNN Loss=0.8434, Acc=0.6781 | MLP Loss=1.6109, Acc=0.5906\n",
      "[Studygroup][1717] CNN Loss=0.9153, Acc=0.6807 | MLP Loss=1.6446, Acc=0.5946\n",
      "[Studygroup][1718] CNN Loss=0.8693, Acc=0.6760 | MLP Loss=1.5919, Acc=0.5915\n",
      "[Studygroup][1719] CNN Loss=0.8412, Acc=0.6763 | MLP Loss=1.6665, Acc=0.5951\n",
      "[Studygroup][1720] CNN Loss=0.8273, Acc=0.6804 | MLP Loss=1.6627, Acc=0.5879\n",
      "[Studygroup][1721] CNN Loss=0.8230, Acc=0.6785 | MLP Loss=1.5581, Acc=0.5888\n",
      "[Studygroup][1722] CNN Loss=0.9498, Acc=0.6752 | MLP Loss=1.6298, Acc=0.5906\n",
      "[Studygroup][1723] CNN Loss=0.8928, Acc=0.6747 | MLP Loss=1.6721, Acc=0.5829\n",
      "[Studygroup][1724] CNN Loss=0.8751, Acc=0.6794 | MLP Loss=1.6451, Acc=0.5998\n",
      "[Studygroup][1725] CNN Loss=0.8789, Acc=0.6820 | MLP Loss=1.6325, Acc=0.5851\n",
      "[Studygroup][1726] CNN Loss=1.0769, Acc=0.6697 | MLP Loss=1.6754, Acc=0.5873\n",
      "[Studygroup][1727] CNN Loss=0.9512, Acc=0.6780 | MLP Loss=1.5416, Acc=0.5926\n",
      "[Studygroup][1728] CNN Loss=0.8768, Acc=0.6814 | MLP Loss=1.6366, Acc=0.5669\n",
      "[Studygroup][1729] CNN Loss=0.9309, Acc=0.6738 | MLP Loss=1.6133, Acc=0.5939\n",
      "[Studygroup][1730] CNN Loss=0.9405, Acc=0.6774 | MLP Loss=1.8189, Acc=0.5863\n",
      "[Studygroup][1731] CNN Loss=0.9636, Acc=0.6802 | MLP Loss=1.7726, Acc=0.5732\n",
      "[Studygroup][1732] CNN Loss=0.8318, Acc=0.6782 | MLP Loss=1.6485, Acc=0.5886\n",
      "[Studygroup][1733] CNN Loss=0.8394, Acc=0.6815 | MLP Loss=1.5743, Acc=0.5965\n",
      "[Studygroup][1734] CNN Loss=0.9200, Acc=0.6798 | MLP Loss=1.6266, Acc=0.5980\n",
      "[Studygroup][1735] CNN Loss=0.8667, Acc=0.6788 | MLP Loss=1.6167, Acc=0.5893\n",
      "[Studygroup][1736] CNN Loss=0.8439, Acc=0.6805 | MLP Loss=1.5912, Acc=0.5899\n",
      "[Studygroup][1737] CNN Loss=0.8526, Acc=0.6730 | MLP Loss=1.6722, Acc=0.5838\n",
      "[Studygroup][1738] CNN Loss=0.9175, Acc=0.6805 | MLP Loss=1.7284, Acc=0.5965\n",
      "[Studygroup][1739] CNN Loss=0.8880, Acc=0.6772 | MLP Loss=1.6661, Acc=0.5961\n",
      "[Studygroup][1740] CNN Loss=0.9039, Acc=0.6797 | MLP Loss=1.6982, Acc=0.5890\n",
      "[Studygroup][1741] CNN Loss=1.0112, Acc=0.6754 | MLP Loss=1.6072, Acc=0.5890\n",
      "[Studygroup][1742] CNN Loss=0.9100, Acc=0.6737 | MLP Loss=1.6013, Acc=0.5828\n",
      "[Studygroup][1743] CNN Loss=0.9047, Acc=0.6827 | MLP Loss=1.5702, Acc=0.5970\n",
      "[Studygroup][1744] CNN Loss=0.9000, Acc=0.6814 | MLP Loss=1.5850, Acc=0.5880\n",
      "[Studygroup][1745] CNN Loss=0.9340, Acc=0.6787 | MLP Loss=1.6894, Acc=0.5816\n",
      "[Studygroup][1746] CNN Loss=1.0314, Acc=0.6737 | MLP Loss=1.6480, Acc=0.5935\n",
      "[Studygroup][1747] CNN Loss=0.8909, Acc=0.6707 | MLP Loss=1.6146, Acc=0.5956\n",
      "[Studygroup][1748] CNN Loss=0.9407, Acc=0.6786 | MLP Loss=1.6151, Acc=0.5897\n",
      "[Studygroup][1749] CNN Loss=0.9054, Acc=0.6825 | MLP Loss=1.5770, Acc=0.5860\n",
      "[Studygroup][1750] CNN Loss=0.9501, Acc=0.6830 | MLP Loss=1.6610, Acc=0.5956\n",
      "[Studygroup][1751] CNN Loss=0.8753, Acc=0.6799 | MLP Loss=1.6136, Acc=0.5856\n",
      "[Studygroup][1752] CNN Loss=0.8328, Acc=0.6817 | MLP Loss=1.6446, Acc=0.5900\n",
      "[Studygroup][1753] CNN Loss=0.9378, Acc=0.6772 | MLP Loss=1.6114, Acc=0.5908\n",
      "[Studygroup][1754] CNN Loss=0.8875, Acc=0.6769 | MLP Loss=1.5914, Acc=0.5869\n",
      "[Studygroup][1755] CNN Loss=1.0802, Acc=0.6756 | MLP Loss=1.6832, Acc=0.5859\n",
      "[Studygroup][1756] CNN Loss=0.9053, Acc=0.6721 | MLP Loss=1.6227, Acc=0.5883\n",
      "[Studygroup][1757] CNN Loss=0.9153, Acc=0.6752 | MLP Loss=1.5600, Acc=0.5833\n",
      "[Studygroup][1758] CNN Loss=0.8737, Acc=0.6801 | MLP Loss=1.6230, Acc=0.5961\n",
      "[Studygroup][1759] CNN Loss=0.9760, Acc=0.6797 | MLP Loss=1.5928, Acc=0.5891\n",
      "[Studygroup][1760] CNN Loss=0.8722, Acc=0.6846 | MLP Loss=1.5543, Acc=0.5936\n",
      "[Studygroup][1761] CNN Loss=0.8685, Acc=0.6737 | MLP Loss=1.5810, Acc=0.5930\n",
      "[Studygroup][1762] CNN Loss=0.8429, Acc=0.6845 | MLP Loss=1.5940, Acc=0.5838\n",
      "[Studygroup][1763] CNN Loss=0.8436, Acc=0.6782 | MLP Loss=1.5276, Acc=0.5806\n",
      "[Studygroup][1764] CNN Loss=0.8338, Acc=0.6865 | MLP Loss=1.6610, Acc=0.5910\n",
      "[Studygroup][1765] CNN Loss=0.7568, Acc=0.6774 | MLP Loss=1.6411, Acc=0.5928\n",
      "[Studygroup][1766] CNN Loss=0.9101, Acc=0.6784 | MLP Loss=1.6444, Acc=0.5870\n",
      "[Studygroup][1767] CNN Loss=0.9680, Acc=0.6788 | MLP Loss=1.7397, Acc=0.5943\n",
      "[Studygroup][1768] CNN Loss=1.0018, Acc=0.6777 | MLP Loss=1.6157, Acc=0.5883\n",
      "[Studygroup][1769] CNN Loss=0.9174, Acc=0.6816 | MLP Loss=1.5926, Acc=0.5836\n",
      "[Studygroup][1770] CNN Loss=0.8123, Acc=0.6797 | MLP Loss=1.6096, Acc=0.5929\n",
      "[Studygroup][1771] CNN Loss=0.8957, Acc=0.6699 | MLP Loss=1.6554, Acc=0.5932\n",
      "[Studygroup][1772] CNN Loss=0.9444, Acc=0.6762 | MLP Loss=1.5835, Acc=0.5923\n",
      "[Studygroup][1773] CNN Loss=0.8083, Acc=0.6823 | MLP Loss=1.6313, Acc=0.5898\n",
      "[Studygroup][1774] CNN Loss=0.9952, Acc=0.6859 | MLP Loss=1.5773, Acc=0.5773\n",
      "[Studygroup][1775] CNN Loss=0.9489, Acc=0.6812 | MLP Loss=1.5796, Acc=0.5886\n",
      "[Studygroup][1776] CNN Loss=0.9073, Acc=0.6820 | MLP Loss=1.7132, Acc=0.5853\n",
      "[Studygroup][1777] CNN Loss=0.9852, Acc=0.6735 | MLP Loss=1.6273, Acc=0.5964\n",
      "[Studygroup][1778] CNN Loss=0.8887, Acc=0.6809 | MLP Loss=1.5933, Acc=0.5881\n",
      "[Studygroup][1779] CNN Loss=0.9338, Acc=0.6840 | MLP Loss=1.5885, Acc=0.5755\n",
      "[Studygroup][1780] CNN Loss=0.8445, Acc=0.6821 | MLP Loss=1.6677, Acc=0.5977\n",
      "[Studygroup][1781] CNN Loss=0.9246, Acc=0.6868 | MLP Loss=1.5770, Acc=0.5940\n",
      "[Studygroup][1782] CNN Loss=0.8784, Acc=0.6822 | MLP Loss=1.6339, Acc=0.5943\n",
      "[Studygroup][1783] CNN Loss=0.8608, Acc=0.6731 | MLP Loss=1.5448, Acc=0.5955\n",
      "[Studygroup][1784] CNN Loss=0.7939, Acc=0.6813 | MLP Loss=1.6085, Acc=0.5913\n",
      "[Studygroup][1785] CNN Loss=0.8020, Acc=0.6731 | MLP Loss=1.6236, Acc=0.5918\n",
      "[Studygroup][1786] CNN Loss=0.8075, Acc=0.6812 | MLP Loss=1.6484, Acc=0.5863\n",
      "[Studygroup][1787] CNN Loss=0.8329, Acc=0.6796 | MLP Loss=1.6714, Acc=0.5948\n",
      "[Studygroup][1788] CNN Loss=0.8098, Acc=0.6821 | MLP Loss=1.6476, Acc=0.5849\n",
      "[Studygroup][1789] CNN Loss=0.9088, Acc=0.6735 | MLP Loss=1.6249, Acc=0.5941\n",
      "[Studygroup][1790] CNN Loss=0.8550, Acc=0.6809 | MLP Loss=1.6534, Acc=0.5925\n",
      "[Studygroup][1791] CNN Loss=0.9430, Acc=0.6703 | MLP Loss=1.6095, Acc=0.5747\n",
      "[Studygroup][1792] CNN Loss=0.9900, Acc=0.6759 | MLP Loss=1.5706, Acc=0.5917\n",
      "[Studygroup][1793] CNN Loss=0.8887, Acc=0.6772 | MLP Loss=1.4947, Acc=0.5877\n",
      "[Studygroup][1794] CNN Loss=0.8955, Acc=0.6769 | MLP Loss=1.5719, Acc=0.5901\n",
      "[Studygroup][1795] CNN Loss=0.8874, Acc=0.6667 | MLP Loss=1.6287, Acc=0.5933\n",
      "[Studygroup][1796] CNN Loss=0.9058, Acc=0.6787 | MLP Loss=1.5721, Acc=0.5806\n",
      "[Studygroup][1797] CNN Loss=0.8708, Acc=0.6842 | MLP Loss=1.6164, Acc=0.5802\n",
      "[Studygroup][1798] CNN Loss=0.9311, Acc=0.6734 | MLP Loss=1.6491, Acc=0.5854\n",
      "[Studygroup][1799] CNN Loss=0.9297, Acc=0.6805 | MLP Loss=1.6100, Acc=0.5914\n",
      "[Studygroup][1800] CNN Loss=0.8131, Acc=0.6796 | MLP Loss=1.6466, Acc=0.5890\n",
      "[Studygroup][1801] CNN Loss=0.9074, Acc=0.6571 | MLP Loss=1.6211, Acc=0.5872\n",
      "[Studygroup][1802] CNN Loss=0.9926, Acc=0.6621 | MLP Loss=1.6235, Acc=0.5950\n",
      "[Studygroup][1803] CNN Loss=0.8735, Acc=0.6809 | MLP Loss=1.5801, Acc=0.5943\n",
      "[Studygroup][1804] CNN Loss=0.7727, Acc=0.6796 | MLP Loss=1.6270, Acc=0.5905\n",
      "[Studygroup][1805] CNN Loss=0.8812, Acc=0.6829 | MLP Loss=1.6369, Acc=0.5931\n",
      "[Studygroup][1806] CNN Loss=0.8703, Acc=0.6791 | MLP Loss=1.6434, Acc=0.5881\n",
      "[Studygroup][1807] CNN Loss=0.8576, Acc=0.6802 | MLP Loss=1.6057, Acc=0.5887\n",
      "[Studygroup][1808] CNN Loss=0.9710, Acc=0.6612 | MLP Loss=1.6359, Acc=0.5727\n",
      "[Studygroup][1809] CNN Loss=0.9577, Acc=0.6814 | MLP Loss=1.5997, Acc=0.5876\n",
      "[Studygroup][1810] CNN Loss=0.9282, Acc=0.6818 | MLP Loss=1.5491, Acc=0.5750\n",
      "[Studygroup][1811] CNN Loss=0.8525, Acc=0.6819 | MLP Loss=1.6042, Acc=0.5837\n",
      "[Studygroup][1812] CNN Loss=0.8502, Acc=0.6805 | MLP Loss=1.6463, Acc=0.5885\n",
      "[Studygroup][1813] CNN Loss=0.9109, Acc=0.6807 | MLP Loss=1.5839, Acc=0.5798\n",
      "[Studygroup][1814] CNN Loss=0.9634, Acc=0.6749 | MLP Loss=1.7447, Acc=0.5846\n",
      "[Studygroup][1815] CNN Loss=0.8726, Acc=0.6791 | MLP Loss=1.6768, Acc=0.5881\n",
      "[Studygroup][1816] CNN Loss=0.8166, Acc=0.6771 | MLP Loss=1.6340, Acc=0.5918\n",
      "[Studygroup][1817] CNN Loss=0.9064, Acc=0.6800 | MLP Loss=1.6325, Acc=0.5603\n",
      "[Studygroup][1818] CNN Loss=0.7947, Acc=0.6855 | MLP Loss=1.5771, Acc=0.5903\n",
      "[Studygroup][1819] CNN Loss=0.8655, Acc=0.6796 | MLP Loss=1.6226, Acc=0.5907\n",
      "[Studygroup][1820] CNN Loss=0.8786, Acc=0.6802 | MLP Loss=1.6041, Acc=0.5926\n",
      "[Studygroup][1821] CNN Loss=0.9256, Acc=0.6673 | MLP Loss=1.6111, Acc=0.5861\n",
      "[Studygroup][1822] CNN Loss=0.9519, Acc=0.6840 | MLP Loss=1.6436, Acc=0.5880\n",
      "[Studygroup][1823] CNN Loss=0.9780, Acc=0.6792 | MLP Loss=1.6750, Acc=0.5884\n",
      "[Studygroup][1824] CNN Loss=0.9225, Acc=0.6775 | MLP Loss=1.6541, Acc=0.5909\n",
      "[Studygroup][1825] CNN Loss=0.8198, Acc=0.6833 | MLP Loss=1.6505, Acc=0.5919\n",
      "[Studygroup][1826] CNN Loss=0.8329, Acc=0.6863 | MLP Loss=1.6717, Acc=0.5917\n",
      "[Studygroup][1827] CNN Loss=0.8184, Acc=0.6824 | MLP Loss=1.6533, Acc=0.5877\n",
      "[Studygroup][1828] CNN Loss=0.8163, Acc=0.6804 | MLP Loss=1.6466, Acc=0.5943\n",
      "[Studygroup][1829] CNN Loss=0.8845, Acc=0.6895 | MLP Loss=1.5708, Acc=0.5946\n",
      "[Studygroup][1830] CNN Loss=0.8557, Acc=0.6807 | MLP Loss=1.6207, Acc=0.5947\n",
      "[Studygroup][1831] CNN Loss=0.9358, Acc=0.6828 | MLP Loss=1.6052, Acc=0.5906\n",
      "[Studygroup][1832] CNN Loss=0.8520, Acc=0.6865 | MLP Loss=1.6094, Acc=0.5882\n",
      "[Studygroup][1833] CNN Loss=1.1357, Acc=0.6832 | MLP Loss=1.5950, Acc=0.5966\n",
      "[Studygroup][1834] CNN Loss=0.8864, Acc=0.6813 | MLP Loss=1.6468, Acc=0.5982\n",
      "[Studygroup][1835] CNN Loss=0.8779, Acc=0.6843 | MLP Loss=1.6329, Acc=0.5853\n",
      "[Studygroup][1836] CNN Loss=0.9699, Acc=0.6730 | MLP Loss=1.6756, Acc=0.5956\n",
      "[Studygroup][1837] CNN Loss=0.8564, Acc=0.6839 | MLP Loss=1.6241, Acc=0.5851\n",
      "[Studygroup][1838] CNN Loss=0.9270, Acc=0.6838 | MLP Loss=1.8817, Acc=0.5801\n",
      "[Studygroup][1839] CNN Loss=0.8865, Acc=0.6781 | MLP Loss=1.6492, Acc=0.5884\n",
      "[Studygroup][1840] CNN Loss=0.8941, Acc=0.6823 | MLP Loss=1.5698, Acc=0.5954\n",
      "[Studygroup][1841] CNN Loss=0.9165, Acc=0.6794 | MLP Loss=1.5896, Acc=0.6016\n",
      "[Studygroup][1842] CNN Loss=0.8991, Acc=0.6848 | MLP Loss=1.6031, Acc=0.5898\n",
      "[Studygroup][1843] CNN Loss=0.9208, Acc=0.6851 | MLP Loss=1.5023, Acc=0.5968\n",
      "[Studygroup][1844] CNN Loss=0.8822, Acc=0.6757 | MLP Loss=1.6010, Acc=0.5917\n",
      "[Studygroup][1845] CNN Loss=0.8201, Acc=0.6869 | MLP Loss=1.5571, Acc=0.5933\n",
      "[Studygroup][1846] CNN Loss=0.8326, Acc=0.6786 | MLP Loss=1.5934, Acc=0.5896\n",
      "[Studygroup][1847] CNN Loss=0.9166, Acc=0.6740 | MLP Loss=1.6323, Acc=0.5962\n",
      "[Studygroup][1848] CNN Loss=0.8518, Acc=0.6783 | MLP Loss=1.5652, Acc=0.5967\n",
      "[Studygroup][1849] CNN Loss=0.8918, Acc=0.6820 | MLP Loss=1.6114, Acc=0.5840\n",
      "[Studygroup][1850] CNN Loss=0.8557, Acc=0.6784 | MLP Loss=1.5697, Acc=0.5944\n",
      "[Studygroup][1851] CNN Loss=0.8793, Acc=0.6823 | MLP Loss=1.5809, Acc=0.6001\n",
      "[Studygroup][1852] CNN Loss=0.8897, Acc=0.6771 | MLP Loss=1.6698, Acc=0.5946\n",
      "[Studygroup][1853] CNN Loss=0.8501, Acc=0.6740 | MLP Loss=1.6011, Acc=0.5878\n",
      "[Studygroup][1854] CNN Loss=0.8238, Acc=0.6851 | MLP Loss=1.6802, Acc=0.5896\n",
      "[Studygroup][1855] CNN Loss=0.8044, Acc=0.6859 | MLP Loss=1.7159, Acc=0.5751\n",
      "[Studygroup][1856] CNN Loss=0.8588, Acc=0.6823 | MLP Loss=1.7043, Acc=0.5932\n",
      "[Studygroup][1857] CNN Loss=0.8515, Acc=0.6796 | MLP Loss=1.6495, Acc=0.5849\n",
      "[Studygroup][1858] CNN Loss=0.8996, Acc=0.6753 | MLP Loss=1.8202, Acc=0.5771\n",
      "[Studygroup][1859] CNN Loss=0.8677, Acc=0.6766 | MLP Loss=1.6929, Acc=0.5850\n",
      "[Studygroup][1860] CNN Loss=0.9105, Acc=0.6716 | MLP Loss=1.6314, Acc=0.5934\n",
      "[Studygroup][1861] CNN Loss=0.8779, Acc=0.6743 | MLP Loss=1.5907, Acc=0.5723\n",
      "[Studygroup][1862] CNN Loss=0.9312, Acc=0.6822 | MLP Loss=1.7566, Acc=0.5936\n",
      "[Studygroup][1863] CNN Loss=0.8873, Acc=0.6776 | MLP Loss=1.6842, Acc=0.5975\n",
      "[Studygroup][1864] CNN Loss=0.8229, Acc=0.6839 | MLP Loss=1.6793, Acc=0.5969\n",
      "[Studygroup][1865] CNN Loss=0.8637, Acc=0.6826 | MLP Loss=1.6073, Acc=0.5926\n",
      "[Studygroup][1866] CNN Loss=0.9792, Acc=0.6644 | MLP Loss=1.5318, Acc=0.5974\n",
      "[Studygroup][1867] CNN Loss=0.9204, Acc=0.6825 | MLP Loss=1.5484, Acc=0.5993\n",
      "[Studygroup][1868] CNN Loss=0.8196, Acc=0.6781 | MLP Loss=1.5991, Acc=0.5982\n",
      "[Studygroup][1869] CNN Loss=0.8138, Acc=0.6819 | MLP Loss=1.5526, Acc=0.5948\n",
      "[Studygroup][1870] CNN Loss=0.8986, Acc=0.6807 | MLP Loss=1.6170, Acc=0.5881\n",
      "[Studygroup][1871] CNN Loss=0.8543, Acc=0.6788 | MLP Loss=1.6780, Acc=0.5858\n",
      "[Studygroup][1872] CNN Loss=0.7975, Acc=0.6745 | MLP Loss=1.5629, Acc=0.5850\n",
      "[Studygroup][1873] CNN Loss=0.8441, Acc=0.6820 | MLP Loss=1.6691, Acc=0.5936\n",
      "[Studygroup][1874] CNN Loss=0.9187, Acc=0.6835 | MLP Loss=1.5804, Acc=0.5911\n",
      "[Studygroup][1875] CNN Loss=0.8783, Acc=0.6753 | MLP Loss=1.5935, Acc=0.5831\n",
      "[Studygroup][1876] CNN Loss=0.8993, Acc=0.6724 | MLP Loss=1.6393, Acc=0.5865\n",
      "[Studygroup][1877] CNN Loss=0.9304, Acc=0.6794 | MLP Loss=1.5474, Acc=0.5996\n",
      "[Studygroup][1878] CNN Loss=0.9320, Acc=0.6767 | MLP Loss=1.5859, Acc=0.5925\n",
      "[Studygroup][1879] CNN Loss=0.8740, Acc=0.6759 | MLP Loss=1.6190, Acc=0.5836\n",
      "[Studygroup][1880] CNN Loss=0.9628, Acc=0.6790 | MLP Loss=1.6321, Acc=0.5960\n",
      "[Studygroup][1881] CNN Loss=0.9343, Acc=0.6769 | MLP Loss=1.6764, Acc=0.5855\n",
      "[Studygroup][1882] CNN Loss=0.9106, Acc=0.6803 | MLP Loss=1.6742, Acc=0.5944\n",
      "[Studygroup][1883] CNN Loss=0.9276, Acc=0.6816 | MLP Loss=1.6454, Acc=0.5831\n",
      "[Studygroup][1884] CNN Loss=0.8295, Acc=0.6768 | MLP Loss=1.6288, Acc=0.5880\n",
      "[Studygroup][1885] CNN Loss=0.9690, Acc=0.6824 | MLP Loss=1.6238, Acc=0.5871\n",
      "[Studygroup][1886] CNN Loss=0.9734, Acc=0.6822 | MLP Loss=1.5360, Acc=0.5953\n",
      "[Studygroup][1887] CNN Loss=0.9084, Acc=0.6865 | MLP Loss=1.5550, Acc=0.5950\n",
      "[Studygroup][1888] CNN Loss=0.8120, Acc=0.6749 | MLP Loss=1.6304, Acc=0.5927\n",
      "[Studygroup][1889] CNN Loss=0.8590, Acc=0.6815 | MLP Loss=1.6226, Acc=0.5951\n",
      "[Studygroup][1890] CNN Loss=0.8787, Acc=0.6781 | MLP Loss=1.5538, Acc=0.5983\n",
      "[Studygroup][1891] CNN Loss=0.8787, Acc=0.6714 | MLP Loss=1.6796, Acc=0.5879\n",
      "[Studygroup][1892] CNN Loss=0.9764, Acc=0.6772 | MLP Loss=1.8201, Acc=0.5782\n",
      "[Studygroup][1893] CNN Loss=0.9549, Acc=0.6764 | MLP Loss=1.7946, Acc=0.5844\n",
      "[Studygroup][1894] CNN Loss=0.9339, Acc=0.6747 | MLP Loss=1.6406, Acc=0.5899\n",
      "[Studygroup][1895] CNN Loss=1.0400, Acc=0.6675 | MLP Loss=1.7035, Acc=0.5879\n",
      "[Studygroup][1896] CNN Loss=0.9595, Acc=0.6748 | MLP Loss=1.6359, Acc=0.5962\n",
      "[Studygroup][1897] CNN Loss=0.8422, Acc=0.6753 | MLP Loss=1.5647, Acc=0.5965\n",
      "[Studygroup][1898] CNN Loss=0.8768, Acc=0.6745 | MLP Loss=1.6317, Acc=0.5950\n",
      "[Studygroup][1899] CNN Loss=0.8879, Acc=0.6782 | MLP Loss=1.5669, Acc=0.5884\n",
      "[Studygroup][1900] CNN Loss=0.8723, Acc=0.6795 | MLP Loss=1.6267, Acc=0.5936\n",
      "[Studygroup][1901] CNN Loss=0.8118, Acc=0.6831 | MLP Loss=1.7159, Acc=0.5967\n",
      "[Studygroup][1902] CNN Loss=0.8606, Acc=0.6803 | MLP Loss=1.6320, Acc=0.5907\n",
      "[Studygroup][1903] CNN Loss=0.9027, Acc=0.6709 | MLP Loss=1.6888, Acc=0.5909\n",
      "[Studygroup][1904] CNN Loss=1.0940, Acc=0.6667 | MLP Loss=1.6266, Acc=0.5849\n",
      "[Studygroup][1905] CNN Loss=0.9051, Acc=0.6823 | MLP Loss=1.6207, Acc=0.5950\n",
      "[Studygroup][1906] CNN Loss=0.8893, Acc=0.6811 | MLP Loss=1.6654, Acc=0.5939\n",
      "[Studygroup][1907] CNN Loss=0.8695, Acc=0.6802 | MLP Loss=1.7929, Acc=0.5829\n",
      "[Studygroup][1908] CNN Loss=1.1133, Acc=0.6738 | MLP Loss=1.7943, Acc=0.5854\n",
      "[Studygroup][1909] CNN Loss=0.9279, Acc=0.6703 | MLP Loss=1.6459, Acc=0.5918\n",
      "[Studygroup][1910] CNN Loss=0.8746, Acc=0.6810 | MLP Loss=1.6367, Acc=0.5856\n",
      "[Studygroup][1911] CNN Loss=0.9974, Acc=0.6782 | MLP Loss=1.5933, Acc=0.5964\n",
      "[Studygroup][1912] CNN Loss=0.8329, Acc=0.6813 | MLP Loss=1.6498, Acc=0.5879\n",
      "[Studygroup][1913] CNN Loss=0.9129, Acc=0.6752 | MLP Loss=1.6586, Acc=0.5977\n",
      "[Studygroup][1914] CNN Loss=0.9157, Acc=0.6788 | MLP Loss=1.6705, Acc=0.5895\n",
      "[Studygroup][1915] CNN Loss=0.8636, Acc=0.6728 | MLP Loss=1.6833, Acc=0.5903\n",
      "[Studygroup][1916] CNN Loss=0.8971, Acc=0.6747 | MLP Loss=1.6489, Acc=0.5971\n",
      "[Studygroup][1917] CNN Loss=0.8928, Acc=0.6783 | MLP Loss=1.6059, Acc=0.5862\n",
      "[Studygroup][1918] CNN Loss=0.8373, Acc=0.6798 | MLP Loss=1.6210, Acc=0.5843\n",
      "[Studygroup][1919] CNN Loss=0.8937, Acc=0.6859 | MLP Loss=1.6654, Acc=0.5909\n",
      "[Studygroup][1920] CNN Loss=0.8645, Acc=0.6776 | MLP Loss=1.5716, Acc=0.5903\n",
      "[Studygroup][1921] CNN Loss=0.8699, Acc=0.6791 | MLP Loss=1.6023, Acc=0.5845\n",
      "[Studygroup][1922] CNN Loss=0.8742, Acc=0.6775 | MLP Loss=1.7248, Acc=0.5960\n",
      "[Studygroup][1923] CNN Loss=0.8630, Acc=0.6760 | MLP Loss=1.6259, Acc=0.5936\n",
      "[Studygroup][1924] CNN Loss=0.8397, Acc=0.6840 | MLP Loss=1.6561, Acc=0.5963\n",
      "[Studygroup][1925] CNN Loss=0.9268, Acc=0.6827 | MLP Loss=1.7020, Acc=0.5829\n",
      "[Studygroup][1926] CNN Loss=0.9161, Acc=0.6756 | MLP Loss=1.6417, Acc=0.5978\n",
      "[Studygroup][1927] CNN Loss=0.8991, Acc=0.6788 | MLP Loss=1.6175, Acc=0.5860\n",
      "[Studygroup][1928] CNN Loss=0.9514, Acc=0.6777 | MLP Loss=1.6295, Acc=0.5793\n",
      "[Studygroup][1929] CNN Loss=0.8070, Acc=0.6840 | MLP Loss=1.6053, Acc=0.5920\n",
      "[Studygroup][1930] CNN Loss=0.9061, Acc=0.6789 | MLP Loss=1.6227, Acc=0.5918\n",
      "[Studygroup][1931] CNN Loss=0.8710, Acc=0.6770 | MLP Loss=1.5895, Acc=0.5879\n",
      "[Studygroup][1932] CNN Loss=0.8699, Acc=0.6698 | MLP Loss=1.6492, Acc=0.5968\n",
      "[Studygroup][1933] CNN Loss=1.0796, Acc=0.6670 | MLP Loss=1.7048, Acc=0.5883\n",
      "[Studygroup][1934] CNN Loss=0.8589, Acc=0.6734 | MLP Loss=1.6446, Acc=0.5881\n",
      "[Studygroup][1935] CNN Loss=0.9515, Acc=0.6802 | MLP Loss=1.6509, Acc=0.5944\n",
      "[Studygroup][1936] CNN Loss=0.8221, Acc=0.6773 | MLP Loss=1.6225, Acc=0.5931\n",
      "[Studygroup][1937] CNN Loss=0.8451, Acc=0.6784 | MLP Loss=1.7898, Acc=0.5775\n",
      "[Studygroup][1938] CNN Loss=1.0150, Acc=0.6771 | MLP Loss=1.7794, Acc=0.5860\n",
      "[Studygroup][1939] CNN Loss=0.8349, Acc=0.6800 | MLP Loss=1.6064, Acc=0.5990\n",
      "[Studygroup][1940] CNN Loss=0.8167, Acc=0.6784 | MLP Loss=1.6855, Acc=0.5940\n",
      "[Studygroup][1941] CNN Loss=0.8608, Acc=0.6752 | MLP Loss=1.6546, Acc=0.5967\n",
      "[Studygroup][1942] CNN Loss=0.8011, Acc=0.6721 | MLP Loss=1.6351, Acc=0.5918\n",
      "[Studygroup][1943] CNN Loss=0.9776, Acc=0.6834 | MLP Loss=1.8074, Acc=0.5888\n",
      "[Studygroup][1944] CNN Loss=0.9752, Acc=0.6769 | MLP Loss=1.6635, Acc=0.5963\n",
      "[Studygroup][1945] CNN Loss=0.8963, Acc=0.6787 | MLP Loss=1.6615, Acc=0.5942\n",
      "[Studygroup][1946] CNN Loss=0.8041, Acc=0.6822 | MLP Loss=1.6214, Acc=0.5966\n",
      "[Studygroup][1947] CNN Loss=0.9753, Acc=0.6759 | MLP Loss=1.6722, Acc=0.5909\n",
      "[Studygroup][1948] CNN Loss=1.1343, Acc=0.6748 | MLP Loss=1.7495, Acc=0.5835\n",
      "[Studygroup][1949] CNN Loss=0.9155, Acc=0.6824 | MLP Loss=1.7326, Acc=0.5958\n",
      "[Studygroup][1950] CNN Loss=0.9429, Acc=0.6766 | MLP Loss=1.6524, Acc=0.5907\n",
      "[Studygroup][1951] CNN Loss=0.8339, Acc=0.6759 | MLP Loss=1.6196, Acc=0.5914\n",
      "[Studygroup][1952] CNN Loss=0.9061, Acc=0.6783 | MLP Loss=1.7124, Acc=0.5806\n",
      "[Studygroup][1953] CNN Loss=0.9573, Acc=0.6735 | MLP Loss=1.7454, Acc=0.5819\n",
      "[Studygroup][1954] CNN Loss=0.8739, Acc=0.6775 | MLP Loss=1.6284, Acc=0.5936\n",
      "[Studygroup][1955] CNN Loss=0.8482, Acc=0.6808 | MLP Loss=1.5487, Acc=0.5993\n",
      "[Studygroup][1956] CNN Loss=0.9185, Acc=0.6731 | MLP Loss=1.5638, Acc=0.5964\n",
      "[Studygroup][1957] CNN Loss=1.0250, Acc=0.6744 | MLP Loss=1.6002, Acc=0.5933\n",
      "[Studygroup][1958] CNN Loss=0.8611, Acc=0.6827 | MLP Loss=1.6526, Acc=0.5906\n",
      "[Studygroup][1959] CNN Loss=1.0015, Acc=0.6745 | MLP Loss=1.6355, Acc=0.5908\n",
      "[Studygroup][1960] CNN Loss=0.8212, Acc=0.6854 | MLP Loss=1.6609, Acc=0.5952\n",
      "[Studygroup][1961] CNN Loss=0.8108, Acc=0.6779 | MLP Loss=1.6304, Acc=0.5906\n",
      "[Studygroup][1962] CNN Loss=0.8452, Acc=0.6739 | MLP Loss=1.5983, Acc=0.5930\n",
      "[Studygroup][1963] CNN Loss=0.8314, Acc=0.6823 | MLP Loss=1.6394, Acc=0.5978\n",
      "[Studygroup][1964] CNN Loss=0.9015, Acc=0.6745 | MLP Loss=1.6651, Acc=0.5961\n",
      "[Studygroup][1965] CNN Loss=0.8699, Acc=0.6769 | MLP Loss=1.5225, Acc=0.6020\n",
      "[Studygroup][1966] CNN Loss=0.8900, Acc=0.6737 | MLP Loss=1.5631, Acc=0.6023\n",
      "[Studygroup][1967] CNN Loss=0.7776, Acc=0.6799 | MLP Loss=1.6194, Acc=0.5932\n",
      "[Studygroup][1968] CNN Loss=0.8521, Acc=0.6777 | MLP Loss=1.6155, Acc=0.5886\n",
      "[Studygroup][1969] CNN Loss=0.7738, Acc=0.6870 | MLP Loss=1.7434, Acc=0.5801\n",
      "[Studygroup][1970] CNN Loss=0.9160, Acc=0.6788 | MLP Loss=1.6245, Acc=0.5889\n",
      "[Studygroup][1971] CNN Loss=0.9332, Acc=0.6763 | MLP Loss=1.5729, Acc=0.6001\n",
      "[Studygroup][1972] CNN Loss=0.8850, Acc=0.6667 | MLP Loss=1.5604, Acc=0.5925\n",
      "[Studygroup][1973] CNN Loss=0.9492, Acc=0.6774 | MLP Loss=1.6087, Acc=0.5805\n",
      "[Studygroup][1974] CNN Loss=0.8487, Acc=0.6653 | MLP Loss=1.5942, Acc=0.5868\n",
      "[Studygroup][1975] CNN Loss=0.9100, Acc=0.6828 | MLP Loss=1.5909, Acc=0.6041\n",
      "[Studygroup][1976] CNN Loss=0.9217, Acc=0.6728 | MLP Loss=1.6210, Acc=0.5823\n",
      "[Studygroup][1977] CNN Loss=0.8185, Acc=0.6746 | MLP Loss=1.7581, Acc=0.5990\n",
      "[Studygroup][1978] CNN Loss=0.9001, Acc=0.6798 | MLP Loss=1.6538, Acc=0.5968\n",
      "[Studygroup][1979] CNN Loss=0.8981, Acc=0.6782 | MLP Loss=1.5426, Acc=0.5991\n",
      "[Studygroup][1980] CNN Loss=0.8900, Acc=0.6758 | MLP Loss=1.6613, Acc=0.5999\n",
      "[Studygroup][1981] CNN Loss=0.9095, Acc=0.6746 | MLP Loss=1.6441, Acc=0.5916\n",
      "[Studygroup][1982] CNN Loss=0.9274, Acc=0.6773 | MLP Loss=1.5768, Acc=0.5949\n",
      "[Studygroup][1983] CNN Loss=0.9008, Acc=0.6838 | MLP Loss=1.6924, Acc=0.5901\n",
      "[Studygroup][1984] CNN Loss=0.9077, Acc=0.6724 | MLP Loss=1.5807, Acc=0.5931\n",
      "[Studygroup][1985] CNN Loss=0.8438, Acc=0.6805 | MLP Loss=1.5615, Acc=0.5930\n",
      "[Studygroup][1986] CNN Loss=0.8359, Acc=0.6774 | MLP Loss=1.5595, Acc=0.5836\n",
      "[Studygroup][1987] CNN Loss=0.8708, Acc=0.6749 | MLP Loss=1.6743, Acc=0.5799\n",
      "[Studygroup][1988] CNN Loss=0.8315, Acc=0.6725 | MLP Loss=1.5491, Acc=0.5878\n",
      "[Studygroup][1989] CNN Loss=0.9115, Acc=0.6788 | MLP Loss=1.5847, Acc=0.5893\n",
      "[Studygroup][1990] CNN Loss=0.8822, Acc=0.6800 | MLP Loss=1.5447, Acc=0.5935\n",
      "[Studygroup][1991] CNN Loss=0.7548, Acc=0.6869 | MLP Loss=1.5665, Acc=0.5960\n",
      "[Studygroup][1992] CNN Loss=0.8896, Acc=0.6815 | MLP Loss=1.6667, Acc=0.5969\n",
      "[Studygroup][1993] CNN Loss=0.7558, Acc=0.6821 | MLP Loss=1.6579, Acc=0.5862\n",
      "[Studygroup][1994] CNN Loss=0.8297, Acc=0.6807 | MLP Loss=1.6996, Acc=0.5925\n",
      "[Studygroup][1995] CNN Loss=0.8074, Acc=0.6702 | MLP Loss=1.5914, Acc=0.5880\n",
      "[Studygroup][1996] CNN Loss=0.9173, Acc=0.6698 | MLP Loss=1.6084, Acc=0.6010\n",
      "[Studygroup][1997] CNN Loss=1.0161, Acc=0.6706 | MLP Loss=1.6433, Acc=0.5956\n",
      "[Studygroup][1998] CNN Loss=0.8744, Acc=0.6743 | MLP Loss=1.6241, Acc=0.5808\n",
      "[Studygroup][1999] CNN Loss=0.8699, Acc=0.6777 | MLP Loss=1.6950, Acc=0.6007\n"
     ]
    }
   ],
   "source": [
    "cnn_id1 = CNN_CIFAR().to(device)\n",
    "cnn_id1.load_state_dict(cnn_init_state)\n",
    "cnn_id2 = CNN_CIFAR().to(device)\n",
    "cnn_id2.load_state_dict(cnn_init_state)\n",
    "\n",
    "opt_cnn_id1 = torch.optim.Adam(cnn_id1.parameters(), lr=1e-3)\n",
    "opt_cnn_id2 = torch.optim.Adam(mlp_id2.parameters(), lr=1e-3)\n",
    "\n",
    "train_studygroup(\n",
    "    mlp_id1,\n",
    "    mlp_id2,\n",
    "    opt_mlp_id1,\n",
    "    opt_mlp_id2,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    device,\n",
    "    epochs,\n",
    "    logs[\"individual_mlp1\"],\n",
    "    logs[\"individual_mlp2\"],\n",
    "    T=2.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f2994-9524-4b3f-ac2b-a326601a8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(logs[\"baseline_cnn\"][\"test_acc\"], label=\"Baseline CNN\")\n",
    "plt.plot(logs[\"individual_cnn1\"][\"test_acc\"], label=\"Studygroup CNN1\")\n",
    "plt.plot(logs[\"individual_cnn2\"][\"test_acc\"], label=\"Studygroup CNN2\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"CIFAR10 Test Accuracy Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98c371-8e1b-4bc2-994a-74500ed9dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(logs[\"baseline_cnn\"][\"test_acc\"]))\n",
    "print(max(logs[\"individual_cnn1\"][\"test_acc\"]))\n",
    "print(max(logs[\"individual_cnn2\"][\"test_acc\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
